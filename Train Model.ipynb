{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from nn_util import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import load_model\n",
    "from keras.losses import *\n",
    "import scipy.io.wavfile as sciwav\n",
    "import multiprocessing\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)\n",
    "\n",
    "# increase recursion limit for adaptive VQ\n",
    "import sys\n",
    "sys.setrecursionlimit(40000)\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# control amount of GPU memory used\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from pesq import *\n",
    "from consts import *\n",
    "from nn_blocks import *\n",
    "from perceptual_loss import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101750, 512, 1)\n",
      "3.81413e-06\n",
      "0.103483\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE, 1))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = (WINDOW_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# softmax hardness variable\n",
    "tau = K.variable(0.0001, name = \"hardness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOWNSAMPLE_FACTOR = 2\n",
    "CHANNEL_SIZE = WINDOW_SIZE / DOWNSAMPLE_FACTOR\n",
    "    \n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 48\n",
    "    FILT_SIZE = 9\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = enc_input\n",
    "    \n",
    "    enc = Reshape(dim, input_shape = dim)(enc)  \n",
    "    \n",
    "    enc = channel_change_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 4)(enc)\n",
    "    enc = channel_change_block(1, FILT_SIZE)(enc)\n",
    "    \n",
    "    # quantization\n",
    "    enc = Reshape((CHANNEL_SIZE,))(enc)\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc)\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (CHANNEL_SIZE, NBINS))\n",
    "    dec = dec_input\n",
    "    \n",
    "    # dequantization\n",
    "    dec = SoftmaxDequantization()(dec)    \n",
    "    dec = Reshape((CHANNEL_SIZE, 1))(dec)\n",
    "    \n",
    "    dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 4)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = channel_change_block(1, FILT_SIZE)(dec)\n",
    "\n",
    "    dec = Model(inputs = dec_input, outputs = dec)\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can compute the entropy of a batch directly\n",
    "def code_entropy(placeholder, code):\n",
    "    all_onehots = K.reshape(code, (-1, NBINS))\n",
    "    onehot_hist = K.sum(all_onehots, axis = 0)\n",
    "    onehot_hist /= K.sum(onehot_hist)\n",
    "\n",
    "    entropy = -K.sum(onehot_hist * K.log(onehot_hist + K.epsilon()) / K.log(2.0))\n",
    "    loss = tau * entropy\n",
    "    return K.switch(QUANTIZATION_ON, loss, K.zeros_like(loss))\n",
    "\n",
    "def code_sparsity(placeholder, code):\n",
    "    sparsity = K.mean(K.sum(K.sqrt(code + K.epsilon()), axis = -1), axis = -1) - 1.0\n",
    "    return K.switch(QUANTIZATION_ON, sparsity, K.zeros_like(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'code_entropy' : code_entropy,\n",
    "                  'code_sparsity' : code_sparsity,\n",
    "                  'rmse' : rmse,\n",
    "                  'ChannelResize1D' : ChannelResize1D,\n",
    "                  'LinearUpSampling1D' : LinearUpSampling1D,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization,\n",
    "                  'AdaptiveQuantization' : AdaptiveQuantization,\n",
    "                  'AdaptiveDequantization' : AdaptiveDequantization,\n",
    "                  'MEL_FILTERBANK' : MEL_FILTERBANK,\n",
    "                  'DFT_REAL' : DFT_REAL,\n",
    "                  'DFT_IMAG' : DFT_IMAG,\n",
    "                  'MFCC_DCT' : MFCC_DCT,\n",
    "                  'keras_dft_mag' : keras_dft_mag,\n",
    "                  'keras_dct' : keras_dct,\n",
    "                  'perceptual_transform' : perceptual_transform,\n",
    "                  'perceptual_distance' : perceptual_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = input_dim)\n",
    "\n",
    "encoder, decoder = autoencoder_structure(input_dim)\n",
    "ac_reconstructed = decoder(encoder(ac_input))\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "loss_weights = [30.0, 1.0, 5.0, 1.0]\n",
    "loss_functions = [rmse, perceptual_distance, code_sparsity, code_entropy]\n",
    "n_recons = 2\n",
    "n_code = 2\n",
    "assert(n_recons + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1511: UserWarning: The list of outputs passed to the model is redundant. All outputs should only appear once. Found: [<tf.Tensor 'model_2_1/add_12/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'model_2_1/add_12/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'model_1_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 32) dtype=float32>, <tf.Tensor 'model_1_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 32) dtype=float32>]\n",
      "  ' Found: ' + str(self.outputs))\n"
     ]
    }
   ],
   "source": [
    "# model specification\n",
    "model_input = Input(shape = input_dim)\n",
    "model_embedding = encoder(model_input)\n",
    "model_reconstructed = decoder(model_embedding)\n",
    "\n",
    "model = Model(inputs = [model_input], outputs = [model_reconstructed] * n_recons + \\\n",
    "                                            [model_embedding] * n_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 256, 32)           188494.0  \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 512, 1)            271597    \n",
      "=================================================================\n",
      "Total params: 460,091\n",
      "Trainable params: 460,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         24252.0\n",
      "Avg err:     76.797\n",
      "PESQ:        1.82472705841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24251.988, 76.797035, 1.8247270584106445]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get untrained baseline for model\n",
    "test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_uninit\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves current model\n",
    "def save_model(prefix = 'best'):\n",
    "    os.system('rm ./' + prefix + '_model.h5')\n",
    "    os.system('rm ./' + prefix + '_auto.h5')\n",
    "    #os.system('rm ./' + prefix + '_quant_bins.npy')\n",
    "    \n",
    "    model.save('./' + prefix + '_model.h5')\n",
    "    autoencoder.save('./' + prefix + '_auto.h5')\n",
    "    #np.save('./' + prefix + '_quant_bins.npy', K.eval(QUANT_BINS))\n",
    "    \n",
    "    f = h5py.File('./' + prefix + '_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    def set_evaluation(windows, wparams, eval_idxs):\n",
    "        before_after_pairs = np.array([run_model_on_windows(windows[i],\n",
    "                                                    wparams[i],\n",
    "                                                    autoencoder,\n",
    "                                                    argmax = True)\n",
    "                                       for i in eval_idxs])\n",
    "        \n",
    "        NUM_THREADS = 8\n",
    "        list_range = np.arange(0, len(eval_idxs))\n",
    "        slices = [list_range[i:None:NUM_THREADS]\n",
    "                  for i in xrange(0, NUM_THREADS)]\n",
    "        \n",
    "        def thread_func(pairs, q):\n",
    "            for p in pairs:\n",
    "                q.put(evaluation_metrics(p[0], p[1]))\n",
    "                \n",
    "        q = multiprocessing.Queue()\n",
    "        threads = [multiprocessing.Process(target = thread_func,\n",
    "                                           args = (before_after_pairs[slices[i]], q))\n",
    "                   for i in xrange(0, NUM_THREADS)]\n",
    "        [t.start() for t in threads]\n",
    "        [t.join() for t in threads]\n",
    "        \n",
    "        return np.array([q.get() for i in list_range])\n",
    "    \n",
    "    train_eval_idxs = random.sample(range(0, len(train_windows)), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_windows)), VAL_EVALUATE)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    \n",
    "    # train set evaluation\n",
    "    train_metrics = set_evaluation(train_windows, train_wparams,\n",
    "                                   train_eval_idxs)\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    \n",
    "    # validation set evaluation\n",
    "    val_metrics = set_evaluation(val_windows, val_wparams,\n",
    "                                 val_eval_idxs)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 1.875\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 200\n",
    "EPOCHS_BEFORE_QUANT_ON = 5\n",
    "EPOCHS_BEFORE_TAU = 20\n",
    "\n",
    "ORIG_BITRATE = 256.00\n",
    "TARGET_BITRATE = 16.00\n",
    "PRE_ENTROPY_RATE = ORIG_BITRATE / DOWNSAMPLE_FACTOR\n",
    "\n",
    "TARGET_ENTROPY = (TARGET_BITRATE / PRE_ENTROPY_RATE * 16.0)\n",
    "TARGET_ENTROPY *= (STEP_SIZE / float(WINDOW_SIZE))\n",
    "TARGET_ENTROPY_FUZZ = 0.1\n",
    "\n",
    "TAU_CHANGE_RATE = 0.0125\n",
    "MIN_TAU = 0.0125\n",
    "\n",
    "NUM_QUANT_VECS = 5000\n",
    "\n",
    "STARTING_LR = 0.0005\n",
    "\n",
    "print \"Target entropy:\", TARGET_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_val_pesq = 0.0\n",
    "K.set_value(tau, 0.0)\n",
    "T_i = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    14080:  [1.178794 0.007320 0.959190 0.000000 0.000000] [1.178794 0.219604 0.959190 0.000000 0.000000] 0.0 0.000499999409527                                                                                        "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "lead = \"    \"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print \"Epoch \" + str(epoch) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    num_batches = len(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        # cosine annealing for model's learning rate\n",
    "        train_pct = T_i / float(NUM_EPOCHS)\n",
    "        opt_lr = 0.5 * STARTING_LR * (1 + math.cos(3.14159 * train_pct))\n",
    "        T_i += (1.0 / num_batches)\n",
    "        K.set_value(model.optimizer.lr, opt_lr)\n",
    "        \n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "               \n",
    "        # train autoencoder\n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.zeros((nbatch, WINDOW_SIZE, NBINS))] * n_code       \n",
    "\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau), opt_lr,\n",
    "        \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # estimate code entropy from random samples (if quantization is on)\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        NUM = 500\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        code = encoder.predict(X_train[rows, :], verbose = 0)\n",
    "        probs = np.reshape(code, (code.shape[0] * code.shape[1], NBINS))\n",
    "        hist = np.sum(probs, axis = 0)\n",
    "        hist /= np.sum(hist)\n",
    "\n",
    "        entropy = 0\n",
    "        for i in hist:\n",
    "            if (i < 1e-4): continue\n",
    "            entropy += i * math.log(i, 2)\n",
    "        entropy = -entropy\n",
    "\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Code entropy:\", entropy\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # handle updating entropy weight (tau)\n",
    "        # ---------------------------------------------------------\n",
    "        if (epoch >= EPOCHS_BEFORE_TAU):\n",
    "            old_tau = K.get_value(tau)\n",
    "\n",
    "            if (entropy < TARGET_ENTROPY - TARGET_ENTROPY_FUZZ):\n",
    "                new_tau = old_tau - TAU_CHANGE_RATE\n",
    "                if (new_tau <= MIN_TAU):\n",
    "                    new_tau = MIN_TAU\n",
    "\n",
    "                K.set_value(tau, new_tau)\n",
    "                print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "            elif (entropy > TARGET_ENTROPY + TARGET_ENTROPY_FUZZ):\n",
    "                new_tau = old_tau + TAU_CHANGE_RATE\n",
    "\n",
    "                K.set_value(tau, new_tau)\n",
    "                print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "            else:\n",
    "                print lead + \"Tau stays at\", old_tau\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    \n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                              autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SA1:         \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SA1 (arg):   \", metrics\n",
    "    \n",
    "    metrics_tst = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SX383:       \", metrics_tst\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SX383 (arg): \", metrics\n",
    "    \n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        val_pesq = evaluate_training(autoencoder, lead)\n",
    "        if (val_pesq > best_val_pesq and entropy <= TARGET_ENTROPY):\n",
    "            print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "\n",
    "            print lead + \"Saving model...\"\n",
    "            save_model()\n",
    "            best_val_pesq = val_pesq\n",
    "            patience_epoch = epoch\n",
    "        else:\n",
    "            print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # turn quantization on after a certain # of epochs\n",
    "    # ---------------------------------------------------------\n",
    "    if (epoch == EPOCHS_BEFORE_QUANT_ON):\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Turning quantization on!\"\n",
    "        \n",
    "        random_windows = []\n",
    "        for i in xrange(0, NUM_QUANT_VECS):\n",
    "            w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "            random_windows.append(train_processed[w_idx])\n",
    "        \n",
    "        random_windows = np.array(random_windows)\n",
    "        print lead + \"    Selecting random code vectors for clustering...\"\n",
    "        encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "        encoded_windows = encoded_windows[:, :, :1]            \n",
    "        encoded_windows = np.reshape(encoded_windows, (-1, 1))\n",
    "        \n",
    "        print lead + \"    K means clustering for bins initialization...\"\n",
    "        km = MiniBatchKMeans(n_clusters = NBINS).fit(encoded_windows)\n",
    "        K.set_value(QUANT_BINS, km.cluster_centers_.flatten())\n",
    "        K.set_value(QUANTIZATION_ON, True)\n",
    "        \n",
    "        cluster_score = np.sqrt(np.median(np.min(km.transform(encoded_windows), axis = 1)))\n",
    "        print lead + \"    Done. Cluster score:\", cluster_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = load_model('best_model.h5', KERAS_LOAD_MAP)\n",
    "    autoencoder = load_model('best_auto.h5', KERAS_LOAD_MAP)\n",
    "    encoder = autoencoder.layers[1]\n",
    "    decoder = autoencoder.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in xrange(0, len(enc)):\n",
    "#    print i, enc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder)\n",
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder)\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder)\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder, argmax = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embed = encoder.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.reshape(all_embed, (all_embed.shape[0] * all_embed.shape[1], NBINS))\n",
    "hist = np.sum(probs, axis = 0)\n",
    "hist /= np.sum(hist)\n",
    "\n",
    "sample_hist_bins = np.linspace(0, NBINS - 1, NBINS)\n",
    "plt.bar(sample_hist_bins, hist, align = 'center', width = 1)\n",
    "plt.show()\n",
    "\n",
    "entropy = 0\n",
    "for i in hist:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print \"Entropy of distribution:\", entropy\n",
    "\n",
    "print hist\n",
    "print \"Bins:\"\n",
    "print K.eval(QUANT_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(CHANGE_SCALES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(np.array(K.eval(QUANT_BINS)).flatten()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocess_waveform(data)\n",
    "windows = extract_windows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed = np.reshape(windows, (windows.shape[0], WINDOW_SIZE, 1))\n",
    "embed = encoder.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = decoder.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(enc[-1].SOFTMAX_TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pct = np.max(embed[25], axis = -1)\n",
    "print max_pct\n",
    "print np.argmax(embed[25], axis = -1)\n",
    "print np.sum(max_pct > 0.98) / float(max_pct.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_max = np.max(embed, axis = -1)\n",
    "print np.mean(embed_max)\n",
    "print np.sum(embed_max > 0.98) / float(embed_max.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 25\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "print \"Original\"\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "print \"Reconstruction\"\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "print \"Code (argmax)\"\n",
    "argmax_code_vec = embed[idx]\n",
    "embed_sum = np.sum(embed[idx], axis = -1)\n",
    "argmax_code_vec = np.eye(NBINS)[np.argmax(argmax_code_vec, axis = -1)]\n",
    "argmax_code_vec[embed_sum < 0.95] = np.zeros(NBINS)\n",
    "argmax_code_vec = unquantize_vec(argmax_code_vec)\n",
    "plt.plot(argmax_code_vec)\n",
    "plt.show()\n",
    "\n",
    "print \"Code (non-argmax)\"\n",
    "na_code_vec = embed[idx]\n",
    "na_code_vec = unquantize_vec(na_code_vec)\n",
    "plt.plot(na_code_vec)\n",
    "plt.show()\n",
    "\n",
    "print \"Difference\"\n",
    "plt.plot(abs(argmax_code_vec - na_code_vec))\n",
    "plt.show()\n",
    "    \n",
    "print \"Error\"\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
