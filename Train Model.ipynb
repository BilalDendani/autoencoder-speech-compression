{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from nn_util import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import load_model\n",
    "from keras.losses import *\n",
    "import scipy.io.wavfile as sciwav\n",
    "import multiprocessing\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from mem_top import mem_top\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)\n",
    "\n",
    "# increase recursion limit for adaptive VQ\n",
    "#import sys\n",
    "#sys.setrecursionlimit(40000)\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# control amount of GPU memory used\n",
    "#import tensorflow as tf\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth=True\n",
    "#set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from pesq import *\n",
    "from consts import *\n",
    "from nn_blocks import *\n",
    "from perceptual_loss import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101814, 512, 1)\n",
      "6.41179e-06\n",
      "0.103588\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE, 1))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLE_FACTOR = 2\n",
    "CHANNEL_SIZE = WINDOW_SIZE / DOWNSAMPLE_FACTOR\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure():   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 32\n",
    "    FILT_SIZE = 9\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "    enc = enc_input\n",
    "    \n",
    "    enc = channel_change_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 4)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 8)(enc)\n",
    "    enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 4)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 8)(enc)\n",
    "    enc = channel_change_block(QUANT_CHANS, FILT_SIZE)(enc)\n",
    "    \n",
    "    # quantization\n",
    "    enc = Reshape((CHANNEL_SIZE, QUANT_CHANS))(enc)\n",
    "    pre_quant = Model(inputs = enc_input, outputs = enc)\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc, name = 'encoder')\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (CHANNEL_SIZE, QUANT_CHANS, NBINS))\n",
    "    dec = dec_input\n",
    "    \n",
    "    # dequantization\n",
    "    dec = SoftmaxDequantization()(dec)\n",
    "    post_dequant = Model(inputs = dec_input, outputs = dec)\n",
    "    dec = Reshape((CHANNEL_SIZE, QUANT_CHANS))(dec)\n",
    "    \n",
    "    dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 8)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 4)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 8)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 4)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = channel_change_block(1, FILT_SIZE)(dec)\n",
    "\n",
    "    dec = Model(inputs = dec_input, outputs = dec, name = 'decoder')\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec, pre_quant, post_dequant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to determine whether an audio window is \"real\" or \"fake\"\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure():   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 32\n",
    "    FILT_SIZE = 9\n",
    "    DENSE_SIZE = 16\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # model\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dsc_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "    dsc = dsc_input\n",
    "    \n",
    "    dsc = channel_change_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    dsc = downsample_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    dsc = downsample_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    dsc = downsample_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE, 1)(dsc)\n",
    "    \n",
    "    dsc = Flatten()(dsc)\n",
    "    \n",
    "    dsc = Dense(DENSE_SIZE, kernel_initializer = W_INIT)(dsc)\n",
    "    dsc = activation()(dsc)\n",
    "    \n",
    "    dsc = Dense(1, kernel_initializer = W_INIT)(dsc)\n",
    "    dsc = Activation('linear')(dsc)\n",
    "    \n",
    "    dsc = Model(inputs = dsc_input, outputs = dsc, name = 'discriminator')\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'code_entropy' : code_entropy,\n",
    "                  'code_sparsity' : code_sparsity,\n",
    "                  'rmse' : rmse,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization,\n",
    "                  'DFT_REAL' : DFT_REAL,\n",
    "                  'DFT_IMAG' : DFT_IMAG,\n",
    "                  'MEL_FILTERBANKS' : MEL_FILTERBANKS,\n",
    "                  'keras_dft_mag' : keras_dft_mag,\n",
    "                  'keras_dct' : keras_dct,\n",
    "                  'perceptual_transform' : perceptual_transform,\n",
    "                  'perceptual_distance' : perceptual_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "\n",
    "encoder, decoder, pre_quant, post_dequant = autoencoder_structure()\n",
    "ac_reconstructed = decoder(encoder(ac_input))\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct discriminator: regular\n",
    "dsc_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "dsc_struct = discriminator_structure()\n",
    "dsc_label = dsc_struct(dsc_input)\n",
    "\n",
    "discriminator = Model(inputs = [dsc_input], outputs = [dsc_label])\n",
    "discriminator.compile(loss = [rmse], optimizer = Adam(lr = 0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "loss_weights = [30.0, 5.0, 0.5, 10.0, 1.0]\n",
    "loss_functions = [rmse, perceptual_distance, rmse, code_sparsity, code_entropy]\n",
    "n_recons = 2\n",
    "n_discrim = 1\n",
    "n_code = 2\n",
    "assert(n_recons + n_discrim + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1511: UserWarning: The list of outputs passed to the model is redundant. All outputs should only appear once. Found: [<tf.Tensor 'decoder_1/add_22/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'decoder_1/add_22/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'discriminator_1/dense_2/BiasAdd:0' shape=(?, 1) dtype=float32>, <tf.Tensor 'encoder_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 1, 32) dtype=float32>, <tf.Tensor 'encoder_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 1, 32) dtype=float32>]\n",
      "  ' Found: ' + str(self.outputs))\n"
     ]
    }
   ],
   "source": [
    "# model specification\n",
    "make_trainable(discriminator, False)\n",
    "make_trainable(autoencoder, True)\n",
    "\n",
    "model_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "model_embedding = encoder(model_input)\n",
    "model_pre_quant = pre_quant(model_input)\n",
    "model_reconstructed = decoder(model_embedding)\n",
    "model_post_dequant = post_dequant(model_embedding)\n",
    "model_dsc_label = dsc_struct(model_reconstructed)\n",
    "\n",
    "model = Model(inputs = [model_input], outputs = [model_reconstructed] * n_recons + \\\n",
    "                                            [model_dsc_label] * n_discrim + \\\n",
    "                                            [model_embedding] * n_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 256, 1, 32)        186927    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 512, 1)            233167    \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 274786    \n",
      "=================================================================\n",
      "Total params: 694,880\n",
      "Trainable params: 420,094\n",
      "Non-trainable params: 274,786\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 274786    \n",
      "=================================================================\n",
      "Total params: 274,786\n",
      "Trainable params: 0\n",
      "Non-trainable params: 274,786\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam())\n",
    "\n",
    "model.summary()\n",
    "if (n_discrim > 0):\n",
    "    discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         155041.0\n",
      "Avg err:     210.465\n",
      "PESQ:        1.03144824505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[155041.05, 210.4651, 1.031448245048523]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get untrained baseline for model\n",
    "test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_uninit\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves current model\n",
    "def save_model(prefix = 'best'):\n",
    "    os.system('rm ./' + prefix + '_model.h5')\n",
    "    os.system('rm ./' + prefix + '_auto.h5')\n",
    "    #os.system('rm ./' + prefix + '_quant_bins.npy')\n",
    "    \n",
    "    model.save('./' + prefix + '_model.h5')\n",
    "    autoencoder.save('./' + prefix + '_auto.h5')\n",
    "    #np.save('./' + prefix + '_quant_bins.npy', K.eval(QUANT_BINS))\n",
    "    \n",
    "    f = h5py.File('./' + prefix + '_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    def set_evaluation(windows, wparams, eval_idxs):\n",
    "        before_after_pairs = np.array([run_model_on_windows(windows[i],\n",
    "                                                    wparams[i],\n",
    "                                                    autoencoder,\n",
    "                                                    argmax = True)\n",
    "                                       for i in eval_idxs])\n",
    "        \n",
    "        NUM_THREADS = 8\n",
    "        list_range = np.arange(0, len(eval_idxs))\n",
    "        slices = [list_range[i:None:NUM_THREADS]\n",
    "                  for i in xrange(0, NUM_THREADS)]\n",
    "        \n",
    "        def thread_func(pairs, q):\n",
    "            for p in pairs:\n",
    "                q.put(evaluation_metrics(p[0], p[1]))\n",
    "                \n",
    "        q = multiprocessing.Queue()\n",
    "        threads = [multiprocessing.Process(target = thread_func,\n",
    "                                           args = (before_after_pairs[slices[i]], q))\n",
    "                   for i in xrange(0, NUM_THREADS)]\n",
    "        [t.start() for t in threads]\n",
    "        [t.join() for t in threads]\n",
    "        results = np.array([q.get() for i in list_range])\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    train_eval_idxs = random.sample(range(0, len(train_windows)), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_windows)), VAL_EVALUATE)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    \n",
    "    # train set evaluation\n",
    "    train_metrics = set_evaluation(train_windows, train_wparams,\n",
    "                                   train_eval_idxs)\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    \n",
    "    # validation set evaluation\n",
    "    val_metrics = set_evaluation(val_windows, val_wparams,\n",
    "                                 val_eval_idxs)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 2.34375\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 300\n",
    "EPOCHS_BEFORE_QUANT_ON = 5\n",
    "#EPOCHS_BEFORE_TAU = 20\n",
    "\n",
    "ORIG_BITRATE = 256.00\n",
    "TARGET_BITRATE = 20.00\n",
    "PRE_ENTROPY_RATE = ORIG_BITRATE / DOWNSAMPLE_FACTOR\n",
    "\n",
    "TARGET_ENTROPY = (TARGET_BITRATE / PRE_ENTROPY_RATE * 16.0)\n",
    "TARGET_ENTROPY *= (STEP_SIZE / float(WINDOW_SIZE))\n",
    "TARGET_ENTROPY_FUZZ = 0.1\n",
    "\n",
    "TAU_CHANGE_RATE = 0.025\n",
    "INITIAL_TAU = 0.5\n",
    "MIN_TAU = 0.0\n",
    "\n",
    "NUM_QUANT_VECS = 5000\n",
    "\n",
    "STARTING_LR = 0.00025\n",
    "ENDING_LR = 0.0001\n",
    "\n",
    "print \"Target entropy:\", TARGET_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_val_pesq = 0.0\n",
    "K.set_value(tau, 0.0)\n",
    "T_i = 0.0\n",
    "K.set_value(QUANTIZATION_ON, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    101120: 0.315088  [3.451242 0.007382 0.564559 0.813969 0.000000 0.000000] [3.451242 0.221462 2.822796 0.406984 0.000000 0.000000] 0.0 0.0002499959494694                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "    Total time for epoch: 163.967998981s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 84.0% d_acc\n",
      "    Total time for evaluation: 0.612809896469s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3229.0039, 30.037447, 3.6834700107574463]\n",
      "    SX383:        [4169.7104, 24.463125, 3.2841978073120117]\n",
      "    Total time for evaluation: 0.5134100914s\n",
      "    Total memory usage: 3657289728\n",
      "Epoch 2:\n",
      "    101120: 0.245237  [2.860933 0.008806 0.430934 0.884141 0.000000 0.000000] [2.860933 0.264191 2.154671 0.442070 0.000000 0.000000] 0.0 0.000249983675036                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 154.038532972s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 84.75% d_acc\n",
      "    Total time for evaluation: 0.092511177063s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3096.2722, 28.204805, 4.097971439361572]\n",
      "    SX383:        [3957.5601, 22.680199, 3.6664302349090576]\n",
      "    Total time for evaluation: 0.170351982117s\n",
      "    Total memory usage: 3657187328\n",
      "Epoch 3:\n",
      "    101120: 0.475042  [2.313244 0.008031 0.383569 0.308944 0.000000 0.000000] [2.313244 0.240925 1.917847 0.154472 0.000000 0.000000] 0.0 0.000249963177811                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 153.974839926s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 68.25% d_acc\n",
      "    Total time for evaluation: 0.0944797992706s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2522.3655, 24.997671, 4.1452107429504395]\n",
      "    SX383:        [3540.1777, 20.06039, 3.84775447845459]\n",
      "    Total time for evaluation: 0.176065921783s\n",
      "    Total memory usage: 3657158656\n",
      "Epoch 4:\n",
      "    101120: 0.321031  [2.388304 0.009256 0.365302 0.568259 0.000000 0.000000] [2.388304 0.277666 1.826509 0.284129 0.000000 0.000000] 0.0 0.000249934460042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "    Total time for epoch: 154.076647043s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 87.75% d_acc\n",
      "    Total time for evaluation: 0.0920209884644s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2584.6062, 25.777954, 4.206634044647217]\n",
      "    SX383:        [3566.2532, 20.684278, 4.0113019943237305]\n",
      "    Total time for evaluation: 0.171370029449s\n",
      "    Total memory usage: 3657543680\n",
      "Epoch 5:\n",
      "    101120: 0.258239  [2.425739 0.006767 0.353375 0.911705 0.000000 0.000000] [2.425739 0.203010 1.766877 0.455853 0.000000 0.000000] 0.0 0.00024989752488                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 154.110374928s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.0% d_acc\n",
      "    Total time for evaluation: 0.0924551486969s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2447.3081, 25.204443, 4.223127841949463]\n",
      "    SX383:        [3574.2507, 20.667328, 4.106093406677246]\n",
      "    Total time for evaluation: 0.168094873428s\n",
      "    Total memory usage: 3657576448\n",
      "    ----------------\n",
      "    Turning quantization on!\n",
      "        Selecting random code vectors for analysis...\n",
      "        K means clustering for bins initialization...\n",
      "        Done. Cluster scores: [0.059650537]\n",
      "Epoch 6:\n",
      "    101120: 0.360138  [5.305182 0.009861 0.569987 0.646787 0.065980 1.176209] [5.305182 0.295842 2.849936 0.323393 0.659800 1.176209] 0.5 0.000249852376374                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "    Total time for epoch: 154.024761915s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 63.5% d_acc\n",
      "    Total time for evaluation: 0.0930089950562s\n",
      "    ----------------\n",
      "    Code entropy: 2.55175\n",
      "    Updated tau from 0.5 to 0.525\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [6238.1309, 50.573391, 2.9378201961517334]\n",
      "    SA1 (arg):    [6733.7485, 53.063396, 2.7283053398132324]\n",
      "    SX383:        [5252.4048, 37.816158, 3.1244797706604004]\n",
      "    SX383 (arg):  [5441.6641, 39.318806, 2.9367589950561523]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [17209.168110 66.254565 3.125839]\n",
      "        Train: (max)  [169410.515625 169.304367 3.703555]\n",
      "        Train: (min)  [1601.514404 21.998684 2.178269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Val:   (mean) [13854.106834 59.680924 3.292110]\n",
      "        Val:   (max)  [97580.273438 137.370331 3.757063]\n",
      "        Val:   (min)  [503.798248 13.055804 2.728775]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 35.139893055s\n",
      "    Total memory usage: 4625276928\n",
      "Epoch 7:\n",
      "    101120: 0.289329  [5.096374 0.011900 0.514065 0.726230 0.056002 1.245918] [5.096374 0.357000 2.570326 0.363115 0.560016 1.245918] 0.525 0.000249799019475                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 153.902817011s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 75.0% d_acc\n",
      "    Total time for evaluation: 0.0919320583344s\n",
      "    ----------------\n",
      "    Code entropy: 2.35891\n",
      "    Tau stays at 0.525\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5558.2754, 46.777523, 2.9145352840423584]\n",
      "    SA1 (arg):    [6056.5376, 49.31485, 2.7582156658172607]\n",
      "    SX383:        [4826.3384, 35.029766, 3.002610445022583]\n",
      "    SX383 (arg):  [5050.2891, 36.794243, 2.8325278759002686]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [12663.033801 56.982783 3.245645]\n",
      "        Train: (max)  [65110.457031 129.908051 4.058781]\n",
      "        Train: (min)  [1324.712524 20.018587 2.281833]\n",
      "        Val:   (mean) [12970.129044 57.105168 3.429209]\n",
      "        Val:   (max)  [98104.507812 129.939377 3.971812]\n",
      "        Val:   (min)  [478.543762 12.653719 2.263252]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 13.7861270905s\n",
      "    Total memory usage: 4625690624\n",
      "Epoch 8:\n",
      "    101120: 0.325977  [5.199127 0.013443 0.541425 0.834774 0.048347 1.187845] [5.199127 0.403304 2.707125 0.417387 0.483467 1.187845] 0.525 0.000249737460034                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "    Total time for epoch: 154.846078873s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 80.25% d_acc\n",
      "    Total time for evaluation: 0.0945529937744s\n",
      "    ----------------\n",
      "    Code entropy: 2.19384\n",
      "    Updated tau from 0.525 to 0.499999976158\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5322.5391, 46.730904, 2.818737506866455]\n",
      "    SA1 (arg):    [5719.6016, 48.75304, 2.6891331672668457]\n",
      "    SX383:        [4775.3608, 34.882908, 2.9321682453155518]\n",
      "    SX383 (arg):  [4952.9854, 36.287712, 2.787693500518799]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10742.858346 54.253534 3.235654]\n",
      "        Train: (max)  [52816.046875 127.798088 3.995846]\n",
      "        Train: (min)  [1377.920288 20.994375 2.405110]\n",
      "        Val:   (mean) [13232.992537 57.305095 3.377881]\n",
      "        Val:   (max)  [99789.515625 135.742386 3.849607]\n",
      "        Val:   (min)  [481.991272 12.718109 2.287394]\n",
      "    NEW best model! Validation mean-PESQ 3.37788082123\n",
      "    Saving model...\n",
      "    Total time for evaluation: 15.0792198181s\n",
      "    Total memory usage: 4628930560\n",
      "Epoch 9:\n",
      "    101120: 0.274224  [5.097716 0.012018 0.529667 0.878800 0.046963 1.179822] [5.097716 0.360528 2.648336 0.439400 0.469630 1.179822] 0.5 0.000249667704803                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 154.626909971s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 72.25% d_acc\n",
      "    Total time for evaluation: 0.0957210063934s\n",
      "    ----------------\n",
      "    Code entropy: 2.36424\n",
      "    Tau stays at 0.5\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5006.4741, 44.827785, 3.065488338470459]\n",
      "    SA1 (arg):    [5324.1626, 46.43763, 2.9269487857818604]\n",
      "    SX383:        [5211.1499, 34.851021, 2.956186294555664]\n",
      "    SX383 (arg):  [5351.0781, 36.027599, 2.8634512424468994]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [13670.016869 57.100559 3.294646]\n",
      "        Train: (max)  [72849.640625 132.922043 4.222893]\n",
      "        Train: (min)  [640.293579 15.972342 2.483906]\n",
      "        Val:   (mean) [12492.824161 54.619303 3.521497]\n",
      "        Val:   (max)  [106728.226562 128.096619 4.096643]\n",
      "        Val:   (min)  [437.867188 12.101352 2.898317]\n",
      "    Best validation mean-PESQ seen: 3.37788082123\n",
      "    Total time for evaluation: 12.5683841705s\n",
      "    Total memory usage: 4627841024\n",
      "Epoch 10:\n",
      "    101120: 0.269202  [4.874329 0.012113 0.497937 0.799028 0.044172 1.180020] [4.874329 0.363384 2.489687 0.399514 0.441724 1.180020] 0.5 0.00024958976143                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 154.644407988s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 85.0% d_acc\n",
      "    Total time for evaluation: 0.0945889949799s\n",
      "    ----------------\n",
      "    Code entropy: 2.44661\n",
      "    Updated tau from 0.5 to 0.524999970198\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4909.3086, 44.851078, 3.0293211936950684]\n",
      "    SA1 (arg):    [5193.8423, 46.446384, 2.9157795906066895]\n",
      "    SX383:        [4859.0664, 34.708549, 3.1404826641082764]\n",
      "    SX383 (arg):  [4990.1592, 35.750008, 3.0220272541046143]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [12644.139015 57.753962 3.343233]\n",
      "        Train: (max)  [69836.289062 129.118851 3.900835]\n",
      "        Train: (min)  [1207.226929 20.135548 2.241154]\n",
      "        Val:   (mean) [12545.957743 56.453890 3.526740]\n",
      "        Val:   (max)  [92149.812500 129.275314 4.020813]\n",
      "        Val:   (min)  [457.112244 12.794440 2.472975]\n",
      "    Best validation mean-PESQ seen: 3.37788082123\n",
      "    Total time for evaluation: 13.3053908348s\n",
      "    Total memory usage: 4626968576\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    101120: 0.179792  [5.043114 0.010587 0.536585 0.844229 0.042151 1.198964] [5.043114 0.317606 2.682924 0.422114 0.421507 1.198964] 0.525 0.000249503638463                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "    Total time for epoch: 153.953372002s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 82.5% d_acc\n",
      "    Total time for evaluation: 0.0932228565216s\n",
      "    ----------------\n",
      "    Code entropy: 2.31589\n",
      "    Tau stays at 0.525\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4989.4053, 45.51696, 2.9841408729553223]\n",
      "    SA1 (arg):    [5321.9736, 47.147758, 2.8578884601593018]\n",
      "    SX383:        [4525.249, 33.943134, 3.121499538421631]\n",
      "    SX383 (arg):  [4673.0391, 35.158577, 2.9997551441192627]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10392.632091 52.400573 3.451157]\n",
      "        Train: (max)  [59166.968750 117.352463 4.197060]\n",
      "        Train: (min)  [1350.278564 18.967979 2.635727]\n",
      "        Val:   (mean) [12160.439335 55.218616 3.629352]\n",
      "        Val:   (max)  [97098.750000 124.712311 4.127344]\n",
      "        Val:   (min)  [455.181488 12.209467 2.996971]\n",
      "    NEW best model! Validation mean-PESQ 3.62935237169\n",
      "    Saving model...\n",
      "    Total time for evaluation: 12.4624140263s\n",
      "    Total memory usage: 4626878464\n",
      "Epoch 12:\n",
      "    101120: 0.204764  [5.018395 0.014013 0.517481 0.900681 0.038394 1.176314] [5.018395 0.420400 2.587406 0.450340 0.383935 1.176314] 0.525 0.000249409345347                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 153.870856047s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 83.5% d_acc\n",
      "    Total time for evaluation: 0.0930860042572s\n",
      "    ----------------\n",
      "    Code entropy: 2.23538\n",
      "    Updated tau from 0.525 to 0.499999976158\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5418.915, 47.09074, 2.8150084018707275]\n",
      "    SA1 (arg):    [5725.2827, 48.731827, 2.6985747814178467]\n",
      "    SX383:        [5095.7178, 36.668304, 2.952035903930664]\n",
      "    SX383 (arg):  [5249.7227, 37.834721, 2.852137804031372]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [12103.673543 56.308087 3.303078]\n",
      "        Train: (max)  [74223.320312 138.307602 4.096729]\n",
      "        Train: (min)  [787.047913 18.503187 2.257555]\n",
      "        Val:   (mean) [13077.204397 57.277434 3.552669]\n",
      "        Val:   (max)  [90674.273438 134.757385 4.016003]\n",
      "        Val:   (min)  [469.996033 12.369934 2.517448]\n",
      "    Best validation mean-PESQ seen: 3.62935237169\n",
      "    Total time for evaluation: 12.4300560951s\n",
      "    Total memory usage: 4629000192\n",
      "Epoch 13:\n",
      "    101120: 0.23438  [4.898622 0.014021 0.475342 0.847851 0.040744 1.269913] [4.898622 0.420637 2.376708 0.423925 0.407439 1.269913] 0.5 0.000249306892421                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 153.76314187s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 83.0% d_acc\n",
      "    Total time for evaluation: 0.0926160812378s\n",
      "    ----------------\n",
      "    Code entropy: 2.3871\n",
      "    Tau stays at 0.5\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5266.4121, 45.664986, 3.0969226360321045]\n",
      "    SA1 (arg):    [5543.4033, 47.162724, 2.995314598083496]\n",
      "    SX383:        [5433.5747, 35.970291, 3.128809928894043]\n",
      "    SX383 (arg):  [5576.4819, 37.104279, 3.051011800765991]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [12227.648159 56.001886 3.465153]\n",
      "        Train: (max)  [72470.671875 127.420662 4.136730]\n",
      "        Train: (min)  [1184.720093 21.476995 2.218984]\n",
      "        Val:   (mean) [12822.096230 55.578655 3.656432]\n",
      "        Val:   (max)  [93304.976562 128.474091 4.071401]\n",
      "        Val:   (min)  [472.273621 12.382162 3.027463]\n",
      "    Best validation mean-PESQ seen: 3.62935237169\n",
      "    Total time for evaluation: 12.7462198734s\n",
      "    Total memory usage: 4626919424\n",
      "Epoch 14:\n",
      "    101120: 0.280233  [4.898364 0.012483 0.504204 0.870219 0.037564 1.192097] [4.898364 0.374497 2.521022 0.435110 0.375639 1.192097] 0.5 0.000249196290921                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 154.357997179s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 80.25% d_acc\n",
      "    Total time for evaluation: 0.0927109718323s\n",
      "    ----------------\n",
      "    Code entropy: 2.35264\n",
      "    Tau stays at 0.5\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5151.1182, 45.162189, 3.01460337638855]\n",
      "    SA1 (arg):    [5387.1113, 46.421326, 2.9040944576263428]\n",
      "    SX383:        [5258.6577, 34.505825, 3.1208598613739014]\n",
      "    SX383 (arg):  [5379.605, 35.432503, 3.0255160331726074]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [13255.740098 55.753950 3.340389]\n",
      "        Train: (max)  [100827.460938 137.767303 4.192124]\n",
      "        Train: (min)  [1287.288452 19.467821 2.112307]\n",
      "        Val:   (mean) [13090.161332 55.921372 3.592124]\n",
      "        Val:   (max)  [112055.289062 128.115845 4.196212]\n",
      "        Val:   (min)  [439.321289 12.011052 2.438899]\n",
      "    Best validation mean-PESQ seen: 3.62935237169\n",
      "    Total time for evaluation: 12.7686450481s\n",
      "    Total memory usage: 4626886656\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    101120: 0.163576  [5.050081 0.014286 0.545288 0.886393 0.035641 1.095456] [5.050081 0.428582 2.726438 0.443196 0.356408 1.095456] 0.5 0.000249077552975                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "    Total time for epoch: 154.632311106s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 84.75% d_acc\n",
      "    Total time for evaluation: 0.0947229862213s\n",
      "    ----------------\n",
      "    Code entropy: 2.17559\n",
      "    Updated tau from 0.5 to 0.474999970198\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5622.1206, 47.567574, 2.8405511379241943]\n",
      "    SA1 (arg):    [5898.0181, 48.972195, 2.7473690509796143]\n",
      "    SX383:        [5620.3154, 37.234917, 2.8058078289031982]\n",
      "    SX383 (arg):  [5757.7036, 38.146374, 2.73057222366333]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [14620.367362 62.611735 3.193502]\n",
      "        Train: (max)  [66516.726562 163.695099 4.078465]\n",
      "        Train: (min)  [1107.070435 21.790028 2.213029]\n",
      "        Val:   (mean) [13501.986400 58.838293 3.461795]\n",
      "        Val:   (max)  [97339.093750 130.965088 4.045824]\n",
      "        Val:   (min)  [493.483826 12.735821 2.328036]\n",
      "    Best validation mean-PESQ seen: 3.62935237169\n",
      "    Total time for evaluation: 12.4724519253s\n",
      "    Total memory usage: 4626866176\n",
      "Epoch 16:\n",
      "    101120: 0.199899  [4.798909 0.012053 0.500265 0.872484 0.037143 1.128317] [4.798909 0.361595 2.501323 0.436242 0.371433 1.128317] 0.475 0.000248950691604                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 154.309390068s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 80.25% d_acc\n",
      "    Total time for evaluation: 0.0936379432678s\n",
      "    ----------------\n",
      "    Code entropy: 2.36551\n",
      "    Tau stays at 0.475\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4795.4971, 43.329609, 3.0357182025909424]\n",
      "    SA1 (arg):    [5050.6436, 44.778416, 2.9255824089050293]\n",
      "    SX383:        [4981.584, 34.361141, 3.1589999198913574]\n",
      "    SX383 (arg):  [5101.3408, 35.328194, 3.0675737857818604]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [11083.257535 53.917316 3.437224]\n",
      "        Train: (max)  [70425.312500 137.477814 4.079420]\n",
      "        Train: (min)  [1131.859497 20.838556 2.673256]\n",
      "        Val:   (mean) [11675.136656 53.940547 3.685044]\n",
      "        Val:   (max)  [85423.742188 123.219070 4.211880]\n",
      "        Val:   (min)  [439.181519 11.975856 2.950376]\n",
      "    Best validation mean-PESQ seen: 3.62935237169\n",
      "    Total time for evaluation: 12.7156620026s\n",
      "    Total memory usage: 4628254720\n",
      "Epoch 17:\n",
      "    101120: 0.191769  [4.766753 0.011586 0.492021 0.974707 0.035822 1.113495] [4.766753 0.347581 2.460104 0.487353 0.358220 1.113495] 0.475 0.00024881572072                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 154.071144104s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.75% d_acc\n",
      "    Total time for evaluation: 0.0926649570465s\n",
      "    ----------------\n",
      "    Code entropy: 2.36388\n",
      "    Tau stays at 0.475\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5318.1016, 46.23167, 2.933382749557495]\n",
      "    SA1 (arg):    [5569.5859, 47.523254, 2.8268542289733887]\n",
      "    SX383:        [5225.2563, 36.578121, 3.0048773288726807]\n",
      "    SX383 (arg):  [5371.7759, 37.567608, 2.894869804382324]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [13522.139486 59.900023 3.366660]\n",
      "        Train: (max)  [72701.140625 162.203568 4.154290]\n",
      "        Train: (min)  [1764.677612 25.275650 2.583225]\n",
      "        Val:   (mean) [12226.654059 55.476337 3.675306]\n",
      "        Val:   (max)  [92187.054688 125.151123 4.156137]\n",
      "        Val:   (min)  [441.423584 12.088949 2.990214]\n",
      "    Best validation mean-PESQ seen: 3.62935237169\n",
      "    Total time for evaluation: 12.7044489384s\n",
      "    Total memory usage: 4626907136\n",
      "Epoch 18:\n",
      "    101120: 0.247408  [4.707259 0.013962 0.455394 0.844424 0.036085 1.228361] [4.707259 0.418864 2.276969 0.422212 0.360853 1.228361] 0.475 0.000248672655124                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 154.757746935s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 82.25% d_acc\n",
      "    Total time for evaluation: 0.0947890281677s\n",
      "    ----------------\n",
      "    Code entropy: 2.46926\n",
      "    Updated tau from 0.475 to 0.499999964237\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4809.4302, 43.006557, 3.1362221240997314]\n",
      "    SA1 (arg):    [4960.8638, 43.881275, 3.070138454437256]\n",
      "    SX383:        [4912.8345, 34.454002, 3.228505849838257]\n",
      "    SX383 (arg):  [4985.6616, 35.038155, 3.1583569049835205]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [11140.041316 54.408300 3.513124]\n",
      "        Train: (max)  [54295.519531 125.609886 4.070730]\n",
      "        Train: (min)  [1410.437012 20.129631 2.587848]\n",
      "        Val:   (mean) [11807.786397 53.521318 3.693206]\n",
      "        Val:   (max)  [87316.281250 123.119331 4.210164]\n",
      "        Val:   (min)  [411.268311 11.550556 2.497706]\n",
      "    Best validation mean-PESQ seen: 3.62935237169\n",
      "    Total time for evaluation: 12.6596028805s\n",
      "    Total memory usage: 4629012480\n",
      "Epoch 19:\n",
      "    38400: 0.248448  [4.543066 0.011157 0.456109 0.825130 0.033772 1.177540] [4.543066 0.334702 2.280544 0.412565 0.337716 1.177540] 0.5 0.000248615506823                                                                                                                                                                                                                                                                        "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b19ccdeee9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdiscrim_batch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscrim_batch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrim_batch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# print statistics every 10 batches so we know what's going on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "lead = \"    \"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print \"Epoch \" + str(epoch) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    num_batches = len(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        # cosine annealing for model's learning rate\n",
    "        train_pct = T_i / float(NUM_EPOCHS)\n",
    "        opt_lr = ENDING_LR + 0.5 * (STARTING_LR - ENDING_LR) * (1 + math.cos(3.14159 * train_pct))\n",
    "        T_i += (1.0 / num_batches)\n",
    "        K.set_value(model.optimizer.lr, opt_lr)\n",
    "        \n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "               \n",
    "        # train autoencoder\n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.ones(nbatch)] * n_discrim + \\\n",
    "              [np.zeros((nbatch, 1, 1, 1))] * n_code\n",
    "\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        if (n_discrim > 0):\n",
    "            # train discriminator            \n",
    "            generated = autoencoder.predict(batch)\n",
    "            discrim_batch_X = interleave([batch, generated])\n",
    "            discrim_batch_y = interleave([np.ones(nbatch), np.zeros(nbatch)])\n",
    "\n",
    "            d_loss = discriminator.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \"\n",
    "            if (n_discrim > 0):\n",
    "                printStr += (str(d_loss) + \" \")\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau), opt_lr,\n",
    "        \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    if (n_discrim > 0):\n",
    "        NUM = 200\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        generated = autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "        d_X = np.concatenate((X_train[rows, :], generated))\n",
    "        d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "        d_acc = evaluate_discriminator(discriminator, autoencoder,\n",
    "                                   d_X, d_y, verbose = False)\n",
    "\n",
    "        print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "        elapsed = time.time() - startTime\n",
    "        print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    else:\n",
    "        print lead + \"No discriminator\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # estimate code entropy from random samples (if quantization is on)\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        NUM = 20000\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        to_predict = np.copy(X_train[rows, :])\n",
    "        code = encoder.predict(to_predict, verbose = 0, batch_size = 128)\n",
    "        \n",
    "        all_onehots = np.reshape(code, (-1, QUANT_CHANS, NBINS))\n",
    "        onehot_hist = np.sum(all_onehots, axis = 0)\n",
    "        onehot_hist /= np.sum(onehot_hist, axis = 1, keepdims = True)\n",
    "        \n",
    "        # entropy for each channel\n",
    "        channel_entropy = -np.sum(onehot_hist * np.log(onehot_hist + np.finfo(float).eps) / np.log(2.0),\n",
    "                                  axis = 1)\n",
    "\n",
    "        # total entropy\n",
    "        entropy = np.sum(channel_entropy)\n",
    "\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Code entropy:\", entropy\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # handle updating entropy weight (tau)\n",
    "        # ---------------------------------------------------------\n",
    "        old_tau = K.get_value(tau)\n",
    "\n",
    "        if (entropy < TARGET_ENTROPY - TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau - TAU_CHANGE_RATE\n",
    "            if (new_tau <= MIN_TAU):\n",
    "                new_tau = MIN_TAU\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        elif (entropy > TARGET_ENTROPY + TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau + TAU_CHANGE_RATE\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        else:\n",
    "            print lead + \"Tau stays at\", old_tau\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    \n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SA1:         \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                    autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SA1 (arg):   \", metrics\n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SX383:       \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                    autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SX383 (arg): \", metrics\n",
    "    \n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        val_pesq = evaluate_training(autoencoder, lead)\n",
    "        if (val_pesq > best_val_pesq and entropy <= TARGET_ENTROPY):\n",
    "            print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "\n",
    "            print lead + \"Saving model...\"\n",
    "            save_model()\n",
    "            best_val_pesq = val_pesq\n",
    "            patience_epoch = epoch\n",
    "        else:\n",
    "            print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_used = process.memory_info().rss\n",
    "    print lead + \"Total memory usage: \" + str(mem_used)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # turn quantization on after a certain # of epochs\n",
    "    # ---------------------------------------------------------\n",
    "    if (epoch == EPOCHS_BEFORE_QUANT_ON):\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Turning quantization on!\"\n",
    "        \n",
    "        random_windows = []\n",
    "        for i in xrange(0, NUM_QUANT_VECS):\n",
    "            w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "            random_windows.append(train_processed[w_idx])\n",
    "\n",
    "        random_windows = np.array(random_windows)\n",
    "        print lead + \"    Selecting random code vectors for analysis...\"\n",
    "        encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "\n",
    "        print lead + \"    K means clustering for bins initialization...\"\n",
    "\n",
    "        all_clustered = []\n",
    "        cluster_scores = []\n",
    "        for i in xrange(0, QUANT_CHANS):\n",
    "            channel_values = encoded_windows[:, :, i, 0]\n",
    "            channel_values = np.reshape(channel_values, (-1, 1))\n",
    "\n",
    "            km = MiniBatchKMeans(n_clusters = NBINS).fit(channel_values)\n",
    "            clustered = np.sort(km.cluster_centers_.flatten())\n",
    "            all_clustered.append(clustered)\n",
    "\n",
    "            cluster_score = np.sqrt(np.median(np.min(km.transform(channel_values), axis = 1)))\n",
    "            cluster_scores.append(cluster_score)\n",
    "\n",
    "        print lead + \"    Done. Cluster scores:\", cluster_scores\n",
    "        \n",
    "        clustered_bins = np.vstack(all_clustered)\n",
    "        K.set_value(QUANTIZATION_ON, True)\n",
    "        K.set_value(QUANT_BINS, clustered_bins)\n",
    "        K.set_value(tau, INITIAL_TAU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_model('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = load_model('best_model.h5', KERAS_LOAD_MAP)\n",
    "    autoencoder = load_model('best_auto.h5', KERAS_LOAD_MAP)\n",
    "    encoder = autoencoder.layers[1]\n",
    "    decoder = autoencoder.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder)\n",
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder)\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder)\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder, argmax = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embed = encoder.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.reshape(all_embed, (all_embed.shape[0] * all_embed.shape[1], QUANT_CHANS, NBINS))\n",
    "hist = np.sum(probs, axis = 0)\n",
    "hist /= np.sum(hist, axis = 1, keepdims = True)\n",
    "\n",
    "for i in xrange(0, hist.shape[0]):\n",
    "    print \"--- CHANNEL\", i, \"---\"\n",
    "    \n",
    "    sample_hist_bins = np.linspace(0, NBINS - 1, NBINS)\n",
    "    plt.bar(sample_hist_bins, hist[i], align = 'center', width = 1)\n",
    "    plt.show()\n",
    "    \n",
    "    entropy = 0\n",
    "    for j in hist[i]:\n",
    "        if (j < 1e-4): continue\n",
    "        entropy += j * math.log(j, 2)\n",
    "    entropy = -entropy\n",
    "    print \"Entropy of distribution:\", entropy\n",
    "    \n",
    "    print \"Hist:\", hist[i]\n",
    "    print \"Bins:\", K.eval(QUANT_BINS[i])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = all_embed[0]\n",
    "\n",
    "oh = K.eval(K.one_hot(K.argmax(K.variable(s)), NBINS))\n",
    "\n",
    "print s.shape\n",
    "print oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocess_waveform(data)\n",
    "windows = extract_windows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed = np.reshape(windows, (windows.shape[0], WINDOW_SIZE, 1))\n",
    "embed = encoder.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = decoder.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_quantization = pre_quant.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)\n",
    "after_dequantization = post_dequant.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pct = np.max(embed[25], axis = -1)\n",
    "print max_pct\n",
    "print np.argmax(embed[25], axis = -1)\n",
    "print np.sum(max_pct > 0.98) / float(max_pct.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_max = np.max(embed, axis = -1)\n",
    "print np.mean(embed_max)\n",
    "print np.sum(embed_max > 0.98) / float(embed_max.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 25\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "print \"Original\"\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "print \"Reconstruction\"\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    print \"Before quantization\"\n",
    "    plt.plot(before_quantization[idx])\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.show()\n",
    "\n",
    "    print \"After dequantization\"\n",
    "    plt.plot(after_dequantization[idx])\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()\n",
    "else:\n",
    "    print \"Embedding\"\n",
    "    plt.plot(before_quantization[idx])\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.show()\n",
    "\n",
    "print \"Error\"\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
