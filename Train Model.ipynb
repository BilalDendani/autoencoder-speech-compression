{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from nn_util import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import load_model\n",
    "from keras.losses import *\n",
    "import scipy.io.wavfile as sciwav\n",
    "import multiprocessing\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)\n",
    "\n",
    "# increase recursion limit for adaptive VQ\n",
    "import sys\n",
    "sys.setrecursionlimit(40000)\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control amount of GPU memory used\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from pesq import *\n",
    "from consts import *\n",
    "from nn_blocks import *\n",
    "from perceptual_loss import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101544, 512, 1)\n",
      "-2.40941e-06\n",
      "0.104158\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE, 1))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = (WINDOW_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax hardness variable\n",
    "tau = K.variable(0.0001, name = \"hardness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLE_FACTOR = 2\n",
    "CHANNEL_SIZE = WINDOW_SIZE / DOWNSAMPLE_FACTOR\n",
    "    \n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 48\n",
    "    FILT_SIZE = 9\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = enc_input\n",
    "    \n",
    "    enc = Reshape(dim, input_shape = dim)(enc)  \n",
    "    \n",
    "    enc = channel_change_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 4)(enc)\n",
    "    enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 4)(enc)\n",
    "    enc = channel_change_block(1, FILT_SIZE)(enc)\n",
    "    \n",
    "    # quantization\n",
    "    enc = Reshape((CHANNEL_SIZE,))(enc)\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc)\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (CHANNEL_SIZE, NBINS))\n",
    "    dec = dec_input\n",
    "    \n",
    "    # dequantization\n",
    "    dec = SoftmaxDequantization()(dec)    \n",
    "    dec = Reshape((CHANNEL_SIZE, 1))(dec)\n",
    "    \n",
    "    dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 4)(dec)\n",
    "    dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 4)(dec)\n",
    "    dec = channel_change_block(1, FILT_SIZE)(dec)\n",
    "\n",
    "    dec = Model(inputs = dec_input, outputs = dec)\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compute the entropy of a batch directly\n",
    "def code_entropy(placeholder, code):\n",
    "    all_onehots = K.reshape(code, (-1, NBINS))\n",
    "    onehot_hist = K.sum(all_onehots, axis = 0)\n",
    "    onehot_hist /= K.sum(onehot_hist)\n",
    "\n",
    "    entropy = -K.sum(onehot_hist * K.log(onehot_hist + K.epsilon()) / K.log(2.0))\n",
    "    loss = tau * entropy\n",
    "    return loss\n",
    "\n",
    "def code_sparsity(placeholder, code):\n",
    "    sparsity = K.mean(K.sum(K.sqrt(code + K.epsilon()), axis = -1), axis = -1) - 1.0\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'code_entropy' : code_entropy,\n",
    "                  'code_sparsity' : code_sparsity,\n",
    "                  'rmse' : rmse,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization,\n",
    "                  'MEL_FILTERBANK' : MEL_FILTERBANK,\n",
    "                  'DFT_REAL' : DFT_REAL,\n",
    "                  'DFT_IMAG' : DFT_IMAG,\n",
    "                  'MFCC_DCT' : MFCC_DCT,\n",
    "                  'keras_dft_mag' : keras_dft_mag,\n",
    "                  'keras_dct' : keras_dct,\n",
    "                  'perceptual_transform' : perceptual_transform,\n",
    "                  'perceptual_distance' : perceptual_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = input_dim)\n",
    "\n",
    "encoder, decoder = autoencoder_structure(input_dim)\n",
    "ac_reconstructed = decoder(encoder(ac_input))\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "loss_weights = [30.0, 1.0, 5.0, 1.0]\n",
    "loss_functions = [rmse, perceptual_distance, code_sparsity, code_entropy]\n",
    "n_recons = 2\n",
    "n_code = 2\n",
    "assert(n_recons + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1511: UserWarning: The list of outputs passed to the model is redundant. All outputs should only appear once. Found: [<tf.Tensor 'model_2_1/p_re_lu_36/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'model_2_1/p_re_lu_36/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'model_1_1/softmax_quantization_1/div:0' shape=(?, 256, 32) dtype=float32>, <tf.Tensor 'model_1_1/softmax_quantization_1/div:0' shape=(?, 256, 32) dtype=float32>]\n",
      "  ' Found: ' + str(self.outputs))\n"
     ]
    }
   ],
   "source": [
    "# model specification\n",
    "model_input = Input(shape = input_dim)\n",
    "model_embedding = encoder(model_input)\n",
    "model_reconstructed = decoder(model_embedding)\n",
    "\n",
    "model = Model(inputs = [model_input], outputs = [model_reconstructed] * n_recons + \\\n",
    "                                            [model_embedding] * n_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 256, 32)           313486.0  \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 512, 1)            396589    \n",
      "=================================================================\n",
      "Total params: 710,075\n",
      "Trainable params: 710,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         155322.0\n",
      "Avg err:     210.913\n",
      "PESQ:        1.02260279655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[155322.05, 210.91307, 1.0226027965545654]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get untrained baseline for model\n",
    "test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_uninit\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves current model\n",
    "def save_model(prefix = 'best'):\n",
    "    os.system('rm ./' + prefix + '_model.h5')\n",
    "    os.system('rm ./' + prefix + '_auto.h5')\n",
    "    \n",
    "    model.save('./' + prefix + '_model.h5')\n",
    "    autoencoder.save('./' + prefix + '_auto.h5')\n",
    "    \n",
    "    f = h5py.File('best_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    def set_evaluation(windows, wparams, eval_idxs):\n",
    "        before_after_pairs = np.array([run_model_on_windows(windows[i],\n",
    "                                                    wparams[i],\n",
    "                                                    autoencoder,\n",
    "                                                    argmax = True)\n",
    "                                       for i in eval_idxs])\n",
    "        \n",
    "        NUM_THREADS = 8\n",
    "        list_range = np.arange(0, len(eval_idxs))\n",
    "        slices = [list_range[i:None:NUM_THREADS]\n",
    "                  for i in xrange(0, NUM_THREADS)]\n",
    "        \n",
    "        def thread_func(pairs, q):\n",
    "            for p in pairs:\n",
    "                q.put(evaluation_metrics(p[0], p[1]))\n",
    "                \n",
    "        q = multiprocessing.Queue()\n",
    "        threads = [multiprocessing.Process(target = thread_func,\n",
    "                                           args = (before_after_pairs[slices[i]], q))\n",
    "                   for i in xrange(0, NUM_THREADS)]\n",
    "        [t.start() for t in threads]\n",
    "        [t.join() for t in threads]\n",
    "        \n",
    "        return np.array([q.get() for i in list_range])\n",
    "    \n",
    "    train_eval_idxs = random.sample(range(0, len(train_windows)), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_windows)), VAL_EVALUATE)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    \n",
    "    # train set evaluation\n",
    "    train_metrics = set_evaluation(train_windows, train_wparams,\n",
    "                                   train_eval_idxs)\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    \n",
    "    # validation set evaluation\n",
    "    val_metrics = set_evaluation(val_windows, val_wparams,\n",
    "                                 val_eval_idxs)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 1.875\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "ORIG_BITRATE = 256.00\n",
    "TARGET_BITRATE = 16.00\n",
    "PRE_ENTROPY_RATE = ORIG_BITRATE / DOWNSAMPLE_FACTOR\n",
    "\n",
    "TARGET_ENTROPY = (TARGET_BITRATE / PRE_ENTROPY_RATE * 16.0)\n",
    "TARGET_ENTROPY *= (STEP_SIZE / float(WINDOW_SIZE))\n",
    "TARGET_ENTROPY_FUZZ = 0.1\n",
    "\n",
    "TAU_CHANGE_RATE = 0.0125\n",
    "MIN_TAU = 0.0125\n",
    "\n",
    "STARTING_LR = 0.001\n",
    "\n",
    "print \"Target entropy:\", TARGET_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_pesq = 0.0\n",
    "K.set_value(tau, MIN_TAU)\n",
    "T_i = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    101120:  [1.843466 0.016325 1.103907 0.041010 0.044768] [1.843466 0.489743 1.103907 0.205048 0.044768] 0.0125 0.000999938936265                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "    Total time for epoch: 88.4746601582s\n",
      "    ----------------\n",
      "    Code entropy: 3.46722149312\n",
      "    Updated tau from 0.0125 to 0.0250000001863\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [6760.3804, 47.327534, 2.5474321842193604]\n",
      "    SA1 (arg):    [6848.8618, 47.83659, 2.501610517501831]\n",
      "    SX383:        [7436.6929, 40.469631, 2.435767650604248]\n",
      "    SX383 (arg):  [7471.2056, 40.783089, 2.404904365539551]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [14367.139761 56.820931 2.483356]\n",
      "        Train: (max)  [72338.835938 143.534515 3.215546]\n",
      "        Train: (min)  [1545.768311 19.841795 1.761508]\n",
      "        Val:   (mean) [16556.389480 59.581190 2.610015]\n",
      "        Val:   (max)  [97462.601562 130.453720 3.464754]\n",
      "        Val:   (min)  [497.529694 11.467934 1.875103]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 29.0190351009s\n",
      "Epoch 2:\n",
      "    101120:  [1.603038 0.010914 1.027123 0.034866 0.074172] [1.603038 0.327415 1.027123 0.174329 0.074172] 0.025 0.000999754521852                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 85.7547080517s\n",
      "    ----------------\n",
      "    Code entropy: 3.0499826185\n",
      "    Updated tau from 0.025 to 0.0375000003725\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5266.3223, 43.72118, 2.574883222579956]\n",
      "    SA1 (arg):    [5403.6812, 44.639233, 2.5240519046783447]\n",
      "    SX383:        [4152.6094, 31.369843, 2.7024409770965576]\n",
      "    SX383 (arg):  [4223.0288, 32.06221, 2.653489351272583]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10059.325246 49.472201 2.772548]\n",
      "        Train: (max)  [63925.554688 108.770950 3.540639]\n",
      "        Train: (min)  [972.712341 18.267393 2.075737]\n",
      "        Val:   (mean) [11275.611060 51.286140 2.883281]\n",
      "        Val:   (max)  [72027.703125 118.380424 3.736919]\n",
      "        Val:   (min)  [378.187073 10.945183 2.287551]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 14.6299209595s\n",
      "Epoch 3:\n",
      "    101120:  [1.570523 0.011256 0.944732 0.032922 0.123488] [1.570523 0.337694 0.944732 0.164609 0.123488] 0.0375 0.000999446800696                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "    Total time for epoch: 86.032173872s\n",
      "    ----------------\n",
      "    Code entropy: 3.24604806788\n",
      "    Updated tau from 0.0375 to 0.0500000014901\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4425.6094, 40.463272, 2.848052501678467]\n",
      "    SA1 (arg):    [4484.2612, 40.858482, 2.8097620010375977]\n",
      "    SX383:        [4560.2334, 31.236046, 2.8521218299865723]\n",
      "    SX383 (arg):  [4594.8647, 31.54718, 2.812268018722534]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10817.028368 51.490907 2.836419]\n",
      "        Train: (max)  [58249.953125 140.998413 3.730740]\n",
      "        Train: (min)  [1771.426880 23.545227 2.332359]\n",
      "        Val:   (mean) [11360.412362 50.002106 2.973143]\n",
      "        Val:   (max)  [73804.289062 112.392822 3.828936]\n",
      "        Val:   (min)  [402.850372 10.481836 2.015019]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 14.0009679794s\n",
      "Epoch 4:\n",
      "    101120:  [1.570592 0.011497 0.906674 0.031624 0.160889] [1.570592 0.344909 0.906674 0.158120 0.160889] 0.05 0.000999015848725                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.6011970043s\n",
      "    ----------------\n",
      "    Code entropy: 3.17129322647\n",
      "    Updated tau from 0.05 to 0.0625000007451\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3827.1353, 38.435886, 3.008554697036743]\n",
      "    SA1 (arg):    [3915.5022, 39.035782, 2.9552700519561768]\n",
      "    SX383:        [3737.845, 28.465361, 2.9827795028686523]\n",
      "    SX383 (arg):  [3776.8613, 28.912302, 2.9438483715057373]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10482.109566 49.244337 2.987247]\n",
      "        Train: (max)  [53683.828125 127.999191 3.816388]\n",
      "        Train: (min)  [424.759583 13.579091 2.309494]\n",
      "        Val:   (mean) [9764.933398 46.253789 3.137202]\n",
      "        Val:   (max)  [72371.046875 106.898872 3.893419]\n",
      "        Val:   (min)  [315.121796 9.870281 2.047427]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 13.1610939503s\n",
      "Epoch 5:\n",
      "    101120:  [1.471841 0.009178 0.842409 0.030048 0.203841] [1.471841 0.275350 0.842409 0.150241 0.203841] 0.0625 0.000998461772267                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "    Total time for epoch: 86.0284159184s\n",
      "    ----------------\n",
      "    Code entropy: 3.24123104638\n",
      "    Updated tau from 0.0625 to 0.075\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3312.3054, 35.548157, 3.222975969314575]\n",
      "    SA1 (arg):    [3373.5469, 35.992172, 3.172522783279419]\n",
      "    SX383:        [3498.25, 26.856606, 3.140094518661499]\n",
      "    SX383 (arg):  [3534.8679, 27.197906, 3.1079766750335693]\n",
      "    Format: [MSE, avg err, PESQ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Train: (mean) [8348.027719 43.542152 3.259009]\n",
      "        Train: (max)  [51647.621094 105.420296 3.834939]\n",
      "        Train: (min)  [590.548889 15.285256 2.569921]\n",
      "        Val:   (mean) [8957.331049 44.131442 3.357575]\n",
      "        Val:   (max)  [66408.281250 100.465195 4.013525]\n",
      "        Val:   (min)  [299.850403 9.698038 2.349842]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 13.4389770031s\n",
      "Epoch 6:\n",
      "    101120:  [1.578600 0.010117 0.900721 0.028269 0.233040] [1.578600 0.303495 0.900721 0.141343 0.233040] 0.075 0.000997784708034                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.1405758858s\n",
      "    ----------------\n",
      "    Code entropy: 3.19285810468\n",
      "    Updated tau from 0.075 to 0.0875000029802\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3716.9138, 37.211578, 3.3032822608947754]\n",
      "    SA1 (arg):    [3773.7393, 37.693821, 3.244856357574463]\n",
      "    SX383:        [3553.0393, 27.380972, 3.1896984577178955]\n",
      "    SX383 (arg):  [3584.23, 27.72802, 3.1532394886016846]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10252.453655 46.515002 3.275438]\n",
      "        Train: (max)  [63131.843750 127.622849 3.953075]\n",
      "        Train: (min)  [499.010376 14.541749 2.593860]\n",
      "        Val:   (mean) [9743.290204 45.719391 3.373519]\n",
      "        Val:   (max)  [68980.640625 103.333801 4.068163]\n",
      "        Val:   (min)  [346.078003 10.224600 2.190695]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 13.1718189716s\n",
      "Epoch 7:\n",
      "    101120:  [1.657548 0.010950 0.880978 0.030125 0.297433] [1.657548 0.328514 0.880978 0.150623 0.297433] 0.0875 0.00099698482308                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 86.4005029202s\n",
      "    ----------------\n",
      "    Code entropy: 3.51911111201\n",
      "    Updated tau from 0.0875 to 0.10000000596\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3835.8057, 37.519756, 2.966865301132202]\n",
      "    SA1 (arg):    [3884.0813, 37.938122, 2.94553279876709]\n",
      "    SX383:        [3882.4792, 28.22571, 2.945883274078369]\n",
      "    SX383 (arg):  [3901.4219, 28.455156, 2.921189546585083]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8338.468091 44.385895 3.214193]\n",
      "        Train: (max)  [47639.234375 102.631630 3.895215]\n",
      "        Train: (min)  [850.930542 16.374413 2.442434]\n",
      "        Val:   (mean) [10214.131721 47.495173 3.257224]\n",
      "        Val:   (max)  [74458.906250 105.780190 4.001761]\n",
      "        Val:   (min)  [321.483185 10.093969 2.234358]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.7108647823s\n",
      "Epoch 8:\n",
      "    101120:  [1.577546 0.009849 0.825764 0.027524 0.318693] [1.577546 0.295469 0.825764 0.137620 0.318693] 0.1 0.000996062314765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.1081409454s\n",
      "    ----------------\n",
      "    Code entropy: 3.17655322295\n",
      "    Updated tau from 0.1 to 0.112500008941\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3621.1003, 36.966118, 3.269442081451416]\n",
      "    SA1 (arg):    [3695.7917, 37.45195, 3.21781587600708]\n",
      "    SX383:        [3403.0046, 27.648355, 3.0940701961517334]\n",
      "    SX383 (arg):  [3432.6494, 27.935928, 3.0726277828216553]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [9238.734424 45.335186 3.289063]\n",
      "        Train: (max)  [50945.113281 125.236328 3.994315]\n",
      "        Train: (min)  [941.545166 16.771090 1.974590]\n",
      "        Val:   (mean) [8606.284048 44.045784 3.450110]\n",
      "        Val:   (max)  [67677.921875 102.845863 4.080490]\n",
      "        Val:   (min)  [315.432343 9.808281 2.422743]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.9823060036s\n",
      "Epoch 9:\n",
      "    101120:  [1.512444 0.009819 0.767772 0.025370 0.323261] [1.512444 0.294562 0.767772 0.126850 0.323261] 0.1125 0.000995017410702                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.1654791832s\n",
      "    ----------------\n",
      "    Code entropy: 2.95541716399\n",
      "    Updated tau from 0.1125 to 0.125000011921\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3048.7234, 34.522797, 3.2099826335906982]\n",
      "    SA1 (arg):    [3134.7729, 35.162476, 3.1466288566589355]\n",
      "    SX383:        [3335.6687, 26.713604, 3.234342098236084]\n",
      "    SX383 (arg):  [3365.1689, 26.989523, 3.196786880493164]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6667.112034 41.122264 3.463328]\n",
      "        Train: (max)  [25630.970703 90.145279 4.105040]\n",
      "        Train: (min)  [786.654663 16.615284 2.805578]\n",
      "        Val:   (mean) [7862.938164 42.467549 3.517358]\n",
      "        Val:   (max)  [69585.695312 95.685219 4.071865]\n",
      "        Val:   (min)  [302.668335 9.740552 2.480393]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.8875529766s\n",
      "Epoch 10:\n",
      "    101120:  [1.514377 0.008230 0.800621 0.023649 0.348618] [1.514377 0.246891 0.800621 0.118247 0.348618] 0.125 0.000993850368708                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.2607309818s\n",
      "    ----------------\n",
      "    Code entropy: 2.91854389926\n",
      "    Updated tau from 0.125 to 0.137500014901\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2931.9375, 34.109367, 3.2941842079162598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SA1 (arg):    [2997.2808, 34.609268, 3.238420009613037]\n",
      "    SX383:        [3147.9775, 25.630877, 3.2412943840026855]\n",
      "    SX383 (arg):  [3171.0674, 25.908075, 3.20552659034729]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6826.529619 40.206363 3.420714]\n",
      "        Train: (max)  [49288.468750 114.222519 3.980240]\n",
      "        Train: (min)  [844.431641 15.288953 1.981934]\n",
      "        Val:   (mean) [7337.869198 41.188717 3.562171]\n",
      "        Val:   (max)  [62555.281250 91.970467 4.133838]\n",
      "        Val:   (min)  [281.905945 9.420243 2.414114]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.8149600029s\n",
      "Epoch 11:\n",
      "    101120:  [1.548590 0.009252 0.822200 0.022248 0.337586] [1.548590 0.277561 0.822200 0.111242 0.337586] 0.1375 0.00099256147673                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 86.2869470119s\n",
      "    ----------------\n",
      "    Code entropy: 2.56174606614\n",
      "    Updated tau from 0.1375 to 0.150000017881\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4013.801, 39.892906, 2.8545846939086914]\n",
      "    SA1 (arg):    [4111.9136, 40.471756, 2.8058557510375977]\n",
      "    SX383:        [3484.1697, 29.260616, 2.9614293575286865]\n",
      "    SX383 (arg):  [3530.323, 29.659294, 2.943606376647949]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8780.096110 48.673092 3.154826]\n",
      "        Train: (max)  [39641.101562 127.361847 3.688080]\n",
      "        Train: (min)  [1378.267090 20.028360 2.508977]\n",
      "        Val:   (mean) [8824.692273 47.455592 3.309963]\n",
      "        Val:   (max)  [66207.632812 106.082199 3.849202]\n",
      "        Val:   (min)  [348.912384 10.679517 2.172302]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 13.0383448601s\n",
      "Epoch 12:\n",
      "    101120:  [1.577986 0.011007 0.725677 0.024068 0.401766] [1.577986 0.330202 0.725677 0.120341 0.401766] 0.15 0.000991151052783                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.3327028751s\n",
      "    ----------------\n",
      "    Code entropy: 2.60427653485\n",
      "    Updated tau from 0.15 to 0.162500020862\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3166.6333, 36.560249, 2.9629151821136475]\n",
      "    SA1 (arg):    [3253.0884, 37.131565, 2.918954372406006]\n",
      "    SX383:        [3042.1301, 27.167532, 3.058546543121338]\n",
      "    SX383 (arg):  [3079.9761, 27.557447, 3.028320550918579]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6426.873217 40.713733 3.319651]\n",
      "        Train: (max)  [40262.558594 119.013229 4.016444]\n",
      "        Train: (min)  [607.569824 14.430755 2.477128]\n",
      "        Val:   (mean) [7606.215004 43.880402 3.469049]\n",
      "        Val:   (max)  [60779.796875 98.853470 3.996835]\n",
      "        Val:   (min)  [324.367126 10.344915 2.597511]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.7215559483s\n",
      "Epoch 13:\n",
      "    101120:  [1.570146 0.009836 0.750380 0.022572 0.411832] [1.570146 0.295075 0.750380 0.112859 0.411832] 0.1625 0.000989619444869                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.5701880455s\n",
      "    ----------------\n",
      "    Code entropy: 2.64266770905\n",
      "    Updated tau from 0.1625 to 0.175000023842\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3350.8367, 36.859852, 3.0819759368896484]\n",
      "    SA1 (arg):    [3417.1807, 37.369278, 3.030510902404785]\n",
      "    SX383:        [3205.188, 27.93379, 3.071460247039795]\n",
      "    SX383 (arg):  [3241.77, 28.252312, 3.0299253463745117]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5966.989510 39.125028 3.328653]\n",
      "        Train: (max)  [25335.009766 83.042023 4.087245]\n",
      "        Train: (min)  [390.593903 13.271969 2.543555]\n",
      "        Val:   (mean) [7910.110359 44.361974 3.441787]\n",
      "        Val:   (max)  [64107.191406 98.783905 4.004582]\n",
      "        Val:   (min)  [327.964966 10.463899 2.255202]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.8706409931s\n",
      "Epoch 14:\n",
      "    101120:  [1.613660 0.009560 0.808106 0.020620 0.415666] [1.613660 0.286789 0.808106 0.103099 0.415666] 0.175 0.000987967030886                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "    Total time for epoch: 85.8597228527s\n",
      "    ----------------\n",
      "    Code entropy: 2.38104543999\n",
      "    Updated tau from 0.175 to 0.187500026822\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3410.0684, 37.875519, 2.985771417617798]\n",
      "    SA1 (arg):    [3491.1453, 38.404819, 2.9398746490478516]\n",
      "    SX383:        [3119.4312, 28.050432, 2.979274272918701]\n",
      "    SX383 (arg):  [3157.7593, 28.410175, 2.9506547451019287]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8635.522277 48.163840 3.284977]\n",
      "        Train: (max)  [51457.156250 122.641792 3.843473]\n",
      "        Train: (min)  [872.806091 15.964905 2.312595]\n",
      "        Val:   (mean) [7941.368544 45.222367 3.407016]\n",
      "        Val:   (max)  [72145.085938 103.652222 3.961665]\n",
      "        Val:   (min)  [343.531677 10.832438 2.306268]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.8771669865s\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    101120:  [1.594662 0.009306 0.769592 0.021077 0.440515] [1.594662 0.279170 0.769592 0.105385 0.440515] 0.1875 0.000986194218544                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "    Total time for epoch: 86.0721609592s\n",
      "    ----------------\n",
      "    Code entropy: 2.54676670425\n",
      "    Updated tau from 0.1875 to 0.200000029802\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3442.6379, 38.275223, 2.942209482192993]\n",
      "    SA1 (arg):    [3523.5625, 38.866608, 2.9021944999694824]\n",
      "    SX383:        [3057.698, 28.288425, 3.036055326461792]\n",
      "    SX383 (arg):  [3095.769, 28.676027, 3.0145211219787598]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7546.543096 45.171573 3.423848]\n",
      "        Train: (max)  [50794.625000 115.214661 3.928698]\n",
      "        Train: (min)  [770.281982 17.661243 2.587044]\n",
      "        Val:   (mean) [7861.161348 45.573929 3.504348]\n",
      "        Val:   (max)  [61904.058594 104.084038 3.995991]\n",
      "        Val:   (min)  [348.763275 10.812046 2.382690]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 12.6487481594s\n",
      "Epoch 16:\n",
      "    101120:  [1.626375 0.010296 0.744560 0.020618 0.469855] [1.626375 0.308868 0.744560 0.103091 0.469855] 0.2 0.000984301445256                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.2933709621s\n",
      "    ----------------\n",
      "    Code entropy: 2.21730702761\n",
      "    Updated tau from 0.2 to 0.212500032783\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3798.2537, 41.188644, 2.817793369293213]\n",
      "    SA1 (arg):    [3882.2756, 41.734161, 2.785856246948242]\n",
      "    SX383:        [3268.9695, 30.296682, 2.893476724624634]\n",
      "    SX383 (arg):  [3324.083, 30.78989, 2.861943006515503]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8463.388644 48.266630 3.125384]\n",
      "        Train: (max)  [50165.179688 105.641678 3.943336]\n",
      "        Train: (min)  [460.544617 14.672132 1.913869]\n",
      "        Val:   (mean) [8118.115235 47.648732 3.352212]\n",
      "        Val:   (max)  [56912.031250 109.670990 3.987894]\n",
      "        Val:   (min)  [390.954865 11.506968 2.224208]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 13.1621549129s\n",
      "Epoch 17:\n",
      "    101120:  [1.813031 0.013291 0.767132 0.020214 0.546092] [1.813031 0.398735 0.767132 0.101072 0.546092] 0.2125 0.000982289178035                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 86.3894791603s\n",
      "    ----------------\n",
      "    Code entropy: 2.47880547374\n",
      "    Updated tau from 0.2125 to 0.225000035763\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3271.2698, 36.996788, 2.9885568618774414]\n",
      "    SA1 (arg):    [3324.2126, 37.369701, 2.952265739440918]\n",
      "    SX383:        [2801.0896, 27.399551, 3.1557748317718506]\n",
      "    SX383 (arg):  [2837.6194, 27.705114, 3.1153676509857178]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7331.287195 45.642915 3.363138]\n",
      "        Train: (max)  [30002.896484 109.318375 3.894896]\n",
      "        Train: (min)  [389.434723 13.373271 2.578408]\n",
      "        Val:   (mean) [7415.182892 44.224275 3.457516]\n",
      "        Val:   (max)  [54645.531250 97.983818 3.977661]\n",
      "        Val:   (min)  [343.140137 10.790765 2.600747]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 13.0063970089s\n",
      "Epoch 18:\n",
      "    101120:  [1.659605 0.011048 0.737764 0.019192 0.494428] [1.659605 0.331452 0.737764 0.095961 0.494428] 0.225 0.000980157913377                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 94.5966110229s\n",
      "    ----------------\n",
      "    Code entropy: 2.25182654862\n",
      "    Updated tau from 0.225 to 0.237500038743\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4206.1504, 42.792656, 2.8750863075256348]\n",
      "    SA1 (arg):    [4288.873, 43.2229, 2.8592734336853027]\n",
      "    SX383:        [3602.3457, 32.286457, 2.930257797241211]\n",
      "    SX383 (arg):  [3640.3374, 32.606247, 2.8818912506103516]\n",
      "    Format: [MSE, avg err, PESQ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-62f1b14498a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mlead\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"SX383 (arg): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mval_pesq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_pesq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_pesq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mTARGET_ENTROPY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mlead\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"NEW best model! Validation mean-PESQ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pesq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d95ad8fc6a5b>\u001b[0m in \u001b[0;36mevaluate_training\u001b[0;34m(autoencoder, lead)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# train set evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     train_metrics = set_evaluation(train_windows, train_wparams,\n\u001b[0;32m---> 34\u001b[0;31m                                    train_eval_idxs)\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mlead\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"    Train: (mean)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mlead\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"    Train: (max) \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d95ad8fc6a5b>\u001b[0m in \u001b[0;36mset_evaluation\u001b[0;34m(windows, wparams, eval_idxs)\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                     argmax = True)\n\u001b[0;32m----> 7\u001b[0;31m                                        for i in eval_idxs])\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mNUM_THREADS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sri/Desktop/autoencoder-speech-compression/evaluation.pyc\u001b[0m in \u001b[0;36mrun_model_on_windows\u001b[0;34m(windows, wparams, autoencoder, argmax)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mautoencOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mautoencOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mautoencOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mrecons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconstruct_from_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOVERLAP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOVERLAP_FUNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1594\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "lead = \"    \"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print \"Epoch \" + str(epoch) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    num_batches = len(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        # cosine annealing for model's learning rate\n",
    "        train_pct = T_i / float(NUM_EPOCHS)\n",
    "        opt_lr = 0.5 * STARTING_LR * (1 + math.cos(3.14159 * train_pct))\n",
    "        T_i += (1.0 / num_batches)\n",
    "        K.set_value(model.optimizer.lr, opt_lr)\n",
    "        \n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "               \n",
    "        # train autoencoder\n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.zeros((nbatch, WINDOW_SIZE, NBINS))] * n_code       \n",
    "\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau), opt_lr,\n",
    "        \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # estimate code entropy from random samples (if quantization is on)\n",
    "    # ---------------------------------------------------------\n",
    "    NUM = 500\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    code = encoder.predict(X_train[rows, :], verbose = 0)\n",
    "    probs = np.reshape(code, (code.shape[0] * code.shape[1], NBINS))\n",
    "    hist = np.sum(probs, axis = 0)\n",
    "    hist /= np.sum(hist)\n",
    "\n",
    "    entropy = 0\n",
    "    for i in hist:\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Code entropy:\", entropy\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # handle updating entropy weight (tau)\n",
    "    # ---------------------------------------------------------\n",
    "    old_tau = K.get_value(tau)\n",
    "\n",
    "    if (entropy < TARGET_ENTROPY - TARGET_ENTROPY_FUZZ):\n",
    "        new_tau = old_tau - TAU_CHANGE_RATE\n",
    "        if (new_tau <= MIN_TAU):\n",
    "            new_tau = MIN_TAU\n",
    "\n",
    "        K.set_value(tau, new_tau)\n",
    "        print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "    elif (entropy > TARGET_ENTROPY + TARGET_ENTROPY_FUZZ):\n",
    "        new_tau = old_tau + TAU_CHANGE_RATE\n",
    "\n",
    "        K.set_value(tau, new_tau)\n",
    "        print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "    else:\n",
    "        print lead + \"Tau stays at\", old_tau\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    \n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                              autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SA1:         \", metrics\n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                              autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "    print lead + \"SA1 (arg):   \", metrics\n",
    "    \n",
    "    metrics_tst = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SX383:       \", metrics_tst\n",
    "    metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                              autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "    print lead + \"SX383 (arg): \", metrics\n",
    "    \n",
    "    val_pesq = evaluate_training(autoencoder, lead)\n",
    "    if (val_pesq > best_val_pesq and entropy <= TARGET_ENTROPY):\n",
    "        print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "\n",
    "        print lead + \"Saving model...\"\n",
    "        save_model()\n",
    "        best_val_pesq = val_pesq\n",
    "        patience_epoch = epoch\n",
    "    else:\n",
    "        print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = load_model('best_model.h5', KERAS_LOAD_MAP)\n",
    "    autoencoder = load_model('best_auto.h5', KERAS_LOAD_MAP)\n",
    "    encoder = autoencoder.layers[1]\n",
    "    decoder = autoencoder.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in xrange(0, len(enc)):\n",
    "#    print i, enc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder)\n",
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder)\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder)\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder, argmax = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embed = encoder.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.reshape(all_embed, (all_embed.shape[0] * all_embed.shape[1], NBINS))\n",
    "hist = np.sum(probs, axis = 0)\n",
    "hist /= np.sum(hist)\n",
    "\n",
    "sample_hist_bins = np.linspace(0, NBINS - 1, NBINS)\n",
    "plt.bar(sample_hist_bins, hist, align = 'center', width = 1)\n",
    "plt.show()\n",
    "\n",
    "entropy = 0\n",
    "for i in hist:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print \"Entropy of distribution:\", entropy\n",
    "\n",
    "print \"Bins:\"\n",
    "print K.eval(QUANT_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(np.array(K.eval(QUANT_BINS)).flatten()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocess_waveform(data)\n",
    "windows = extract_windows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed = np.reshape(windows, (windows.shape[0], WINDOW_SIZE, 1))\n",
    "embed = encoder.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = decoder.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(enc[-1].SOFTMAX_TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pct = np.max(embed[25], axis = -1)\n",
    "print max_pct\n",
    "print np.argmax(embed[25], axis = -1)\n",
    "print np.sum(max_pct > 0.98) / float(max_pct.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_max = np.max(embed, axis = -1)\n",
    "print np.mean(embed_max)\n",
    "print np.sum(embed_max > 0.98) / float(embed_max.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 25\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "print \"Original\"\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "print \"Reconstruction\"\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "print \"Code (argmax)\"\n",
    "argmax_code_vec = embed[idx]\n",
    "embed_sum = np.sum(embed[idx], axis = -1)\n",
    "argmax_code_vec = np.eye(NBINS)[np.argmax(argmax_code_vec, axis = -1)]\n",
    "argmax_code_vec[embed_sum < 0.95] = np.zeros(NBINS)\n",
    "argmax_code_vec = unquantize_vec(argmax_code_vec)\n",
    "plt.plot(argmax_code_vec)\n",
    "plt.show()\n",
    "\n",
    "print \"Code (non-argmax)\"\n",
    "na_code_vec = embed[idx]\n",
    "na_code_vec = unquantize_vec(na_code_vec)\n",
    "plt.plot(na_code_vec)\n",
    "plt.show()\n",
    "\n",
    "print \"Difference\"\n",
    "plt.plot(abs(argmax_code_vec - na_code_vec))\n",
    "plt.show()\n",
    "    \n",
    "print \"Error\"\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
