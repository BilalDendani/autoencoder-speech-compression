{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from nn_util import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import load_model\n",
    "from keras.losses import *\n",
    "import multiprocessing\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import psutil\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# control amount of GPU memory used\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from pesq import *\n",
    "from consts import *\n",
    "from nn_blocks import *\n",
    "from perceptual_loss import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101814, 512)\n",
      "2.44142e-06\n",
      "0.0994002\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE,))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHANNEL_SIZE = WINDOW_SIZE / 2\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure():   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 64\n",
    "    FILT_SIZE = 9\n",
    "    \n",
    "    # feature extractor module, used in both encoder and decoder\n",
    "    #     (structure is the same, but weights aren't shared)\n",
    "    def feature_extractor():\n",
    "        def f(inp):\n",
    "            out = inp\n",
    "            \n",
    "            out = residual_block(NCHAN, FILT_SIZE, 1)(out)\n",
    "            out = residual_block(NCHAN, FILT_SIZE, 2)(out)\n",
    "            out = residual_block(NCHAN, FILT_SIZE, 4)(out)\n",
    "            out = residual_block(NCHAN, FILT_SIZE, 8)(out)\n",
    "            \n",
    "            return out\n",
    "        \n",
    "        return f\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = (WINDOW_SIZE,))\n",
    "    enc = Reshape((WINDOW_SIZE, 1))(enc_input)\n",
    "    \n",
    "    # processing steps\n",
    "    enc = channel_change_block(NCHAN, FILT_SIZE)(enc)  \n",
    "    enc = feature_extractor()(enc)\n",
    "    enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = feature_extractor()(enc)\n",
    "    enc = channel_change_block(1, FILT_SIZE)(enc)\n",
    "    \n",
    "    # quantization (real numbers => soft bin assignments)\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc, name = 'encoder')\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (CHANNEL_SIZE, NBINS))\n",
    "    dec = dec_input\n",
    "    \n",
    "    # \"dequantization\" (soft bin assignments => real numbers)\n",
    "    dec = SoftmaxDequantization()(dec)\n",
    "    \n",
    "    # processing steps\n",
    "    dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = feature_extractor()(dec)\n",
    "    dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = feature_extractor()(dec)\n",
    "    dec = channel_change_block(1, FILT_SIZE)(dec)\n",
    "    \n",
    "    dec = Reshape((WINDOW_SIZE,))(dec)\n",
    "    dec = Model(inputs = dec_input, outputs = dec, name = 'decoder')\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'code_entropy' : code_entropy,\n",
    "                  'code_sparsity' : code_sparsity,\n",
    "                  'rmse' : rmse,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization,\n",
    "                  'DFT_REAL' : DFT_REAL,\n",
    "                  'DFT_IMAG' : DFT_IMAG,\n",
    "                  'MEL_FILTERBANKS' : MEL_FILTERBANKS,\n",
    "                  'keras_dft_mag' : keras_dft_mag,\n",
    "                  'keras_dct' : keras_dct,\n",
    "                  'perceptual_transform' : perceptual_transform,\n",
    "                  'perceptual_distance' : perceptual_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = (WINDOW_SIZE,))\n",
    "\n",
    "encoder, decoder = autoencoder_structure()\n",
    "ac_reconstructed = decoder(encoder(ac_input))\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "loss_weights = [30.0, 5.0, 10.0, 1.0]\n",
    "loss_functions = [rmse, perceptual_distance, code_sparsity, code_entropy]\n",
    "n_recons = 2\n",
    "n_code = 2\n",
    "assert(n_recons + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1511: UserWarning: The list of outputs passed to the model is redundant. All outputs should only appear once. Found: [<tf.Tensor 'decoder_1/reshape_2/Reshape:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'decoder_1/reshape_2/Reshape:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'encoder_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 32) dtype=float32>, <tf.Tensor 'encoder_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 32) dtype=float32>]\n",
      "  ' Found: ' + str(self.outputs))\n"
     ]
    }
   ],
   "source": [
    "# model specification\n",
    "model_input = Input(shape = (WINDOW_SIZE,))\n",
    "model_embedding = encoder(model_input)\n",
    "model_reconstructed = decoder(model_embedding)\n",
    "\n",
    "model = Model(inputs = [model_input], outputs = [model_reconstructed] * n_recons + \\\n",
    "                                            [model_embedding] * n_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 256, 32)           742448.0  \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 512)               816399    \n",
      "=================================================================\n",
      "Total params: 1,558,847\n",
      "Trainable params: 1,558,847\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         154586.0\n",
      "Avg err:     210.205\n",
      "PESQ:        1.05026233196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[154586.23, 210.20505, 1.0502623319625854]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model without any training\n",
    "test_model_on_wav(\"./SA1.wav\", \"\", autoencoder,\n",
    "                  save_recons = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves current model\n",
    "def save_model(prefix = 'best'):\n",
    "    os.system('rm ./' + prefix + '_model.h5')\n",
    "    os.system('rm ./' + prefix + '_coder.h5')\n",
    "    \n",
    "    model.save('./' + prefix + '_model.h5')\n",
    "    autoencoder.save('./' + prefix + '_coder.h5')\n",
    "    \n",
    "    f = h5py.File('./' + prefix + '_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    def set_evaluation(paths, eval_idxs):\n",
    "        before_after_pairs = [run_model_on_wav(paths[i],\n",
    "                                               autoencoder,\n",
    "                                               argmax = True)\n",
    "                              for i in eval_idxs]\n",
    "        \n",
    "        def thread_func(my_id, q):\n",
    "            my_slice = np.arange(my_id, len(eval_idxs), NUM_THREADS)\n",
    "            \n",
    "            for i in my_slice:\n",
    "                p = before_after_pairs[i]\n",
    "                q.put(evaluation_metrics(p[0], p[1]))\n",
    "        \n",
    "        q = multiprocessing.Queue()\n",
    "        threads = [multiprocessing.Process(target = thread_func,\n",
    "                                           args = (i, q))\n",
    "                   for i in xrange(0, NUM_THREADS)]\n",
    "        [t.start() for t in threads]\n",
    "        [t.join() for t in threads]\n",
    "        results = np.array([q.get() for i in xrange(0, len(eval_idxs))])\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    train_eval_idxs = random.sample(range(0, len(train_paths)), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_paths)), VAL_EVALUATE)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    \n",
    "    # train set evaluation\n",
    "    train_metrics = set_evaluation(train_paths,\n",
    "                                   train_eval_idxs)\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    \n",
    "    # validation set evaluation\n",
    "    val_metrics = set_evaluation(val_paths,\n",
    "                                 val_eval_idxs)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 1.875\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "NUM_EPOCHS = 300\n",
    "EPOCHS_BEFORE_QUANT_ON = 10\n",
    "\n",
    "ORIG_BITRATE = 256.00\n",
    "TARGET_BITRATE = 16.00\n",
    "PRE_ENTROPY_RATE = ORIG_BITRATE * (float(CHANNEL_SIZE) / WINDOW_SIZE)\n",
    "\n",
    "TARGET_ENTROPY = (TARGET_BITRATE / PRE_ENTROPY_RATE * 16.0)\n",
    "TARGET_ENTROPY *= (STEP_SIZE / float(WINDOW_SIZE))\n",
    "TARGET_ENTROPY_FUZZ = 0.1\n",
    "\n",
    "TAU_CHANGE_RATE = 0.025\n",
    "INITIAL_TAU = 0.5\n",
    "\n",
    "NUM_QUANT_VECS = 5000\n",
    "\n",
    "STARTING_LR = 0.00025\n",
    "ENDING_LR = 0.0001\n",
    "\n",
    "print \"Target entropy:\", TARGET_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_val_pesq = 0.0\n",
    "K.set_value(tau, 0.0)\n",
    "T_i = 0.0\n",
    "K.set_value(QUANTIZATION_ON, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 200:\n",
      "    101120:  [3.596668 0.014527 0.349130 0.015673 1.258474] [3.596668 0.435816 1.745652 0.156725 1.258474] 0.65 0.000100001251954                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 143.117285967s\n",
      "    ----------------\n",
      "    Code entropy: 1.86098487643\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3823.5962, 39.254967, 3.812554121017456]\n",
      "    SA1 (arg):    [3892.6162, 39.632523, 3.7767834663391113]\n",
      "    SX383:        [3155.6785, 29.602215, 3.6721856594085693]\n",
      "    SX383 (arg):  [3197.1931, 29.874887, 3.6451733112335205]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10103.340071 50.641432 4.005475]\n",
      "        Train: (max)  [92763.015625 176.197647 4.407579]\n",
      "        Train: (min)  [773.879883 16.947203 2.230900]\n",
      "        Val:   (mean) [8740.873887 48.373185 4.161234]\n",
      "        Val:   (max)  [51021.933594 108.538910 4.443086]\n",
      "        Val:   (min)  [404.931183 11.412870 3.765365]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.5892159939s\n",
      "    Total memory usage: 3809099776\n",
      "Epoch 201:\n",
      "    101120:  [3.649404 0.014443 0.360014 0.015356 1.262478] [3.649404 0.433300 1.800068 0.153558 1.262478] 0.65 0.00010000082624                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 143.861388922s\n",
      "    ----------------\n",
      "    Code entropy: 1.82857870281\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3989.3206, 39.742188, 3.7377421855926514]\n",
      "    SA1 (arg):    [4064.5063, 40.159447, 3.713564395904541]\n",
      "    SX383:        [3190.4519, 29.995119, 3.7297396659851074]\n",
      "    SX383 (arg):  [3219.4419, 30.190544, 3.720193862915039]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8086.126937 46.703021 3.999523]\n",
      "        Train: (max)  [44114.859375 116.701942 4.448587]\n",
      "        Train: (min)  [772.596008 17.525452 3.061869]\n",
      "        Val:   (mean) [8979.166490 49.180005 4.154089]\n",
      "        Val:   (max)  [50076.898438 110.443718 4.419283]\n",
      "        Val:   (min)  [420.935028 11.650528 3.687915]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.5038380623s\n",
      "    Total memory usage: 3807244288\n",
      "Epoch 202:\n",
      "    101120:  [3.604795 0.015648 0.358141 0.015052 1.194133] [3.604795 0.469433 1.790706 0.150522 1.194133] 0.65 0.000100008625017                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 143.353129148s\n",
      "    ----------------\n",
      "    Code entropy: 1.83409331627\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3980.1731, 39.846554, 3.796293258666992]\n",
      "    SA1 (arg):    [4027.8547, 40.139732, 3.8002147674560547]\n",
      "    SX383:        [3088.7185, 29.921497, 3.633922815322876]\n",
      "    SX383 (arg):  [3122.7769, 30.200871, 3.618464469909668]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7968.754326 47.653794 4.050711]\n",
      "        Train: (max)  [34867.789062 103.263206 4.417629]\n",
      "        Train: (min)  [1186.827271 19.360626 3.237405]\n",
      "        Val:   (mean) [8783.747363 48.647871 4.141476]\n",
      "        Val:   (max)  [49373.699219 107.885155 4.416601]\n",
      "        Val:   (min)  [394.589874 11.336362 3.395406]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.311866045s\n",
      "    Total memory usage: 3807617024\n",
      "Epoch 203:\n",
      "    101120:  [3.594385 0.014135 0.355508 0.015638 1.236427] [3.594385 0.424037 1.777539 0.156382 1.236427] 0.65 0.000100024647429                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 143.122179985s\n",
      "    ----------------\n",
      "    Code entropy: 1.84725962104\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3844.2693, 39.240376, 3.8147904872894287]\n",
      "    SA1 (arg):    [3895.106, 39.529953, 3.8016717433929443]\n",
      "    SX383:        [3356.0864, 30.434956, 3.7288379669189453]\n",
      "    SX383 (arg):  [3408.2915, 30.760107, 3.704185962677002]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [10559.043730 52.848792 4.033033]\n",
      "        Train: (max)  [91778.992188 128.814911 4.450739]\n",
      "        Train: (min)  [956.055298 19.274054 3.155229]\n",
      "        Val:   (mean) [9267.104146 49.508110 4.156082]\n",
      "        Val:   (max)  [53181.492188 111.893440 4.426364]\n",
      "        Val:   (min)  [425.259277 11.727515 3.720121]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.2128050327s\n",
      "    Total memory usage: 3807203328\n",
      "Epoch 204:\n",
      "    101120:  [3.467073 0.012792 0.346285 0.015471 1.197170] [3.467073 0.383762 1.731427 0.154714 1.197170] 0.65 0.00010004889172                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 142.604496002s\n",
      "    ----------------\n",
      "    Code entropy: 1.85120643173\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3874.4712, 39.534321, 3.7233340740203857]\n",
      "    SA1 (arg):    [3940.4453, 39.96537, 3.6982061862945557]\n",
      "    SX383:        [3266.1479, 30.006292, 3.752944231033325]\n",
      "    SX383 (arg):  [3312.5623, 30.296539, 3.737875461578369]\n",
      "    Format: [MSE, avg err, PESQ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Train: (mean) [8430.802546 45.592243 4.019145]\n",
      "        Train: (max)  [94693.328125 178.642487 4.442926]\n",
      "        Train: (min)  [997.685608 17.455538 3.207587]\n",
      "        Val:   (mean) [8728.262581 48.246197 4.152999]\n",
      "        Val:   (max)  [50232.695312 108.515091 4.426256]\n",
      "        Val:   (min)  [402.424957 11.418186 3.734662]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.0283670425s\n",
      "    Total memory usage: 3809247232\n",
      "Epoch 205:\n",
      "    101120:  [3.508477 0.012874 0.346714 0.015989 1.228805] [3.508477 0.386218 1.733568 0.159885 1.228805] 0.65 0.00010008135523                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.35868597s\n",
      "    ----------------\n",
      "    Code entropy: 1.87283850586\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3833.1624, 39.120777, 3.8269474506378174]\n",
      "    SA1 (arg):    [3900.5044, 39.445091, 3.798957109451294]\n",
      "    SX383:        [3252.5232, 29.724585, 3.757131338119507]\n",
      "    SX383 (arg):  [3282.5361, 29.929575, 3.741363525390625]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8894.386107 49.455533 4.075625]\n",
      "        Train: (max)  [69137.632812 108.710655 4.439425]\n",
      "        Train: (min)  [1149.166992 19.371386 3.218236]\n",
      "        Val:   (mean) [8887.058067 48.523014 4.157540]\n",
      "        Val:   (max)  [49907.156250 108.841843 4.422973]\n",
      "        Val:   (min)  [409.171173 11.527129 3.540020]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.4494240284s\n",
      "    Total memory usage: 3807232000\n",
      "Epoch 206:\n",
      "    101120:  [3.389415 0.010449 0.358544 0.014969 1.133525] [3.389415 0.313475 1.792722 0.149693 1.133525] 0.65 0.00010012203445                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "    Total time for epoch: 142.600487947s\n",
      "    ----------------\n",
      "    Code entropy: 1.82174579721\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4001.0479, 40.274197, 3.7689900398254395]\n",
      "    SA1 (arg):    [4069.2749, 40.685684, 3.755030632019043]\n",
      "    SX383:        [3246.7224, 30.456072, 3.810529947280884]\n",
      "    SX383 (arg):  [3280.6287, 30.733883, 3.7875401973724365]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7234.574299 45.488657 4.051268]\n",
      "        Train: (max)  [37086.156250 103.803604 4.447436]\n",
      "        Train: (min)  [884.181458 18.370859 3.084844]\n",
      "        Val:   (mean) [9179.920589 49.635473 4.148953]\n",
      "        Val:   (max)  [51506.785156 110.197487 4.413270]\n",
      "        Val:   (min)  [435.972076 11.905321 3.762075]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.3346419334s\n",
      "    Total memory usage: 3807211520\n",
      "Epoch 207:\n",
      "    101120:  [3.459793 0.012445 0.356161 0.014930 1.156352] [3.459793 0.373335 1.780806 0.149300 1.156352] 0.65 0.000100170924769                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.986835957s\n",
      "    ----------------\n",
      "    Code entropy: 1.82035548131\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3897.6812, 39.725525, 3.696847915649414]\n",
      "    SA1 (arg):    [3956.9385, 40.03363, 3.671062469482422]\n",
      "    SX383:        [3176.3789, 30.294695, 3.6556999683380127]\n",
      "    SX383 (arg):  [3204.542, 30.475664, 3.6346051692962646]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [11090.685432 53.709371 4.006565]\n",
      "        Train: (max)  [85911.687500 146.623825 4.446273]\n",
      "        Train: (min)  [1019.769836 18.820152 3.305384]\n",
      "        Val:   (mean) [9073.392614 49.614835 4.130792]\n",
      "        Val:   (max)  [49759.167969 110.818665 4.432824]\n",
      "        Val:   (min)  [407.916351 11.470378 3.529316]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.4970500469s\n",
      "    Total memory usage: 3808239616\n",
      "Epoch 208:\n",
      "    101120:  [3.449875 0.011290 0.362543 0.014815 1.150315] [3.449875 0.338693 1.812715 0.148152 1.150315] 0.65 0.000100228020976                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.888494015s\n",
      "    ----------------\n",
      "    Code entropy: 1.81412782299\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3985.4768, 40.089432, 3.7410888671875]\n",
      "    SA1 (arg):    [4043.6938, 40.336277, 3.733947515487671]\n",
      "    SX383:        [3137.667, 29.825951, 3.6655540466308594]\n",
      "    SX383 (arg):  [3161.1106, 30.060223, 3.665264129638672]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8912.561794 49.697304 4.043938]\n",
      "        Train: (max)  [45319.011719 121.952324 4.466323]\n",
      "        Train: (min)  [635.795593 16.649824 2.871446]\n",
      "        Val:   (mean) [8794.788051 48.861228 4.138302]\n",
      "        Val:   (max)  [49792.089844 108.638985 4.398260]\n",
      "        Val:   (min)  [418.015747 11.630862 3.517107]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.4881188869s\n",
      "    Total memory usage: 3808636928\n",
      "Epoch 209:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    101120:  [3.459387 0.012263 0.351895 0.015315 1.178873] [3.459387 0.367888 1.759474 0.153151 1.178873] 0.65 0.000100293316758                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "    Total time for epoch: 142.83237505s\n",
      "    ----------------\n",
      "    Code entropy: 1.8505464285\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3979.4282, 39.672791, 3.6787362098693848]\n",
      "    SA1 (arg):    [4056.0378, 40.061253, 3.653937816619873]\n",
      "    SX383:        [3268.2012, 30.039026, 3.812459707260132]\n",
      "    SX383 (arg):  [3303.9663, 30.289858, 3.788468837738037]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8295.468868 48.790751 4.024736]\n",
      "        Train: (max)  [36654.347656 103.721611 4.421831]\n",
      "        Train: (min)  [911.986084 18.337946 3.031838]\n",
      "        Val:   (mean) [8891.393692 48.835033 4.152669]\n",
      "        Val:   (max)  [51025.621094 108.453957 4.426191]\n",
      "        Val:   (min)  [415.498352 11.511134 3.818344]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.4548490047s\n",
      "    Total memory usage: 3807182848\n",
      "Epoch 210:\n",
      "    101120:  [3.502287 0.013575 0.350113 0.015488 1.189604] [3.502287 0.407240 1.750563 0.154881 1.189604] 0.65 0.000100366804957                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.7282691s\n",
      "    ----------------\n",
      "    Code entropy: 1.83844645755\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3966.5322, 39.616226, 3.765639066696167]\n",
      "    SA1 (arg):    [4034.3435, 39.952404, 3.756040334701538]\n",
      "    SX383:        [3209.9409, 30.118404, 3.7672152519226074]\n",
      "    SX383 (arg):  [3245.2954, 30.314022, 3.746014356613159]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7337.952918 46.559004 4.021777]\n",
      "        Train: (max)  [23797.134766 90.387283 4.437272]\n",
      "        Train: (min)  [703.989929 17.454987 2.211565]\n",
      "        Val:   (mean) [9070.399991 49.194347 4.145710]\n",
      "        Val:   (max)  [51764.203125 108.891182 4.399266]\n",
      "        Val:   (min)  [419.910950 11.584900 3.387348]\n",
      "    Best validation mean-PESQ seen: 4.16707407475\n",
      "    Total time for evaluation: 13.5259160995s\n",
      "    Total memory usage: 3807199232\n",
      "Epoch 211:\n",
      "    101120:  [3.522269 0.012099 0.364582 0.015113 1.185262] [3.522269 0.362962 1.822912 0.151132 1.185262] 0.65 0.000100448477512                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.667468071s\n",
      "    ----------------\n",
      "    Code entropy: 1.85339987491\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3879.917, 39.101143, 3.814051389694214]\n",
      "    SA1 (arg):    [3918.6243, 39.348221, 3.805330514907837]\n",
      "    SX383:        [3088.832, 29.622314, 3.773195505142212]\n",
      "    SX383 (arg):  [3127.2783, 29.882488, 3.74526309967041]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8235.888043 46.478274 4.087113]\n",
      "        Train: (max)  [67125.531250 107.581650 4.463122]\n",
      "        Train: (min)  [628.480103 16.315674 2.261645]\n",
      "        Val:   (mean) [8661.683765 47.972322 4.175266]\n",
      "        Val:   (max)  [50873.796875 106.194283 4.406411]\n",
      "        Val:   (min)  [399.477325 11.378177 3.812649]\n",
      "    NEW best model! Validation mean-PESQ 4.17526584387\n",
      "    Saving model...\n",
      "    Total time for evaluation: 13.6396350861s\n",
      "    Total memory usage: 3807404032\n",
      "Epoch 212:\n",
      "    101120:  [3.428258 0.012034 0.350506 0.015526 1.159438] [3.428258 0.361025 1.752532 0.155264 1.159438] 0.65 0.000100538325469                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.890336037s\n",
      "    ----------------\n",
      "    Code entropy: 1.84180813533\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3833.5439, 39.111839, 3.7481460571289062]\n",
      "    SA1 (arg):    [3883.4746, 39.41391, 3.732149600982666]\n",
      "    SX383:        [3200.8955, 30.103502, 3.824108600616455]\n",
      "    SX383 (arg):  [3244.9297, 30.374699, 3.789625644683838]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8234.958776 47.875988 4.070316]\n",
      "        Train: (max)  [35275.640625 102.365540 4.423910]\n",
      "        Train: (min)  [1023.666809 17.363871 3.524753]\n",
      "        Val:   (mean) [8682.128866 48.258512 4.142472]\n",
      "        Val:   (max)  [49575.519531 106.912460 4.418425]\n",
      "        Val:   (min)  [401.288422 11.361396 3.376492]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.6360459328s\n",
      "    Total memory usage: 3807358976\n",
      "Epoch 213:\n",
      "    101120:  [3.583985 0.015215 0.334381 0.015726 1.298371] [3.583985 0.456446 1.671907 0.157261 1.298371] 0.65 0.000100636338973                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 143.352483988s\n",
      "    ----------------\n",
      "    Code entropy: 1.83802208267\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3899.2563, 39.103218, 3.7393672466278076]\n",
      "    SA1 (arg):    [3964.2222, 39.460648, 3.743415355682373]\n",
      "    SX383:        [3134.3657, 29.67034, 3.83255934715271]\n",
      "    SX383 (arg):  [3161.4219, 29.870081, 3.7874350547790527]\n",
      "    Format: [MSE, avg err, PESQ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Train: (mean) [7084.563668 44.706720 4.102064]\n",
      "        Train: (max)  [36891.125000 117.277687 4.443181]\n",
      "        Train: (min)  [809.097229 17.476883 3.324991]\n",
      "        Val:   (mean) [8789.030560 48.533211 4.144813]\n",
      "        Val:   (max)  [49869.933594 108.544952 4.468220]\n",
      "        Val:   (min)  [414.291870 11.534764 3.257351]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.4500999451s\n",
      "    Total memory usage: 3807772672\n",
      "Epoch 214:\n",
      "    101120:  [3.593310 0.014070 0.362025 0.015520 1.205894] [3.593310 0.422095 1.810125 0.155196 1.205894] 0.65 0.000100742507277                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 143.324243069s\n",
      "    ----------------\n",
      "    Code entropy: 1.85431531989\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4054.7625, 39.984062, 3.6473593711853027]\n",
      "    SA1 (arg):    [4122.5244, 40.370834, 3.640838861465454]\n",
      "    SX383:        [3136.2678, 29.70096, 3.807729959487915]\n",
      "    SX383 (arg):  [3162.3115, 29.917645, 3.7807579040527344]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8268.040029 47.194669 4.094661]\n",
      "        Train: (max)  [44334.515625 119.351357 4.437795]\n",
      "        Train: (min)  [751.140869 17.274599 3.200060]\n",
      "        Val:   (mean) [9009.205892 49.098573 4.132612]\n",
      "        Val:   (max)  [51664.148438 109.108795 4.383636]\n",
      "        Val:   (min)  [424.400452 11.601463 3.278598]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.1919260025s\n",
      "    Total memory usage: 3807375360\n",
      "Epoch 215:\n",
      "    101120:  [3.459675 0.013842 0.334295 0.014998 1.222970] [3.459675 0.415247 1.671474 0.149983 1.222970] 0.65 0.000100856818738                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.481127977s\n",
      "    ----------------\n",
      "    Code entropy: 1.85927120055\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3879.2939, 39.190952, 3.725403308868408]\n",
      "    SA1 (arg):    [3937.3933, 39.573181, 3.6972012519836426]\n",
      "    SX383:        [3340.3152, 30.272562, 3.642831563949585]\n",
      "    SX383 (arg):  [3379.0684, 30.488508, 3.641455888748169]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7014.609883 45.289809 4.052261]\n",
      "        Train: (max)  [33996.843750 102.146729 4.444191]\n",
      "        Train: (min)  [1333.894409 21.824368 3.141853]\n",
      "        Val:   (mean) [8954.050479 48.811093 4.152587]\n",
      "        Val:   (max)  [51838.695312 109.596817 4.410861]\n",
      "        Val:   (min)  [407.677429 11.417391 3.316465]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.1706011295s\n",
      "    Total memory usage: 3807383552\n",
      "Epoch 216:\n",
      "    101120:  [3.464225 0.011742 0.351926 0.015251 1.199830] [3.464225 0.352254 1.759631 0.152509 1.199830] 0.65 0.000100979260821                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.632822037s\n",
      "    ----------------\n",
      "    Code entropy: 1.85145450064\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4149.7915, 39.774345, 3.799159288406372]\n",
      "    SA1 (arg):    [4215.2686, 40.212582, 3.7832841873168945]\n",
      "    SX383:        [3127.5022, 29.997509, 3.8146843910217285]\n",
      "    SX383 (arg):  [3157.5696, 30.209835, 3.791325092315674]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [9197.651107 50.451701 4.042451]\n",
      "        Train: (max)  [47825.019531 138.664352 4.421119]\n",
      "        Train: (min)  [991.129028 18.523930 3.127729]\n",
      "        Val:   (mean) [8998.276799 48.952935 4.159758]\n",
      "        Val:   (max)  [50835.191406 111.293907 4.416120]\n",
      "        Val:   (min)  [428.697601 11.632415 3.741332]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.318502903s\n",
      "    Total memory usage: 3807363072\n",
      "Epoch 217:\n",
      "    101120:  [3.527557 0.012973 0.355451 0.015118 1.209921] [3.527557 0.389202 1.777255 0.151180 1.209921] 0.65 0.000101109820098                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.81773591s\n",
      "    ----------------\n",
      "    Code entropy: 1.82989353378\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3810.5107, 38.930618, 3.8349545001983643]\n",
      "    SA1 (arg):    [3862.4512, 39.260303, 3.8287551403045654]\n",
      "    SX383:        [3127.0874, 29.793064, 3.763132095336914]\n",
      "    SX383 (arg):  [3153.2009, 30.003731, 3.749037027359009]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7245.862523 45.764343 4.057090]\n",
      "        Train: (max)  [26304.521484 88.130928 4.445459]\n",
      "        Train: (min)  [1229.763916 19.466652 2.270643]\n",
      "        Val:   (mean) [8661.653615 48.142283 4.156569]\n",
      "        Val:   (max)  [50273.773438 107.577446 4.416002]\n",
      "        Val:   (min)  [399.678375 11.302348 3.777076]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.3924291134s\n",
      "    Total memory usage: 3807375360\n",
      "Epoch 218:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    101120:  [3.563709 0.013026 0.361854 0.015299 1.210686] [3.563709 0.390769 1.809268 0.152985 1.210686] 0.65 0.000101248482252                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "    Total time for epoch: 142.858081102s\n",
      "    ----------------\n",
      "    Code entropy: 1.83853412217\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3760.8228, 38.844559, 3.720597743988037]\n",
      "    SA1 (arg):    [3841.9187, 39.284367, 3.705071210861206]\n",
      "    SX383:        [3123.2754, 29.70056, 3.605752468109131]\n",
      "    SX383 (arg):  [3147.2598, 29.916491, 3.589017391204834]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8197.077948 47.391869 4.055733]\n",
      "        Train: (max)  [35020.722656 100.148621 4.434010]\n",
      "        Train: (min)  [915.873169 17.540569 3.496402]\n",
      "        Val:   (mean) [8765.166054 48.565366 4.126040]\n",
      "        Val:   (max)  [50407.804688 108.012886 4.411840]\n",
      "        Val:   (min)  [412.744537 11.504496 3.379266]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.1095290184s\n",
      "    Total memory usage: 3807342592\n",
      "Epoch 219:\n",
      "    101120:  [3.438174 0.011200 0.359700 0.015221 1.151463] [3.438174 0.336006 1.798499 0.152207 1.151463] 0.65 0.000101395232078                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.688199043s\n",
      "    ----------------\n",
      "    Code entropy: 1.8576551439\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3940.5337, 39.705173, 3.668642997741699]\n",
      "    SA1 (arg):    [3988.8225, 39.962559, 3.647346258163452]\n",
      "    SX383:        [3167.8865, 30.028795, 3.802671194076538]\n",
      "    SX383 (arg):  [3221.2256, 30.347914, 3.796422004699707]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8954.129361 47.449395 4.033382]\n",
      "        Train: (max)  [47377.675781 138.147827 4.400023]\n",
      "        Train: (min)  [555.399902 15.033135 3.254567]\n",
      "        Val:   (mean) [8860.758316 48.875019 4.129022]\n",
      "        Val:   (max)  [50530.480469 109.556572 4.434700]\n",
      "        Val:   (min)  [412.400696 11.560843 3.373328]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.4069449902s\n",
      "    Total memory usage: 3807371264\n",
      "Epoch 220:\n",
      "    101120:  [3.562658 0.014640 0.341749 0.015848 1.256228] [3.562658 0.439210 1.708743 0.158477 1.256228] 0.65 0.000101550053482                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.788511038s\n",
      "    ----------------\n",
      "    Code entropy: 1.83873167344\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4049.0532, 39.924709, 3.737882375717163]\n",
      "    SA1 (arg):    [4137.936, 40.314358, 3.70137882232666]\n",
      "    SX383:        [3236.9756, 30.344219, 3.7204105854034424]\n",
      "    SX383 (arg):  [3273.2476, 30.625252, 3.709794759750366]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8218.759509 47.448387 4.023132]\n",
      "        Train: (max)  [85123.390625 124.449356 4.436020]\n",
      "        Train: (min)  [1249.533691 20.637085 3.171907]\n",
      "        Val:   (mean) [9034.361135 49.156954 4.133706]\n",
      "        Val:   (max)  [49938.968750 111.491753 4.412797]\n",
      "        Val:   (min)  [417.670227 11.600091 3.426286]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.366724968s\n",
      "    Total memory usage: 3807367168\n",
      "Epoch 221:\n",
      "    101120:  [3.583638 0.013442 0.351729 0.015696 1.264760] [3.583638 0.403274 1.758645 0.156959 1.264760] 0.65 0.000101712929487                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.821360111s\n",
      "    ----------------\n",
      "    Code entropy: 1.90183116533\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3725.5876, 38.196754, 3.8000526428222656]\n",
      "    SA1 (arg):    [3776.1821, 38.44688, 3.79412841796875]\n",
      "    SX383:        [3197.188, 29.930059, 3.7407586574554443]\n",
      "    SX383 (arg):  [3240.2571, 30.141783, 3.72784161567688]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8249.260016 47.288862 4.055652]\n",
      "        Train: (max)  [46901.957031 115.744362 4.438965]\n",
      "        Train: (min)  [501.787811 14.306213 3.063483]\n",
      "        Val:   (mean) [8642.505910 47.849591 4.164023]\n",
      "        Val:   (max)  [50764.734375 106.485481 4.417799]\n",
      "        Val:   (min)  [395.189697 11.284723 3.766068]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.3818621635s\n",
      "    Total memory usage: 3807350784\n",
      "Epoch 222:\n",
      "    101120:  [3.422267 0.011204 0.357631 0.015058 1.147413] [3.422267 0.336122 1.788155 0.150577 1.147413] 0.65 0.000101883842232                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.63586092s\n",
      "    ----------------\n",
      "    Code entropy: 1.84341100392\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3939.5439, 39.776569, 3.779221296310425]\n",
      "    SA1 (arg):    [4015.0378, 40.153332, 3.7293193340301514]\n",
      "    SX383:        [3158.0215, 29.874533, 3.7817180156707764]\n",
      "    SX383 (arg):  [3210.5447, 30.234795, 3.766831636428833]\n",
      "    Format: [MSE, avg err, PESQ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Train: (mean) [8938.434194 48.531702 4.011656]\n",
      "        Train: (max)  [44758.710938 106.473244 4.439744]\n",
      "        Train: (min)  [1055.224976 17.525166 3.065242]\n",
      "        Val:   (mean) [8830.951830 48.625332 4.130303]\n",
      "        Val:   (max)  [50206.984375 108.688995 4.411980]\n",
      "        Val:   (min)  [426.688904 11.657377 3.265307]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.2996869087s\n",
      "    Total memory usage: 3808145408\n",
      "Epoch 223:\n",
      "    101120:  [3.452085 0.010976 0.355138 0.015470 1.192415] [3.452085 0.329281 1.775691 0.154699 1.192415] 0.65 0.000102062772974                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "    Total time for epoch: 142.647857904s\n",
      "    ----------------\n",
      "    Code entropy: 1.85829634024\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3768.9827, 38.664028, 3.7645113468170166]\n",
      "    SA1 (arg):    [3844.5364, 39.044216, 3.7376153469085693]\n",
      "    SX383:        [3183.0601, 29.904076, 3.7627508640289307]\n",
      "    SX383 (arg):  [3222.5918, 30.147594, 3.7441353797912598]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8750.273074 50.188918 4.009849]\n",
      "        Train: (max)  [34695.480469 106.345261 4.440399]\n",
      "        Train: (min)  [1105.783569 19.562593 3.182913]\n",
      "        Val:   (mean) [8675.925529 48.097535 4.150094]\n",
      "        Val:   (max)  [48546.675781 108.424362 4.419547]\n",
      "        Val:   (min)  [396.965210 11.349050 3.797234]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.2811250687s\n",
      "    Total memory usage: 3808776192\n",
      "Epoch 224:\n",
      "    101120:  [3.478106 0.011432 0.360916 0.015015 1.180424] [3.478106 0.342948 1.804579 0.150155 1.180424] 0.65 0.000102249702091                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.502196074s\n",
      "    ----------------\n",
      "    Code entropy: 1.82770815224\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3846.9683, 39.227558, 3.6601386070251465]\n",
      "    SA1 (arg):    [3903.531, 39.575317, 3.6451003551483154]\n",
      "    SX383:        [3247.7109, 30.257206, 3.7570207118988037]\n",
      "    SX383 (arg):  [3277.5002, 30.515995, 3.7169406414031982]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8997.334853 48.790491 4.084711]\n",
      "        Train: (max)  [86563.023438 144.361298 4.459219]\n",
      "        Train: (min)  [949.887634 18.406069 3.175499]\n",
      "        Val:   (mean) [8865.000388 48.606930 4.149330]\n",
      "        Val:   (max)  [51288.843750 107.344017 4.432425]\n",
      "        Val:   (min)  [413.006012 11.575027 3.682523]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.010573864s\n",
      "    Total memory usage: 3807371264\n",
      "Epoch 225:\n",
      "    101120:  [3.427473 0.011731 0.347060 0.014991 1.190343] [3.427473 0.351925 1.735299 0.149907 1.190343] 0.65 0.000102444609085                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.408216s\n",
      "    ----------------\n",
      "    Code entropy: 1.83180631396\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3928.4109, 39.312183, 3.7384607791900635]\n",
      "    SA1 (arg):    [3965.6948, 39.5485, 3.7310962677001953]\n",
      "    SX383:        [3304.0271, 30.467892, 3.707326650619507]\n",
      "    SX383 (arg):  [3337.5024, 30.690773, 3.69520902633667]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8617.454585 48.124515 4.086192]\n",
      "        Train: (max)  [49598.316406 108.441551 4.458345]\n",
      "        Train: (min)  [910.877441 18.026461 3.177541]\n",
      "        Val:   (mean) [8917.548089 48.571658 4.154204]\n",
      "        Val:   (max)  [52324.816406 108.321129 4.405779]\n",
      "        Val:   (min)  [413.642120 11.477529 3.382895]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.4735810757s\n",
      "    Total memory usage: 3807440896\n",
      "Epoch 226:\n",
      "    101120:  [3.459059 0.012588 0.345925 0.015090 1.200898] [3.459059 0.377632 1.729625 0.150903 1.200898] 0.65 0.000102647472581                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.502629995s\n",
      "    ----------------\n",
      "    Code entropy: 1.855767492\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3937.1196, 39.370743, 3.7896251678466797]\n",
      "    SA1 (arg):    [3982.0562, 39.622028, 3.774080276489258]\n",
      "    SX383:        [3316.4233, 30.235718, 3.734696865081787]\n",
      "    SX383 (arg):  [3359.6379, 30.518261, 3.7156119346618652]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8122.452356 46.010043 4.027980]\n",
      "        Train: (max)  [49321.449219 118.208099 4.460812]\n",
      "        Train: (min)  [1005.911255 17.458214 3.347517]\n",
      "        Val:   (mean) [9056.406447 48.788408 4.173189]\n",
      "        Val:   (max)  [53138.671875 108.635117 4.438823]\n",
      "        Val:   (min)  [417.246887 11.527153 3.776997]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.2011461258s\n",
      "    Total memory usage: 3807383552\n",
      "Epoch 227:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    101120:  [3.397980 0.012594 0.340823 0.014552 1.170539] [3.397980 0.377808 1.704114 0.145519 1.170539] 0.65 0.000102858270334                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "    Total time for epoch: 142.140394926s\n",
      "    ----------------\n",
      "    Code entropy: 1.85905619574\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3920.2666, 39.524754, 3.775261878967285]\n",
      "    SA1 (arg):    [4006.6592, 39.930569, 3.7448267936706543]\n",
      "    SX383:        [3292.8979, 30.487892, 3.6836862564086914]\n",
      "    SX383 (arg):  [3327.1865, 30.731636, 3.667433261871338]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8482.354874 48.139591 4.015766]\n",
      "        Train: (max)  [43870.921875 120.891624 4.383109]\n",
      "        Train: (min)  [1010.626709 17.296728 3.162009]\n",
      "        Val:   (mean) [8999.750499 48.970670 4.143404]\n",
      "        Val:   (max)  [52289.964844 110.724777 4.399484]\n",
      "        Val:   (min)  [406.873749 11.444176 3.348004]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.1907410622s\n",
      "    Total memory usage: 3807375360\n",
      "Epoch 228:\n",
      "    101120:  [3.412894 0.011530 0.346694 0.015125 1.182273] [3.412894 0.345904 1.733468 0.151249 1.182273] 0.65 0.000103076979227                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.414224148s\n",
      "    ----------------\n",
      "    Code entropy: 1.86064820499\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3867.4023, 39.149464, 3.780773162841797]\n",
      "    SA1 (arg):    [3915.1211, 39.450226, 3.7608044147491455]\n",
      "    SX383:        [3131.1741, 29.734106, 3.757669687271118]\n",
      "    SX383 (arg):  [3194.6096, 30.117722, 3.7185046672821045]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8809.691203 49.371773 4.050948]\n",
      "        Train: (max)  [38282.109375 100.436554 4.462444]\n",
      "        Train: (min)  [945.748596 17.265287 3.269629]\n",
      "        Val:   (mean) [8871.856952 48.578391 4.165271]\n",
      "        Val:   (max)  [51214.496094 108.253944 4.441308]\n",
      "        Val:   (min)  [416.095825 11.580424 3.749789]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.3868072033s\n",
      "    Total memory usage: 3809234944\n",
      "Epoch 229:\n",
      "    101120:  [3.453310 0.012477 0.344640 0.015301 1.202794] [3.453310 0.374305 1.723200 0.153011 1.202794] 0.65 0.000103303575277                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "    Total time for epoch: 142.695064068s\n",
      "    ----------------\n",
      "    Code entropy: 1.82635552085\n",
      "    Tau stays at 0.65\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3947.5781, 39.602692, 3.7597694396972656]\n",
      "    SA1 (arg):    [4002.1772, 39.932621, 3.7365517616271973]\n",
      "    SX383:        [3112.4197, 29.743757, 3.775174856185913]\n",
      "    SX383 (arg):  [3153.0024, 30.015123, 3.7435836791992188]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8569.932548 48.586818 4.015731]\n",
      "        Train: (max)  [43627.027344 108.294975 4.434348]\n",
      "        Train: (min)  [740.581238 17.298830 3.190638]\n",
      "        Val:   (mean) [8809.201347 48.700610 4.122778]\n",
      "        Val:   (max)  [49705.769531 107.996338 4.406538]\n",
      "        Val:   (min)  [421.916168 11.603997 3.315958]\n",
      "    Best validation mean-PESQ seen: 4.17526584387\n",
      "    Total time for evaluation: 13.0166649818s\n",
      "    Total memory usage: 3807399936\n",
      "Epoch 230:\n",
      "    39680:  [3.526616 0.014206 0.348417 0.015334 1.205006] [3.526616 0.426182 1.742083 0.153345 1.205006] 0.65 0.000103395712053                                                                                                                                                                                                                                                                                   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-749059559888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_recons\u001b[0m \u001b[0;34m+\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# print statistics every 10 batches so we know what's going on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "lead = \"    \"\n",
    "\n",
    "for epoch in range(200, NUM_EPOCHS + 1):\n",
    "    print \"Epoch \" + str(epoch) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    num_batches = len(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        # cosine annealing for model's learning rate\n",
    "        train_pct = T_i / float(NUM_EPOCHS)\n",
    "        opt_lr = ENDING_LR + 0.5 * (STARTING_LR - ENDING_LR) * (1 + math.cos(3.14159 * train_pct))\n",
    "        T_i += (1.0 / num_batches)\n",
    "        K.set_value(model.optimizer.lr, opt_lr)\n",
    "        \n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :]\n",
    "        nbatch = batch.shape[0]\n",
    "               \n",
    "        # train autoencoder\n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.zeros((nbatch, 1, 1))] * n_code\n",
    "\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau), opt_lr,\n",
    "        \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # estimate code entropy from random samples (if quantization is on)\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        NUM = 20000\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        to_predict = np.copy(X_train[rows, :])\n",
    "        code = encoder.predict(to_predict, verbose = 0, batch_size = 128)\n",
    "        \n",
    "        all_onehots = np.reshape(code, (-1, NBINS))\n",
    "        onehot_hist = np.sum(all_onehots, axis = 0)\n",
    "        onehot_hist /= np.sum(onehot_hist)\n",
    "\n",
    "        entropy = 0\n",
    "        for i in onehot_hist:\n",
    "            if (i < 1e-5): continue\n",
    "            entropy += i * math.log(i, 2)\n",
    "        entropy = -entropy\n",
    "\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Code entropy:\", entropy\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # handle updating entropy weight (tau)\n",
    "        # ---------------------------------------------------------\n",
    "        old_tau = K.get_value(tau)\n",
    "\n",
    "        if (entropy < TARGET_ENTROPY - TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau - TAU_CHANGE_RATE\n",
    "            if (new_tau < 0.0):\n",
    "                new_tau = 0.0\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        elif (entropy > TARGET_ENTROPY + TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau + TAU_CHANGE_RATE\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        else:\n",
    "            print lead + \"Tau stays at\", old_tau\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    \n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SA1:         \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                    autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SA1 (arg):   \", metrics\n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SX383:       \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                    autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SX383 (arg): \", metrics\n",
    "    \n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        val_pesq = evaluate_training(autoencoder, lead)\n",
    "        if (val_pesq > best_val_pesq and entropy <= TARGET_ENTROPY):\n",
    "            print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "\n",
    "            print lead + \"Saving model...\"\n",
    "            save_model()\n",
    "            best_val_pesq = val_pesq\n",
    "            patience_epoch = epoch\n",
    "        else:\n",
    "            print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_used = process.memory_info().rss\n",
    "    print lead + \"Total memory usage: \" + str(mem_used)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # turn quantization on after a certain # of epochs\n",
    "    # ---------------------------------------------------------\n",
    "    if (epoch == EPOCHS_BEFORE_QUANT_ON):\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Turning quantization on!\"\n",
    "        \n",
    "        random_windows = []\n",
    "        for i in xrange(0, NUM_QUANT_VECS):\n",
    "            w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "            random_windows.append(train_processed[w_idx])\n",
    "\n",
    "        random_windows = np.array(random_windows)\n",
    "        print lead + \"    Selecting random code vectors for analysis...\"\n",
    "        encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "        encoded_windows = encoded_windows[:, :, 0]\n",
    "        encoded_windows = np.reshape(encoded_windows, (-1, 1))\n",
    "\n",
    "        print lead + \"    K means clustering for bins initialization...\"\n",
    "        km = MiniBatchKMeans(n_clusters = NBINS).fit(encoded_windows)\n",
    "        clustered_bins = km.cluster_centers_.flatten()\n",
    "        \n",
    "        cluster_score = np.sqrt(np.median(np.min(km.transform(encoded_windows), axis = 1)))\n",
    "        print lead + \"    Done. Cluster score:\", cluster_score\n",
    "        \n",
    "        K.set_value(QUANTIZATION_ON, True)\n",
    "        K.set_value(QUANT_BINS, clustered_bins)\n",
    "        K.set_value(tau, INITIAL_TAU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_model('haha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
