{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from nn_util import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import load_model\n",
    "from keras.losses import *\n",
    "import scipy.io.wavfile as sciwav\n",
    "import multiprocessing\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from mem_top import mem_top\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)\n",
    "\n",
    "# increase recursion limit for adaptive VQ\n",
    "#import sys\n",
    "#sys.setrecursionlimit(40000)\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# control amount of GPU memory used\n",
    "#import tensorflow as tf\n",
    "#from keras.backend.tensorflow_backend import set_session\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth=True\n",
    "#set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from pesq import *\n",
    "from consts import *\n",
    "from nn_blocks import *\n",
    "from perceptual_loss import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101814, 512, 1)\n",
      "2.44142e-06\n",
      "0.0994002\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE, 1))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nidx = 5\\n\\nprint train_paths[idx]\\n\\nre = reconstruct_from_windows(train_windows[idx], OVERLAP_SIZE)\\nre = unpreprocess_waveform(re, train_wparams[idx])\\nre = np.clip(re, -32767, 32767)\\nsciwav.write('./re.wav', SAMPLE_RATE, re.astype(np.int16))\\n\\nprint WINDOWING_MULT[:32] + WINDOWING_MULT[-32:]\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "idx = 5\n",
    "\n",
    "print train_paths[idx]\n",
    "\n",
    "re = reconstruct_from_windows(train_windows[idx], OVERLAP_SIZE)\n",
    "re = unpreprocess_waveform(re, train_wparams[idx])\n",
    "re = np.clip(re, -32767, 32767)\n",
    "sciwav.write('./re.wav', SAMPLE_RATE, re.astype(np.int16))\n",
    "\n",
    "print WINDOWING_MULT[:32] + WINDOWING_MULT[-32:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_SIZE = WINDOW_SIZE / 2\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure():   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 32\n",
    "    FILT_SIZE = 9\n",
    "    NUM_SCALES = 4\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "    enc = enc_input\n",
    "    \n",
    "    enc = channel_change_block(NCHAN, FILT_SIZE)(enc)\n",
    "    \n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 4)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 8)(enc)\n",
    "    enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 4)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 8)(enc)\n",
    "    \n",
    "    enc = channel_change_block(QUANT_CHANS, FILT_SIZE)(enc)\n",
    "    \n",
    "    # quantization\n",
    "    enc = Reshape((CHANNEL_SIZE, QUANT_CHANS))(enc)\n",
    "    pre_quant = Model(inputs = enc_input, outputs = enc)\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc, name = 'encoder')\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (CHANNEL_SIZE, QUANT_CHANS, NBINS))\n",
    "    \n",
    "    dec = dec_input\n",
    "    dec = SoftmaxDequantization()(dec)\n",
    "    post_dequant = Model(inputs = dec_input, outputs = dec)\n",
    "    dec = Reshape((CHANNEL_SIZE, QUANT_CHANS))(dec)\n",
    "    \n",
    "    dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    \n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 8)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 4)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 8)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 4)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    \n",
    "    dec = channel_change_block(1, FILT_SIZE)(dec)\n",
    "    \n",
    "    dec = Model(inputs = dec_input, outputs = dec, name = 'decoder')\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec, pre_quant, post_dequant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'code_entropy' : code_entropy,\n",
    "                  'code_sparsity' : code_sparsity,\n",
    "                  'rmse' : rmse,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization,\n",
    "                  'DFT_REAL' : DFT_REAL,\n",
    "                  'DFT_IMAG' : DFT_IMAG,\n",
    "                  'MEL_FILTERBANKS' : MEL_FILTERBANKS,\n",
    "                  'keras_dft_mag' : keras_dft_mag,\n",
    "                  'keras_dct' : keras_dct,\n",
    "                  'perceptual_transform' : perceptual_transform,\n",
    "                  'perceptual_distance' : perceptual_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "\n",
    "encoder, decoder, pre_quant, post_dequant = autoencoder_structure()\n",
    "ac_reconstructed = decoder(encoder(ac_input))\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "loss_weights = [30.0, 5.0, 10.0, 1.0]\n",
    "loss_functions = [rmse, perceptual_distance, code_sparsity, code_entropy]\n",
    "n_recons = 2\n",
    "n_code = 2\n",
    "assert(n_recons + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1511: UserWarning: The list of outputs passed to the model is redundant. All outputs should only appear once. Found: [<tf.Tensor 'decoder_1/add_22/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'decoder_1/add_22/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'encoder_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 1, 32) dtype=float32>, <tf.Tensor 'encoder_1/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 1, 32) dtype=float32>]\n",
      "  ' Found: ' + str(self.outputs))\n"
     ]
    }
   ],
   "source": [
    "# model specification\n",
    "model_input = Input(shape = (WINDOW_SIZE, 1))\n",
    "model_embedding = encoder(model_input)\n",
    "model_pre_quant = pre_quant(model_input)\n",
    "model_reconstructed = decoder(model_embedding)\n",
    "model_post_dequant = post_dequant(model_embedding)\n",
    "\n",
    "model = Model(inputs = [model_input], outputs = [model_reconstructed] * n_recons + \\\n",
    "                                            [model_embedding] * n_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 256, 1, 32)        186927    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 512, 1)            233167    \n",
      "=================================================================\n",
      "Total params: 420,094\n",
      "Trainable params: 420,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         154632.0\n",
      "Avg err:     210.231\n",
      "PESQ:        1.03064227104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[154632.45, 210.2307, 1.0306422710418701]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get untrained baseline for model\n",
    "test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_uninit\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves current model\n",
    "def save_model(prefix = 'best'):\n",
    "    os.system('rm ./' + prefix + '_model.h5')\n",
    "    os.system('rm ./' + prefix + '_auto.h5')\n",
    "    #os.system('rm ./' + prefix + '_quant_bins.npy')\n",
    "    \n",
    "    model.save('./' + prefix + '_model.h5')\n",
    "    autoencoder.save('./' + prefix + '_auto.h5')\n",
    "    #np.save('./' + prefix + '_quant_bins.npy', K.eval(QUANT_BINS))\n",
    "    \n",
    "    f = h5py.File('./' + prefix + '_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    def set_evaluation(paths, eval_idxs):\n",
    "        NUM_THREADS = 8\n",
    "        \n",
    "        before_after_pairs = [run_model_on_wav(paths[i],\n",
    "                                               autoencoder,\n",
    "                                               argmax = True)\n",
    "                              for i in eval_idxs]\n",
    "        \n",
    "        def thread_func(my_id, q):\n",
    "            my_slice = np.arange(my_id, len(eval_idxs), NUM_THREADS)\n",
    "            \n",
    "            for i in my_slice:\n",
    "                p = before_after_pairs[i]\n",
    "                q.put(evaluation_metrics(p[0], p[1]))\n",
    "        \n",
    "        q = multiprocessing.Queue()\n",
    "        threads = [multiprocessing.Process(target = thread_func,\n",
    "                                           args = (i, q))\n",
    "                   for i in xrange(0, NUM_THREADS)]\n",
    "        [t.start() for t in threads]\n",
    "        [t.join() for t in threads]\n",
    "        results = np.array([q.get() for i in xrange(0, len(eval_idxs))])\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    train_eval_idxs = random.sample(range(0, len(train_paths)), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_paths)), VAL_EVALUATE)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    \n",
    "    # train set evaluation\n",
    "    train_metrics = set_evaluation(train_paths,\n",
    "                                   train_eval_idxs)\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    \n",
    "    # validation set evaluation\n",
    "    val_metrics = set_evaluation(val_paths,\n",
    "                                 val_eval_idxs)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 2.34375\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 300\n",
    "EPOCHS_BEFORE_QUANT_ON = 5\n",
    "#EPOCHS_BEFORE_TAU = 20\n",
    "\n",
    "ORIG_BITRATE = 256.00\n",
    "TARGET_BITRATE = 20.00\n",
    "PRE_ENTROPY_RATE = ORIG_BITRATE * (float(CHANNEL_SIZE) / WINDOW_SIZE)\n",
    "\n",
    "TARGET_ENTROPY = (TARGET_BITRATE / PRE_ENTROPY_RATE * 16.0)\n",
    "TARGET_ENTROPY *= (STEP_SIZE / float(WINDOW_SIZE))\n",
    "TARGET_ENTROPY_FUZZ = 0.1\n",
    "\n",
    "TAU_CHANGE_RATE = 0.025\n",
    "INITIAL_TAU = 0.5\n",
    "MIN_TAU = 0.0\n",
    "\n",
    "NUM_QUANT_VECS = 5000\n",
    "\n",
    "STARTING_LR = 0.00025\n",
    "ENDING_LR = 0.0001\n",
    "\n",
    "print \"Target entropy:\", TARGET_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_val_pesq = 0.0\n",
    "K.set_value(tau, 0.0)\n",
    "T_i = 0.0\n",
    "K.set_value(QUANTIZATION_ON, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "lead = \"    \"\n",
    "\n",
    "for epoch in range(213, NUM_EPOCHS + 1):\n",
    "    print \"Epoch \" + str(epoch) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    num_batches = len(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        # cosine annealing for model's learning rate\n",
    "        train_pct = T_i / float(NUM_EPOCHS)\n",
    "        opt_lr = ENDING_LR + 0.5 * (STARTING_LR - ENDING_LR) * (1 + math.cos(3.14159 * train_pct))\n",
    "        T_i += (1.0 / num_batches)\n",
    "        K.set_value(model.optimizer.lr, opt_lr)\n",
    "        \n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "               \n",
    "        # train autoencoder\n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.zeros((nbatch, 1, 1, 1))] * n_code\n",
    "\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau), opt_lr,\n",
    "        \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # estimate code entropy from random samples (if quantization is on)\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        NUM = 20000\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        to_predict = np.copy(X_train[rows, :])\n",
    "        code = encoder.predict(to_predict, verbose = 0, batch_size = 128)\n",
    "        \n",
    "        all_onehots = np.reshape(code, (-1, QUANT_CHANS, NBINS))\n",
    "        onehot_hist = np.sum(all_onehots, axis = 0)\n",
    "        onehot_hist /= np.sum(onehot_hist, axis = 1, keepdims = True)\n",
    "        \n",
    "        # entropy for each channel\n",
    "        channel_entropy = -np.sum(onehot_hist * np.log(onehot_hist + np.finfo(float).eps) / np.log(2.0),\n",
    "                                  axis = 1)\n",
    "\n",
    "        # total entropy\n",
    "        entropy = np.sum(channel_entropy)\n",
    "\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Code entropy:\", entropy\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # handle updating entropy weight (tau)\n",
    "        # ---------------------------------------------------------\n",
    "        old_tau = K.get_value(tau)\n",
    "\n",
    "        if (entropy < TARGET_ENTROPY - TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau - TAU_CHANGE_RATE\n",
    "            if (new_tau <= MIN_TAU):\n",
    "                new_tau = MIN_TAU\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        elif (entropy > TARGET_ENTROPY + TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau + TAU_CHANGE_RATE\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        else:\n",
    "            print lead + \"Tau stays at\", old_tau\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    \n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SA1:         \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                    autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SA1 (arg):   \", metrics\n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SX383:       \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                    autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SX383 (arg): \", metrics\n",
    "    \n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        val_pesq = evaluate_training(autoencoder, lead)\n",
    "        if (val_pesq > best_val_pesq and entropy <= TARGET_ENTROPY):\n",
    "            print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "\n",
    "            print lead + \"Saving model...\"\n",
    "            save_model()\n",
    "            best_val_pesq = val_pesq\n",
    "            patience_epoch = epoch\n",
    "        else:\n",
    "            print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_used = process.memory_info().rss\n",
    "    print lead + \"Total memory usage: \" + str(mem_used)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # turn quantization on after a certain # of epochs\n",
    "    # ---------------------------------------------------------\n",
    "    if (epoch == EPOCHS_BEFORE_QUANT_ON):\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Turning quantization on!\"\n",
    "        \n",
    "        random_windows = []\n",
    "        for i in xrange(0, NUM_QUANT_VECS):\n",
    "            w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "            random_windows.append(train_processed[w_idx])\n",
    "\n",
    "        random_windows = np.array(random_windows)\n",
    "        print lead + \"    Selecting random code vectors for analysis...\"\n",
    "        encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "\n",
    "        print lead + \"    K means clustering for bins initialization...\"\n",
    "\n",
    "        all_clustered = []\n",
    "        cluster_scores = []\n",
    "        for i in xrange(0, QUANT_CHANS):\n",
    "            channel_values = encoded_windows[:, :, i, 0]\n",
    "            channel_values = np.reshape(channel_values, (-1, 1))\n",
    "\n",
    "            km = MiniBatchKMeans(n_clusters = NBINS).fit(channel_values)\n",
    "            clustered = np.sort(km.cluster_centers_.flatten())\n",
    "            all_clustered.append(clustered)\n",
    "\n",
    "            cluster_score = np.sqrt(np.median(np.min(km.transform(channel_values), axis = 1)))\n",
    "            cluster_scores.append(cluster_score)\n",
    "\n",
    "        print lead + \"    Done. Cluster scores:\", cluster_scores\n",
    "        \n",
    "        clustered_bins = np.vstack(all_clustered)\n",
    "        K.set_value(QUANTIZATION_ON, True)\n",
    "        K.set_value(QUANT_BINS, clustered_bins)\n",
    "        K.set_value(tau, INITIAL_TAU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_model('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1511: UserWarning: The list of outputs passed to the model is redundant. All outputs should only appear once. Found: [<tf.Tensor 'decoder_2/add_22/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'decoder_2/add_22/add:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'encoder_2/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 1, 32) dtype=float32>, <tf.Tensor 'encoder_2/softmax_quantization_1/cond/Merge:0' shape=(?, 256, 1, 32) dtype=float32>]\n",
      "  ' Found: ' + str(self.outputs))\n",
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:258: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    model = load_model('best_model.h5', KERAS_LOAD_MAP)\n",
    "    autoencoder = load_model('best_auto.h5', KERAS_LOAD_MAP)\n",
    "    encoder = autoencoder.layers[1]\n",
    "    decoder = autoencoder.layers[2]\n",
    "    K.set_value(QUANTIZATION_ON, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder)\n",
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder)\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder)\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder, argmax = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embed = encoder.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.reshape(all_embed, (all_embed.shape[0] * all_embed.shape[1], QUANT_CHANS, NBINS))\n",
    "hist = np.sum(probs, axis = 0)\n",
    "hist /= np.sum(hist, axis = 1, keepdims = True)\n",
    "\n",
    "for i in xrange(0, hist.shape[0]):\n",
    "    print \"--- CHANNEL\", i, \"---\"\n",
    "    \n",
    "    sample_hist_bins = np.linspace(0, NBINS - 1, NBINS)\n",
    "    plt.bar(sample_hist_bins, hist[i], align = 'center', width = 1)\n",
    "    plt.show()\n",
    "    \n",
    "    entropy = 0\n",
    "    for j in hist[i]:\n",
    "        if (j < 1e-4): continue\n",
    "        entropy += j * math.log(j, 2)\n",
    "    entropy = -entropy\n",
    "    print \"Entropy of distribution:\", entropy\n",
    "    \n",
    "    print \"Hist:\", hist[i]\n",
    "    print \"Bins:\", K.eval(QUANT_BINS[i])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = all_embed[0]\n",
    "\n",
    "oh = K.eval(K.one_hot(K.argmax(K.variable(s)), NBINS))\n",
    "\n",
    "print s.shape\n",
    "print oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocess_waveform(data)\n",
    "windows = extract_windows(processedWave, STEP_SIZE, OVERLAP_SIZE,\n",
    "                          WINDOWING_MULT)\n",
    "\n",
    "transformed = np.reshape(windows, (windows.shape[0], WINDOW_SIZE, 1))\n",
    "embed = encoder.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons = decoder.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_quantization = pre_quant.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)\n",
    "after_dequantization = post_dequant.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pct = np.max(embed[25], axis = -1)\n",
    "print max_pct\n",
    "print np.argmax(embed[25], axis = -1)\n",
    "print np.sum(max_pct > 0.98) / float(max_pct.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_max = np.max(embed, axis = -1)\n",
    "print np.mean(embed_max)\n",
    "print np.sum(embed_max > 0.98) / float(embed_max.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 44\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "print \"Original\"\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "print \"Reconstruction\"\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    print \"Before quantization\"\n",
    "    plt.plot(before_quantization[idx])\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.show()\n",
    "\n",
    "    print \"After dequantization\"\n",
    "    plt.plot(after_dequantization[idx])\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()\n",
    "else:\n",
    "    print \"Embedding\"\n",
    "    plt.plot(before_quantization[idx])\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.show()\n",
    "\n",
    "print \"Error\"\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
