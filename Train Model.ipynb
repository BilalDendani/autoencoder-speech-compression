{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 Ti (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import load_model\n",
    "from keras.losses import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import *\n",
    "from scipy.fftpack import dct, idct\n",
    "from keras.activations import softmax\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import scipy.io.wavfile as sciwav\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)\n",
    "\n",
    "# increase recursion limit for adaptive VQ\n",
    "import sys\n",
    "sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from utility import *\n",
    "from pesq import *\n",
    "from consts import *\n",
    "from nn_blocks import *\n",
    "from transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# number of speech files for train, val, and test\n",
    "TRAIN_SIZE = 1000\n",
    "VAL_SIZE = 100\n",
    "TEST_SIZE = 500\n",
    "\n",
    "# during training, we evaluate PESQ and RMSE and such on full speech files every epoch, which\n",
    "# is kind of expensive. so instead of selecting the full training and validation set, we\n",
    "# randomly select this many waveforms\n",
    "TRAIN_EVALUATE = 50\n",
    "VAL_EVALUATE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSJK1/SI1025.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MPPC0/SX152.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FLAC0/SI1339.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLBC0/SX339.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLOD0/SX117.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSDJ0/SA1.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA1.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SI721.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SA1.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FLMC0/SI1372.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAKR0/SX272.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FJWB1/SI2055.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLOD0/SA1.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSDJ0/SX305.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI2311.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SX411.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX54.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FLMC0/SX336.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FLJD0/SX346.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMGC0/SX315.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJA0/SI1708.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FRJB0/SI1470.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI979.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FNKL0/SX172.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA2.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDSS0/SX171.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJLG1/SA2.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FKLC0/SA1.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MGSH0/SI1176.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKLN0/SA2.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI2282.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SX352.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMGG0/SX269.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FLMC0/SX22.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MADC0/SI1997.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MKAM0/SA2.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEWM0/SI1978.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MESJ0/SA1.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SA2.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SA2.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX37.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJBG0/SX332.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCDC0/SI662.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FCAG0/SI1641.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MCHL0/SX87.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEJL0/SI1592.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI2126.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FNKL0/SX442.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJEB1/SX387.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDXW0/SX161.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSJW0/SX343.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLSH0/SI2047.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSDC0/SA1.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKES0/SX443.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX158.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SA1.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSAH0/SX327.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJEB0/SX26.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAKR0/SX92.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MFWK0/SI1879.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSKP0/SX288.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MPGR1/SI1269.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX359.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FJRB0/SA2.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MGRL0/SX147.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MARC0/SA1.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAPV0/SX123.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMDM0/SX141.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSMM0/SX414.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FJDM2/SI1582.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SA1.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SI2121.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX144.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FSRH0/SI1719.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FPAZ0/SA2.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MESG0/SA1.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FKKH0/SX120.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MAJP0/SX444.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX400.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SX70.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FKFB0/SI1608.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCMM0/SI453.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FALK0/SX186.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MESG0/SI702.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMVP0/SA2.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MABC0/SI2041.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX78.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SX178.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MCPM0/SA2.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDEM0/SI608.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMEB0/SI1357.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FLHD0/SI1827.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FGMB0/SI515.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SI1063.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX253.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SX93.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI2067.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJHI0/SX68.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDLH0/SX160.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FKDW0/SA2.WAV\r",
      "100: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMAB1/SA2.WAV\r",
      "101: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MCAE0/SX97.WAV\r",
      "102: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX391.WAV\r",
      "103: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FPLS0/SX330.WAV\r",
      "104: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVFB0/SX42.WAV\r",
      "105: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJMD0/SA2.WAV\r",
      "106: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDTB0/SA1.WAV\r",
      "107: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLEL0/SX76.WAV\r",
      "108: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDWH0/SX305.WAV\r",
      "109: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FLAG0/SX204.WAV\r",
      "110: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX426.WAV\r",
      "111: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SX127.WAV\r",
      "112: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1778.WAV\r",
      "113: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDEM0/SX338.WAV\r",
      "114: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMEB0/SI1987.WAV\r",
      "115: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FLHD0/SA1.WAV\r",
      "116: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMWB0/SA1.WAV\r",
      "117: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FHXS0/SA1.WAV\r",
      "118: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI1047.WAV\r",
      "119: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SA1.WAV\r",
      "120: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA2.WAV\r",
      "121: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FLMA0/SI1873.WAV\r",
      "122: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDHS0/SX180.WAV\r",
      "123: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJXL0/SA1.WAV\r",
      "124: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FEXM0/SX291.WAV\r",
      "125: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FPAD0/SA1.WAV\r",
      "126: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI2318.WAV\r",
      "127: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SA2.WAV\r",
      "128: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1149.WAV\r",
      "129: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMDS0/SX443.WAV\r",
      "130: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSKC0/SX426.WAV\r",
      "131: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGAG0/SA1.WAV\r",
      "132: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJWG0/SX265.WAV\r",
      "133: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FBCH0/SX56.WAV\r",
      "134: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA2.WAV\r",
      "135: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SI610.WAV\r",
      "136: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FKFB0/SX438.WAV\r",
      "137: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDXW0/SX251.WAV\r",
      "138: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDDC0/SI789.WAV\r",
      "139: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLEL0/SA1.WAV\r",
      "140: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FTLG0/SI483.WAV\r",
      "141: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MJRK0/SX70.WAV\r",
      "142: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX219.WAV\r",
      "143: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SX3.WAV\r",
      "144: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSJK1/SI2285.WAV\r",
      "145: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJRP0/SX405.WAV\r",
      "146: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCDC0/SX302.WAV\r",
      "147: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FLHD0/SX444.WAV\r",
      "148: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDHL0/SI2069.WAV\r",
      "149: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MCAE0/SX277.WAV\r",
      "150: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI2110.WAV\r",
      "151: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SX267.WAV\r",
      "152: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI1466.WAV\r",
      "153: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FMKF0/SI1536.WAV\r",
      "154: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDLC0/SX225.WAV\r",
      "155: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MARW0/SX106.WAV\r",
      "156: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJFH0/SX387.WAV\r",
      "157: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MJRK0/SA1.WAV\r",
      "158: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA2.WAV\r",
      "159: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SX268.WAV\r",
      "160: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI1844.WAV\r",
      "161: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJRP0/SX315.WAV\r",
      "162: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAR0/SX256.WAV\r",
      "163: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJMM0/SX445.WAV\r",
      "164: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSKP0/SX198.WAV\r",
      "165: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSDJ0/SX125.WAV\r",
      "166: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX169.WAV\r",
      "167: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SX357.WAV\r",
      "168: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSJK1/SI696.WAV\r",
      "169: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FRLL0/SI1514.WAV\r",
      "170: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJRH1/SI1774.WAV\r",
      "171: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MKAM0/SA1.WAV\r",
      "172: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJG0/SX81.WAV\r",
      "173: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FRJB0/SX347.WAV\r",
      "174: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA1.WAV\r",
      "175: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SX430.WAV\r",
      "176: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MGRL0/SA1.WAV\r",
      "177: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDAS1/SX381.WAV\r",
      "178: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDWM0/SI1546.WAV\r",
      "179: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FKDW0/SX217.WAV\r",
      "180: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJDM0/SA2.WAV\r",
      "181: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MBMA1/SI954.WAV\r",
      "182: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX334.WAV\r",
      "183: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SI2197.WAV\r",
      "184: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX444.WAV\r",
      "185: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FHLM0/SX300.WAV\r",
      "186: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MHJB0/SX387.WAV\r",
      "187: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MBWP0/SX169.WAV\r",
      "188: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MHIT0/SI983.WAV\r",
      "189: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MCAE0/SX7.WAV\r",
      "190: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX40.WAV\r",
      "191: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FPLS0/SA1.WAV\r",
      "192: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX206.WAV\r",
      "193: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJBG0/SI1862.WAV\r",
      "194: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MBEF0/SX381.WAV\r",
      "195: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FJXP0/SI1122.WAV\r",
      "196: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FEAR0/SI1252.WAV\r",
      "197: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FMJU0/SX309.WAV\r",
      "198: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX355.WAV\r",
      "199: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SA1.WAV\r",
      "200: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SA1.WAV\r",
      "201: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDNC0/SX378.WAV\r",
      "202: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FJLG0/SX449.WAV\r",
      "203: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MAEB0/SI2250.WAV\r",
      "204: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FTBW0/SX85.WAV\r",
      "205: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEJL0/SX152.WAV\r",
      "206: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX197.WAV\r",
      "207: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SI1248.WAV\r",
      "208: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX150.WAV\r",
      "209: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCMM0/SA1.WAV\r",
      "210: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAKB0/SX206.WAV\r",
      "211: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJSR0/SX344.WAV\r",
      "212: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MBGT0/SX261.WAV\r",
      "213: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MESJ0/SA2.WAV\r",
      "214: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX332.WAV\r",
      "215: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SX398.WAV\r",
      "216: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI2327.WAV\r",
      "217: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJAE0/SX264.WAV\r",
      "218: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MBEF0/SI651.WAV\r",
      "219: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FPAF0/SI1054.WAV\r",
      "220: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMVP0/SX114.WAV\r",
      "221: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FJDM2/SI2212.WAV\r",
      "222: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1698.WAV\r",
      "223: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SI1257.WAV\r",
      "224: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDPK0/SI552.WAV\r",
      "225: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJAE0/SX354.WAV\r",
      "226: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FCKE0/SI481.WAV\r",
      "227: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MKAM0/SI1250.WAV\r",
      "228: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJA0/SI1078.WAV\r",
      "229: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSGF0/SX387.WAV\r",
      "230: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX436.WAV\r",
      "231: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SI861.WAV\r",
      "232: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1148.WAV\r",
      "233: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MEFG0/SX375.WAV\r",
      "234: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FALK0/SA1.WAV\r",
      "235: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJPM1/SI1897.WAV\r",
      "236: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FDMY0/SX207.WAV\r",
      "237: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MBMA1/SX234.WAV\r",
      "238: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI2206.WAV\r",
      "239: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SI1887.WAV\r",
      "240: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI2251.WAV\r",
      "241: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MBJV0/SI1877.WAV\r",
      "242: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FCMG0/SX72.WAV\r",
      "243: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLJH0/SX154.WAV\r",
      "244: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJDM0/SI974.WAV\r",
      "245: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FPAD0/SI716.WAV\r",
      "246: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX235.WAV\r",
      "247: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SI1567.WAV\r",
      "248: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI804.WAV\r",
      "249: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCMM0/SI1083.WAV\r",
      "250: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FCMG0/SX162.WAV\r",
      "251: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FPAF0/SA1.WAV\r",
      "252: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJFH0/SX27.WAV\r",
      "253: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSBK0/SX169.WAV\r",
      "254: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1800.WAV\r",
      "255: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMLM0/SX447.WAV\r",
      "256: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX361.WAV\r",
      "257: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKJO0/SI1517.WAV\r",
      "258: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FJLG0/SI1506.WAV\r",
      "259: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MESG0/SA2.WAV\r",
      "260: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDHL0/SA1.WAV\r",
      "261: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FMJU0/SX399.WAV\r",
      "262: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1702.WAV\r",
      "263: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMLM0/SX357.WAV\r",
      "264: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSAH0/SX434.WAV\r",
      "265: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FLMA0/SX73.WAV\r",
      "266: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDEF0/SX213.WAV\r",
      "267: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLBC0/SI609.WAV\r",
      "268: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSMM0/SX324.WAV\r",
      "269: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FRJB0/SX167.WAV\r",
      "270: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX345.WAV\r",
      "271: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SI808.WAV\r",
      "272: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSAH0/SX74.WAV\r",
      "273: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJDE0/SX220.WAV\r",
      "274: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAKB0/SI2276.WAV\r",
      "275: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MCDR0/SI1784.WAV\r",
      "276: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEWM0/SX448.WAV\r",
      "277: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MABC0/SX241.WAV\r",
      "278: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI710.WAV\r",
      "279: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SA2.WAV\r",
      "280: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MGRL0/SA2.WAV\r",
      "281: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FPJF0/SX236.WAV\r",
      "282: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FLAC0/SX91.WAV\r",
      "283: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MFRM0/SI1155.WAV\r",
      "284: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEGJ0/SX257.WAV\r",
      "285: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEJL0/SA1.WAV\r",
      "286: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX360.WAV\r",
      "287: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SI1353.WAV\r",
      "288: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX84.WAV\r",
      "289: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCAJ0/SX129.WAV\r",
      "290: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSJW0/SA1.WAV\r",
      "291: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJXL0/SA2.WAV\r",
      "292: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MHIT0/SX443.WAV\r",
      "293: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FMJU0/SI759.WAV\r",
      "294: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA2.WAV\r",
      "295: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMLM0/SA1.WAV\r",
      "296: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX159.WAV\r",
      "297: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJEB0/SI656.WAV\r",
      "298: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MADC0/SX17.WAV\r",
      "299: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMBS0/SX431.WAV\r",
      "300: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FBMH0/SX56.WAV\r",
      "301: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKES0/SX263.WAV\r",
      "302: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX340.WAV\r",
      "303: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SX363.WAV\r",
      "304: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SA1.WAV\r",
      "305: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FEAC0/SX165.WAV\r",
      "306: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDBB1/SA2.WAV\r",
      "307: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FKLC0/SI985.WAV\r",
      "308: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FDTD0/SI931.WAV\r",
      "309: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FKLC1/SX238.WAV\r",
      "310: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI797.WAV\r",
      "311: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SI1878.WAV\r",
      "312: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA2.WAV\r",
      "313: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FMKF0/SA2.WAV\r",
      "314: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJJB0/SA2.WAV\r",
      "315: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMGC0/SX405.WAV\r",
      "316: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FTBW0/SA1.WAV\r",
      "317: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKES0/SX83.WAV\r",
      "318: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA2.WAV\r",
      "319: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SX358.WAV\r",
      "320: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX420.WAV\r",
      "321: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJDE0/SA2.WAV\r",
      "322: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FPAZ0/SI1593.WAV\r",
      "323: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FDKN0/SI1081.WAV\r",
      "324: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMDM1/SX333.WAV\r",
      "325: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSBK0/SI2329.WAV\r",
      "326: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI1569.WAV\r",
      "327: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SI618.WAV\r",
      "328: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVFB0/SX222.WAV\r",
      "329: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FMMH0/SI907.WAV\r",
      "330: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAM0/SX67.WAV\r",
      "331: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FSSB0/SX362.WAV\r",
      "332: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEWM0/SI1348.WAV\r",
      "333: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSGF0/SI927.WAV\r",
      "334: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX358.WAV\r",
      "335: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SX87.WAV\r",
      "336: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJEB1/SI837.WAV\r",
      "337: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDWD0/SI1890.WAV\r",
      "338: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MLNS0/SX237.WAV\r",
      "339: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MESG0/SX72.WAV\r",
      "340: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MBGT0/SA2.WAV\r",
      "341: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FMJU0/SX39.WAV\r",
      "342: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX37.WAV\r",
      "343: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SX271.WAV\r",
      "344: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX391.WAV\r",
      "345: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMAA0/SI1588.WAV\r",
      "346: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAKB0/SI1016.WAV\r",
      "347: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMBS0/SA1.WAV\r",
      "348: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMDM1/SX63.WAV\r",
      "349: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSBK0/SX439.WAV\r",
      "350: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX422.WAV\r",
      "351: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBCG0/SX57.WAV\r",
      "352: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDPK0/SX243.WAV\r",
      "353: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDXW0/SX71.WAV\r",
      "354: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSKC0/SX246.WAV\r",
      "355: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJLS0/SX16.WAV\r",
      "356: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FGDP0/SX358.WAV\r",
      "357: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FBCH0/SA1.WAV\r",
      "358: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX324.WAV\r",
      "359: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SX448.WAV\r",
      "360: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA1.WAV\r",
      "361: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDWD0/SI557.WAV\r",
      "362: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FJLG0/SI2306.WAV\r",
      "363: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJJJ0/SX173.WAV\r",
      "364: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLMK0/SI1035.WAV\r",
      "365: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MMDB0/SX177.WAV\r",
      "366: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA1.WAV\r",
      "367: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBCG0/SA1.WAV\r",
      "368: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMGG0/SX179.WAV\r",
      "369: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MPRB0/SX305.WAV\r",
      "370: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MKLS1/SI915.WAV\r",
      "371: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJRH0/SX315.WAV\r",
      "372: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMDM1/SX243.WAV\r",
      "373: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FPAD0/SX86.WAV\r",
      "374: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI1771.WAV\r",
      "375: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMLM0/SI2150.WAV\r",
      "376: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX248.WAV\r",
      "377: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDEM0/SX158.WAV\r",
      "378: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDBB1/SI2056.WAV\r",
      "379: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLEL0/SX166.WAV\r",
      "380: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FJXM0/SI581.WAV\r",
      "381: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MMDB0/SI987.WAV\r",
      "382: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA1.WAV\r",
      "383: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FPLS0/SI1590.WAV\r",
      "384: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SA2.WAV\r",
      "385: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJEB0/SX386.WAV\r",
      "386: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDLH0/SI574.WAV\r",
      "387: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJEE0/SX337.WAV\r",
      "388: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MHIT0/SI2243.WAV\r",
      "389: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MPGR1/SA2.WAV\r",
      "390: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX424.WAV\r",
      "391: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SX88.WAV\r",
      "392: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX414.WAV\r",
      "393: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FAJW0/SI633.WAV\r",
      "394: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDHS0/SA2.WAV\r",
      "395: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FBAS0/SI1387.WAV\r",
      "396: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MGSH0/SA2.WAV\r",
      "397: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MESJ0/SX7.WAV\r",
      "398: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1326.WAV\r",
      "399: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FNKL0/SA2.WAV\r",
      "400: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI631.WAV\r",
      "401: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCYL0/SA1.WAV\r",
      "402: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MLNS0/SI2037.WAV\r",
      "403: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MDCD0/SI1415.WAV\r",
      "404: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJPG0/SI1821.WAV\r",
      "405: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SX163.WAV\r",
      "406: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX392.WAV\r",
      "407: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBCG0/SX417.WAV\r",
      "408: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSJK1/SA2.WAV\r",
      "409: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MARC0/SX288.WAV\r",
      "410: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSLS0/SX426.WAV\r",
      "411: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FPAF0/SX154.WAV\r",
      "412: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJG0/SA1.WAV\r",
      "413: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSDJ0/SA2.WAV\r",
      "414: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX336.WAV\r",
      "415: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMLM0/SI897.WAV\r",
      "416: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX167.WAV\r",
      "417: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKAH0/SX268.WAV\r",
      "418: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MILB0/SA1.WAV\r",
      "419: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MBMA0/SX232.WAV\r",
      "420: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSKP0/SX378.WAV\r",
      "421: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MAJP0/SI2334.WAV\r",
      "422: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI535.WAV\r",
      "423: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SA1.WAV\r",
      "424: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA1.WAV\r",
      "425: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJMA0/SI2125.WAV\r",
      "426: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FCMG0/SX252.WAV\r",
      "427: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FSAK0/SX40.WAV\r",
      "428: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMCC0/SX78.WAV\r",
      "429: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FBCH0/SI1586.WAV\r",
      "430: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX147.WAV\r",
      "431: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SA1.WAV\r",
      "432: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJEB1/SX207.WAV\r",
      "433: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MPPC0/SI2042.WAV\r",
      "434: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAR0/SX346.WAV\r",
      "435: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGAG0/SX151.WAV\r",
      "436: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMDM1/SI2043.WAV\r",
      "437: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MABC0/SA2.WAV\r",
      "438: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX152.WAV\r",
      "439: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FMBG0/SI1160.WAV\r",
      "440: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI836.WAV\r",
      "441: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMDS0/SX83.WAV\r",
      "442: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MHMR0/SX309.WAV\r",
      "443: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FCAG0/SX63.WAV\r",
      "444: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FEXM0/SX201.WAV\r",
      "445: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FLAG0/SI1464.WAV\r",
      "446: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SA1.WAV\r",
      "447: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SX128.WAV\r",
      "448: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI1418.WAV\r",
      "449: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FJKL0/SI1562.WAV\r",
      "450: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSLS0/SI2316.WAV\r",
      "451: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FKDW0/SI1891.WAV\r",
      "452: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FBMH0/SX146.WAV\r",
      "453: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FTAJ0/SI699.WAV\r",
      "454: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX156.WAV\r",
      "455: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SI2018.WAV\r",
      "456: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX294.WAV\r",
      "457: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDEM0/SI800.WAV\r",
      "458: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDNS0/SI873.WAV\r",
      "459: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMDM0/SI1311.WAV\r",
      "460: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FDMY0/SX387.WAV\r",
      "461: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SX73.WAV\r",
      "462: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA2.WAV\r",
      "463: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FMBG0/SX3.WAV\r",
      "464: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1779.WAV\r",
      "465: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FTMG0/SX272.WAV\r",
      "466: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDEF0/SA1.WAV\r",
      "467: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJSR0/SX164.WAV\r",
      "468: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FDTD0/SI2191.WAV\r",
      "469: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MDRD0/SX122.WAV\r",
      "470: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX66.WAV\r",
      "471: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SX348.WAV\r",
      "472: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX91.WAV\r",
      "473: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MPPC0/SX242.WAV\r",
      "474: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FLTM0/SX170.WAV\r",
      "475: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FDKN0/SX271.WAV\r",
      "476: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDHL0/SX449.WAV\r",
      "477: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MPGR1/SX239.WAV\r",
      "478: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SA1.WAV\r",
      "479: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMLM0/SX177.WAV\r",
      "480: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX307.WAV\r",
      "481: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FRLL0/SA1.WAV\r",
      "482: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJRH1/SA1.WAV\r",
      "483: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJLS0/SI1726.WAV\r",
      "484: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FEAR0/SA1.WAV\r",
      "485: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEJL0/SI962.WAV\r",
      "486: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX406.WAV\r",
      "487: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SI1981.WAV\r",
      "488: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MCPM0/SX114.WAV\r",
      "489: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FJKL0/SX302.WAV\r",
      "490: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MHJB0/SA2.WAV\r",
      "491: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGRP0/SI687.WAV\r",
      "492: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MFER0/SX322.WAV\r",
      "493: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MAJP0/SX354.WAV\r",
      "494: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI2237.WAV\r",
      "495: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBCG0/SX147.WAV\r",
      "496: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1657.WAV\r",
      "497: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKDT0/SX353.WAV\r",
      "498: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJKR0/SA1.WAV\r",
      "499: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJSR0/SA2.WAV\r",
      "500: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMVP0/SX384.WAV\r",
      "501: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSBK0/SI1699.WAV\r",
      "502: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX251.WAV\r",
      "503: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FNKL0/SI1522.WAV\r",
      "504: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MCPM0/SA1.WAV\r",
      "505: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FRLL0/SX434.WAV\r",
      "506: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAR0/SX436.WAV\r",
      "507: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FLKM0/SX260.WAV\r",
      "508: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMVP0/SI1914.WAV\r",
      "509: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MCAE0/SX367.WAV\r",
      "510: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX242.WAV\r",
      "511: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SX172.WAV\r",
      "512: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI518.WAV\r",
      "513: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDAS1/SI1461.WAV\r",
      "514: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDNS0/SA1.WAV\r",
      "515: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMDM0/SI681.WAV\r",
      "516: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMVP0/SI1284.WAV\r",
      "517: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSBK0/SI1069.WAV\r",
      "518: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX265.WAV\r",
      "519: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SX258.WAV\r",
      "520: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FKFB0/SA2.WAV\r",
      "521: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMXS0/SI876.WAV\r",
      "522: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDJM0/SX15.WAV\r",
      "523: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJPM1/SA1.WAV\r",
      "524: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMWB0/SX89.WAV\r",
      "525: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SX253.WAV\r",
      "526: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA2.WAV\r",
      "527: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SX307.WAV\r",
      "528: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVFB0/SA1.WAV\r",
      "529: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMXS0/SI629.WAV\r",
      "530: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FJLR0/SX241.WAV\r",
      "531: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MKAM0/SX326.WAV\r",
      "532: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MCHL0/SA1.WAV\r",
      "533: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MDRD0/SI2012.WAV\r",
      "534: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1071.WAV\r",
      "535: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SX168.WAV\r",
      "536: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX68.WAV\r",
      "537: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKJO0/SX167.WAV\r",
      "538: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MADC0/SX377.WAV\r",
      "539: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGRP0/SA2.WAV\r",
      "540: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MHIT0/SA2.WAV\r",
      "541: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FJDM2/SI1964.WAV\r",
      "542: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI977.WAV\r",
      "543: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SI1870.WAV\r",
      "544: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSAH0/SI1244.WAV\r",
      "545: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJDE0/SX130.WAV\r",
      "546: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJDA0/SX311.WAV\r",
      "547: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FSSB0/SX182.WAV\r",
      "548: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJG0/SI2241.WAV\r",
      "549: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MDRD0/SA2.WAV\r",
      "550: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX175.WAV\r",
      "551: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBCG0/SI2217.WAV\r",
      "552: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX447.WAV\r",
      "553: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FSCN0/SX176.WAV\r",
      "554: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MGAF0/SI1282.WAV\r",
      "555: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJLB0/SA2.WAV\r",
      "556: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSMS1/SX347.WAV\r",
      "557: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MESJ0/SX97.WAV\r",
      "558: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI1607.WAV\r",
      "559: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SA1.WAV\r",
      "560: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SA2.WAV\r",
      "561: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDBP0/SX168.WAV\r",
      "562: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCDC0/SX212.WAV\r",
      "563: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FKDW0/SI577.WAV\r",
      "564: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSMM0/SI684.WAV\r",
      "565: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FBCH0/SX236.WAV\r",
      "566: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA1.WAV\r",
      "567: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SX250.WAV\r",
      "568: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX127.WAV\r",
      "569: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKDT0/SI2153.WAV\r",
      "570: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FPAZ0/SX423.WAV\r",
      "571: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MFRM0/SX165.WAV\r",
      "572: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSKP0/SA2.WAV\r",
      "573: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MJRK0/SX160.WAV\r",
      "574: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA2.WAV\r",
      "575: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SX442.WAV\r",
      "576: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA1.WAV\r",
      "577: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FAJW0/SX363.WAV\r",
      "578: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCDD0/SA1.WAV\r",
      "579: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FSSB0/SX452.WAV\r",
      "580: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSKP0/SA1.WAV\r",
      "581: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEAL0/SX347.WAV\r",
      "582: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX250.WAV\r",
      "583: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SA1.WAV\r",
      "584: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX158.WAV\r",
      "585: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FHLM0/SX390.WAV\r",
      "586: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MHMR0/SX39.WAV\r",
      "587: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJLB0/SI986.WAV\r",
      "588: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSKP0/SX108.WAV\r",
      "589: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SI1693.WAV\r",
      "590: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1956.WAV\r",
      "591: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SI937.WAV\r",
      "592: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA2.WAV\r",
      "593: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJDE0/SI463.WAV\r",
      "594: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAPV0/SA2.WAV\r",
      "595: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGAG0/SI645.WAV\r",
      "596: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDSJ0/SX382.WAV\r",
      "597: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MJRK0/SA2.WAV\r",
      "598: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX416.WAV\r",
      "599: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SI1351.WAV\r",
      "600: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI2075.WAV\r",
      "601: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FJKL0/SX122.WAV\r",
      "602: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDLC0/SA2.WAV\r",
      "603: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLJC0/SI595.WAV\r",
      "604: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEWM0/SI718.WAV\r",
      "605: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FPAD0/SI1346.WAV\r",
      "606: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA2.WAV\r",
      "607: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FPLS0/SI960.WAV\r",
      "608: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX381.WAV\r",
      "609: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKAJ0/SI784.WAV\r",
      "610: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCAL0/SX418.WAV\r",
      "611: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FBAS0/SX397.WAV\r",
      "612: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MGSH0/SX96.WAV\r",
      "613: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKES0/SI1883.WAV\r",
      "614: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA2.WAV\r",
      "615: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FNKL0/SX196.WAV\r",
      "616: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMGG0/SX359.WAV\r",
      "617: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FAEM0/SX222.WAV\r",
      "618: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FLTM0/SA2.WAV\r",
      "619: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MFWK0/SX439.WAV\r",
      "620: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FBJL0/SI2182.WAV\r",
      "621: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSGF0/SI2187.WAV\r",
      "622: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX174.WAV\r",
      "623: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FNKL0/SA1.WAV\r",
      "624: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDPK0/SA2.WAV\r",
      "625: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDXW0/SA1.WAV\r",
      "626: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJLG1/SI2272.WAV\r",
      "627: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJLS0/SA2.WAV\r",
      "628: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSAG0/SI1953.WAV\r",
      "629: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEAL0/SX287.WAV\r",
      "630: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX161.WAV\r",
      "631: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FJRB0/SA1.WAV\r",
      "632: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJEB1/SX117.WAV\r",
      "633: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCAJ0/SX39.WAV\r",
      "634: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCDC0/SX32.WAV\r",
      "635: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MFRM0/SX435.WAV\r",
      "636: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDSJ0/SI1462.WAV\r",
      "637: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSGF0/SX27.WAV\r",
      "638: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX54.WAV\r",
      "639: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FJRB0/SX402.WAV\r",
      "640: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX56.WAV\r",
      "641: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDMT0/SX32.WAV\r",
      "642: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSLS0/SA2.WAV\r",
      "643: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJDC0/SX171.WAV\r",
      "644: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FEAR0/SX172.WAV\r",
      "645: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEJL0/SX422.WAV\r",
      "646: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX153.WAV\r",
      "647: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FNKL0/SX262.WAV\r",
      "648: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX87.WAV\r",
      "649: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJMA0/SX415.WAV\r",
      "650: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAKB0/SA1.WAV\r",
      "651: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMBS0/SX71.WAV\r",
      "652: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJG0/SX351.WAV\r",
      "653: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FHXS0/SX265.WAV\r",
      "654: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA2.WAV\r",
      "655: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SX31.WAV\r",
      "656: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSAH0/SX344.WAV\r",
      "657: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MEFG0/SA1.WAV\r",
      "658: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDJM0/SI825.WAV\r",
      "659: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJDC0/SI2165.WAV\r",
      "660: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDAS0/SX6.WAV\r",
      "661: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MESJ0/SX187.WAV\r",
      "662: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX269.WAV\r",
      "663: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SI1240.WAV\r",
      "664: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MCPM0/SI1194.WAV\r",
      "665: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDXW0/SA2.WAV\r",
      "666: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MKLS1/SX15.WAV\r",
      "667: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJDC0/SI1161.WAV\r",
      "668: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJA0/SX448.WAV\r",
      "669: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FBCH0/SI956.WAV\r",
      "670: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SA1.WAV\r",
      "671: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FMBG0/SX260.WAV\r",
      "672: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDPK0/SX423.WAV\r",
      "673: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMAG0/SX136.WAV\r",
      "674: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDNS0/SX21.WAV\r",
      "675: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FALR0/SI695.WAV\r",
      "676: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSKP0/SI1098.WAV\r",
      "677: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SA2.WAV\r",
      "678: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX434.WAV\r",
      "679: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SX451.WAV\r",
      "680: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX324.WAV\r",
      "681: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKAH0/SX358.WAV\r",
      "682: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MFMC0/SI1762.WAV\r",
      "683: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJLB0/SX86.WAV\r",
      "684: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMVP0/SA1.WAV\r",
      "685: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SA1.WAV\r",
      "686: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX145.WAV\r",
      "687: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCEG0/SX438.WAV\r",
      "688: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SA2.WAV\r",
      "689: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FSCN0/SI626.WAV\r",
      "690: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FPAZ0/SX153.WAV\r",
      "691: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FDKN0/SX361.WAV\r",
      "692: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMAB1/SX324.WAV\r",
      "693: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSGF0/SX117.WAV\r",
      "694: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX75.WAV\r",
      "695: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SA1.WAV\r",
      "696: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVFB0/SI2292.WAV\r",
      "697: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FLMC0/SI2002.WAV\r",
      "698: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCAL0/SX58.WAV\r",
      "699: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FJXP0/SX402.WAV\r",
      "700: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMVP0/SX204.WAV\r",
      "701: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FAPB0/SX433.WAV\r",
      "702: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI2062.WAV\r",
      "703: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBCG0/SI957.WAV\r",
      "704: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX264.WAV\r",
      "705: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FSCN0/SX446.WAV\r",
      "706: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MHMR0/SI1119.WAV\r",
      "707: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FBAS0/SX307.WAV\r",
      "708: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FPMY0/SA2.WAV\r",
      "709: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FRJB0/SI1794.WAV\r",
      "710: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX338.WAV\r",
      "711: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SI2242.WAV\r",
      "712: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX26.WAV\r",
      "713: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FSCN0/SI1886.WAV\r",
      "714: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MAKB0/SX296.WAV\r",
      "715: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLBC0/SA1.WAV\r",
      "716: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FCDR1/SX196.WAV\r",
      "717: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEJL0/SX242.WAV\r",
      "718: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX341.WAV\r",
      "719: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FMBG0/SX80.WAV\r",
      "720: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMGG0/SX89.WAV\r",
      "721: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MARC0/SI1188.WAV\r",
      "722: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MKLS1/SA1.WAV\r",
      "723: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FEEH0/SX212.WAV\r",
      "724: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLMK0/SX135.WAV\r",
      "725: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FHXS0/SI2302.WAV\r",
      "726: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX400.WAV\r",
      "727: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SI2068.WAV\r",
      "728: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX146.WAV\r",
      "729: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDXW0/SI881.WAV\r",
      "730: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAM0/SX247.WAV\r",
      "731: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMGC0/SX45.WAV\r",
      "732: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJDM0/SI1937.WAV\r",
      "733: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FHXS0/SI1075.WAV\r",
      "734: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI2011.WAV\r",
      "735: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SX160.WAV\r",
      "736: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX397.WAV\r",
      "737: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCAJ0/SA2.WAV\r",
      "738: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAM0/SA2.WAV\r",
      "739: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGJC0/SX345.WAV\r",
      "740: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDAS0/SI1266.WAV\r",
      "741: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSDJ0/SI1745.WAV\r",
      "742: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX167.WAV\r",
      "743: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FJRB0/SI1932.WAV\r",
      "744: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FMEM0/SI747.WAV\r",
      "745: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MKAH0/SX448.WAV\r",
      "746: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJKR0/SX391.WAV\r",
      "747: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLBC0/SX159.WAV\r",
      "748: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MRAM0/SX105.WAV\r",
      "749: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MMDB0/SI1358.WAV\r",
      "750: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX136.WAV\r",
      "751: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SI1388.WAV\r",
      "752: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA1.WAV\r",
      "753: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMAG0/SX316.WAV\r",
      "754: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAR0/SA1.WAV\r",
      "755: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MBWP0/SX349.WAV\r",
      "756: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FKKH0/SX300.WAV\r",
      "757: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKES0/SI1253.WAV\r",
      "758: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX85.WAV\r",
      "759: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SX177.WAV\r",
      "760: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX271.WAV\r",
      "761: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJEB0/SX206.WAV\r",
      "762: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MHMR0/SI489.WAV\r",
      "763: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MARW0/SX16.WAV\r",
      "764: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSAG0/SI693.WAV\r",
      "765: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FRJB0/SA1.WAV\r",
      "766: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX71.WAV\r",
      "767: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SX82.WAV\r",
      "768: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX384.WAV\r",
      "769: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FJKL0/SX212.WAV\r",
      "770: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FLTM0/SI1700.WAV\r",
      "771: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLJC0/SA2.WAV\r",
      "772: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEWM0/SA2.WAV\r",
      "773: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FBCH0/SI959.WAV\r",
      "774: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA2.WAV\r",
      "775: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SA2.WAV\r",
      "776: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX234.WAV\r",
      "777: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJEB0/SX170.WAV\r",
      "778: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FSLS0/SX202.WAV\r",
      "779: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJWS0/SX243.WAV\r",
      "780: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEWM0/SX178.WAV\r",
      "781: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FPAD0/SX176.WAV\r",
      "782: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX377.WAV\r",
      "783: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SX38.WAV\r",
      "784: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MGRL0/SX417.WAV\r",
      "785: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FJKL0/SX32.WAV\r",
      "786: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FCMG0/SI1872.WAV\r",
      "787: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FDKN0/SA2.WAV\r",
      "788: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJA0/SI2338.WAV\r",
      "789: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKES0/SA2.WAV\r",
      "790: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI538.WAV\r",
      "791: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SX183.WAV\r",
      "792: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI1261.WAV\r",
      "793: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDSS0/SA1.WAV\r",
      "794: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDJM0/SI1455.WAV\r",
      "795: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MMBS0/SA2.WAV\r",
      "796: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJPG0/SX291.WAV\r",
      "797: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MAJP0/SX174.WAV\r",
      "798: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX147.WAV\r",
      "799: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SX397.WAV\r",
      "800: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA1.WAV\r",
      "801: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FKAA0/SI1208.WAV\r",
      "802: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FALK0/SX366.WAV\r",
      "803: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MFWK0/SI619.WAV\r",
      "804: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJPG0/SX111.WAV\r",
      "805: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MDRD0/SX302.WAV\r",
      "806: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX423.WAV\r",
      "807: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SX51.WAV\r",
      "808: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MCPM0/SX204.WAV\r",
      "809: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJMA0/SI865.WAV\r",
      "810: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDLH0/SX250.WAV\r",
      "811: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLSH0/SX427.WAV\r",
      "812: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MCHL0/SI1977.WAV\r",
      "813: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEAL0/SA1.WAV\r",
      "814: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1051.WAV\r",
      "815: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SI982.WAV\r",
      "816: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI924.WAV\r",
      "817: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDNC0/SI2287.WAV\r",
      "818: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MCEF0/SA1.WAV\r",
      "819: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FSSB0/SI2342.WAV\r",
      "820: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MCHL0/SI1404.WAV\r",
      "821: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MESJ0/SI2039.WAV\r",
      "822: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX172.WAV\r",
      "823: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FKLH0/SI627.WAV\r",
      "824: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA2.WAV\r",
      "825: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FTMG0/SX362.WAV\r",
      "826: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDTB0/SX120.WAV\r",
      "827: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MDCD0/SA2.WAV\r",
      "828: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FKKH0/SX210.WAV\r",
      "829: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSDJ0/SX35.WAV\r",
      "830: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1457.WAV\r",
      "831: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKDD0/SX37.WAV\r",
      "832: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI1410.WAV\r",
      "833: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MCTM0/SX90.WAV\r",
      "834: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FALK0/SI658.WAV\r",
      "835: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJPM1/SX41.WAV\r",
      "836: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLMK0/SX45.WAV\r",
      "837: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FKLC1/SX58.WAV\r",
      "838: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX331.WAV\r",
      "839: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FJRB0/SI1302.WAV\r",
      "840: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA1.WAV\r",
      "841: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FDNC0/SX198.WAV\r",
      "842: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAR0/SX166.WAV\r",
      "843: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FEEH0/SX302.WAV\r",
      "844: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSDC0/SX412.WAV\r",
      "845: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FRJB0/SX437.WAV\r",
      "846: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SA1.WAV\r",
      "847: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FPLS0/SX3.WAV\r",
      "848: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1027.WAV\r",
      "849: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJPM0/SX108.WAV\r",
      "850: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJJB0/SX239.WAV\r",
      "851: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGXP0/SX277.WAV\r",
      "852: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MDAS0/SA2.WAV\r",
      "853: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FBCH0/SX146.WAV\r",
      "854: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA2.WAV\r",
      "855: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SX218.WAV\r",
      "856: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FMEM0/SX387.WAV\r",
      "857: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FCYL0/SX37.WAV\r",
      "858: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FGCS0/SI1486.WAV\r",
      "859: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FDKN0/SX91.WAV\r",
      "860: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MMWB0/SI989.WAV\r",
      "861: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MEJL0/SX62.WAV\r",
      "862: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI802.WAV\r",
      "863: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FPLS0/SI2220.WAV\r",
      "864: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVFB0/SX312.WAV\r",
      "865: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJBG0/SX62.WAV\r",
      "866: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FGRW0/SX252.WAV\r",
      "867: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FLKM0/SX440.WAV\r",
      "868: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSDC0/SX322.WAV\r",
      "869: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FKLC1/SA2.WAV\r",
      "870: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA1.WAV\r",
      "871: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SX273.WAV\r",
      "872: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVFB0/SX132.WAV\r",
      "873: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FTMG0/SX452.WAV\r",
      "874: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDNS0/SX111.WAV\r",
      "875: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FLHD0/SX84.WAV\r",
      "876: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJXA0/SA2.WAV\r",
      "877: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FMJU0/SI1389.WAV\r",
      "878: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX149.WAV\r",
      "879: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SX361.WAV\r",
      "880: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX121.WAV\r",
      "881: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MPRB0/SX215.WAV\r",
      "882: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDNS0/SA2.WAV\r",
      "883: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJEE0/SX427.WAV\r",
      "884: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FSMS1/SA2.WAV\r",
      "885: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MKES0/SX173.WAV\r",
      "886: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX402.WAV\r",
      "887: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SX231.WAV\r",
      "888: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX91.WAV\r",
      "889: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FAEM0/SX42.WAV\r",
      "890: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMAM0/SA1.WAV\r",
      "891: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MAEB0/SX90.WAV\r",
      "892: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FMPG0/SA1.WAV\r",
      "893: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FLAG0/SI2094.WAV\r",
      "894: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX82.WAV\r",
      "895: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MEJS0/SX340.WAV\r",
      "896: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA1.WAV\r",
      "897: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDMT0/SA1.WAV\r",
      "898: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FNTB0/SX33.WAV\r",
      "899: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJJJ0/SI1163.WAV\r",
      "900: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FPMY0/SI1153.WAV\r",
      "901: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MBMA1/SI2214.WAV\r",
      "902: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX24.WAV\r",
      "903: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SA1.WAV\r",
      "904: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI774.WAV\r",
      "905: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MEFG0/SX15.WAV\r",
      "906: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJKR0/SX31.WAV\r",
      "907: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLSH0/SX157.WAV\r",
      "908: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FGMB0/SA1.WAV\r",
      "909: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FSBK0/SA1.WAV\r",
      "910: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX159.WAV\r",
      "911: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FCLT0/SI1438.WAV\r",
      "912: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA2.WAV\r",
      "913: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJHI0/SX338.WAV\r",
      "914: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MJKR0/SA2.WAV\r",
      "915: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJRH0/SI1755.WAV\r",
      "916: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MFER0/SX52.WAV\r",
      "917: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FJDM2/SA2.WAV\r",
      "918: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX310.WAV\r",
      "919: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SI1612.WAV\r",
      "920: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX24.WAV\r",
      "921: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MDEM0/SX248.WAV\r",
      "922: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMJB1/SA1.WAV\r",
      "923: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FKDW0/SA1.WAV\r",
      "924: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MFER0/SX142.WAV\r",
      "925: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MABC0/SX421.WAV\r",
      "926: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA1.WAV\r",
      "927: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FMBG0/SX350.WAV\r",
      "928: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FMEM0/SX117.WAV\r",
      "929: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FLMC0/SA2.WAV\r",
      "930: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMJB1/SX58.WAV\r",
      "931: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/FSSB0/SX92.WAV\r",
      "932: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FMPG0/SA2.WAV\r",
      "933: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MBMA1/SX414.WAV\r",
      "934: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1751.WAV\r",
      "935: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FBCG1/SX262.WAV\r",
      "936: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FMEM0/SX207.WAV\r",
      "937: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FSCN0/SA1.WAV\r",
      "938: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FLJD0/SA2.WAV\r",
      "939: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLJC0/SI1855.WAV\r",
      "940: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MEGJ0/SX77.WAV\r",
      "941: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MPGR1/SX329.WAV\r",
      "942: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA2.WAV\r",
      "943: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBSB0/SI1983.WAV\r",
      "944: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FMEM0/SA1.WAV\r",
      "945: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMGK0/SI692.WAV\r",
      "946: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FNTB0/SA2.WAV\r",
      "947: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MCDR0/SX74.WAV\r",
      "948: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FLJG0/SX441.WAV\r",
      "949: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MDRD0/SX212.WAV\r",
      "950: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX245.WAV\r",
      "951: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MBCG0/SX237.WAV\r",
      "952: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FKFB0/SA1.WAV\r",
      "953: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MHRM0/SI1475.WAV\r",
      "954: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/FDJH0/SI2195.WAV\r",
      "955: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJWS0/SX423.WAV\r",
      "956: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MCHL0/SX447.WAV\r",
      "957: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MCAE0/SI1447.WAV\r",
      "958: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SA1.WAV\r",
      "959: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SA2.WAV\r",
      "960: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDPK0/SI1683.WAV\r",
      "961: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJMA0/SA1.WAV\r",
      "962: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MLNS0/SX147.WAV\r",
      "963: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MJEE0/SA1.WAV\r",
      "964: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MGSH0/SX186.WAV\r",
      "965: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MJRK0/SX250.WAV\r",
      "966: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI1052.WAV\r",
      "967: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MCXM0/SX91.WAV\r",
      "968: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SA1.WAV\r",
      "969: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FMJB0/SA1.WAV\r",
      "970: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MGAF0/SX292.WAV\r",
      "971: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MDMA0/SI2060.WAV\r",
      "972: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MJXA0/SI877.WAV\r",
      "973: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FTAJ0/SX249.WAV\r",
      "974: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI2144.WAV\r",
      "975: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MKRG0/SX141.WAV\r",
      "976: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA2.WAV\r",
      "977: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MMXS0/SX426.WAV\r",
      "978: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MMJB1/SX238.WAV\r",
      "979: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MLEL0/SX346.WAV\r",
      "980: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FDMY0/SX27.WAV\r",
      "981: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FLAG0/SX294.WAV\r",
      "982: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1058.WAV\r",
      "983: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SX308.WAV\r",
      "984: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FMEM0/SA2.WAV\r",
      "985: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MJBG0/SX152.WAV\r",
      "986: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MGAF0/SI1912.WAV\r",
      "987: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGRP0/SX417.WAV\r",
      "988: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FTBW0/SI1345.WAV\r",
      "989: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/FHXS0/SA2.WAV\r",
      "990: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA1.WAV\r",
      "991: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/FJRB0/SX222.WAV\r",
      "992: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI1381.WAV\r",
      "993: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/FMKF0/SI1018.WAV\r",
      "994: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MDSS1/SA2.WAV\r",
      "995: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MGXP0/SX97.WAV\r",
      "996: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/FBJL0/SX382.WAV\r",
      "997: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MJRK0/SI1662.WAV\r",
      "998: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX237.WAV\r",
      "999: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMEA0/SI758.WAV\r",
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI605.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MTDB0/SA2.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MTLB0/SA1.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MPRT0/SX220.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MRML0/SI791.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MTJU0/SI760.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI1485.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MTCS0/SI1972.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRSO0/SX309.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MRGS0/SA1.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MPRD0/SX81.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MSTF0/SX226.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MVLO0/SX427.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MSJK0/SX66.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX180.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRRE0/SI704.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI562.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MRFK0/SA2.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MRBC0/SI1859.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MPEB0/SX330.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MTAT0/SX390.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MSMR0/SX55.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI847.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMWS0/SI888.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRDD0/SX240.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MTBC0/SI543.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MRTJ0/SI2032.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MSFH0/SA1.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MWSH0/SA1.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MSMR0/SI1150.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SA1.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRDM0/SA2.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI1102.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MTDB0/SX231.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MTLB0/SI504.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MPRK0/SX377.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MSAS0/SX296.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MTJU0/SI2269.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI1671.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMWS0/SX168.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SA1.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MTDB0/SI771.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MVJH0/SI1556.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MSTF0/SX316.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MRKM0/SX367.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MSVS0/SI2198.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI1349.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MMPM0/SX341.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SA2.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MZMB0/SI1166.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MWDK0/SX176.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MSFH0/SX316.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MTMT0/SX218.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MSJK0/SI1596.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX3.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRDM0/SI1595.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX425.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MTDB0/SX411.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MRJB1/SI1020.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MPRT0/SX40.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MWCH0/SX182.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MRXB0/SX235.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX231.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRRE0/SA1.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRDD0/SX150.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MRJT0/SX418.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MTKP0/SX213.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MTAS0/SX215.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MWCH0/SI1895.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MSDS0/SI1707.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI2325.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRRE0/SX74.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRSO0/SX399.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MRFK0/SX176.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MTJM0/SA1.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MTAS0/SX395.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MWEM0/SI1320.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MTJU0/SX310.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA2.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRRE0/SX434.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX252.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MRLJ0/SX70.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MWDK0/SA1.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MTRC0/SI993.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MTDP0/SI2151.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MSJK0/SX336.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX67.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRRE0/SX254.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTRR0/SA1.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MRCW0/SI741.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MRWA0/SX163.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MPRK0/SI467.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR5/MRKM0/SI637.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR6/MTXS0/SA2.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2026.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR8/MRDM0/SX425.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX342.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR2/MTDB0/SI2031.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR3/MTPG0/SX303.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR4/MSRG0/SX411.WAV\r",
      "0: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MDAB0/SA1.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MMDM2/SX102.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MHPG0/SI1720.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FMAF0/SX199.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FUTB0/SA2.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJR0/SX372.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FDHC0/SX389.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MPAM0/SA2.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MDAB0/SX49.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FDRD1/SI1544.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMAB0/SX12.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MRKO0/SX407.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MRRK0/SX118.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJFC0/SX223.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FMML0/SX410.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FMLD0/SI2185.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FDAC1/SA2.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MCEM0/SX228.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMDH0/SI2286.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FLBW0/SX319.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MRPP0/SX14.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJR0/SX12.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MCHH0/SA2.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FCMH1/SX53.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FDAC1/SX214.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MCEM0/SA1.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBDG0/SA1.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MTLS0/SX20.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FMAH0/SI659.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MCMJ0/SI602.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MERS0/SI497.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MDAW1/SI1453.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MRJO0/SX104.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MGWT0/SA1.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MCTW0/SI743.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FADG0/SI1279.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MKLT0/SX403.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJFC0/SA1.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRMS1/SX407.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJLN0/SX99.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SI2183.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MCCS0/SX29.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MKCH0/SA2.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FEDW0/SA1.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MCRC0/SI462.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MDSC0/SA2.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MTWH0/SX20.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTC0/SX110.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSJS1/SX369.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MWEW0/SX371.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMJR0/SI2166.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MKCL0/SI461.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FASW0/SX200.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJFC0/SX313.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MGRT0/SX10.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MDAW1/SX283.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MJSW0/SI1010.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MJAR0/SX188.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJMP0/SX95.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FJMG0/SA1.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDAC2/SA2.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MCMJ0/SX374.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MTWH0/SI1820.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTH0/SX396.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FDAC1/SI844.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MGWT0/SX279.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MKCH0/SI1425.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MLLL0/SX373.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDAC2/SI2259.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJFC0/SX43.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRMS1/SI2117.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MAJC0/SX295.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSTK0/SI1024.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MTMR0/SA2.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MTHC0/SX115.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MRKO0/SI2027.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MLIH0/SX283.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FMGD0/SX214.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MDVC0/SA1.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTH0/SX306.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MJSW0/SX380.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FRAM1/SX10.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMWH0/SI1301.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FLBW0/SA2.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FAWF0/SI2260.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MCMJ0/SI1094.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRJM4/SA2.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTH0/SX216.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FDAC1/SI2104.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJRE0/SX126.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBDG0/SX113.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MBNS0/SI1220.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MRRK0/SA2.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FMGD0/SA1.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MDVC0/SX306.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTH0/SA1.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FAKS0/SA1.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MWEW0/SX11.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MGJF0/SI776.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MPCS0/SI1359.WAV\r",
      "100: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MFGK0/SX214.WAV\r",
      "101: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJDH0/SI1984.WAV\r",
      "102: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FDHC0/SX209.WAV\r",
      "103: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MDAW1/SX13.WAV\r",
      "104: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSTK0/SI2222.WAV\r",
      "105: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MMDB1/SI2255.WAV\r",
      "106: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJMP0/SA2.WAV\r",
      "107: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MTEB0/SA1.WAV\r",
      "108: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MRJM3/SX368.WAV\r",
      "109: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJS0/SX4.WAV\r",
      "110: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MGRT0/SA2.WAV\r",
      "111: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MPAM0/SI1189.WAV\r",
      "112: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FELC0/SI2016.WAV\r",
      "113: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MCEM0/SX318.WAV\r",
      "114: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MWJG0/SX314.WAV\r",
      "115: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FJMG0/SX371.WAV\r",
      "116: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDRB0/SX364.WAV\r",
      "117: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MPAM1/SA2.WAV\r",
      "118: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MNJM0/SI1580.WAV\r",
      "119: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MAJC0/SX25.WAV\r",
      "120: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SX383.WAV\r",
      "121: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MMDM2/SI1555.WAV\r",
      "122: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MWJG0/SA2.WAV\r",
      "123: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MPLB0/SX404.WAV\r",
      "124: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FCAL1/SA2.WAV\r",
      "125: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FMGD0/SX394.WAV\r",
      "126: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FISB0/SA2.WAV\r",
      "127: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FMLD0/SA1.WAV\r",
      "128: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MREB0/SA1.WAV\r",
      "129: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MWEW0/SX191.WAV\r",
      "130: /home/sri/Desktop/timit/TIMIT/TEST/DR3/FPKT0/SX8.WAV\r",
      "131: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MDLS0/SI1628.WAV\r",
      "132: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FJCS0/SI1309.WAV\r",
      "133: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FLNH0/SA2.WAV\r",
      "134: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FDHC0/SX299.WAV\r",
      "135: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJLN0/SX189.WAV\r",
      "136: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FAKS0/SX313.WAV\r",
      "137: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJWB0/SX95.WAV\r",
      "138: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MHPG0/SI1090.WAV\r",
      "139: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FDMS0/SA2.WAV\r",
      "140: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FHEW0/SI690.WAV\r",
      "141: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MPAM1/SX396.WAV\r",
      "142: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FMML0/SX320.WAV\r",
      "143: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FMLD0/SX115.WAV\r",
      "144: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MJSW0/SA2.WAV\r",
      "145: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MWEW0/SA2.WAV\r",
      "146: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MTAA0/SI1285.WAV\r",
      "147: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FMAF0/SX289.WAV\r",
      "148: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FCAL1/SI1403.WAV\r",
      "149: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJR0/SX192.WAV\r",
      "150: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MNLS0/SA2.WAV\r",
      "151: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MSLB0/SI1193.WAV\r",
      "152: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SX113.WAV\r",
      "153: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJAS0/SA1.WAV\r",
      "154: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJES0/SX304.WAV\r",
      "155: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MBNS0/SA2.WAV\r",
      "156: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MFGK0/SA1.WAV\r",
      "157: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MPAM1/SX126.WAV\r",
      "158: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRJM4/SI2119.WAV\r",
      "159: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTC0/SX380.WAV\r",
      "160: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FELC0/SX306.WAV\r",
      "161: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MRGG0/SX299.WAV\r",
      "162: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBWM0/SX314.WAV\r",
      "163: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FMAF0/SX379.WAV\r",
      "164: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWA0/SI519.WAV\r",
      "165: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FDRW0/SX23.WAV\r",
      "166: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRMS1/SI857.WAV\r",
      "167: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MPAM0/SX109.WAV\r",
      "168: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FAKS0/SX43.WAV\r",
      "169: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MMDB1/SX185.WAV\r",
      "170: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MLNT0/SI1574.WAV\r",
      "171: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MDRM0/SI2273.WAV\r",
      "172: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MBPM0/SX317.WAV\r",
      "173: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FDRW0/SA1.WAV\r",
      "174: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FCAU0/SX47.WAV\r",
      "175: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MDAW1/SI2083.WAV\r",
      "176: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MREB0/SX205.WAV\r",
      "177: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FDRD1/SX104.WAV\r",
      "178: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MHPG0/SX100.WAV\r",
      "179: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MPCS0/SA2.WAV\r",
      "180: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MCMB0/SX368.WAV\r",
      "181: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJS0/SA2.WAV\r",
      "182: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MNJM0/SX230.WAV\r",
      "183: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MAJC0/SX115.WAV\r",
      "184: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSJS1/SI869.WAV\r",
      "185: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MDBB0/SX25.WAV\r",
      "186: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJBR0/SX371.WAV\r",
      "187: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MGMM0/SX139.WAV\r",
      "188: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MSFH1/SI640.WAV\r",
      "189: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MDSC0/SX318.WAV\r",
      "190: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRPC0/SI493.WAV\r",
      "191: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SX227.WAV\r",
      "192: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MRJO0/SX14.WAV\r",
      "193: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FRAM1/SI1360.WAV\r",
      "194: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBDG0/SX293.WAV\r",
      "195: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MTLS0/SX290.WAV\r",
      "196: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FUTB0/SX124.WAV\r",
      "197: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MPAM1/SX306.WAV\r",
      "198: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FSXA0/SI1108.WAV\r",
      "199: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MAJC0/SI1946.WAV\r",
      "200: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SX293.WAV\r",
      "201: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FRAM1/SX190.WAV\r",
      "202: /home/sri/Desktop/timit/TIMIT/TEST/DR3/FKMS0/SX230.WAV\r",
      "203: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FGJD0/SI818.WAV\r",
      "204: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FHES0/SX389.WAV\r",
      "205: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FLNH0/SX404.WAV\r",
      "206: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FTLH0/SX379.WAV\r",
      "207: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SI1217.WAV\r",
      "208: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MRJO0/SI734.WAV\r",
      "209: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MRGG0/SI1199.WAV\r",
      "210: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MRTK0/SX193.WAV\r",
      "211: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MLLL0/SA2.WAV\r",
      "212: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MBPM0/SI947.WAV\r",
      "213: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MESD0/SX372.WAV\r",
      "214: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FLAS0/SX138.WAV\r",
      "215: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MSLB0/SX293.WAV\r",
      "216: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FELC0/SI1386.WAV\r",
      "217: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MWVW0/SI1476.WAV\r",
      "218: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MTAA0/SI1915.WAV\r",
      "219: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MJDM1/SX95.WAV\r",
      "220: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FMAH0/SX29.WAV\r",
      "221: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FLNH0/SA1.WAV\r",
      "222: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MERS0/SA1.WAV\r",
      "223: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJLN0/SI1449.WAV\r",
      "224: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MJSW0/SI2270.WAV\r",
      "225: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MDBB0/SX205.WAV\r",
      "226: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MCSH0/SX19.WAV\r",
      "227: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FEDW0/SX184.WAV\r",
      "228: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWK0/SI910.WAV\r",
      "229: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJR0/SX102.WAV\r",
      "230: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FMML0/SX50.WAV\r",
      "231: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MPAM0/SX289.WAV\r",
      "232: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FAKS0/SA2.WAV\r",
      "233: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MABW0/SX44.WAV\r",
      "234: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJES0/SA1.WAV\r",
      "235: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FMAF0/SI1459.WAV\r",
      "236: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FNLP0/SX48.WAV\r",
      "237: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJR0/SA2.WAV\r",
      "238: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FTLH0/SX289.WAV\r",
      "239: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SA1.WAV\r",
      "240: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FAKS0/SI943.WAV\r",
      "241: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MJAR0/SX368.WAV\r",
      "242: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MLNT0/SA1.WAV\r",
      "243: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MGMM0/SX409.WAV\r",
      "244: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MRWS1/SX320.WAV\r",
      "245: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJS0/SX94.WAV\r",
      "246: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MKJL0/SX110.WAV\r",
      "247: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MDAW1/SA2.WAV\r",
      "248: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSJS1/SI1899.WAV\r",
      "249: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MGWT0/SI1539.WAV\r",
      "250: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMDH0/SX126.WAV\r",
      "251: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FGJD0/SX9.WAV\r",
      "252: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MCTT0/SA1.WAV\r",
      "253: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FDRW0/SI1423.WAV\r",
      "254: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FLAS0/SI1026.WAV\r",
      "255: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SI587.WAV\r",
      "256: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FAKS0/SX403.WAV\r",
      "257: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MCEM0/SI768.WAV\r",
      "258: /home/sri/Desktop/timit/TIMIT/TEST/DR3/FKMS0/SX320.WAV\r",
      "259: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MDLS0/SX368.WAV\r",
      "260: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MRRK0/SX388.WAV\r",
      "261: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJDH0/SI724.WAV\r",
      "262: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MGRT0/SX280.WAV\r",
      "263: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MPAM0/SI1961.WAV\r",
      "264: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FJEM0/SI634.WAV\r",
      "265: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJWB0/SI635.WAV\r",
      "266: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJVW0/SA2.WAV\r",
      "267: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MJDM1/SI1085.WAV\r",
      "268: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MLIH0/SX373.WAV\r",
      "269: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJR0/SA1.WAV\r",
      "270: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MDLF0/SA1.WAV\r",
      "271: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FJSJ0/SA2.WAV\r",
      "272: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MRJO0/SI1624.WAV\r",
      "273: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FRAM1/SA1.WAV\r",
      "274: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJMP0/SX185.WAV\r",
      "275: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FCRH0/SX8.WAV\r",
      "276: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MCRC0/SI1092.WAV\r",
      "277: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJR0/SX282.WAV\r",
      "278: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MERS0/SX389.WAV\r",
      "279: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FJSJ0/SX44.WAV\r",
      "280: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSTK0/SA2.WAV\r",
      "281: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MRGG0/SI569.WAV\r",
      "282: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMJR0/SI2278.WAV\r",
      "283: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FMCM0/SX10.WAV\r",
      "284: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FNLP0/SI1308.WAV\r",
      "285: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MCMJ0/SA2.WAV\r",
      "286: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MGRT0/SX190.WAV\r",
      "287: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SX47.WAV\r",
      "288: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FELC0/SX216.WAV\r",
      "289: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MRGG0/SX119.WAV\r",
      "290: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MCSH0/SI2179.WAV\r",
      "291: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FDMS0/SX138.WAV\r",
      "292: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FJSA0/SX29.WAV\r",
      "293: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FLNH0/SI584.WAV\r",
      "294: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FCAU0/SI1037.WAV\r",
      "295: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FMLD0/SX25.WAV\r",
      "296: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SX203.WAV\r",
      "297: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MPDF0/SI1542.WAV\r",
      "298: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMWH0/SI1089.WAV\r",
      "299: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MGMM0/SX319.WAV\r",
      "300: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FNLP0/SA1.WAV\r",
      "301: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJFC0/SI1663.WAV\r",
      "302: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FCAU0/SX227.WAV\r",
      "303: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJLN0/SX9.WAV\r",
      "304: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MJSW0/SI1640.WAV\r",
      "305: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MRCZ0/SX101.WAV\r",
      "306: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MKCH0/SA1.WAV\r",
      "307: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MTEB0/SX233.WAV\r",
      "308: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWA0/SX5.WAV\r",
      "309: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJS0/SI1523.WAV\r",
      "310: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRPC0/SX43.WAV\r",
      "311: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FJSJ0/SX404.WAV\r",
      "312: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FJEM0/SI1264.WAV\r",
      "313: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJWB0/SX365.WAV\r",
      "314: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBWM0/SX44.WAV\r",
      "315: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MDRM0/SX23.WAV\r",
      "316: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FJSA0/SI749.WAV\r",
      "317: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FMGD0/SX34.WAV\r",
      "318: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRMS1/SA1.WAV\r",
      "319: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJLN0/SI819.WAV\r",
      "320: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSJS1/SX99.WAV\r",
      "321: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJAS0/SX50.WAV\r",
      "322: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBWM0/SI674.WAV\r",
      "323: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MJRF0/SX281.WAV\r",
      "324: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWA0/SA2.WAV\r",
      "325: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FDRW0/SI1283.WAV\r",
      "326: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MCHH0/SI530.WAV\r",
      "327: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTC0/SI830.WAV\r",
      "328: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FDAC1/SX394.WAV\r",
      "329: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJRE0/SX36.WAV\r",
      "330: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBDG0/SX383.WAV\r",
      "331: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FJMG0/SI551.WAV\r",
      "332: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWK0/SI1540.WAV\r",
      "333: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MCMJ0/SA1.WAV\r",
      "334: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MPAB0/SX318.WAV\r",
      "335: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FMLD0/SI925.WAV\r",
      "336: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSTK0/SA1.WAV\r",
      "337: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MMDM2/SI1452.WAV\r",
      "338: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MRTK0/SX373.WAV\r",
      "339: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MJRF0/SI821.WAV\r",
      "340: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDAC2/SX369.WAV\r",
      "341: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FMGD0/SI1564.WAV\r",
      "342: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FLAS0/SI858.WAV\r",
      "343: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTH0/SI1926.WAV\r",
      "344: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FELC0/SA2.WAV\r",
      "345: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MWVW0/SI2106.WAV\r",
      "346: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MRTK0/SX13.WAV\r",
      "347: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MGMM0/SI1759.WAV\r",
      "348: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MAHH0/SX124.WAV\r",
      "349: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MPAM1/SI1029.WAV\r",
      "350: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FSXA0/SI478.WAV\r",
      "351: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MSLB0/SI1823.WAV\r",
      "352: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FAKS0/SI1573.WAV\r",
      "353: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJRE0/SI1116.WAV\r",
      "354: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MLNT0/SX192.WAV\r",
      "355: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MLJB0/SX140.WAV\r",
      "356: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWK0/SX100.WAV\r",
      "357: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MRJS0/SA1.WAV\r",
      "358: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MTWH0/SA1.WAV\r",
      "359: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FJSJ0/SI2114.WAV\r",
      "360: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SI923.WAV\r",
      "361: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MRGG0/SA1.WAV\r",
      "362: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MHPG0/SA1.WAV\r",
      "363: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FLKD0/SX19.WAV\r",
      "364: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FHEW0/SI763.WAV\r",
      "365: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MCMJ0/SX14.WAV\r",
      "366: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRPC0/SX313.WAV\r",
      "367: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MDAW1/SA1.WAV\r",
      "368: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MREB0/SA2.WAV\r",
      "369: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MBJK0/SI2128.WAV\r",
      "370: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMDH0/SX36.WAV\r",
      "371: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FCRH0/SX98.WAV\r",
      "372: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FHEW0/SX43.WAV\r",
      "373: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FDRW0/SX113.WAV\r",
      "374: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MGRT0/SI820.WAV\r",
      "375: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FCMH1/SI1493.WAV\r",
      "376: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSJS1/SA1.WAV\r",
      "377: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FRAM1/SA2.WAV\r",
      "378: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MTAA0/SX25.WAV\r",
      "379: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MLLL0/SA1.WAV\r",
      "380: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MAHH0/SX34.WAV\r",
      "381: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FLNH0/SX224.WAV\r",
      "382: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FTLH0/SX19.WAV\r",
      "383: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SX137.WAV\r",
      "384: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MDAB0/SX319.WAV\r",
      "385: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MCEM0/SA2.WAV\r",
      "386: /home/sri/Desktop/timit/TIMIT/TEST/DR3/FPKT0/SX98.WAV\r",
      "387: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MDLS0/SX8.WAV\r",
      "388: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWA0/SA1.WAV\r",
      "389: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MPAM1/SI1836.WAV\r",
      "390: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MTWH0/SX290.WAV\r",
      "391: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FJSJ0/SX134.WAV\r",
      "392: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MSTK0/SX124.WAV\r",
      "393: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FCMR0/SA1.WAV\r",
      "394: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MGJF0/SA2.WAV\r",
      "395: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FLKD0/SI1369.WAV\r",
      "396: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MAHH0/SX394.WAV\r",
      "397: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MPAM1/SX216.WAV\r",
      "398: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FCAU0/SI1667.WAV\r",
      "399: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SX317.WAV\r",
      "400: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MDAB0/SI1669.WAV\r",
      "401: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FSLB1/SI891.WAV\r",
      "402: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MTAA0/SX295.WAV\r",
      "403: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MLJB0/SX410.WAV\r",
      "404: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MRJM3/SX278.WAV\r",
      "405: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJFC0/SI2293.WAV\r",
      "406: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRPC0/SX403.WAV\r",
      "407: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MRES0/SA2.WAV\r",
      "408: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FJEM0/SI1894.WAV\r",
      "409: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FRAM1/SX280.WAV\r",
      "410: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MTDT0/SX4.WAV\r",
      "411: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MJRF0/SX101.WAV\r",
      "412: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MLIH0/SX103.WAV\r",
      "413: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MESD0/SA1.WAV\r",
      "414: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FGWR0/SI1578.WAV\r",
      "415: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MAJC0/SX205.WAV\r",
      "416: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FELC0/SX396.WAV\r",
      "417: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MDLD0/SX13.WAV\r",
      "418: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MKCH0/SI1378.WAV\r",
      "419: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FGJD0/SI1179.WAV\r",
      "420: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FUTB0/SI1834.WAV\r",
      "421: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FMGD0/SA2.WAV\r",
      "422: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FDHC0/SI1559.WAV\r",
      "423: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJLN0/SA2.WAV\r",
      "424: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SI1553.WAV\r",
      "425: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJWB0/SX5.WAV\r",
      "426: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MMWH0/SI459.WAV\r",
      "427: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MROA0/SA2.WAV\r",
      "428: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDRB0/SA1.WAV\r",
      "429: /home/sri/Desktop/timit/TIMIT/TEST/DR6/FLNH0/SI941.WAV\r",
      "430: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MCHH0/SI1634.WAV\r",
      "431: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTC0/SX290.WAV\r",
      "432: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FJEM0/SA1.WAV\r",
      "433: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FSLB1/SA1.WAV\r",
      "434: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MBDG0/SX23.WAV\r",
      "435: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FMAF0/SI829.WAV\r",
      "436: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FASW0/SX20.WAV\r",
      "437: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MDSC0/SX138.WAV\r",
      "438: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRMS1/SX317.WAV\r",
      "439: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTH0/SI666.WAV\r",
      "440: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MDAB0/SI2299.WAV\r",
      "441: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FCMR0/SX205.WAV\r",
      "442: /home/sri/Desktop/timit/TIMIT/TEST/DR3/FKMS0/SX140.WAV\r",
      "443: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MPCS0/SX369.WAV\r",
      "444: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FASW0/SI1550.WAV\r",
      "445: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MCMJ0/SX194.WAV\r",
      "446: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MTWH0/SA2.WAV\r",
      "447: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJLN0/SI2079.WAV\r",
      "448: /home/sri/Desktop/timit/TIMIT/TEST/DR1/FELC0/SI756.WAV\r",
      "449: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MPDF0/SX192.WAV\r",
      "450: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MJJG0/SX103.WAV\r",
      "451: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MJRF0/SX11.WAV\r",
      "452: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FGMD0/SX143.WAV\r",
      "453: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MESD0/SI1632.WAV\r",
      "454: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MRMS1/SX47.WAV\r",
      "455: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FJSJ0/SX314.WAV\r",
      "456: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MWBT0/SA2.WAV\r",
      "457: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FJAS0/SX410.WAV\r",
      "458: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MCTW0/SX293.WAV\r",
      "459: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FNMR0/SX409.WAV\r",
      "460: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FNLP0/SI1938.WAV\r",
      "461: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MESD0/SI2262.WAV\r",
      "462: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MKDR0/SI643.WAV\r",
      "463: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FCMH1/SA2.WAV\r",
      "464: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MDAB0/SX229.WAV\r",
      "465: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MPDF0/SX282.WAV\r",
      "466: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MCTW0/SX203.WAV\r",
      "467: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FCFT0/SX278.WAV\r",
      "468: /home/sri/Desktop/timit/TIMIT/TEST/DR5/FHES0/SX299.WAV\r",
      "469: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MDSC0/SI2298.WAV\r",
      "470: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FISB0/SI2209.WAV\r",
      "471: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MPAM0/SX19.WAV\r",
      "472: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MREB0/SI2005.WAV\r",
      "473: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MTAS1/SA1.WAV\r",
      "474: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MCSH0/SA2.WAV\r",
      "475: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FRNG0/SA2.WAV\r",
      "476: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MSFH1/SA2.WAV\r",
      "477: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MDSC0/SI967.WAV\r",
      "478: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MKDR0/SX283.WAV\r",
      "479: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MJTH0/SX126.WAV\r",
      "480: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MDAB0/SX409.WAV\r",
      "481: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MGWT0/SI2169.WAV\r",
      "482: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MGLB0/SI2164.WAV\r",
      "483: /home/sri/Desktop/timit/TIMIT/TEST/DR4/MTLS0/SI2000.WAV\r",
      "484: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MCMB0/SX8.WAV\r",
      "485: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MJDH0/SI1354.WAV\r",
      "486: /home/sri/Desktop/timit/TIMIT/TEST/DR7/MKDR0/SA1.WAV\r",
      "487: /home/sri/Desktop/timit/TIMIT/TEST/DR8/FJSJ0/SA1.WAV\r",
      "488: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MJSW0/SX20.WAV\r",
      "489: /home/sri/Desktop/timit/TIMIT/TEST/DR2/FSLB1/SI1904.WAV\r",
      "490: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MGJF0/SI641.WAV\r",
      "491: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FMAF0/SA1.WAV\r",
      "492: /home/sri/Desktop/timit/TIMIT/TEST/DR5/MDWA0/SX185.WAV\r",
      "493: /home/sri/Desktop/timit/TIMIT/TEST/DR6/MESD0/SX282.WAV\r",
      "494: /home/sri/Desktop/timit/TIMIT/TEST/DR7/FTLH0/SA2.WAV\r",
      "495: /home/sri/Desktop/timit/TIMIT/TEST/DR8/MDAW1/SX193.WAV\r",
      "496: /home/sri/Desktop/timit/TIMIT/TEST/DR1/MREB0/SX385.WAV\r",
      "497: /home/sri/Desktop/timit/TIMIT/TEST/DR2/MTMR0/SI673.WAV\r",
      "498: /home/sri/Desktop/timit/TIMIT/TEST/DR3/MTAA0/SA2.WAV\r",
      "499: /home/sri/Desktop/timit/TIMIT/TEST/DR4/FNMR0/SI1399.WAV\r"
     ]
    }
   ],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101814, 512, 1)\n",
      "6.41179e-06\n",
      "0.103588\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE, 1))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = (WINDOW_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# softmax hardness variable\n",
    "tau = K.variable(0.0001, name = \"hardness\")\n",
    "tau_add_rate = 0.1\n",
    "\n",
    "NBINS = 32\n",
    "VEC_SIZE = 1\n",
    "\n",
    "# initially, quantization is not on\n",
    "QUANT_BINS = K.zeros((NBINS, VEC_SIZE), name = 'QUANT_BINS')\n",
    "QUANTIZATION_ON = K.variable(False)\n",
    "\n",
    "DOWNSAMPLE_FACTOR = 2\n",
    "CHANNEL_SIZE = WINDOW_SIZE / DOWNSAMPLE_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unquantize_batch(one_hot):\n",
    "    out = T.tensordot(one_hot, QUANT_BINS, axes = [2, 0])\n",
    "    out = K.reshape(out, (out.shape[0], out.shape[1] * VEC_SIZE))\n",
    "    return out\n",
    "\n",
    "def unquantize_vec(one_hot):\n",
    "    out = T.tensordot(one_hot, QUANT_BINS, axes = [1, 0])\n",
    "    out = K.reshape(out, (CHANNEL_SIZE,))\n",
    "    return out\n",
    "\n",
    "class SoftmaxQuantization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftmaxQuantization, self).__init__(**kwargs)\n",
    "   \n",
    "    def build(self, input_shape):\n",
    "        self.SOFTMAX_TEMP = K.variable(256.0)\n",
    "        self.trainable_weights = [QUANT_BINS,\n",
    "                                  self.SOFTMAX_TEMP]\n",
    "        super(SoftmaxQuantization, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        # x is an array: [BATCH x WINDOW_SIZE]\n",
    "        # x_r becomes: [BATCH x (WINDOW_SIZE / VEC_SIZE) x 1 x VEC_SIZE]\n",
    "        x_r = K.reshape(x, (-1, x.shape[1] // VEC_SIZE, 1, VEC_SIZE))\n",
    "\n",
    "        # quant_bins is an array: [NBINS x VEC_SIZE] \n",
    "        # q_r becomes: [1 x 1 x NBINS x VEC_SIZE]\n",
    "        q_r = K.reshape(QUANT_BINS, (1, 1, QUANT_BINS.shape[0], VEC_SIZE))\n",
    "\n",
    "        # get L2 distance from each element to each of the bins\n",
    "        dist = K.sqrt(K.sum(K.square(x_r - q_r), axis = -1) + K.epsilon())\n",
    "\n",
    "        # turn into softmax probabilities, which we return\n",
    "        probs = softmax(self.SOFTMAX_TEMP * -dist)\n",
    "        \n",
    "        # if quantization isn't on yet, we just return the original vector x, reshaped\n",
    "        # and padded to the right shape\n",
    "        #     (this is a bad hack and I hope there is a better way to do this)\n",
    "        quant_on = probs\n",
    "        quant_off = K.zeros_like(quant_on)\n",
    "        quant_off = T.set_subtensor(quant_off[:, :, :VEC_SIZE],\n",
    "                                    K.reshape(x, (-1, x.shape[1] // VEC_SIZE, VEC_SIZE)))\n",
    "        \n",
    "        return K.switch(QUANTIZATION_ON, quant_on, quant_off)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] // VEC_SIZE, NBINS)\n",
    "\n",
    "\n",
    "class SoftmaxDequantization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftmaxDequantization, self).__init__(**kwargs)\n",
    "        self.supports_masking = False\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "        super(SoftmaxDequantization, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        out = T.tensordot(x, QUANT_BINS, axes = [2, 0])\n",
    "        out = K.reshape(out, (out.shape[0], out.shape[1] * VEC_SIZE))\n",
    "        \n",
    "        quant_on = out\n",
    "        quant_off = K.reshape(x[:, :, :VEC_SIZE], (-1, x.shape[1] * VEC_SIZE))\n",
    "        return K.switch(QUANTIZATION_ON, quant_on, quant_off)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_MFCC_COEFFS = 64\n",
    "\n",
    "# precompute Mel filterbank\n",
    "MEL_FILTERBANK_NPY = melFilterBank(NUM_MFCC_COEFFS).transpose()\n",
    "MEL_FILTERBANK = K.variable(MEL_FILTERBANK_NPY)\n",
    "\n",
    "# we precompute matrices for MFCC calculation\n",
    "DFT_REAL, DFT_IMAG = generate_dft_mats(WINDOW_SIZE)\n",
    "MFCC_DCT = generate_dct_mat(NUM_MFCC_COEFFS)\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE (or M x WINDOW_SIZE x 1)\n",
    "#     this returns an array M x N where each window has been replaced\n",
    "#     by some perceptual transform (in this case, MFCC coeffs)\n",
    "def perceptual_transform(x):\n",
    "    powerSpectrum = T.pow(theano_dft_mag(x, DFT_REAL, DFT_IMAG), 2)\n",
    "    filteredSpectrum = T.tensordot(powerSpectrum, MEL_FILTERBANK, axes = 1)\n",
    "    logSpectrum = T.log(filteredSpectrum + K.epsilon())\n",
    "    \n",
    "    mfccs = theano_dct(logSpectrum, MFCC_DCT)[:, 1:-1]\n",
    "    return mfccs\n",
    "\n",
    "# perceptual loss function\n",
    "def perceptual_distance(y_true, y_pred):\n",
    "    y_true = K.reshape(y_true, (y_true.shape[0], y_true.shape[1]))\n",
    "    y_pred = K.reshape(y_pred, (y_pred.shape[0], y_pred.shape[1]))\n",
    "    #silent_frame = K.max(K.abs(y_true), axis = -1) >= 0.01\n",
    "    \n",
    "    pvec_true = perceptual_transform(y_true)\n",
    "    pvec_pred = perceptual_transform(y_pred)\n",
    "    \n",
    "    distance = rmse(pvec_true, pvec_pred)\n",
    "    return distance\n",
    "    #return distance * silent_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 32\n",
    "    FILT_SIZE = 9\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = enc_input\n",
    "    \n",
    "    enc = Reshape(dim, input_shape = dim)(enc)  \n",
    "    \n",
    "    #enc = channel_increase_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = channel_change_block(NCHAN, FILT_SIZE)(enc)\n",
    "    #enc = channel_change_block(NCHAN, FILT_SIZE)(enc)\n",
    "    \n",
    "    #enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    #enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    #enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    #enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    \n",
    "    #enc = channel_change_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = channel_change_block(1, FILT_SIZE)(enc)\n",
    "    #enc = channel_decrease_block(NCHAN, FILT_SIZE)(enc)\n",
    "    \n",
    "    enc = Reshape((CHANNEL_SIZE,))(enc)\n",
    "    #enc = Dense(CHANNEL_SIZE)(enc)\n",
    "    \n",
    "    # softmax quantization\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc)\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (CHANNEL_SIZE / VEC_SIZE, NBINS))\n",
    "    dec = dec_input\n",
    "    \n",
    "    dec = SoftmaxDequantization()(dec)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    #dec = Dense(CHANNEL_SIZE)(dec)\n",
    "    dec = Reshape((CHANNEL_SIZE, 1))(dec)\n",
    "    \n",
    "    #dec = channel_increase_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    #dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    \n",
    "    #dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    #dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    #dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    #dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    \n",
    "    # decrease back down to 1 channel\n",
    "    #dec = channel_change_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = channel_change_block(1, FILT_SIZE)(dec)\n",
    "    #dec = channel_decrease_block(NCHAN, FILT_SIZE)(dec)\n",
    "    \n",
    "    #dec = Activation('tanh')(dec)\n",
    "    #dec = Lambda(lambda x : K.clip(x, -1.0, 1.0))(dec)\n",
    "    \n",
    "    dec = Model(inputs = dec_input, outputs = dec)\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can compute the entropy of a batch directly\n",
    "def code_entropy(placeholder, code):\n",
    "    all_onehots = K.reshape(code, (code.shape[0] * code.shape[1], NBINS))\n",
    "    onehot_hist = K.sum(all_onehots, axis = 0)\n",
    "    onehot_hist /= K.sum(onehot_hist)\n",
    "\n",
    "    entropy = -K.sum(onehot_hist * K.log(onehot_hist + K.epsilon()) / K.log(2.0))\n",
    "    return K.switch(QUANTIZATION_ON, tau * entropy, 0.0)\n",
    "\n",
    "def code_sparsity(placeholder, code):\n",
    "    sparsity = K.mean(K.sum(K.sqrt(code + K.epsilon()), axis = -1), axis = -1) - 1.0\n",
    "    return K.switch(QUANTIZATION_ON, sparsity, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'code_entropy' : code_entropy,\n",
    "                  'code_sparsity' : code_sparsity,\n",
    "                  'rmse' : rmse,\n",
    "                  'EuclideanDistance': EuclideanDistance,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization,\n",
    "                  'NBINS' : NBINS,\n",
    "                  'QUANT_BINS' : QUANT_BINS,\n",
    "                  'VEC_SIZE' : VEC_SIZE,\n",
    "                  'MEL_FILTERBANK' : MEL_FILTERBANK,\n",
    "                  'DFT_REAL' : DFT_REAL,\n",
    "                  'DFT_IMAG' : DFT_IMAG,\n",
    "                  'MFCC_DCT' : MFCC_DCT,\n",
    "                  'theano_dft_mag' : theano_dft_mag,\n",
    "                  'theano_dct' : theano_dct,\n",
    "                  'perceptual_transform' : perceptual_transform,\n",
    "                  'perceptual_distance' : perceptual_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = input_dim)\n",
    "\n",
    "encoder, decoder = autoencoder_structure(input_dim)\n",
    "ac_reconstructed = decoder(encoder(ac_input))\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "loss_weights = [300.0, 10.0, 10.0, 1.0]\n",
    "loss_functions = [rmse, perceptual_distance, code_sparsity, code_entropy]\n",
    "n_recons = 2\n",
    "n_code = 2\n",
    "assert(n_recons + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model specification\n",
    "model_input = Input(shape = input_dim)\n",
    "model_embedding = encoder(model_input)\n",
    "model_reconstructed = decoder(model_embedding)\n",
    "\n",
    "model = Model(inputs = [model_input], outputs = [model_reconstructed] * n_recons + \\\n",
    "                                            [model_embedding] * n_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 256, 32)           92526     \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 512, 1)            103853    \n",
      "=================================================================\n",
      "Total params: 196,379.0\n",
      "Trainable params: 196,379.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam(lr = 0.001))\n",
    "\n",
    "#autoencoder.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model on a set of speech windows (which should originally have been extracted in\n",
    "# order from some speech waveform)\n",
    "def test_model_on_windows(orig_windows, wparams, autoencoder, argmax = False):\n",
    "    # first, get desired reconstruction\n",
    "    desired = reconstruct_from_windows(orig_windows, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocess_waveform(desired, wparams)\n",
    "    desired = np.clip(desired, -32767, 32767)\n",
    "    \n",
    "    # then, run NN on windows to get our model's reconstruction\n",
    "    transformed = np.reshape(orig_windows, (orig_windows.shape[0], WINDOW_SIZE, 1))\n",
    "    enc = autoencoder.layers[1]\n",
    "    embed = enc.predict(transformed, batch_size = 128, verbose = 0)\n",
    "    if (argmax):\n",
    "        for wnd in xrange(0, embed.shape[0]):\n",
    "            max_idxs = np.argmax(embed[wnd], axis = -1)\n",
    "            embed[wnd] = np.eye(NBINS)[max_idxs]\n",
    "    \n",
    "    dec = autoencoder.layers[2]\n",
    "    autoencOutput = dec.predict(embed, batch_size = 128, verbose = 0)\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    recons = reconstruct_from_windows(autoencOutput, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocess_waveform(recons, wparams)\n",
    "    recons = np.clip(recons, -32767, 32767)\n",
    "    \n",
    "    # compute PESQ between desired and reconstructed waveforms\n",
    "    pesq = run_pesq_waveforms(desired, recons)\n",
    "    \n",
    "    # return some metrics, as well as the two waveforms\n",
    "    metrics = [\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired),\n",
    "        pesq\n",
    "    ]\n",
    "    \n",
    "    return metrics, desired, recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model given the filename for a .wav file\n",
    "def test_model_on_wav(wave_filename, prefix, autoencoder,\n",
    "                      lead = \"\", save_recons = True, verbose = True,\n",
    "                      argmax = False):\n",
    "    [rate, data] = sciwav.read(wave_filename)\n",
    "    data = data.astype(np.float32)\n",
    "    processed_wave, wparams = preprocess_waveform(data)\n",
    "    windows = extract_windows(processed_wave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "    metrics, desired, recons = test_model_on_windows(windows, wparams, autoencoder, argmax)\n",
    "    \n",
    "    if (save_recons):\n",
    "        outFilename = prefix + \"_output.wav\"\n",
    "        sciwav.write(outFilename, SAMPLE_RATE, recons.astype(np.int16))\n",
    "    \n",
    "    if (verbose):\n",
    "        print lead + \"MSE:        \", metrics[0]\n",
    "        print lead + \"Avg err:    \", metrics[1]\n",
    "        print lead + \"PESQ:       \", metrics[2]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_model(prefix = 'best'):\n",
    "    os.system('rm ./' + prefix + '_model.h5')\n",
    "    os.system('rm ./' + prefix + '_auto.h5')\n",
    "    os.system('rm ./' + prefix + '_quant_bins.npy')\n",
    "    \n",
    "    model.save('./' + prefix + '_model.h5')\n",
    "    autoencoder.save('./' + prefix + '_auto.h5')\n",
    "    np.save('./' + prefix + '_quant_bins.npy', K.eval(QUANT_BINS))\n",
    "    \n",
    "    f = h5py.File('best_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         40036.0\n",
      "Avg err:     107.254\n",
      "PESQ:        1.279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[40035.953, 107.25391, 1.279]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get untrained baseline for model\n",
    "test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_uninit\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    train_eval_idxs = random.sample(range(0, len(train_windows) - 1), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_windows) - 1), VAL_EVALUATE)\n",
    "    \n",
    "    train_metrics = []\n",
    "    for idx in train_eval_idxs:\n",
    "        windows = train_windows[idx]\n",
    "        wparams = train_wparams[idx]\n",
    "        metrics, _, _ = test_model_on_windows(windows, wparams, autoencoder,\n",
    "                                              argmax = True)\n",
    "        \n",
    "        train_metrics.append(metrics)\n",
    "        \n",
    "    val_metrics = []\n",
    "    for idx in val_eval_idxs:\n",
    "        windows = val_windows[idx]\n",
    "        wparams = val_wparams[idx]\n",
    "        metrics, _, _ = test_model_on_windows(windows, wparams, autoencoder,\n",
    "                                              argmax = True)\n",
    "        \n",
    "        val_metrics.append(metrics)\n",
    "    \n",
    "    train_metrics = np.array(train_metrics)\n",
    "    val_metrics = np.array(val_metrics)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_weight_change(before, after):\n",
    "    avg = 0.0\n",
    "    \n",
    "    for i in xrange(0, len(before)):\n",
    "        diff = np.mean(np.abs(before[i] * 1000.0 - after[i] * 1000.0))\n",
    "        avg += diff\n",
    "        \n",
    "    avg /= float(len(before))\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interleave numpy arrays of the same size along the first axis\n",
    "def interleave(arr):    \n",
    "    num = len(arr)\n",
    "    \n",
    "    r = np.empty(arr[0].shape)\n",
    "    r = np.repeat(r, num, axis = 0)\n",
    "    \n",
    "    for i in xrange(0, num):\n",
    "        r[i::num] = arr[i]\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 1.875\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 200\n",
    "EPOCHS_BEFORE_QUANT = 5\n",
    "EPOCHS_BEFORE_TAU = EPOCHS_BEFORE_QUANT + 5\n",
    "NUM_QUANT_VECS = 5000\n",
    "\n",
    "ORIG_BITRATE = 256.00\n",
    "TARGET_BITRATE = 16.00\n",
    "PRE_ENTROPY_RATE = ORIG_BITRATE / DOWNSAMPLE_FACTOR / VEC_SIZE\n",
    "\n",
    "TARGET_ENTROPY = (TARGET_BITRATE / PRE_ENTROPY_RATE * 16.0)\n",
    "TARGET_ENTROPY *= (STEP_SIZE / float(WINDOW_SIZE))\n",
    "TARGET_ENTROPY_FUZZ = 0.1\n",
    "\n",
    "print \"Target entropy:\", TARGET_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    101120:  [6.778085 0.004244 0.550494 0.000000 0.000000] [6.778085 1.273147 5.504938 0.000000 0.000000] 9.99999974738e-05 \n",
      "    Total time for epoch: 198.616806984s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1746.8325, 20.669437, 4.074]\n",
      "    SX383:        [2795.1018, 16.815321, 3.948]\n",
      "        (Not saving model yet)\n",
      "    Total time for evaluation: 0.556437969208s\n",
      "Epoch 2:\n",
      "    101120:  [6.740635 0.006702 0.473004 0.000000 0.000000] [6.740635 2.010597 4.730038 0.000000 0.000000] 9.99999974738e-05 \n",
      "    Total time for epoch: 161.67060709s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1738.5314, 20.956213, 4.242]\n",
      "    SX383:        [2882.1267, 17.486, 3.96]\n",
      "        (Not saving model yet)\n",
      "    Total time for evaluation: 0.553833007812s\n",
      "Epoch 3:\n",
      "    101120:  [7.284322 0.007098 0.515505 0.000000 0.000000] [7.284322 2.129269 5.155052 0.000000 0.000000] 9.99999974738e-05 \n",
      "    Total time for epoch: 161.111915827s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1577.1847, 20.409872, 4.328]\n",
      "    SX383:        [2562.9026, 16.52804, 3.965]\n",
      "        (Not saving model yet)\n",
      "    Total time for evaluation: 0.561608076096s\n",
      "Epoch 4:\n",
      "    101120:  [6.395569 0.006571 0.442420 0.000000 0.000000] [6.395569 1.971372 4.424198 0.000000 0.000000] 9.99999974738e-05 \n",
      "    Total time for epoch: 161.39357996s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1453.2113, 19.358017, 4.24]\n",
      "    SX383:        [2430.5273, 15.875053, 4.076]\n",
      "        (Not saving model yet)\n",
      "    Total time for evaluation: 0.544229984283s\n",
      "Epoch 5:\n",
      "    101120:  [6.659240 0.005838 0.490793 0.000000 0.000000] [6.659240 1.751312 4.907928 0.000000 0.000000] 9.99999974738e-05 \n",
      "    Total time for epoch: 161.042972088s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1580.1969, 21.230841, 4.282]\n",
      "    SX383:        [2404.3267, 17.341564, 4.222]\n",
      "        (Not saving model yet)\n",
      "    Total time for evaluation: 0.53097987175s\n",
      "    ----------------\n",
      "    Turning quantization on!\n",
      "        Selecting random code vectors for clustering...\n",
      "        K means clustering for bins initialization...\n",
      "        Done. Cluster score: 0.0636727\n",
      "    Decreased learning rate from 0.0010000000475 to 0.000500000023749\n",
      "Epoch 6:\n",
      "    101120:  [8.433003 0.006909 0.500000 0.135994 0.000387] [8.433003 2.072679 5.000001 1.359936 0.000387] 9.99999974738e-05 \n",
      "    Total time for epoch: 162.196116924s\n",
      "    ----------------\n",
      "    Code entropy: 3.96820707697\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2380.9985, 24.593771, 3.754]\n",
      "    SA1 (arg):    [2506.8635, 26.607706, 3.221]\n",
      "    SX383:        [2566.3569, 19.6523, 3.828]\n",
      "    SX383 (arg):  [2619.4016, 20.923607, 3.431]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4624.553347 31.274630 3.369460]\n",
      "        Train: (max)  [28013.550781 79.994217 3.818000]\n",
      "        Train: (min)  [531.332214 13.304019 1.947000]\n",
      "        Val:   (mean) [6353.765751 32.300723 3.410400]\n",
      "        Val:   (max)  [68143.898438 89.163063 4.063000]\n",
      "        Val:   (min)  [264.787842 8.360330 2.125000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 26.9836940765s\n",
      "Epoch 7:\n",
      "    101120:  [8.506021 0.006648 0.539476 0.111648 0.000394] [8.506021 1.994387 5.394762 1.116478 0.000394] 9.99999974738e-05 \n",
      "    Total time for epoch: 162.036693096s\n",
      "    ----------------\n",
      "    Code entropy: 3.86540417317\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2033.3372, 24.529251, 3.79]\n",
      "    SA1 (arg):    [2143.9072, 26.011124, 3.4]\n",
      "    SX383:        [2202.8618, 18.722555, 3.935]\n",
      "    SX383 (arg):  [2254.5713, 19.702217, 3.734]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4273.174017 29.413646 3.715120]\n",
      "        Train: (max)  [16154.022461 66.341690 4.118000]\n",
      "        Train: (min)  [530.640198 12.258175 2.886000]\n",
      "        Val:   (mean) [6257.768470 33.286053 3.722600]\n",
      "        Val:   (max)  [67898.460938 87.707886 4.175000]\n",
      "        Val:   (min)  [421.232941 11.188848 2.318000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 26.3189899921s\n",
      "Epoch 8:\n",
      "    101120:  [8.680761 0.008482 0.512799 0.100775 0.000420] [8.680761 2.544597 5.127992 1.007753 0.000420] 9.99999974738e-05 \n",
      "    Total time for epoch: 161.620104074s\n",
      "    ----------------\n",
      "    Code entropy: 4.20727295313\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2078.3713, 23.604511, 3.904]\n",
      "    SA1 (arg):    [2150.3535, 24.638315, 3.751]\n",
      "    SX383:        [2117.9678, 18.154684, 4.023]\n",
      "    SX383 (arg):  [2174.2502, 18.955004, 3.917]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7485.419237 34.362757 3.815340]\n",
      "        Train: (max)  [58176.078125 88.119522 4.240000]\n",
      "        Train: (min)  [688.155762 11.820213 3.334000]\n",
      "        Val:   (mean) [7200.371585 34.725173 3.894180]\n",
      "        Val:   (max)  [65793.500000 85.785927 4.289000]\n",
      "        Val:   (min)  [431.130585 10.363761 3.074000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 26.0596117973s\n",
      "Epoch 9:\n",
      "    101120:  [7.149958 0.006012 0.439543 0.095060 0.000417] [7.149958 1.803515 4.395427 0.950599 0.000417] 9.99999974738e-05 \n",
      "    Total time for epoch: 161.139883041s\n",
      "    ----------------\n",
      "    Code entropy: 4.24976299081\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1984.123, 23.106302, 3.979]\n",
      "    SA1 (arg):    [2055.8108, 24.069939, 3.806]\n",
      "    SX383:        [2197.2234, 18.117573, 3.939]\n",
      "    SX383 (arg):  [2236.1162, 18.805664, 3.867]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5503.470535 32.716450 3.900040]\n",
      "        Train: (max)  [20270.570312 66.990189 4.238000]\n",
      "        Train: (min)  [402.531708 10.065333 3.358000]\n",
      "        Val:   (mean) [4536.738819 28.213890 4.008660]\n",
      "        Val:   (max)  [19208.015625 64.372513 4.421000]\n",
      "        Val:   (min)  [242.518814 7.647608 3.073000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.8718910217s\n",
      "Epoch 10:\n",
      "    101120:  [7.229751 0.005162 0.476739 0.091325 0.000419] [7.229751 1.548696 4.767385 0.913251 0.000419] 9.99999974738e-05 \n",
      "    Total time for epoch: 160.834670067s\n",
      "    ----------------\n",
      "    Code entropy: 4.26031578278\n",
      "    Updated tau from 9.99999974738e-05 to 0.100099999997\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2078.96, 24.63512, 4.027]\n",
      "    SA1 (arg):    [2157.438, 25.520916, 3.932]\n",
      "    SX383:        [2239.4136, 19.39691, 3.886]\n",
      "    SX383 (arg):  [2278.9011, 19.989271, 3.797]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7303.475692 35.850795 3.841840]\n",
      "        Train: (max)  [35114.394531 68.165840 4.283000]\n",
      "        Train: (min)  [680.145081 14.132394 2.654000]\n",
      "        Val:   (mean) [6611.790490 32.790233 3.977900]\n",
      "        Val:   (max)  [61958.839844 85.283745 4.406000]\n",
      "        Val:   (min)  [391.904633 11.007471 3.066000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.3456878662s\n",
      "Epoch 11:\n",
      "    101120:  [7.912991 0.007313 0.446061 0.082955 0.428851] [7.912991 2.193973 4.460614 0.829553 0.428851] 0.100100003183 \n",
      "    Total time for epoch: 158.994072199s\n",
      "    ----------------\n",
      "    Code entropy: 4.09094151992\n",
      "    Updated tau from 0.100100003183 to 0.200100003183\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1959.4004, 23.654577, 3.961]\n",
      "    SA1 (arg):    [2030.35, 24.47419, 3.854]\n",
      "    SX383:        [1996.1907, 18.126884, 3.996]\n",
      "    SX383 (arg):  [2022.972, 18.673458, 3.929]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5117.497110 29.430931 4.022700]\n",
      "        Train: (max)  [65427.945312 97.115280 4.330000]\n",
      "        Train: (min)  [475.934357 11.173395 3.456000]\n",
      "        Val:   (mean) [4447.952384 29.588233 4.075340]\n",
      "        Val:   (max)  [17802.519531 65.638214 4.414000]\n",
      "        Val:   (min)  [255.959015 8.856159 3.641000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.6197099686s\n",
      "Epoch 12:\n",
      "    101120:  [8.168968 0.006891 0.446994 0.079301 0.838626] [8.168968 2.067390 4.469940 0.793011 0.838626] 0.200100004673 \n",
      "    Total time for epoch: 160.658640146s\n",
      "    ----------------\n",
      "    Code entropy: 4.15018851337\n",
      "    Updated tau from 0.200100004673 to 0.300100004673\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2083.4485, 24.244421, 3.89]\n",
      "    SA1 (arg):    [2166.2986, 25.07579, 3.781]\n",
      "    SX383:        [1932.5962, 18.38241, 4.062]\n",
      "    SX383 (arg):  [1957.2032, 18.902746, 4.01]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5141.909755 30.526348 3.946580]\n",
      "        Train: (max)  [33633.222656 85.921051 4.261000]\n",
      "        Train: (min)  [435.765747 11.506302 3.151000]\n",
      "        Val:   (mean) [4831.488970 28.725505 4.036920]\n",
      "        Val:   (max)  [53901.230469 80.845360 4.399000]\n",
      "        Val:   (min)  [277.071960 9.092046 3.325000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.1768040657s\n",
      "Epoch 13:\n",
      "    101120:  [8.891442 0.007391 0.470467 0.073024 1.239134] [8.891442 2.217398 4.704673 0.730237 1.239134] 0.300099998713 \n",
      "    Total time for epoch: 160.585952044s\n",
      "    ----------------\n",
      "    Code entropy: 4.02512392147\n",
      "    Updated tau from 0.300099998713 to 0.400099998713\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1921.5895, 23.51915, 3.83]\n",
      "    SA1 (arg):    [1988.9296, 24.397881, 3.739]\n",
      "    SX383:        [1482.0781, 16.688921, 3.929]\n",
      "    SX383 (arg):  [1519.7327, 17.340244, 3.857]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4465.247205 30.052927 3.911300]\n",
      "        Train: (max)  [14816.938477 61.799648 4.370000]\n",
      "        Train: (min)  [519.129944 13.265535 3.310000]\n",
      "        Val:   (mean) [5661.640680 31.196829 4.001420]\n",
      "        Val:   (max)  [48501.468750 77.408401 4.414000]\n",
      "        Val:   (min)  [231.326630 7.872106 2.598000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.1620998383s\n",
      "Epoch 14:\n",
      "    101120:  [9.047829 0.007069 0.467389 0.069537 1.557988] [9.047829 2.120573 4.673893 0.695374 1.557988] 0.400099992752 \n",
      "    Total time for epoch: 160.923255205s\n",
      "    ----------------\n",
      "    Code entropy: 3.7718436634\n",
      "    Updated tau from 0.400099992752 to 0.500099992752\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1833.5795, 23.493507, 3.84]\n",
      "    SA1 (arg):    [1908.3473, 24.461569, 3.711]\n",
      "    SX383:        [1552.4504, 16.847717, 3.924]\n",
      "    SX383 (arg):  [1585.4702, 17.466917, 3.849]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6067.685111 31.320081 3.860040]\n",
      "        Train: (max)  [65616.335938 96.746666 4.297000]\n",
      "        Train: (min)  [397.168701 11.807812 2.957000]\n",
      "        Val:   (mean) [4136.441970 26.808820 3.988960]\n",
      "        Val:   (max)  [46050.464844 76.288132 4.365000]\n",
      "        Val:   (min)  [223.632233 7.759450 3.644000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 24.7023389339s\n",
      "Epoch 15:\n",
      "    101120:  [9.270330 0.006881 0.471552 0.066669 1.823819] [9.270330 2.064304 4.715519 0.666689 1.823819] 0.500100016594 \n",
      "    Total time for epoch: 158.54392004s\n",
      "    ----------------\n",
      "    Code entropy: 3.82033749254\n",
      "    Updated tau from 0.500100016594 to 0.600100016594\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1837.6289, 24.292437, 3.902]\n",
      "    SA1 (arg):    [1914.9869, 25.196569, 3.796]\n",
      "    SX383:        [1427.2025, 17.202518, 3.854]\n",
      "    SX383 (arg):  [1459.6277, 17.810564, 3.766]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4694.007977 31.044609 3.898000]\n",
      "        Train: (max)  [20649.472656 73.462982 4.340000]\n",
      "        Train: (min)  [186.525146 8.070505 3.266000]\n",
      "        Val:   (mean) [5725.220969 32.707999 3.960280]\n",
      "        Val:   (max)  [45800.937500 76.344177 4.349000]\n",
      "        Val:   (min)  [404.394531 10.614120 3.302000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.4145400524s\n",
      "Epoch 16:\n",
      "    101120:  [9.320165 0.006534 0.467270 0.060786 2.079274] [9.320165 1.960333 4.672703 0.607855 2.079274] 0.600100040436 \n",
      "    Total time for epoch: 160.718710899s\n",
      "    ----------------\n",
      "    Code entropy: 3.53048244259\n",
      "    Updated tau from 0.600100040436 to 0.700100040436\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2013.5435, 27.273897, 3.691]\n",
      "    SA1 (arg):    [2101.1289, 28.21102, 3.589]\n",
      "    SX383:        [1454.8759, 18.910408, 3.81]\n",
      "    SX383 (arg):  [1494.774, 19.559626, 3.687]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6309.836316 37.474191 3.812060]\n",
      "        Train: (max)  [38087.015625 89.455933 4.255000]\n",
      "        Train: (min)  [254.790955 10.407967 3.100000]\n",
      "        Val:   (mean) [4404.279262 32.260550 3.933080]\n",
      "        Val:   (max)  [17036.869141 71.198631 4.270000]\n",
      "        Val:   (min)  [246.617218 8.666160 3.510000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.6266570091s\n",
      "Epoch 17:\n",
      "    101120:  [10.185177 0.007991 0.464649 0.059897 2.542469] [10.185177 2.397249 4.646491 0.598969 2.542469] 0.700100064278 \n",
      "    Total time for epoch: 160.734022856s\n",
      "    ----------------\n",
      "    Code entropy: 3.45509323194\n",
      "    Updated tau from 0.700100064278 to 0.800100064278\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2057.0452, 26.112213, 3.682]\n",
      "    SA1 (arg):    [2152.2144, 27.109123, 3.579]\n",
      "    SX383:        [1386.3478, 18.497814, 3.797]\n",
      "    SX383 (arg):  [1442.2498, 19.240513, 3.697]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [3642.103474 29.237678 3.829340]\n",
      "        Train: (max)  [13760.563477 53.066414 4.311000]\n",
      "        Train: (min)  [499.329712 11.278016 3.228000]\n",
      "        Val:   (mean) [4851.401475 31.264975 3.936520]\n",
      "        Val:   (max)  [43444.320312 78.429604 4.375000]\n",
      "        Val:   (min)  [237.155518 8.335749 3.394000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 24.9961578846s\n",
      "Epoch 18:\n",
      "    101120:  [10.037388 0.006781 0.480278 0.055338 2.646815] [10.037388 2.034415 4.802776 0.553381 2.646815] 0.80010008812 \n",
      "    Total time for epoch: 155.55975318s\n",
      "    ----------------\n",
      "    Code entropy: 3.36592717849\n",
      "    Updated tau from 0.80010008812 to 0.90010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [1972.3719, 25.716621, 3.776]\n",
      "    SA1 (arg):    [2069.9329, 26.800922, 3.636]\n",
      "    SX383:        [1272.0334, 17.677744, 3.797]\n",
      "    SX383 (arg):  [1315.3417, 18.428101, 3.698]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4710.509667 31.694961 3.777920]\n",
      "        Train: (max)  [19712.773438 77.093102 4.310000]\n",
      "        Train: (min)  [750.456055 15.600337 2.065000]\n",
      "        Val:   (mean) [3846.272058 29.613014 3.976360]\n",
      "        Val:   (max)  [16150.626953 65.593597 4.352000]\n",
      "        Val:   (min)  [235.468262 8.227560 3.514000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.4628190994s\n",
      "Epoch 19:\n",
      "    101120:  [10.727962 0.007512 0.495555 0.053489 2.983890] [10.727962 2.253633 4.955545 0.534893 2.983890] 0.900100111961 \n",
      "    Total time for epoch: 158.715377808s\n",
      "    ----------------\n",
      "    Code entropy: 3.23805424251\n",
      "    Updated tau from 0.900100111961 to 1.00010011196\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2022.7759, 27.062128, 3.657]\n",
      "    SA1 (arg):    [2120.3315, 28.039242, 3.55]\n",
      "    SX383:        [1373.454, 18.789486, 3.793]\n",
      "    SX383 (arg):  [1432.3408, 19.537416, 3.719]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4987.578703 34.421737 3.832980]\n",
      "        Train: (max)  [28266.072266 78.039589 4.301000]\n",
      "        Train: (min)  [241.934341 10.135025 3.314000]\n",
      "        Val:   (mean) [4134.433558 30.323147 3.895040]\n",
      "        Val:   (max)  [16890.648438 67.584846 4.357000]\n",
      "        Val:   (min)  [248.747192 8.479262 2.507000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 24.7278261185s\n",
      "Epoch 20:\n",
      "    101120:  [10.619467 0.006972 0.494189 0.051394 3.072146] [10.619467 2.091497 4.941885 0.513939 3.072146] 1.0001001358 \n",
      "    Total time for epoch: 161.084691048s\n",
      "    ----------------\n",
      "    Code entropy: 3.27828496592\n",
      "    Updated tau from 1.0001001358 to 1.1001001358\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2145.4355, 27.844961, 3.584]\n",
      "    SA1 (arg):    [2264.7002, 29.013777, 3.467]\n",
      "    SX383:        [1173.4907, 18.385633, 3.73]\n",
      "    SX383 (arg):  [1229.557, 19.20783, 3.632]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4863.977700 32.223074 3.753580]\n",
      "        Train: (max)  [51795.644531 81.436905 4.346000]\n",
      "        Train: (min)  [456.121674 13.134606 3.264000]\n",
      "        Val:   (mean) [4866.840033 33.232494 3.891680]\n",
      "        Val:   (max)  [38293.855469 76.540474 4.314000]\n",
      "        Val:   (min)  [290.514465 10.604433 3.392000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.0107440948s\n",
      "Epoch 21:\n",
      "    101120:  [11.253648 0.008574 0.460889 0.050922 3.563486] [11.253648 2.572052 4.608887 0.509223 3.563486] 1.10010015965 \n",
      "    Total time for epoch: 156.955498934s\n",
      "    ----------------\n",
      "    Code entropy: 3.0414824813\n",
      "    Updated tau from 1.10010015965 to 1.20010015965\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2328.8328, 28.88483, 3.429]\n",
      "    SA1 (arg):    [2459.3811, 30.125486, 3.323]\n",
      "    SX383:        [1226.8257, 19.476507, 3.502]\n",
      "    SX383 (arg):  [1295.3818, 20.374144, 3.394]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [3885.091941 31.798378 3.761820]\n",
      "        Train: (max)  [18697.005859 80.718315 4.254000]\n",
      "        Train: (min)  [652.986267 16.172220 2.962000]\n",
      "        Val:   (mean) [4263.219601 33.028413 3.905820]\n",
      "        Val:   (max)  [18054.644531 77.601059 4.369000]\n",
      "        Val:   (min)  [244.911835 8.612745 3.538000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.0673100948s\n",
      "Epoch 22:\n",
      "    101120:  [11.170781 0.007084 0.490540 0.048901 3.651020] [11.170781 2.125344 4.905404 0.489013 3.651020] 1.20010018349 \n",
      "    Total time for epoch: 157.793210983s\n",
      "    ----------------\n",
      "    Code entropy: 2.94285607338\n",
      "    Updated tau from 1.20010018349 to 1.30010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2229.1775, 29.52813, 3.447]\n",
      "    SA1 (arg):    [2357.8984, 30.661781, 3.329]\n",
      "    SX383:        [1382.9176, 20.545645, 3.571]\n",
      "    SX383 (arg):  [1451.8827, 21.435253, 3.451]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5789.887336 36.412682 3.728540]\n",
      "        Train: (max)  [35705.113281 96.783066 4.228000]\n",
      "        Train: (min)  [514.600464 13.380161 2.947000]\n",
      "        Val:   (mean) [5723.989922 37.112315 3.869220]\n",
      "        Val:   (max)  [36939.417969 78.921989 4.294000]\n",
      "        Val:   (min)  [763.534058 17.276167 3.272000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 26.5888619423s\n",
      "Epoch 23:\n",
      "    101120:  [12.076479 0.008402 0.527572 0.052329 3.756974] [12.076479 2.520492 5.275724 0.523291 3.756974] 1.30010020733 \n",
      "    Total time for epoch: 160.245053053s\n",
      "    ----------------\n",
      "    Code entropy: 2.91697683918\n",
      "    Updated tau from 1.30010020733 to 1.40010020733\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2307.6143, 30.020479, 3.462]\n",
      "    SA1 (arg):    [2427.0071, 31.156477, 3.343]\n",
      "    SX383:        [1239.0338, 20.189201, 3.442]\n",
      "    SX383 (arg):  [1311.6282, 21.120356, 3.287]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4376.871012 36.357211 3.617640]\n",
      "        Train: (max)  [12195.038086 68.077087 4.153000]\n",
      "        Train: (min)  [520.301758 13.418756 2.972000]\n",
      "        Val:   (mean) [4422.642216 33.296080 3.772860]\n",
      "        Val:   (max)  [33310.855469 76.982529 4.307000]\n",
      "        Val:   (min)  [273.677216 9.231934 3.340000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.5260748863s\n",
      "Epoch 24:\n",
      "    101120:  [11.974337 0.008372 0.493791 0.043239 4.092477] [11.974337 2.511564 4.937906 0.432390 4.092477] 1.40010023117 \n",
      "    Total time for epoch: 157.931459904s\n",
      "    ----------------\n",
      "    Code entropy: 2.71162674215\n",
      "    Updated tau from 1.40010023117 to 1.50010023117\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2295.7805, 30.079374, 3.324]\n",
      "    SA1 (arg):    [2428.7456, 31.281887, 3.19]\n",
      "    SX383:        [1295.599, 20.387644, 3.396]\n",
      "    SX383 (arg):  [1365.6554, 21.249323, 3.318]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [3283.627809 31.394824 3.573720]\n",
      "        Train: (max)  [13920.311523 74.386711 4.171000]\n",
      "        Train: (min)  [637.868958 14.577258 2.836000]\n",
      "        Val:   (mean) [4942.209914 34.998343 3.672800]\n",
      "        Val:   (max)  [33324.496094 76.003456 4.184000]\n",
      "        Val:   (min)  [253.323151 8.995779 3.142000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.4864578247s\n",
      "Epoch 25:\n",
      "    101120:  [12.563132 0.008530 0.544102 0.043525 4.127831] [12.563132 2.559036 5.441018 0.435249 4.127831] 1.50010025501 \n",
      "    Total time for epoch: 159.48004818s\n",
      "    ----------------\n",
      "    Code entropy: 2.65217854727\n",
      "    Updated tau from 1.50010025501 to 1.60010025501\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2978.3315, 33.144066, 3.258]\n",
      "    SA1 (arg):    [3147.9028, 34.588642, 3.11]\n",
      "    SX383:        [1491.9807, 22.131571, 3.442]\n",
      "    SX383 (arg):  [1560.8854, 22.967987, 3.334]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4536.429059 36.373996 3.657320]\n",
      "        Train: (max)  [23437.082031 79.124306 4.196000]\n",
      "        Train: (min)  [533.765076 14.452800 3.081000]\n",
      "        Val:   (mean) [5124.776893 37.286075 3.703380]\n",
      "        Val:   (max)  [20269.888672 85.591019 4.187000]\n",
      "        Val:   (min)  [446.239777 12.757858 3.047000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.3873260021s\n",
      "Epoch 26:\n",
      "    101120:  [11.847959 0.007304 0.526522 0.038210 4.009295] [11.847959 2.191346 5.265217 0.382100 4.009295] 1.60010027885 \n",
      "    Total time for epoch: 162.987505913s\n",
      "    ----------------\n",
      "    Code entropy: 2.5532842514\n",
      "    Updated tau from 1.60010027885 to 1.70010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2599.8374, 32.995029, 3.086]\n",
      "    SA1 (arg):    [2764.1829, 34.303871, 2.98]\n",
      "    SX383:        [1630.8654, 22.731161, 3.135]\n",
      "    SX383 (arg):  [1702.9268, 23.613251, 3.051]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5942.990038 39.495147 3.345140]\n",
      "        Train: (max)  [23969.482422 80.447685 4.104000]\n",
      "        Train: (min)  [369.027222 12.846698 1.958000]\n",
      "        Val:   (mean) [6040.729212 40.520780 3.499540]\n",
      "        Val:   (max)  [34473.984375 79.418739 4.096000]\n",
      "        Val:   (min)  [277.477264 9.514773 2.391000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.0593369007s\n",
      "Epoch 27:\n",
      "    101120:  [12.169295 0.007665 0.549534 0.037289 4.001630] [12.169295 2.299434 5.495339 0.372893 4.001630] 1.7001003027 \n",
      "    Total time for epoch: 158.059865952s\n",
      "    ----------------\n",
      "    Code entropy: 2.40390529821\n",
      "    Updated tau from 1.7001003027 to 1.8001003027\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2836.3933, 34.888962, 3.075]\n",
      "    SA1 (arg):    [3027.0212, 36.253136, 2.936]\n",
      "    SX383:        [1541.6166, 23.322803, 3.223]\n",
      "    SX383 (arg):  [1641.0741, 24.326466, 3.122]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5437.254596 39.521054 3.316560]\n",
      "        Train: (max)  [34320.542969 110.821404 4.000000]\n",
      "        Train: (min)  [696.553040 15.966007 2.739000]\n",
      "        Val:   (mean) [5368.197412 37.791162 3.535860]\n",
      "        Val:   (max)  [38140.335938 82.267563 4.061000]\n",
      "        Val:   (min)  [310.325012 10.104874 3.052000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.1257030964s\n",
      "Epoch 28:\n",
      "    101120:  [12.351286 0.007217 0.566104 0.035600 4.169171] [12.351286 2.165074 5.661043 0.355997 4.169171] 1.80010032654 \n",
      "    Total time for epoch: 160.726413012s\n",
      "    ----------------\n",
      "    Code entropy: 2.28912959553\n",
      "    Updated tau from 1.80010032654 to 1.90010032654\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2852.45, 34.462872, 3.046]\n",
      "    SA1 (arg):    [3025.8381, 35.755421, 2.935]\n",
      "    SX383:        [1637.1342, 23.85264, 3.252]\n",
      "    SX383 (arg):  [1734.9486, 24.838051, 3.161]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7376.420615 42.632118 3.425580]\n",
      "        Train: (max)  [68159.984375 152.211044 4.068000]\n",
      "        Train: (min)  [715.156738 15.894766 2.777000]\n",
      "        Val:   (mean) [6362.993210 42.477188 3.539100]\n",
      "        Val:   (max)  [36689.402344 92.741722 3.961000]\n",
      "        Val:   (min)  [299.765472 9.948824 3.047000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.7552099228s\n",
      "Epoch 29:\n",
      "    101120:  [13.111925 0.009252 0.566658 0.034701 4.322739] [13.111925 2.775591 5.666581 0.347015 4.322739] 1.90010035038 \n",
      "    Total time for epoch: 159.181712866s\n",
      "    ----------------\n",
      "    Code entropy: 2.31476977653\n",
      "    Updated tau from 1.90010035038 to 2.00010035038\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3047.1995, 36.412331, 3.069]\n",
      "    SA1 (arg):    [3268.7952, 37.915375, 2.956]\n",
      "    SX383:        [1785.3485, 25.144659, 3.15]\n",
      "    SX383 (arg):  [1900.4954, 26.303244, 3.06]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6100.644979 42.251319 3.392180]\n",
      "        Train: (max)  [28063.875000 88.965050 3.970000]\n",
      "        Train: (min)  [404.299255 13.728720 2.421000]\n",
      "        Val:   (mean) [5574.258270 38.731550 3.550520]\n",
      "        Val:   (max)  [37735.351562 97.214241 3.969000]\n",
      "        Val:   (min)  [319.373749 10.328249 3.070000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.3859322071s\n",
      "Epoch 30:\n",
      "    101120:  [13.317152 0.009692 0.578503 0.035443 4.269969] [13.317152 2.907720 5.785032 0.354431 4.269969] 2.00010037422 \n",
      "    Total time for epoch: 160.123728991s\n",
      "    ----------------\n",
      "    Code entropy: 2.26556269772\n",
      "    Updated tau from 2.00010037422 to 2.10010037422\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3231.7053, 37.245651, 2.932]\n",
      "    SA1 (arg):    [3439.4636, 38.673714, 2.837]\n",
      "    SX383:        [1877.2416, 25.791077, 3.082]\n",
      "    SX383 (arg):  [1977.5774, 26.742378, 2.989]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7657.467058 47.900492 3.243180]\n",
      "        Train: (max)  [27159.996094 90.013260 3.959000]\n",
      "        Train: (min)  [609.636780 16.000956 2.468000]\n",
      "        Val:   (mean) [6614.335764 43.408769 3.479620]\n",
      "        Val:   (max)  [40932.988281 86.593948 3.973000]\n",
      "        Val:   (min)  [640.404785 16.173138 3.015000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.7061707973s\n",
      "Epoch 31:\n",
      "    101120:  [13.047935 0.009149 0.560209 0.032549 4.375690] [13.047935 2.744667 5.602089 0.325490 4.375690] 2.10010027885 \n",
      "    Total time for epoch: 157.042768002s\n",
      "    ----------------\n",
      "    Code entropy: 2.02429063733\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3591.6973, 39.526325, 2.905]\n",
      "    SA1 (arg):    [3839.4404, 41.119102, 2.798]\n",
      "    SX383:        [1978.5537, 27.267748, 2.992]\n",
      "    SX383 (arg):  [2119.4387, 28.439554, 2.867]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [9637.726086 50.902424 3.216920]\n",
      "        Train: (max)  [78445.835938 167.339996 3.835000]\n",
      "        Train: (min)  [459.349762 14.172990 2.701000]\n",
      "        Val:   (mean) [6840.084395 44.362903 3.363180]\n",
      "        Val:   (max)  [42570.007812 90.954948 3.786000]\n",
      "        Val:   (min)  [379.477722 11.324628 2.000000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.2938861847s\n",
      "Epoch 32:\n",
      "    101120:  [14.327875 0.011388 0.616618 0.031981 4.425430] [14.327875 3.416460 6.166176 0.319810 4.425430] 2.20010018349 \n",
      "    Total time for epoch: 161.442024946s\n",
      "    ----------------\n",
      "    Code entropy: 1.87974247643\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3709.3286, 40.736378, 2.766]\n",
      "    SA1 (arg):    [3937.4153, 42.135174, 2.679]\n",
      "    SX383:        [1975.2292, 27.70517, 2.983]\n",
      "    SX383 (arg):  [2078.9211, 28.58979, 2.916]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6908.192566 46.445437 3.133580]\n",
      "        Train: (max)  [29734.302734 108.136772 3.609000]\n",
      "        Train: (min)  [1454.627930 22.872000 2.509000]\n",
      "        Val:   (mean) [7131.353646 46.102254 3.321740]\n",
      "        Val:   (max)  [39593.863281 92.644760 3.948000]\n",
      "        Val:   (min)  [368.076569 11.291177 2.876000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.3311479092s\n",
      "Epoch 33:\n",
      "    101120:  [13.417297 0.009632 0.561772 0.031576 4.594217] [13.417297 2.889602 5.617717 0.315763 4.594217] 2.20010018349 \n",
      "    Total time for epoch: 160.907358885s\n",
      "    ----------------\n",
      "    Code entropy: 2.08117950907\n",
      "    Updated tau from 2.20010018349 to 2.30010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3414.446, 38.534878, 2.859]\n",
      "    SA1 (arg):    [3647.2354, 39.992031, 2.777]\n",
      "    SX383:        [1837.868, 26.453506, 2.961]\n",
      "    SX383 (arg):  [1973.2461, 27.645832, 2.872]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6821.338246 44.061091 3.239000]\n",
      "        Train: (max)  [73924.687500 164.910446 3.791000]\n",
      "        Train: (min)  [780.421936 17.763027 2.712000]\n",
      "        Val:   (mean) [7438.372995 47.230083 3.303160]\n",
      "        Val:   (max)  [38747.078125 103.485886 3.798000]\n",
      "        Val:   (min)  [351.900421 10.988766 2.773000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.5491888523s\n",
      "Epoch 34:\n",
      "    101120:  [13.807919 0.010680 0.577856 0.029724 4.528252] [13.807919 3.203871 5.778558 0.297237 4.528252] 2.30010008812 \n",
      "    Total time for epoch: 161.692481995s\n",
      "    ----------------\n",
      "    Code entropy: 1.9903695806\n",
      "    Updated tau from 2.30010008812 to 2.40010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3986.6509, 41.982204, 2.81]\n",
      "    SA1 (arg):    [4172.0352, 43.107571, 2.726]\n",
      "    SX383:        [2293.906, 28.991026, 2.977]\n",
      "    SX383 (arg):  [2408.47, 29.875532, 2.889]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6645.539241 46.617344 3.155360]\n",
      "        Train: (max)  [33619.726562 109.278839 3.688000]\n",
      "        Train: (min)  [1032.242065 20.633902 2.685000]\n",
      "        Val:   (mean) [7540.475214 46.665865 3.325100]\n",
      "        Val:   (max)  [42729.355469 93.983986 4.008000]\n",
      "        Val:   (min)  [608.197266 14.848435 2.799000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.4276971817s\n",
      "Epoch 35:\n",
      "    101120:  [13.671711 0.009526 0.562361 0.030851 4.881774] [13.671711 2.857822 5.623606 0.308509 4.881774] 2.40009999275 \n",
      "    Total time for epoch: 161.866645813s\n",
      "    ----------------\n",
      "    Code entropy: 2.02460056429\n",
      "    Updated tau from 2.40009999275 to 2.50009999275\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3602.8315, 39.912781, 2.926]\n",
      "    SA1 (arg):    [3844.9902, 41.39743, 2.836]\n",
      "    SX383:        [1930.2313, 27.179472, 2.951]\n",
      "    SX383 (arg):  [2050.2654, 28.23056, 2.849]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7055.021477 47.989340 3.310300]\n",
      "        Train: (max)  [43477.082031 134.826584 3.823000]\n",
      "        Train: (min)  [1172.536011 21.197592 2.505000]\n",
      "        Val:   (mean) [7604.684495 46.947723 3.408820]\n",
      "        Val:   (max)  [38969.097656 104.296524 4.028000]\n",
      "        Val:   (min)  [368.377777 11.235769 2.802000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.1301219463s\n",
      "Epoch 36:\n",
      "    101120:  [13.717010 0.010436 0.568951 0.028871 4.608107] [13.717010 3.130691 5.689506 0.288707 4.608107] 2.50009989738 \n",
      "    Total time for epoch: 162.929769039s\n",
      "    ----------------\n",
      "    Code entropy: 1.89197032075\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4105.1504, 42.534168, 2.8]\n",
      "    SA1 (arg):    [4403.6616, 44.209785, 2.708]\n",
      "    SX383:        [2239.0908, 29.429922, 2.913]\n",
      "    SX383 (arg):  [2370.0222, 30.487265, 2.85]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6800.031073 47.559556 3.151860]\n",
      "        Train: (max)  [24536.246094 93.385445 3.779000]\n",
      "        Train: (min)  [990.609802 19.521526 2.225000]\n",
      "        Val:   (mean) [7765.239445 48.846809 3.304520]\n",
      "        Val:   (max)  [36738.332031 115.018318 3.754000]\n",
      "        Val:   (min)  [590.793884 14.938652 2.778000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "    Total time for evaluation: 25.3857440948s\n",
      "Epoch 37:\n",
      "    101120:  [13.839506 0.010413 0.582270 0.028408 4.608843] [13.839506 3.123883 5.822696 0.284084 4.608843] 2.50009989738 \n",
      "    Total time for epoch: 161.497469187s\n",
      "    ----------------\n",
      "    Code entropy: 1.84620272595\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3959.1633, 41.799103, 2.849]\n",
      "    SA1 (arg):    [4209.2568, 43.236095, 2.74]\n",
      "    SX383:        [2092.052, 28.456945, 2.932]\n",
      "    SX383 (arg):  [2229.4509, 29.549036, 2.869]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7100.375947 46.890813 3.266860]\n",
      "        Train: (max)  [37477.789062 110.571732 3.748000]\n",
      "        Train: (min)  [881.116699 16.116421 2.410000]\n",
      "        Val:   (mean) [7002.444718 46.087442 3.349440]\n",
      "        Val:   (max)  [37881.800781 98.104050 3.750000]\n",
      "        Val:   (min)  [371.052551 11.440816 2.887000]\n",
      "    NEW best model! Validation mean-PESQ 3.34944\n",
      "    Saving model...\n",
      "    Total time for evaluation: 25.5502929688s\n",
      "Epoch 38:\n",
      "    101120:  [13.702062 0.009638 0.604078 0.026671 4.503220] [13.702062 2.891352 6.040775 0.266715 4.503220] 2.50009989738 \n",
      "    Total time for epoch: 160.932337999s\n",
      "    ----------------\n",
      "    Code entropy: 1.8473388265\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3980.1689, 42.107464, 2.851]\n",
      "    SA1 (arg):    [4240.1816, 43.580807, 2.765]\n",
      "    SX383:        [2115.261, 28.601778, 2.937]\n",
      "    SX383 (arg):  [2242.1946, 29.649853, 2.872]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8058.068020 49.482568 3.032080]\n",
      "        Train: (max)  [35156.949219 103.426163 3.585000]\n",
      "        Train: (min)  [1351.537109 19.494202 2.303000]\n",
      "        Val:   (mean) [7454.120881 48.155247 3.322060]\n",
      "        Val:   (max)  [44475.214844 93.566109 3.877000]\n",
      "        Val:   (min)  [808.609192 14.968635 2.049000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.1188120842s\n",
      "Epoch 39:\n",
      "    101120:  [13.874170 0.010350 0.580717 0.027423 4.687698] [13.874170 3.105078 5.807166 0.274227 4.687698] 2.50009989738 \n",
      "    Total time for epoch: 161.010478973s\n",
      "    ----------------\n",
      "    Code entropy: 1.77882196726\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3948.085, 42.093437, 2.801]\n",
      "    SA1 (arg):    [4205.6338, 43.53101, 2.751]\n",
      "    SX383:        [2007.9878, 27.871069, 2.943]\n",
      "    SX383 (arg):  [2124.2107, 28.811213, 2.857]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [9195.651332 49.423872 3.104600]\n",
      "        Train: (max)  [79738.890625 173.623444 3.786000]\n",
      "        Train: (min)  [504.290833 14.966431 2.490000]\n",
      "        Val:   (mean) [7059.125575 45.297937 3.257220]\n",
      "        Val:   (max)  [41315.699219 98.475937 3.740000]\n",
      "        Val:   (min)  [383.977661 11.692154 2.480000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.1072769165s\n",
      "Epoch 40:\n",
      "    101120:  [13.403171 0.009708 0.569734 0.027108 4.522223] [13.403171 2.912531 5.697337 0.271079 4.522223] 2.50009989738 \n",
      "    Total time for epoch: 160.974279881s\n",
      "    ----------------\n",
      "    Code entropy: 1.80461488551\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3856.9248, 41.379177, 2.856]\n",
      "    SA1 (arg):    [4066.7407, 42.544292, 2.77]\n",
      "    SX383:        [2122.3052, 28.170681, 2.969]\n",
      "    SX383 (arg):  [2230.1113, 29.073675, 2.899]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7291.917428 47.124523 3.135540]\n",
      "        Train: (max)  [74482.226562 114.068016 3.584000]\n",
      "        Train: (min)  [964.903992 19.121811 2.558000]\n",
      "        Val:   (mean) [5885.116649 44.253120 3.343060]\n",
      "        Val:   (max)  [28063.638672 107.440125 3.823000]\n",
      "        Val:   (min)  [583.713440 14.771980 2.175000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.1536180973s\n",
      "Epoch 41:\n",
      "    101120:  [14.309042 0.011436 0.595251 0.026990 4.655685] [14.309042 3.430950 5.952509 0.269897 4.655685] 2.50009989738 \n",
      "    Total time for epoch: 160.929184198s\n",
      "    ----------------\n",
      "    Code entropy: 1.9014390363\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3625.6306, 40.315197, 2.865]\n",
      "    SA1 (arg):    [3837.116, 41.664505, 2.784]\n",
      "    SX383:        [2002.7285, 27.849598, 2.911]\n",
      "    SX383 (arg):  [2125.9814, 28.893913, 2.83]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6243.181731 45.031807 3.152000]\n",
      "        Train: (max)  [27742.978516 98.506714 3.736000]\n",
      "        Train: (min)  [938.332642 18.725851 2.424000]\n",
      "        Val:   (mean) [7111.190829 47.571043 3.246020]\n",
      "        Val:   (max)  [23514.236328 96.248589 3.771000]\n",
      "        Val:   (min)  [587.424133 14.805449 2.609000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.4176108837s\n",
      "Epoch 42:\n",
      "    101120:  [13.957384 0.009980 0.585371 0.027396 4.835792] [13.957384 2.993930 5.853705 0.273957 4.835792] 2.50009989738 \n",
      "    Total time for epoch: 160.969602823s\n",
      "    ----------------\n",
      "    Code entropy: 1.81909306143\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3716.5212, 40.278202, 2.911]\n",
      "    SA1 (arg):    [3905.5676, 41.374332, 2.832]\n",
      "    SX383:        [2136.6597, 28.111851, 2.98]\n",
      "    SX383 (arg):  [2232.6616, 28.889313, 2.893]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7112.401199 48.780890 3.209040]\n",
      "        Train: (max)  [24056.460938 95.354446 3.747000]\n",
      "        Train: (min)  [1574.564331 25.370888 2.580000]\n",
      "        Val:   (mean) [8572.861473 51.546076 3.286580]\n",
      "        Val:   (max)  [41562.171875 107.639671 3.743000]\n",
      "        Val:   (min)  [374.775299 11.398646 2.281000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.2297410965s\n",
      "Epoch 43:\n",
      "    101120:  [13.872847 0.010133 0.615775 0.026475 4.410491] [13.872847 3.039856 6.157753 0.264746 4.410491] 2.50009989738 \n",
      "    Total time for epoch: 160.887988091s\n",
      "    ----------------\n",
      "    Code entropy: 1.7877418165\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3955.8708, 41.668316, 2.834]\n",
      "    SA1 (arg):    [4204.4966, 43.014267, 2.744]\n",
      "    SX383:        [2310.0149, 28.869043, 2.918]\n",
      "    SX383 (arg):  [2416.5105, 29.744381, 2.858]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7656.125288 47.029227 3.163900]\n",
      "        Train: (max)  [46210.875000 139.878525 3.776000]\n",
      "        Train: (min)  [863.058655 16.425173 1.834000]\n",
      "        Val:   (mean) [6274.542840 44.252709 3.273920]\n",
      "        Val:   (max)  [23576.251953 96.192284 3.966000]\n",
      "        Val:   (min)  [391.265228 11.618243 2.070000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.6409101486s\n",
      "Epoch 44:\n",
      "    101120:  [13.783554 0.010766 0.586631 0.026318 4.424207] [13.783554 3.229858 5.866311 0.263177 4.424207] 2.50009989738 \n",
      "    Total time for epoch: 160.961462975s\n",
      "    ----------------\n",
      "    Code entropy: 1.8992395149\n",
      "    Tau stays at 2.50009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4196.2104, 42.740784, 2.772]\n",
      "    SA1 (arg):    [4376.9819, 43.782436, 2.684]\n",
      "    SX383:        [2255.2251, 29.240301, 2.919]\n",
      "    SX383 (arg):  [2348.6414, 29.946455, 2.836]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [9730.286377 54.170536 3.117520]\n",
      "        Train: (max)  [66704.914062 111.942848 3.656000]\n",
      "        Train: (min)  [1372.917480 24.643021 2.651000]\n",
      "        Val:   (mean) [8478.112741 51.219476 3.225180]\n",
      "        Val:   (max)  [41360.183594 113.765244 3.917000]\n",
      "        Val:   (min)  [432.123138 12.212540 2.399000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.4804868698s\n",
      "Epoch 45:\n",
      "    101120:  [14.554903 0.012348 0.593394 0.025342 4.663086] [14.554903 3.704453 5.933942 0.253423 4.663086] 2.50009989738 \n",
      "    Total time for epoch: 161.157218933s\n",
      "    ----------------\n",
      "    Code entropy: 1.75794133395\n",
      "    Updated tau from 2.50009989738 to 2.40009989738\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3715.5491, 41.170746, 2.854]\n",
      "    SA1 (arg):    [3946.9976, 42.525433, 2.754]\n",
      "    SX383:        [2063.4641, 28.3092, 2.919]\n",
      "    SX383 (arg):  [2168.6904, 29.194254, 2.844]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7054.408875 46.823812 3.106560]\n",
      "        Train: (max)  [40216.324219 131.851578 3.676000]\n",
      "        Train: (min)  [869.210693 18.738733 2.548000]\n",
      "        Val:   (mean) [7495.725357 48.207730 3.287520]\n",
      "        Val:   (max)  [41172.695312 97.657150 3.764000]\n",
      "        Val:   (min)  [385.739655 11.633021 2.595000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.0488159657s\n",
      "Epoch 46:\n",
      "    101120:  [14.237404 0.011673 0.604469 0.025576 4.435126] [14.237404 3.501832 6.044686 0.255762 4.435126] 2.40009999275 \n",
      "    Total time for epoch: 161.056872845s\n",
      "    ----------------\n",
      "    Code entropy: 1.90671465015\n",
      "    Tau stays at 2.40009999275\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3619.0479, 39.946625, 2.949]\n",
      "    SA1 (arg):    [3822.2178, 41.135731, 2.862]\n",
      "    SX383:        [2050.3572, 28.058971, 3.074]\n",
      "    SX383 (arg):  [2148.3154, 28.839136, 2.996]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [9451.635886 51.899511 3.167900]\n",
      "        Train: (max)  [66803.750000 110.047363 3.826000]\n",
      "        Train: (min)  [1677.116943 24.235020 1.774000]\n",
      "        Val:   (mean) [6944.617904 46.127520 3.372820]\n",
      "        Val:   (max)  [38016.289062 93.903328 4.008000]\n",
      "        Val:   (min)  [356.730408 11.262526 2.639000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 24.6785898209s\n",
      "Epoch 47:\n",
      "    101120:  [13.827465 0.010343 0.594513 0.025556 4.523954] [13.827465 3.102823 5.945134 0.255555 4.523954] 2.40009999275 \n",
      "    Total time for epoch: 161.355264187s\n",
      "    ----------------\n",
      "    Code entropy: 1.71974225624\n",
      "    Updated tau from 2.40009999275 to 2.30009999275\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3605.5999, 39.969471, 2.923]\n",
      "    SA1 (arg):    [3800.053, 41.143173, 2.854]\n",
      "    SX383:        [1929.2638, 27.298027, 2.903]\n",
      "    SX383 (arg):  [2027.757, 28.1884, 2.835]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6587.261879 45.583946 3.118740]\n",
      "        Train: (max)  [25556.982422 94.738831 3.637000]\n",
      "        Train: (min)  [752.157104 17.241800 2.503000]\n",
      "        Val:   (mean) [7007.129105 45.967018 3.250480]\n",
      "        Val:   (max)  [38620.023438 95.146461 3.643000]\n",
      "        Val:   (min)  [716.697327 14.200251 2.392000]\n",
      "    Best validation mean-PESQ seen: 3.34944\n",
      "    Total time for evaluation: 25.3442969322s\n",
      "Epoch 48:\n",
      "    101120:  [13.603301 0.010382 0.568737 0.026257 4.538785] [13.603301 3.114582 5.687366 0.262568 4.538785] 2.30010008812 \n",
      "    Total time for epoch: 158.639337063s\n",
      "    ----------------\n",
      "    Code entropy: 1.81726908022\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3517.4263, 39.419968, 2.978]\n",
      "    SA1 (arg):    [3727.8875, 40.603886, 2.909]\n",
      "    SX383:        [2124.7334, 28.237629, 2.966]\n",
      "    SX383 (arg):  [2231.0579, 29.169048, 2.899]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6374.556774 45.957194 3.332840]\n",
      "        Train: (max)  [21537.050781 86.921173 3.831000]\n",
      "        Train: (min)  [944.187195 16.287348 2.691000]\n",
      "        Val:   (mean) [7420.453148 47.355159 3.447580]\n",
      "        Val:   (max)  [39571.667969 105.565536 4.035000]\n",
      "        Val:   (min)  [820.891541 18.159340 2.921000]\n",
      "    NEW best model! Validation mean-PESQ 3.44758\n",
      "    Saving model...\n",
      "    Total time for evaluation: 25.0552928448s\n",
      "Epoch 49:\n",
      "    101120:  [13.698002 0.010956 0.582962 0.025911 4.322608] [13.698002 3.286665 5.829624 0.259105 4.322608] 2.30010008812 \n",
      "    Total time for epoch: 161.700021029s\n",
      "    ----------------\n",
      "    Code entropy: 2.01346571625\n",
      "    Updated tau from 2.30010008812 to 2.40010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3304.2395, 38.170433, 2.931]\n",
      "    SA1 (arg):    [3449.2798, 39.062111, 2.854]\n",
      "    SX383:        [1970.6648, 26.862839, 3.02]\n",
      "    SX383 (arg):  [2049.9258, 27.584894, 2.961]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6236.943796 44.403754 3.248780]\n",
      "        Train: (max)  [30153.853516 98.805450 3.787000]\n",
      "        Train: (min)  [444.668976 13.963458 2.483000]\n",
      "        Val:   (mean) [6999.430837 45.905833 3.458420]\n",
      "        Val:   (max)  [38249.570312 90.778191 4.001000]\n",
      "        Val:   (min)  [943.908081 17.228277 2.867000]\n",
      "    Best validation mean-PESQ seen: 3.44758\n",
      "    Total time for evaluation: 24.891064167s\n",
      "Epoch 50:\n",
      "    101120:  [12.968031 0.009221 0.574146 0.024388 4.216276] [12.968031 2.766407 5.741465 0.243883 4.216276] 2.40009999275 \n",
      "    Total time for epoch: 159.174041986s\n",
      "    ----------------\n",
      "    Code entropy: 1.88807871315\n",
      "    Tau stays at 2.40009999275\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3644.019, 40.199203, 3.005]\n",
      "    SA1 (arg):    [3828.6196, 41.31609, 2.909]\n",
      "    SX383:        [2082.136, 28.199554, 2.964]\n",
      "    SX383 (arg):  [2169.4473, 28.937628, 2.908]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7208.109231 46.033786 3.262620]\n",
      "        Train: (max)  [30505.876953 109.847137 3.716000]\n",
      "        Train: (min)  [1017.858276 19.207741 2.612000]\n",
      "        Val:   (mean) [7057.406705 45.475613 3.377820]\n",
      "        Val:   (max)  [37786.722656 107.562912 3.715000]\n",
      "        Val:   (min)  [378.930634 11.417268 2.665000]\n",
      "    Best validation mean-PESQ seen: 3.44758\n",
      "    Total time for evaluation: 24.9537918568s\n",
      "Epoch 51:\n",
      "    101120:  [12.794650 0.008997 0.565236 0.024144 4.201609] [12.794650 2.699243 5.652361 0.241437 4.201609] 2.40009999275 \n",
      "    Total time for epoch: 162.734730005s\n",
      "    ----------------\n",
      "    Code entropy: 1.88421365589\n",
      "    Tau stays at 2.40009999275\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3497.8315, 39.155888, 2.915]\n",
      "    SA1 (arg):    [3687.897, 40.365002, 2.84]\n",
      "    SX383:        [1982.2247, 27.731524, 2.89]\n",
      "    SX383 (arg):  [2086.5256, 28.616114, 2.83]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6025.013311 43.940483 3.213940]\n",
      "        Train: (max)  [32138.244141 114.382118 3.852000]\n",
      "        Train: (min)  [1309.557007 22.753986 2.471000]\n",
      "        Val:   (mean) [7592.865880 47.923185 3.392020]\n",
      "        Val:   (max)  [37423.390625 105.559616 3.821000]\n",
      "        Val:   (min)  [372.670837 11.305341 2.818000]\n",
      "    Best validation mean-PESQ seen: 3.44758\n",
      "    Total time for evaluation: 25.1301090717s\n",
      "Epoch 52:\n",
      "    101120:  [13.300369 0.009839 0.573035 0.025059 4.367609] [13.300369 2.951816 5.730352 0.250593 4.367609] 2.40009999275 \n",
      "    Total time for epoch: 162.183281183s\n",
      "    ----------------\n",
      "    Code entropy: 1.76243648159\n",
      "    Updated tau from 2.40009999275 to 2.30009999275\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3655.604, 40.453972, 2.888]\n",
      "    SA1 (arg):    [3879.0142, 41.717274, 2.818]\n",
      "    SX383:        [1991.7635, 27.628229, 3.033]\n",
      "    SX383 (arg):  [2101.2288, 28.527914, 2.938]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7212.453287 46.397835 3.201280]\n",
      "        Train: (max)  [42239.625000 111.354012 3.800000]\n",
      "        Train: (min)  [1002.862488 19.154226 2.588000]\n",
      "        Val:   (mean) [6788.148541 47.191542 3.327280]\n",
      "        Val:   (max)  [23375.166016 92.566246 3.748000]\n",
      "        Val:   (min)  [386.489563 11.617615 2.398000]\n",
      "    Best validation mean-PESQ seen: 3.44758\n",
      "    Total time for evaluation: 24.8088798523s\n",
      "Epoch 53:\n",
      "    101120:  [12.971550 0.009348 0.568910 0.025454 4.223596] [12.971550 2.804316 5.689096 0.254541 4.223596] 2.30010008812 \n",
      "    Total time for epoch: 157.220753908s\n",
      "    ----------------\n",
      "    Code entropy: 1.76189247703\n",
      "    Updated tau from 2.30010008812 to 2.20010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3390.0671, 38.544781, 2.985]\n",
      "    SA1 (arg):    [3574.9792, 39.714195, 2.92]\n",
      "    SX383:        [1881.868, 26.418221, 3.067]\n",
      "    SX383 (arg):  [1972.842, 27.235075, 2.985]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7643.122183 47.097708 3.251540]\n",
      "        Train: (max)  [38294.078125 94.856293 3.894000]\n",
      "        Train: (min)  [491.458740 15.085038 2.655000]\n",
      "        Val:   (mean) [6041.824351 43.403743 3.471560]\n",
      "        Val:   (max)  [35407.339844 89.930321 4.159000]\n",
      "        Val:   (min)  [692.914001 13.846833 2.754000]\n",
      "    NEW best model! Validation mean-PESQ 3.47156\n",
      "    Saving model...\n",
      "    Total time for evaluation: 24.7702131271s\n",
      "Epoch 54:\n",
      "    101120:  [12.811258 0.009689 0.547768 0.025590 4.170988] [12.811258 2.906685 5.477683 0.255902 4.170988] 2.20010018349 \n",
      "    Total time for epoch: 159.298492193s\n",
      "    ----------------\n",
      "    Code entropy: 1.83582449289\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3249.3787, 37.90559, 3.055]\n",
      "    SA1 (arg):    [3420.8806, 38.869228, 2.99]\n",
      "    SX383:        [1873.2754, 26.147408, 3.099]\n",
      "    SX383 (arg):  [1959.1414, 26.895639, 3.022]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5997.366124 43.304504 3.347840]\n",
      "        Train: (max)  [33775.007812 119.940033 4.018000]\n",
      "        Train: (min)  [750.557434 15.133193 2.648000]\n",
      "        Val:   (mean) [6254.075414 42.590300 3.483040]\n",
      "        Val:   (max)  [32594.925781 99.601784 3.985000]\n",
      "        Val:   (min)  [531.241028 14.090109 3.034000]\n",
      "    NEW best model! Validation mean-PESQ 3.48304\n",
      "    Saving model...\n",
      "    Total time for evaluation: 24.9765238762s\n",
      "Epoch 55:\n",
      "    101120:  [11.959722 0.008228 0.535210 0.024502 3.894076] [11.959722 2.468526 5.352098 0.245022 3.894076] 2.20010018349 \n",
      "    Total time for epoch: 157.382791996s\n",
      "    ----------------\n",
      "    Code entropy: 1.74690016455\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3213.7861, 37.911873, 3.042]\n",
      "    SA1 (arg):    [3371.5781, 38.913639, 2.957]\n",
      "    SX383:        [1867.8947, 26.314838, 3.022]\n",
      "    SX383 (arg):  [1958.0768, 27.050241, 2.959]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5970.377452 41.235049 3.288140]\n",
      "        Train: (max)  [43207.339844 95.251602 3.864000]\n",
      "        Train: (min)  [925.965759 18.435238 2.696000]\n",
      "        Val:   (mean) [5533.135974 41.489927 3.455340]\n",
      "        Val:   (max)  [20618.343750 87.421219 4.065000]\n",
      "        Val:   (min)  [510.813141 13.743608 2.423000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.4291419983s\n",
      "Epoch 56:\n",
      "    101120:  [12.741543 0.009163 0.596858 0.024519 3.778892] [12.741543 2.748886 5.968578 0.245188 3.778892] 2.10010027885 \n",
      "    Total time for epoch: 160.016222s\n",
      "    ----------------\n",
      "    Code entropy: 1.93516668363\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3225.1594, 37.962219, 3.05]\n",
      "    SA1 (arg):    [3392.2229, 39.009075, 2.992]\n",
      "    SX383:        [2054.249, 26.552055, 3.086]\n",
      "    SX383 (arg):  [2139.6831, 27.293135, 3.029]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6613.372738 45.621025 3.280120]\n",
      "        Train: (max)  [20068.656250 91.516792 3.906000]\n",
      "        Train: (min)  [848.011353 18.197443 2.561000]\n",
      "        Val:   (mean) [7339.252217 46.370457 3.416520]\n",
      "        Val:   (max)  [39492.031250 102.449562 3.953000]\n",
      "        Val:   (min)  [350.050873 11.046571 2.619000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.7037320137s\n",
      "Epoch 57:\n",
      "    101120:  [12.830999 0.009385 0.570072 0.025127 4.063397] [12.830999 2.815610 5.700721 0.251272 4.063397] 2.10010027885 \n",
      "    Total time for epoch: 160.671891928s\n",
      "    ----------------\n",
      "    Code entropy: 1.92524341356\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2994.9268, 36.586193, 3.135]\n",
      "    SA1 (arg):    [3123.1421, 37.443974, 3.069]\n",
      "    SX383:        [1763.6227, 24.707607, 3.253]\n",
      "    SX383 (arg):  [1849.9436, 25.477798, 3.18]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6221.114335 40.472022 3.343400]\n",
      "        Train: (max)  [37287.753906 97.117943 3.913000]\n",
      "        Train: (min)  [752.236755 15.490449 2.508000]\n",
      "        Val:   (mean) [6617.713481 45.555971 3.491460]\n",
      "        Val:   (max)  [24229.517578 96.517288 3.917000]\n",
      "        Val:   (min)  [702.906616 13.781159 2.431000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.6911449432s\n",
      "Epoch 58:\n",
      "    101120:  [12.912999 0.009643 0.581957 0.024899 3.951485] [12.912999 2.892956 5.819568 0.248990 3.951485] 2.10010027885 \n",
      "    Total time for epoch: 161.094556093s\n",
      "    ----------------\n",
      "    Code entropy: 1.99435173453\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3261.812, 38.268246, 3.057]\n",
      "    SA1 (arg):    [3420.3267, 39.283543, 2.982]\n",
      "    SX383:        [1933.6565, 26.749151, 3.073]\n",
      "    SX383 (arg):  [2014.7769, 27.449759, 3.012]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6595.054794 44.952998 3.296940]\n",
      "        Train: (max)  [59534.445312 105.005608 3.801000]\n",
      "        Train: (min)  [596.919983 16.322968 2.642000]\n",
      "        Val:   (mean) [6815.122389 44.588293 3.433200]\n",
      "        Val:   (max)  [36089.941406 101.162674 4.023000]\n",
      "        Val:   (min)  [357.982117 11.014124 2.617000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.0757849216s\n",
      "Epoch 59:\n",
      "    101120:  [12.507345 0.008744 0.546825 0.025246 4.163492] [12.507345 2.623140 5.468249 0.252464 4.163492] 2.20010018349 \n",
      "    Total time for epoch: 160.657813072s\n",
      "    ----------------\n",
      "    Code entropy: 1.8432737528\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3230.001, 38.086723, 3.085]\n",
      "    SA1 (arg):    [3389.7502, 39.067104, 3.0]\n",
      "    SX383:        [1885.0226, 26.556046, 3.083]\n",
      "    SX383 (arg):  [1983.9602, 27.391809, 3.02]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6381.905586 43.942802 3.246480]\n",
      "        Train: (max)  [36006.570312 87.891342 3.865000]\n",
      "        Train: (min)  [990.931641 17.704382 2.312000]\n",
      "        Val:   (mean) [6250.219681 44.013835 3.461900]\n",
      "        Val:   (max)  [37367.136719 102.446152 4.009000]\n",
      "        Val:   (min)  [344.385834 10.965066 2.787000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.452475071s\n",
      "Epoch 60:\n",
      "    101120:  [12.603535 0.008680 0.591607 0.024087 3.842465] [12.603535 2.604124 5.916073 0.240873 3.842465] 2.20010018349 \n",
      "    Total time for epoch: 160.915380955s\n",
      "    ----------------\n",
      "    Code entropy: 1.86059643922\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3276.4927, 38.591106, 3.005]\n",
      "    SA1 (arg):    [3446.9202, 39.616222, 2.917]\n",
      "    SX383:        [2030.8524, 27.116932, 2.964]\n",
      "    SX383 (arg):  [2128.1401, 27.940807, 2.896]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6664.133108 47.652669 3.181580]\n",
      "        Train: (max)  [24124.044922 107.026009 3.874000]\n",
      "        Train: (min)  [1180.307129 22.286375 1.764000]\n",
      "        Val:   (mean) [6093.312248 44.073661 3.379420]\n",
      "        Val:   (max)  [25765.611328 103.657303 3.840000]\n",
      "        Val:   (min)  [363.376068 11.299919 2.792000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.5995008945s\n",
      "Epoch 61:\n",
      "    101120:  [12.875529 0.009390 0.578772 0.024465 4.026088] [12.875529 2.817070 5.787717 0.244653 4.026088] 2.20010018349 \n",
      "    Total time for epoch: 160.480539083s\n",
      "    ----------------\n",
      "    Code entropy: 1.87715385614\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3320.4221, 38.783161, 2.993]\n",
      "    SA1 (arg):    [3478.3857, 39.787067, 2.933]\n",
      "    SX383:        [1919.8987, 26.833624, 3.119]\n",
      "    SX383 (arg):  [2015.9434, 27.696127, 3.056]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6448.669434 44.902952 3.369240]\n",
      "        Train: (max)  [29289.701172 101.759972 4.197000]\n",
      "        Train: (min)  [863.955444 17.148895 2.578000]\n",
      "        Val:   (mean) [6496.955503 46.521478 3.486520]\n",
      "        Val:   (max)  [24251.376953 100.684052 3.933000]\n",
      "        Val:   (min)  [1466.707275 21.323072 2.435000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.1940860748s\n",
      "Epoch 62:\n",
      "    101120:  [12.980061 0.009438 0.580330 0.024348 4.101912] [12.980061 2.831369 5.803299 0.243481 4.101912] 2.20010018349 \n",
      "    Total time for epoch: 160.973270893s\n",
      "    ----------------\n",
      "    Code entropy: 1.81538724387\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3345.8655, 38.62656, 2.933]\n",
      "    SA1 (arg):    [3509.7778, 39.648956, 2.865]\n",
      "    SX383:        [2034.3252, 27.183828, 3.032]\n",
      "    SX383 (arg):  [2135.6602, 27.985449, 2.971]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5791.292870 43.740456 3.236700]\n",
      "        Train: (max)  [30228.056641 110.586327 3.767000]\n",
      "        Train: (min)  [672.371765 16.931940 2.624000]\n",
      "        Val:   (mean) [6540.522374 43.742533 3.422960]\n",
      "        Val:   (max)  [37843.910156 90.306427 3.986000]\n",
      "        Val:   (min)  [354.508331 11.057408 2.567000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.1553418636s\n",
      "Epoch 63:\n",
      "    101120:  [13.672623 0.011416 0.558129 0.024219 4.424396] [13.672623 3.424750 5.581291 0.242186 4.424396] 2.20010018349 \n",
      "    Total time for epoch: 160.726938963s\n",
      "    ----------------\n",
      "    Code entropy: 1.92120096\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3217.8042, 37.601974, 3.007]\n",
      "    SA1 (arg):    [3390.3486, 38.744301, 2.931]\n",
      "    SX383:        [1899.6614, 26.594307, 3.046]\n",
      "    SX383 (arg):  [1996.2542, 27.408791, 2.992]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7114.955378 46.261626 3.336240]\n",
      "        Train: (max)  [28827.521484 108.305023 3.879000]\n",
      "        Train: (min)  [795.941101 17.538488 2.656000]\n",
      "        Val:   (mean) [6334.868353 43.271785 3.457980]\n",
      "        Val:   (max)  [35319.656250 88.063950 3.894000]\n",
      "        Val:   (min)  [527.105652 13.718374 2.322000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.236353159s\n",
      "Epoch 64:\n",
      "    101120:  [13.438143 0.010901 0.581276 0.024036 4.114838] [13.438143 3.270185 5.812755 0.240364 4.114838] 2.20010018349 \n",
      "    Total time for epoch: 160.991312981s\n",
      "    ----------------\n",
      "    Code entropy: 1.88891575259\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3310.6333, 37.881149, 2.961]\n",
      "    SA1 (arg):    [3444.3992, 38.707981, 2.894]\n",
      "    SX383:        [1782.0157, 25.808014, 3.092]\n",
      "    SX383 (arg):  [1852.2561, 26.374735, 3.052]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5324.691732 39.443791 3.311180]\n",
      "        Train: (max)  [28554.517578 106.377678 3.996000]\n",
      "        Train: (min)  [466.168610 14.776597 2.797000]\n",
      "        Val:   (mean) [6412.722620 45.213297 3.458320]\n",
      "        Val:   (max)  [24346.414062 98.880089 3.834000]\n",
      "        Val:   (min)  [880.661743 16.401224 2.947000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.7136440277s\n",
      "Epoch 65:\n",
      "    101120:  [12.208426 0.008664 0.536515 0.023604 4.008081] [12.208426 2.599154 5.365149 0.236041 4.008081] 2.20010018349 \n",
      "    Total time for epoch: 160.574368954s\n",
      "    ----------------\n",
      "    Code entropy: 1.98588064917\n",
      "    Updated tau from 2.20010018349 to 2.30010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3155.2756, 37.206268, 3.168]\n",
      "    SA1 (arg):    [3327.4756, 38.373272, 3.061]\n",
      "    SX383:        [1889.6282, 26.72821, 3.1]\n",
      "    SX383 (arg):  [1984.8899, 27.58596, 3.019]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6336.109573 43.043935 3.314020]\n",
      "        Train: (max)  [42331.679688 97.579002 3.886000]\n",
      "        Train: (min)  [793.199341 17.430359 2.525000]\n",
      "        Val:   (mean) [5812.123748 42.750305 3.516780]\n",
      "        Val:   (max)  [20330.521484 88.581985 3.969000]\n",
      "        Val:   (min)  [502.356354 13.708084 2.944000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.6466150284s\n",
      "Epoch 66:\n",
      "    101120:  [12.970432 0.009627 0.573212 0.023933 4.110977] [12.970432 2.888013 5.732116 0.239328 4.110977] 2.30010008812 \n",
      "    Total time for epoch: 161.095943928s\n",
      "    ----------------\n",
      "    Code entropy: 1.93320454755\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3427.6436, 38.978668, 2.969]\n",
      "    SA1 (arg):    [3599.0286, 40.052418, 2.889]\n",
      "    SX383:        [1847.9865, 26.617411, 3.055]\n",
      "    SX383 (arg):  [1924.6703, 27.260622, 2.991]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6659.102311 43.073948 3.239260]\n",
      "        Train: (max)  [55995.175781 102.541794 3.704000]\n",
      "        Train: (min)  [893.596985 17.496540 2.668000]\n",
      "        Val:   (mean) [7857.521088 48.860481 3.401200]\n",
      "        Val:   (max)  [34691.140625 102.077858 4.003000]\n",
      "        Val:   (min)  [356.357788 11.163802 2.906000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.7374870777s\n",
      "Epoch 67:\n",
      "    101120:  [13.576340 0.011018 0.568469 0.024113 4.345131] [13.576340 3.305387 5.684691 0.241130 4.345131] 2.30010008812 \n",
      "    Total time for epoch: 161.428674936s\n",
      "    ----------------\n",
      "    Code entropy: 1.88749804196\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3187.7793, 37.449139, 3.096]\n",
      "    SA1 (arg):    [3339.7266, 38.489395, 2.988]\n",
      "    SX383:        [1759.1456, 25.676373, 3.144]\n",
      "    SX383 (arg):  [1830.3547, 26.309534, 3.099]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5430.700634 41.166476 3.382280]\n",
      "        Train: (max)  [26093.919922 102.825157 4.076000]\n",
      "        Train: (min)  [853.783325 14.950584 2.731000]\n",
      "        Val:   (mean) [5466.706973 41.446414 3.535840]\n",
      "        Val:   (max)  [32692.970703 85.873268 3.975000]\n",
      "        Val:   (min)  [1423.332764 21.585203 3.109000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.7507488728s\n",
      "Epoch 68:\n",
      "    101120:  [12.753148 0.009164 0.543654 0.023357 4.333854] [12.753148 2.749180 5.436543 0.233571 4.333854] 2.30010008812 \n",
      "    Total time for epoch: 161.813239098s\n",
      "    ----------------\n",
      "    Code entropy: 1.81693674677\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3106.2681, 37.428356, 2.986]\n",
      "    SA1 (arg):    [3266.6731, 38.463303, 2.893]\n",
      "    SX383:        [1880.734, 26.449903, 3.102]\n",
      "    SX383 (arg):  [1965.5653, 27.196684, 3.001]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5081.102251 41.663514 3.240460]\n",
      "        Train: (max)  [11981.880859 76.075211 4.018000]\n",
      "        Train: (min)  [680.301636 16.296997 2.538000]\n",
      "        Val:   (mean) [5674.041064 41.772060 3.445320]\n",
      "        Val:   (max)  [33580.027344 99.905357 3.776000]\n",
      "        Val:   (min)  [521.193054 13.770362 2.744000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 24.8780498505s\n",
      "Epoch 69:\n",
      "    101120:  [13.186681 0.010136 0.565575 0.023719 4.253015] [13.186681 3.040722 5.655754 0.237191 4.253015] 2.30010008812 \n",
      "    Total time for epoch: 162.921619892s\n",
      "    ----------------\n",
      "    Code entropy: 1.85511641797\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3281.873, 38.185631, 3.084]\n",
      "    SA1 (arg):    [3443.1694, 39.162491, 3.011]\n",
      "    SX383:        [1932.9865, 26.979923, 3.054]\n",
      "    SX383 (arg):  [2029.1243, 27.768009, 2.952]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5020.856284 41.068931 3.336140]\n",
      "        Train: (max)  [15038.163086 74.116341 3.941000]\n",
      "        Train: (min)  [795.710999 16.456078 2.847000]\n",
      "        Val:   (mean) [6968.247842 45.983265 3.452140]\n",
      "        Val:   (max)  [34344.511719 102.750389 3.880000]\n",
      "        Val:   (min)  [342.217896 10.884899 2.944000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.3572461605s\n",
      "Epoch 70:\n",
      "    101120:  [12.525212 0.008812 0.580121 0.022274 3.857762] [12.525212 2.643505 5.801208 0.222738 3.857762] 2.30010008812 \n",
      "    Total time for epoch: 162.493813992s\n",
      "    ----------------\n",
      "    Code entropy: 1.85848417677\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3341.418, 38.228004, 3.051]\n",
      "    SA1 (arg):    [3500.3171, 39.262585, 2.975]\n",
      "    SX383:        [1879.1393, 26.382477, 3.08]\n",
      "    SX383 (arg):  [1959.5879, 27.077404, 2.999]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5447.657954 42.160092 3.247320]\n",
      "        Train: (max)  [19411.503906 83.013565 3.765000]\n",
      "        Train: (min)  [941.551758 19.175337 2.644000]\n",
      "        Val:   (mean) [6787.307173 45.008453 3.430680]\n",
      "        Val:   (max)  [34935.574219 90.333084 4.027000]\n",
      "        Val:   (min)  [361.041992 11.103356 2.548000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.3930799961s\n",
      "Epoch 71:\n",
      "    101120:  [13.192668 0.010770 0.555791 0.022957 4.174115] [13.192668 3.231066 5.557915 0.229572 4.174115] 2.30010008812 \n",
      "    Total time for epoch: 162.933776855s\n",
      "    ----------------\n",
      "    Code entropy: 1.69989066031\n",
      "    Updated tau from 2.30010008812 to 2.20010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3423.6702, 39.301609, 2.999]\n",
      "    SA1 (arg):    [3569.7, 40.103359, 2.929]\n",
      "    SX383:        [2019.1097, 27.435354, 3.084]\n",
      "    SX383 (arg):  [2091.0627, 28.048378, 3.015]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6938.136339 47.826662 3.263320]\n",
      "        Train: (max)  [29090.654297 96.167175 3.865000]\n",
      "        Train: (min)  [743.896423 17.500589 2.474000]\n",
      "        Val:   (mean) [6256.926993 43.743969 3.402660]\n",
      "        Val:   (max)  [33979.804688 84.906151 4.053000]\n",
      "        Val:   (min)  [371.215393 11.369205 2.559000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.277050972s\n",
      "Epoch 72:\n",
      "    101120:  [12.788718 0.009515 0.574714 0.022978 3.957260] [12.788718 2.854534 5.747141 0.229782 3.957260] 2.20010018349 \n",
      "    Total time for epoch: 162.554519176s\n",
      "    ----------------\n",
      "    Code entropy: 1.84778704591\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3232.614, 37.803463, 3.038]\n",
      "    SA1 (arg):    [3390.3933, 38.782776, 2.978]\n",
      "    SX383:        [1762.3347, 25.811951, 3.048]\n",
      "    SX383 (arg):  [1840.8098, 26.486162, 3.004]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6032.505331 41.211349 3.261080]\n",
      "        Train: (max)  [34454.285156 93.868225 3.854000]\n",
      "        Train: (min)  [801.437927 15.687853 2.685000]\n",
      "        Val:   (mean) [5927.137232 43.275928 3.396440]\n",
      "        Val:   (max)  [20993.978516 86.403938 4.121000]\n",
      "        Val:   (min)  [365.780365 11.076515 2.632000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.7006430626s\n",
      "Epoch 73:\n",
      "    101120:  [13.117720 0.010366 0.548647 0.023306 4.288445] [13.117720 3.109745 5.486472 0.233059 4.288445] 2.20010018349 \n",
      "    Total time for epoch: 162.354333878s\n",
      "    ----------------\n",
      "    Code entropy: 1.85529277744\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3365.6599, 38.69416, 3.054]\n",
      "    SA1 (arg):    [3517.272, 39.614201, 2.976]\n",
      "    SX383:        [1854.0122, 26.68166, 2.985]\n",
      "    SX383 (arg):  [1938.1322, 27.409857, 2.931]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [8672.353126 50.219196 3.217400]\n",
      "        Train: (max)  [66119.171875 159.423050 3.776000]\n",
      "        Train: (min)  [996.690002 20.761869 2.574000]\n",
      "        Val:   (mean) [6510.078486 46.086665 3.450440]\n",
      "        Val:   (max)  [33590.425781 92.452255 3.920000]\n",
      "        Val:   (min)  [569.820190 14.746254 2.967000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.6760210991s\n",
      "Epoch 74:\n",
      "    101120:  [12.387701 0.008382 0.583211 0.022291 3.818087] [12.387701 2.514602 5.832107 0.222906 3.818087] 2.20010018349 \n",
      "    Total time for epoch: 163.26876092s\n",
      "    ----------------\n",
      "    Code entropy: 1.86323758576\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3227.4507, 37.675732, 3.067]\n",
      "    SA1 (arg):    [3383.4485, 38.617477, 2.997]\n",
      "    SX383:        [1961.8661, 26.470787, 3.094]\n",
      "    SX383 (arg):  [2049.2754, 27.186312, 3.042]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5252.101929 40.352772 3.337600]\n",
      "        Train: (max)  [25623.802734 91.617226 3.879000]\n",
      "        Train: (min)  [880.728516 18.134605 2.514000]\n",
      "        Val:   (mean) [6700.471632 45.662263 3.403460]\n",
      "        Val:   (max)  [25707.753906 101.885063 3.781000]\n",
      "        Val:   (min)  [363.453674 11.110927 2.478000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.4471509457s\n",
      "Epoch 75:\n",
      "    101120:  [12.499937 0.009331 0.559861 0.022351 3.878642] [12.499937 2.799170 5.598614 0.223510 3.878642] 2.20010018349 \n",
      "    Total time for epoch: 163.63000989s\n",
      "    ----------------\n",
      "    Code entropy: 1.84865137335\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3199.9023, 37.780239, 3.1]\n",
      "    SA1 (arg):    [3349.7065, 38.700523, 3.025]\n",
      "    SX383:        [1857.8049, 26.096716, 3.083]\n",
      "    SX383 (arg):  [1930.8344, 26.742918, 3.035]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5806.205673 42.700443 3.324960]\n",
      "        Train: (max)  [23052.275391 90.000740 3.870000]\n",
      "        Train: (min)  [879.802795 18.955692 2.672000]\n",
      "        Val:   (mean) [6638.081853 45.628846 3.461480]\n",
      "        Val:   (max)  [33409.207031 89.917175 4.050000]\n",
      "        Val:   (min)  [1380.105957 20.911757 3.034000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.710944891s\n",
      "Epoch 76:\n",
      "    101120:  [12.499052 0.008210 0.607281 0.022841 3.734848] [12.499052 2.462983 6.072808 0.228412 3.734848] 2.20010018349 \n",
      "    Total time for epoch: 160.780313969s\n",
      "    ----------------\n",
      "    Code entropy: 1.75084797301\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3306.0452, 38.491611, 3.086]\n",
      "    SA1 (arg):    [3450.157, 39.436962, 3.023]\n",
      "    SX383:        [2016.437, 26.874491, 3.139]\n",
      "    SX383 (arg):  [2110.3918, 27.622602, 3.062]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6840.472688 44.762612 3.319660]\n",
      "        Train: (max)  [35881.878906 95.817932 4.065000]\n",
      "        Train: (min)  [669.719727 14.813019 2.763000]\n",
      "        Val:   (mean) [6454.873927 45.283545 3.440620]\n",
      "        Val:   (max)  [25875.498047 103.243401 3.956000]\n",
      "        Val:   (min)  [697.758606 14.031871 2.483000]\n",
      "    Best validation mean-PESQ seen: 3.48304\n",
      "    Total time for evaluation: 25.3696060181s\n",
      "Epoch 77:\n",
      "    101120:  [12.787989 0.009727 0.551632 0.023796 4.115689] [12.787989 2.918024 5.516317 0.237959 4.115689] 2.10010027885 \n",
      "    Total time for epoch: 161.966085911s\n",
      "    ----------------\n",
      "    Code entropy: 1.85265424839\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3035.0405, 36.405811, 3.137]\n",
      "    SA1 (arg):    [3181.5908, 37.346573, 3.05]\n",
      "    SX383:        [1768.3826, 25.254248, 3.105]\n",
      "    SX383 (arg):  [1845.2041, 25.957193, 3.036]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5111.790651 39.433680 3.404500]\n",
      "        Train: (max)  [27559.945312 96.567886 3.948000]\n",
      "        Train: (min)  [585.210999 15.761068 2.566000]\n",
      "        Val:   (mean) [6153.490815 43.301944 3.588780]\n",
      "        Val:   (max)  [31467.259766 95.952522 4.105000]\n",
      "        Val:   (min)  [332.610077 10.663237 2.940000]\n",
      "    NEW best model! Validation mean-PESQ 3.58878\n",
      "    Saving model...\n",
      "    Total time for evaluation: 25.7543771267s\n",
      "Epoch 78:\n",
      "    101120:  [12.441679 0.009121 0.546911 0.023583 4.000384] [12.441679 2.736353 5.469109 0.235834 4.000384] 2.10010027885 \n",
      "    Total time for epoch: 161.844787121s\n",
      "    ----------------\n",
      "    Code entropy: 1.97553696255\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2874.4756, 35.464771, 3.052]\n",
      "    SA1 (arg):    [3017.5686, 36.42131, 2.992]\n",
      "    SX383:        [1774.5085, 25.03998, 3.244]\n",
      "    SX383 (arg):  [1845.8002, 25.742411, 3.176]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6136.560730 43.496186 3.280380]\n",
      "        Train: (max)  [31738.419922 81.914505 3.751000]\n",
      "        Train: (min)  [676.866943 16.859833 2.704000]\n",
      "        Val:   (mean) [5709.959648 43.290325 3.471920]\n",
      "        Val:   (max)  [22272.326172 93.942024 3.883000]\n",
      "        Val:   (min)  [1267.402344 20.445438 3.105000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.4610061646s\n",
      "Epoch 79:\n",
      "    101120:  [12.415762 0.008957 0.553503 0.023018 3.963451] [12.415762 2.687102 5.535028 0.230181 3.963451] 2.20010018349 \n",
      "    Total time for epoch: 161.719257116s\n",
      "    ----------------\n",
      "    Code entropy: 1.87197050189\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3160.8049, 36.922424, 3.193]\n",
      "    SA1 (arg):    [3278.668, 37.739929, 3.108]\n",
      "    SX383:        [1927.6383, 26.014936, 3.182]\n",
      "    SX383 (arg):  [1998.446, 26.560398, 3.102]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4917.396454 40.243361 3.351900]\n",
      "        Train: (max)  [19084.095703 88.139481 3.850000]\n",
      "        Train: (min)  [815.869446 18.235594 2.758000]\n",
      "        Val:   (mean) [6859.916055 45.228486 3.486280]\n",
      "        Val:   (max)  [31202.375000 98.447540 4.056000]\n",
      "        Val:   (min)  [340.337067 10.769778 2.961000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.7699329853s\n",
      "Epoch 80:\n",
      "    101120:  [12.525316 0.009256 0.555611 0.021656 3.975734] [12.525316 2.776916 5.556106 0.216560 3.975734] 2.20010018349 \n",
      "    Total time for epoch: 161.991197109s\n",
      "    ----------------\n",
      "    Code entropy: 1.8810936483\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3290.5286, 37.985863, 3.002]\n",
      "    SA1 (arg):    [3459.0637, 38.958008, 2.936]\n",
      "    SX383:        [1874.5142, 26.352934, 3.081]\n",
      "    SX383 (arg):  [1954.4681, 27.033247, 3.038]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6065.517240 43.317793 3.256920]\n",
      "        Train: (max)  [24889.863281 98.716545 3.809000]\n",
      "        Train: (min)  [899.716919 19.416008 2.781000]\n",
      "        Val:   (mean) [5035.341876 39.955065 3.449780]\n",
      "        Val:   (max)  [20962.261719 87.312134 4.012000]\n",
      "        Val:   (min)  [349.119019 10.990153 2.771000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.2684290409s\n",
      "Epoch 81:\n",
      "    101120:  [12.668954 0.009616 0.557181 0.022422 3.988205] [12.668954 2.884714 5.571810 0.224225 3.988205] 2.20010018349 \n",
      "    Total time for epoch: 162.086527824s\n",
      "    ----------------\n",
      "    Code entropy: 1.80883552018\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3340.8464, 38.574924, 3.069]\n",
      "    SA1 (arg):    [3492.5513, 39.432926, 3.009]\n",
      "    SX383:        [1941.201, 26.833588, 3.053]\n",
      "    SX383 (arg):  [2022.0082, 27.4196, 2.979]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7649.342716 48.211554 3.227640]\n",
      "        Train: (max)  [44290.578125 127.918289 4.087000]\n",
      "        Train: (min)  [459.771912 14.332284 2.564000]\n",
      "        Val:   (mean) [5948.672455 43.596036 3.484920]\n",
      "        Val:   (max)  [31862.548828 90.588531 3.915000]\n",
      "        Val:   (min)  [641.195618 13.799755 2.838000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.2704467773s\n",
      "Epoch 82:\n",
      "    101120:  [12.567332 0.009164 0.547879 0.022965 4.109689] [12.567332 2.749203 5.478787 0.229653 4.109689] 2.20010018349 \n",
      "    Total time for epoch: 161.7798841s\n",
      "    ----------------\n",
      "    Code entropy: 1.83434580437\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3115.6646, 37.260742, 3.085]\n",
      "    SA1 (arg):    [3252.906, 38.033672, 3.008]\n",
      "    SX383:        [1745.1085, 25.696428, 3.151]\n",
      "    SX383 (arg):  [1818.5472, 26.31138, 3.096]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5427.093411 39.910384 3.274400]\n",
      "        Train: (max)  [32378.332031 84.411018 3.827000]\n",
      "        Train: (min)  [623.471619 15.918765 2.446000]\n",
      "        Val:   (mean) [6409.270686 44.033934 3.503820]\n",
      "        Val:   (max)  [30785.593750 98.729790 4.009000]\n",
      "        Val:   (min)  [613.628906 13.265181 2.805000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.101872921s\n",
      "Epoch 83:\n",
      "    101120:  [12.577330 0.008965 0.581488 0.022188 3.850964] [12.577330 2.689599 5.814885 0.221881 3.850964] 2.20010018349 \n",
      "    Total time for epoch: 162.085194111s\n",
      "    ----------------\n",
      "    Code entropy: 1.92065281272\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3323.7, 38.312771, 3.044]\n",
      "    SA1 (arg):    [3463.8025, 39.196037, 2.988]\n",
      "    SX383:        [1898.0684, 26.938255, 3.121]\n",
      "    SX383 (arg):  [1981.3823, 27.672773, 3.056]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4961.736884 41.132954 3.322740]\n",
      "        Train: (max)  [18338.773438 86.742607 3.914000]\n",
      "        Train: (min)  [641.950012 16.567955 2.411000]\n",
      "        Val:   (mean) [5552.998597 42.966854 3.529820]\n",
      "        Val:   (max)  [21363.232422 88.664986 4.070000]\n",
      "        Val:   (min)  [355.535736 11.024540 2.957000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.0117328167s\n",
      "Epoch 84:\n",
      "    101120:  [12.657673 0.009459 0.566487 0.022178 3.933443] [12.657673 2.837579 5.664874 0.221777 3.933443] 2.20010018349 \n",
      "    Total time for epoch: 161.773529053s\n",
      "    ----------------\n",
      "    Code entropy: 1.78999014448\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3386.5964, 38.164589, 3.073]\n",
      "    SA1 (arg):    [3519.811, 38.982857, 3.014]\n",
      "    SX383:        [1727.084, 25.802673, 3.106]\n",
      "    SX383 (arg):  [1803.8217, 26.452215, 3.032]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4961.524746 40.484921 3.290280]\n",
      "        Train: (max)  [14356.004883 77.731163 3.934000]\n",
      "        Train: (min)  [808.410645 18.071178 2.452000]\n",
      "        Val:   (mean) [6243.784141 45.621322 3.409900]\n",
      "        Val:   (max)  [20933.218750 89.930397 3.768000]\n",
      "        Val:   (min)  [363.788422 11.107769 2.521000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.9407420158s\n",
      "Epoch 85:\n",
      "    101120:  [12.858216 0.009883 0.543869 0.023588 4.218890] [12.858216 2.964759 5.438690 0.235877 4.218890] 2.20010018349 \n",
      "    Total time for epoch: 162.015552998s\n",
      "    ----------------\n",
      "    Code entropy: 1.8472157457\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3090.3252, 37.041935, 3.024]\n",
      "    SA1 (arg):    [3223.3689, 37.89035, 2.945]\n",
      "    SX383:        [1717.7122, 25.623539, 3.111]\n",
      "    SX383 (arg):  [1782.7821, 26.193796, 3.039]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7301.027788 47.929297 3.357920]\n",
      "        Train: (max)  [33228.753906 112.696030 4.222000]\n",
      "        Train: (min)  [1105.870361 19.729773 2.758000]\n",
      "        Val:   (mean) [5498.374343 42.041713 3.473520]\n",
      "        Val:   (max)  [18528.011719 86.366669 3.925000]\n",
      "        Val:   (min)  [353.064697 10.959495 2.748000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.5288341045s\n",
      "Epoch 86:\n",
      "    101120:  [12.805544 0.009769 0.540807 0.023354 4.233244] [12.805544 2.930686 5.408072 0.233542 4.233244] 2.20010018349 \n",
      "    Total time for epoch: 161.806769133s\n",
      "    ----------------\n",
      "    Code entropy: 1.84364340595\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3385.4207, 38.552074, 3.058]\n",
      "    SA1 (arg):    [3507.4021, 39.281231, 2.993]\n",
      "    SX383:        [1895.6381, 26.732656, 3.032]\n",
      "    SX383 (arg):  [1949.0637, 27.229948, 2.981]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5764.417123 42.193206 3.359700]\n",
      "        Train: (max)  [27715.898438 90.420288 3.871000]\n",
      "        Train: (min)  [955.258240 18.897579 2.801000]\n",
      "        Val:   (mean) [5503.262507 41.522772 3.491460]\n",
      "        Val:   (max)  [20534.574219 84.929619 3.869000]\n",
      "        Val:   (min)  [360.116669 11.056163 2.908000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.3060929775s\n",
      "Epoch 87:\n",
      "    101120:  [12.432407 0.008196 0.546513 0.023593 4.272604] [12.432407 2.458747 5.465128 0.235929 4.272604] 2.20010018349 \n",
      "    Total time for epoch: 162.037518024s\n",
      "    ----------------\n",
      "    Code entropy: 1.98238591999\n",
      "    Updated tau from 2.20010018349 to 2.30010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3082.5564, 36.323486, 3.195]\n",
      "    SA1 (arg):    [3215.7808, 37.154591, 3.105]\n",
      "    SX383:        [1675.3528, 24.970572, 3.14]\n",
      "    SX383 (arg):  [1740.6572, 25.530806, 3.099]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6347.621724 44.992092 3.438580]\n",
      "        Train: (max)  [25587.871094 98.324730 3.950000]\n",
      "        Train: (min)  [873.577454 17.929407 2.844000]\n",
      "        Val:   (mean) [5748.188963 42.775812 3.585940]\n",
      "        Val:   (max)  [19223.437500 84.782707 4.096000]\n",
      "        Val:   (min)  [338.368988 10.657386 3.046000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.2260870934s\n",
      "Epoch 88:\n",
      "    101120:  [12.274975 0.008098 0.567086 0.021438 3.960305] [12.274975 2.429430 5.670857 0.214383 3.960305] 2.30010008812 \n",
      "    Total time for epoch: 161.761039019s\n",
      "    ----------------\n",
      "    Code entropy: 1.84713161487\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3455.9668, 38.914864, 3.054]\n",
      "    SA1 (arg):    [3622.2488, 39.838623, 2.964]\n",
      "    SX383:        [1893.6527, 26.745754, 3.07]\n",
      "    SX383 (arg):  [1965.5856, 27.427141, 2.99]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5344.610707 41.005565 3.284060]\n",
      "        Train: (max)  [24852.707031 93.078362 3.971000]\n",
      "        Train: (min)  [617.549133 16.377655 2.624000]\n",
      "        Val:   (mean) [6304.629828 46.198245 3.548220]\n",
      "        Val:   (max)  [24268.847656 99.939995 4.072000]\n",
      "        Val:   (min)  [754.187805 16.850363 3.134000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.261070013s\n",
      "Epoch 89:\n",
      "    101120:  [13.198565 0.009760 0.545650 0.022564 4.588365] [13.198565 2.928061 5.456500 0.225640 4.588365] 2.30010008812 \n",
      "    Total time for epoch: 161.809386969s\n",
      "    ----------------\n",
      "    Code entropy: 1.76243857787\n",
      "    Updated tau from 2.30010008812 to 2.20010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3061.3606, 36.897537, 3.098]\n",
      "    SA1 (arg):    [3192.3381, 37.759628, 3.017]\n",
      "    SX383:        [1848.5883, 25.482721, 3.191]\n",
      "    SX383 (arg):  [1926.5568, 26.158684, 3.119]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6928.460803 44.760765 3.332760]\n",
      "        Train: (max)  [33857.910156 86.255302 3.974000]\n",
      "        Train: (min)  [611.141846 15.685660 2.716000]\n",
      "        Val:   (mean) [6727.711662 44.527651 3.527060]\n",
      "        Val:   (max)  [32439.363281 94.429306 4.109000]\n",
      "        Val:   (min)  [356.741364 10.974833 3.020000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.7100811005s\n",
      "Epoch 90:\n",
      "    101120:  [13.192018 0.010764 0.553092 0.022686 4.204954] [13.192018 3.229285 5.530921 0.226858 4.204954] 2.20010018349 \n",
      "    Total time for epoch: 162.249130964s\n",
      "    ----------------\n",
      "    Code entropy: 1.7695106338\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3386.1824, 38.726501, 2.921]\n",
      "    SA1 (arg):    [3534.5576, 39.605751, 2.847]\n",
      "    SX383:        [1929.5494, 26.828598, 2.995]\n",
      "    SX383 (arg):  [2011.2202, 27.476812, 2.939]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6227.449224 44.120187 3.234520]\n",
      "        Train: (max)  [28244.904297 91.648605 3.908000]\n",
      "        Train: (min)  [767.406433 16.369675 2.452000]\n",
      "        Val:   (mean) [5834.840701 43.137476 3.385860]\n",
      "        Val:   (max)  [21652.056641 88.913696 3.988000]\n",
      "        Val:   (min)  [352.730316 11.097971 2.643000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.1085050106s\n",
      "Epoch 91:\n",
      "    101120:  [12.537182 0.008534 0.560305 0.023423 4.139618] [12.537182 2.560277 5.603054 0.234233 4.139618] 2.10010027885 \n",
      "    Total time for epoch: 161.938672066s\n",
      "    ----------------\n",
      "    Code entropy: 1.98146113887\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2989.8875, 36.461357, 3.144]\n",
      "    SA1 (arg):    [3124.1106, 37.312561, 3.082]\n",
      "    SX383:        [1764.5465, 25.74958, 3.169]\n",
      "    SX383 (arg):  [1822.0706, 26.294455, 3.118]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6940.516718 46.435821 3.370880]\n",
      "        Train: (max)  [40852.410156 88.857719 4.018000]\n",
      "        Train: (min)  [756.406311 16.678028 2.703000]\n",
      "        Val:   (mean) [5331.654683 41.100773 3.585300]\n",
      "        Val:   (max)  [28222.224609 82.824051 4.031000]\n",
      "        Val:   (min)  [335.557190 10.648671 2.987000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.5294139385s\n",
      "Epoch 92:\n",
      "    101120:  [13.131386 0.010249 0.544784 0.022825 4.380551] [13.131386 3.074743 5.447844 0.228248 4.380551] 2.20010018349 \n",
      "    Total time for epoch: 161.941811085s\n",
      "    ----------------\n",
      "    Code entropy: 1.89346676817\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3177.969, 37.259392, 3.076]\n",
      "    SA1 (arg):    [3305.0801, 38.08844, 3.033]\n",
      "    SX383:        [1631.7738, 25.439346, 3.082]\n",
      "    SX383 (arg):  [1695.1127, 26.057119, 3.018]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7161.172289 45.753215 3.395200]\n",
      "        Train: (max)  [60316.699219 152.842697 3.886000]\n",
      "        Train: (min)  [811.726562 17.416218 2.559000]\n",
      "        Val:   (mean) [5388.987533 41.872712 3.551460]\n",
      "        Val:   (max)  [23581.187500 97.382767 3.924000]\n",
      "        Val:   (min)  [624.840820 13.355754 2.878000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.1669909954s\n",
      "Epoch 93:\n",
      "    101120:  [12.776958 0.009996 0.538790 0.022348 4.166801] [12.776958 2.998780 5.387898 0.223481 4.166801] 2.20010018349 \n",
      "    Total time for epoch: 162.072878122s\n",
      "    ----------------\n",
      "    Code entropy: 1.8772164301\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3174.6243, 37.138046, 3.162]\n",
      "    SA1 (arg):    [3303.6099, 37.964233, 3.093]\n",
      "    SX383:        [1768.6171, 25.778812, 3.12]\n",
      "    SX383 (arg):  [1844.358, 26.427944, 3.048]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6392.594143 43.110718 3.315800]\n",
      "        Train: (max)  [60610.593750 153.076050 4.003000]\n",
      "        Train: (min)  [1180.677612 20.328182 2.780000]\n",
      "        Val:   (mean) [4820.689662 39.447561 3.538420]\n",
      "        Val:   (max)  [23490.904297 97.748871 3.855000]\n",
      "        Val:   (min)  [496.037781 13.722505 2.991000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.3023378849s\n",
      "Epoch 94:\n",
      "    101120:  [13.103924 0.009817 0.580533 0.022277 4.130849] [13.103924 2.944976 5.805326 0.222772 4.130849] 2.20010018349 \n",
      "    Total time for epoch: 161.841470957s\n",
      "    ----------------\n",
      "    Code entropy: 1.80605792434\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3455.323, 38.85437, 3.044]\n",
      "    SA1 (arg):    [3598.2559, 39.686165, 2.977]\n",
      "    SX383:        [1891.8658, 27.313049, 3.04]\n",
      "    SX383 (arg):  [1970.3615, 27.961418, 2.975]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7210.588265 48.864768 3.309440]\n",
      "        Train: (max)  [28193.210938 98.328735 3.885000]\n",
      "        Train: (min)  [755.100281 17.332235 2.492000]\n",
      "        Val:   (mean) [6819.626747 45.896438 3.427540]\n",
      "        Val:   (max)  [30923.025391 104.317490 4.006000]\n",
      "        Val:   (min)  [378.236450 11.393727 2.726000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.9347438812s\n",
      "Epoch 95:\n",
      "    101120:  [12.570034 0.008508 0.590679 0.021312 3.897859] [12.570034 2.552268 5.906789 0.213117 3.897859] 2.20010018349 \n",
      "    Total time for epoch: 161.346784115s\n",
      "    ----------------\n",
      "    Code entropy: 1.79280127754\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3133.1289, 37.267639, 3.015]\n",
      "    SA1 (arg):    [3264.3274, 38.103882, 2.955]\n",
      "    SX383:        [1903.421, 26.362696, 3.191]\n",
      "    SX383 (arg):  [1976.1646, 26.970627, 3.136]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5659.588260 40.995553 3.389920]\n",
      "        Train: (max)  [33139.132812 112.613930 3.942000]\n",
      "        Train: (min)  [639.534241 14.925949 2.639000]\n",
      "        Val:   (mean) [5735.596885 42.430314 3.488180]\n",
      "        Val:   (max)  [22544.453125 96.301262 4.090000]\n",
      "        Val:   (min)  [347.564423 10.876935 2.922000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.0245740414s\n",
      "Epoch 96:\n",
      "    101120:  [13.041344 0.010145 0.531168 0.022899 4.457128] [13.041344 3.043549 5.311676 0.228992 4.457128] 2.20010018349 \n",
      "    Total time for epoch: 161.346168995s\n",
      "    ----------------\n",
      "    Code entropy: 1.88838338078\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3134.4006, 37.203724, 3.098]\n",
      "    SA1 (arg):    [3265.2449, 38.078045, 3.042]\n",
      "    SX383:        [1695.4169, 25.99432, 3.128]\n",
      "    SX383 (arg):  [1775.9294, 26.668268, 3.062]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6100.018066 42.390538 3.438300]\n",
      "        Train: (max)  [61516.796875 154.351456 3.950000]\n",
      "        Train: (min)  [677.941833 14.525353 2.805000]\n",
      "        Val:   (mean) [4512.071138 38.601018 3.548400]\n",
      "        Val:   (max)  [24479.974609 99.661095 3.944000]\n",
      "        Val:   (min)  [347.713806 10.836571 2.882000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.3080809116s\n",
      "Epoch 97:\n",
      "    101120:  [12.546251 0.008900 0.558385 0.022197 4.070388] [12.546251 2.670048 5.583851 0.221965 4.070388] 2.20010018349 \n",
      "    Total time for epoch: 161.264159918s\n",
      "    ----------------\n",
      "    Code entropy: 1.87566722833\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3423.7285, 38.415905, 3.046]\n",
      "    SA1 (arg):    [3578.1436, 39.333763, 2.971]\n",
      "    SX383:        [1929.1135, 27.003637, 2.978]\n",
      "    SX383 (arg):  [2014.0824, 27.652683, 2.92]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6687.554536 45.761739 3.372340]\n",
      "        Train: (max)  [26996.644531 88.955833 4.016000]\n",
      "        Train: (min)  [891.350342 17.894369 2.493000]\n",
      "        Val:   (mean) [6104.189608 43.423018 3.521500]\n",
      "        Val:   (max)  [21573.089844 90.564293 4.065000]\n",
      "        Val:   (min)  [350.227295 11.039029 2.911000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.5607049465s\n",
      "Epoch 98:\n",
      "    101120:  [12.767891 0.009124 0.566182 0.021954 4.149240] [12.767891 2.737292 5.661817 0.219543 4.149240] 2.20010018349 \n",
      "    Total time for epoch: 162.080063105s\n",
      "    ----------------\n",
      "    Code entropy: 1.86020742489\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3115.6746, 36.78162, 3.164]\n",
      "    SA1 (arg):    [3234.5613, 37.54554, 3.104]\n",
      "    SX383:        [1859.2428, 26.387047, 3.13]\n",
      "    SX383 (arg):  [1921.8671, 26.909582, 3.085]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5861.861881 43.926863 3.340840]\n",
      "        Train: (max)  [28056.365234 106.664261 3.948000]\n",
      "        Train: (min)  [826.180603 16.980911 2.642000]\n",
      "        Val:   (mean) [5902.250600 42.454520 3.508240]\n",
      "        Val:   (max)  [31200.148438 98.024628 4.017000]\n",
      "        Val:   (min)  [346.470917 10.854016 2.378000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.8178510666s\n",
      "Epoch 99:\n",
      "    101120:  [12.680456 0.009354 0.555597 0.021426 4.104145] [12.680456 2.806081 5.555974 0.214258 4.104145] 2.20010018349 \n",
      "    Total time for epoch: 161.447882891s\n",
      "    ----------------\n",
      "    Code entropy: 1.83221724719\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3187.3315, 37.157444, 3.054]\n",
      "    SA1 (arg):    [3329.1685, 38.005081, 2.994]\n",
      "    SX383:        [1728.7048, 25.459833, 3.115]\n",
      "    SX383 (arg):  [1810.6746, 26.162243, 3.084]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5413.462658 41.522018 3.340380]\n",
      "        Train: (max)  [23609.458984 89.648598 3.837000]\n",
      "        Train: (min)  [431.944244 13.760929 2.694000]\n",
      "        Val:   (mean) [5492.829248 41.235605 3.510740]\n",
      "        Val:   (max)  [19918.121094 86.533493 3.996000]\n",
      "        Val:   (min)  [594.575317 13.212141 2.937000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.0063140392s\n",
      "Epoch 100:\n",
      "    101120:  [12.349461 0.008577 0.548036 0.021780 4.078311] [12.349461 2.572990 5.480361 0.217799 4.078311] 2.20010018349 \n",
      "    Total time for epoch: 161.705094814s\n",
      "    ----------------\n",
      "    Code entropy: 1.8980545828\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3235.8853, 37.325943, 3.127]\n",
      "    SA1 (arg):    [3338.5234, 37.910049, 3.062]\n",
      "    SX383:        [1936.7113, 26.439241, 3.138]\n",
      "    SX383 (arg):  [1991.3784, 26.945572, 3.06]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5961.173253 43.485725 3.369780]\n",
      "        Train: (max)  [25004.451172 91.925873 3.966000]\n",
      "        Train: (min)  [915.338257 17.215477 2.789000]\n",
      "        Val:   (mean) [6238.644529 44.048984 3.535000]\n",
      "        Val:   (max)  [24626.925781 98.294060 3.957000]\n",
      "        Val:   (min)  [350.127441 10.816314 2.462000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.1030659676s\n",
      "Epoch 101:\n",
      "    101120:  [12.342976 0.008460 0.563147 0.021682 3.956621] [12.342976 2.538061 5.631475 0.216818 3.956621] 2.20010018349 \n",
      "    Total time for epoch: 161.346791983s\n",
      "    ----------------\n",
      "    Code entropy: 1.87241588531\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3077.5527, 36.944576, 3.15]\n",
      "    SA1 (arg):    [3203.0591, 37.788761, 3.084]\n",
      "    SX383:        [1764.5387, 25.792263, 3.16]\n",
      "    SX383 (arg):  [1844.4598, 26.421211, 3.118]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5913.940018 43.667013 3.477700]\n",
      "        Train: (max)  [37582.691406 126.239082 3.955000]\n",
      "        Train: (min)  [577.362183 16.130222 2.841000]\n",
      "        Val:   (mean) [6638.286235 46.554800 3.571280]\n",
      "        Val:   (max)  [27893.025391 99.074821 3.921000]\n",
      "        Val:   (min)  [616.539185 13.374829 3.101000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 25.2462470531s\n",
      "Epoch 102:\n",
      "    101120:  [12.222383 0.008428 0.555013 0.020921 3.934532] [12.222383 2.528519 5.550126 0.209207 3.934532] 2.20010018349 \n",
      "    Total time for epoch: 160.74088192s\n",
      "    ----------------\n",
      "    Code entropy: 1.84504784323\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3151.6362, 37.035625, 2.995]\n",
      "    SA1 (arg):    [3293.5422, 37.935875, 2.945]\n",
      "    SX383:        [1766.0118, 25.69158, 3.149]\n",
      "    SX383 (arg):  [1833.799, 26.295696, 3.108]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4740.327897 40.051997 3.363460]\n",
      "        Train: (max)  [24034.283203 96.516357 3.940000]\n",
      "        Train: (min)  [483.990906 14.955097 2.731000]\n",
      "        Val:   (mean) [6069.544968 42.832430 3.488740]\n",
      "        Val:   (max)  [28233.925781 95.647293 4.084000]\n",
      "        Val:   (min)  [340.649292 10.798162 2.269000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.5733010769s\n",
      "Epoch 103:\n",
      "    101120:  [12.961655 0.009341 0.576257 0.022301 4.173700] [12.961655 2.802372 5.762574 0.223009 4.173700] 2.20010018349 \n",
      "    Total time for epoch: 160.632807016s\n",
      "    ----------------\n",
      "    Code entropy: 1.98003986479\n",
      "    Updated tau from 2.20010018349 to 2.30010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3073.7068, 36.349255, 3.153]\n",
      "    SA1 (arg):    [3182.2695, 37.088467, 3.072]\n",
      "    SX383:        [1971.6882, 25.67281, 3.234]\n",
      "    SX383 (arg):  [2034.2504, 26.187151, 3.181]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4803.044243 37.928787 3.420960]\n",
      "        Train: (max)  [33929.664062 83.135307 4.060000]\n",
      "        Train: (min)  [766.579346 17.416000 2.904000]\n",
      "        Val:   (mean) [5303.854526 41.892134 3.581980]\n",
      "        Val:   (max)  [23051.857422 97.241043 4.058000]\n",
      "        Val:   (min)  [606.970276 13.048228 2.925000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.4870550632s\n",
      "Epoch 104:\n",
      "    101120:  [12.955606 0.009057 0.567984 0.021568 4.342957] [12.955606 2.717133 5.679835 0.215680 4.342957] 2.30010008812 \n",
      "    Total time for epoch: 160.461251974s\n",
      "    ----------------\n",
      "    Code entropy: 1.905166303\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3136.6636, 37.321182, 3.035]\n",
      "    SA1 (arg):    [3298.1594, 38.326736, 2.953]\n",
      "    SX383:        [1786.0872, 25.762329, 3.033]\n",
      "    SX383 (arg):  [1850.1403, 26.308096, 2.987]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6905.241753 45.641445 3.403260]\n",
      "        Train: (max)  [26383.896484 100.275055 3.979000]\n",
      "        Train: (min)  [776.829163 14.862241 1.801000]\n",
      "        Val:   (mean) [5852.908137 42.919593 3.489000]\n",
      "        Val:   (max)  [27878.931641 83.633675 3.844000]\n",
      "        Val:   (min)  [344.991821 10.933559 2.949000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.8098080158s\n",
      "Epoch 105:\n",
      "    101120:  [12.696863 0.009123 0.557400 0.020619 4.179919] [12.696863 2.736753 5.574003 0.206189 4.179919] 2.30010008812 \n",
      "    Total time for epoch: 160.042467117s\n",
      "    ----------------\n",
      "    Code entropy: 1.80868398723\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3293.8855, 38.154682, 3.003]\n",
      "    SA1 (arg):    [3436.7019, 39.01004, 2.921]\n",
      "    SX383:        [1841.7549, 26.589287, 3.089]\n",
      "    SX383 (arg):  [1916.2941, 27.279095, 3.018]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [7065.735892 47.154902 3.276380]\n",
      "        Train: (max)  [43308.859375 92.771065 3.860000]\n",
      "        Train: (min)  [654.887024 16.571592 2.519000]\n",
      "        Val:   (mean) [5525.965274 42.553340 3.457760]\n",
      "        Val:   (max)  [20174.097656 90.116196 4.033000]\n",
      "        Val:   (min)  [368.320526 11.330468 2.810000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.4234349728s\n",
      "Epoch 106:\n",
      "    101120:  [12.170623 0.007933 0.564348 0.020468 3.942700] [12.170623 2.379763 5.643478 0.204681 3.942700] 2.30010008812 \n",
      "    Total time for epoch: 160.770400047s\n",
      "    ----------------\n",
      "    Code entropy: 1.80055046647\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3151.4841, 36.996403, 3.112]\n",
      "    SA1 (arg):    [3266.3259, 37.72068, 3.044]\n",
      "    SX383:        [1761.4481, 25.850714, 3.089]\n",
      "    SX383 (arg):  [1825.3668, 26.405743, 3.017]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5187.412078 41.660200 3.379720]\n",
      "        Train: (max)  [15214.715820 80.449623 3.800000]\n",
      "        Train: (min)  [631.126465 16.133406 2.804000]\n",
      "        Val:   (mean) [6465.770475 44.277956 3.503020]\n",
      "        Val:   (max)  [30325.794922 97.833191 3.911000]\n",
      "        Val:   (min)  [351.179321 11.004331 2.616000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.3484549522s\n",
      "Epoch 107:\n",
      "    101120:  [12.053026 0.008685 0.509610 0.020724 4.144206] [12.053026 2.605479 5.096103 0.207239 4.144206] 2.30010008812 \n",
      "    Total time for epoch: 160.061235905s\n",
      "    ----------------\n",
      "    Code entropy: 1.89004968387\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3163.1304, 37.32629, 3.069]\n",
      "    SA1 (arg):    [3286.5247, 38.094479, 2.999]\n",
      "    SX383:        [1775.3707, 26.437429, 3.024]\n",
      "    SX383 (arg):  [1837.7523, 26.953049, 2.976]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5403.948038 42.498776 3.398900]\n",
      "        Train: (max)  [22930.804688 79.725616 3.878000]\n",
      "        Train: (min)  [859.566040 17.307838 2.698000]\n",
      "        Val:   (mean) [5770.792630 44.401348 3.465580]\n",
      "        Val:   (max)  [19399.923828 89.409447 3.917000]\n",
      "        Val:   (min)  [483.194733 13.229656 2.455000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.4118869305s\n",
      "Epoch 108:\n",
      "    101120:  [12.605234 0.008845 0.553634 0.021059 4.204762] [12.605234 2.653541 5.536345 0.210586 4.204762] 2.30010008812 \n",
      "    Total time for epoch: 160.554583073s\n",
      "    ----------------\n",
      "    Code entropy: 1.81064951223\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3121.8108, 37.182293, 3.112]\n",
      "    SA1 (arg):    [3237.5881, 37.988552, 3.05]\n",
      "    SX383:        [1870.6361, 26.307409, 3.096]\n",
      "    SX383 (arg):  [1940.6951, 26.911692, 3.037]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6385.476871 45.563721 3.422940]\n",
      "        Train: (max)  [32788.414062 113.338364 4.141000]\n",
      "        Train: (min)  [983.664978 19.612207 2.623000]\n",
      "        Val:   (mean) [6706.399427 46.937396 3.499160]\n",
      "        Val:   (max)  [31926.021484 99.416771 4.103000]\n",
      "        Val:   (min)  [500.678772 13.701707 2.298000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.5349240303s\n",
      "Epoch 109:\n",
      "    101120:  [12.024691 0.007598 0.536168 0.020898 4.174657] [12.024691 2.279372 5.361681 0.208982 4.174657] 2.30010008812 \n",
      "    Total time for epoch: 160.033952951s\n",
      "    ----------------\n",
      "    Code entropy: 1.88727381346\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3202.4673, 37.855038, 3.228]\n",
      "    SA1 (arg):    [3326.5679, 38.65535, 3.162]\n",
      "    SX383:        [1744.1116, 26.27062, 3.232]\n",
      "    SX383 (arg):  [1802.9991, 26.792244, 3.169]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5721.783761 44.065548 3.425780]\n",
      "        Train: (max)  [17540.568359 81.769150 4.106000]\n",
      "        Train: (min)  [928.648132 17.841408 2.784000]\n",
      "        Val:   (mean) [5350.331300 41.050585 3.641320]\n",
      "        Val:   (max)  [29713.822266 99.258102 4.061000]\n",
      "        Val:   (min)  [345.503296 10.837498 3.221000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.3195109367s\n",
      "Epoch 110:\n",
      "    101120:  [12.228463 0.007921 0.572805 0.019728 3.926884] [12.228463 2.376249 5.728054 0.197277 3.926884] 2.30010008812 \n",
      "    Total time for epoch: 160.65031004s\n",
      "    ----------------\n",
      "    Code entropy: 1.78646976842\n",
      "    Tau stays at 2.30010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3193.9578, 37.171623, 3.092]\n",
      "    SA1 (arg):    [3315.488, 37.920998, 3.041]\n",
      "    SX383:        [1713.4943, 25.660149, 3.105]\n",
      "    SX383 (arg):  [1773.2821, 26.217583, 3.042]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5943.699155 40.499693 3.366880]\n",
      "        Train: (max)  [59069.105469 151.176559 4.027000]\n",
      "        Train: (min)  [812.414673 17.471899 2.674000]\n",
      "        Val:   (mean) [6162.878490 44.220301 3.512820]\n",
      "        Val:   (max)  [23768.773438 97.945778 4.023000]\n",
      "        Val:   (min)  [617.994324 13.435040 2.431000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.9292581081s\n",
      "Epoch 111:\n",
      "    101120:  [12.045206 0.008068 0.562665 0.019596 3.802246] [12.045206 2.420347 5.626651 0.195963 3.802246] 2.30010008812 \n",
      "    Total time for epoch: 160.515441895s\n",
      "    ----------------\n",
      "    Code entropy: 1.71865335397\n",
      "    Updated tau from 2.30010008812 to 2.20010008812\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3184.1934, 37.349888, 3.163]\n",
      "    SA1 (arg):    [3310.0264, 38.121582, 3.1]\n",
      "    SX383:        [1861.1759, 26.44466, 3.108]\n",
      "    SX383 (arg):  [1950.0468, 27.14045, 3.077]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5595.289026 42.578638 3.316800]\n",
      "        Train: (max)  [26388.175781 90.892502 4.023000]\n",
      "        Train: (min)  [901.804016 19.320633 2.494000]\n",
      "        Val:   (mean) [6005.690175 44.487233 3.514520]\n",
      "        Val:   (max)  [23275.937500 99.809074 4.047000]\n",
      "        Val:   (min)  [331.711395 10.672811 2.533000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.9427580833s\n",
      "Epoch 112:\n",
      "    101120:  [12.230194 0.009302 0.521258 0.021244 4.014665] [12.230194 2.790510 5.212583 0.212436 4.014665] 2.20010018349 \n",
      "    Total time for epoch: 160.805010796s\n",
      "    ----------------\n",
      "    Code entropy: 1.82066182105\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3076.4104, 36.886383, 3.142]\n",
      "    SA1 (arg):    [3190.4753, 37.610497, 3.083]\n",
      "    SX383:        [1654.2316, 25.486294, 3.18]\n",
      "    SX383 (arg):  [1726.9114, 26.100285, 3.127]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4974.165459 39.340996 3.491720]\n",
      "        Train: (max)  [25821.056641 87.849487 4.067000]\n",
      "        Train: (min)  [1049.854980 19.198957 2.865000]\n",
      "        Val:   (mean) [5672.535410 40.870663 3.571740]\n",
      "        Val:   (max)  [27918.109375 95.869423 4.031000]\n",
      "        Val:   (min)  [328.523499 10.703338 3.020000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.3472650051s\n",
      "Epoch 113:\n",
      "    101120:  [12.718154 0.009092 0.543703 0.021042 4.343156] [12.718154 2.727547 5.437031 0.210420 4.343156] 2.20010018349 \n",
      "    Total time for epoch: 160.611045122s\n",
      "    ----------------\n",
      "    Code entropy: 1.94909093173\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2885.4468, 35.675419, 3.212]\n",
      "    SA1 (arg):    [3000.3176, 36.449581, 3.153]\n",
      "    SX383:        [1549.2461, 24.502354, 3.222]\n",
      "    SX383 (arg):  [1604.7357, 25.013994, 3.19]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4282.324191 37.441840 3.449060]\n",
      "        Train: (max)  [14037.446289 78.203896 4.016000]\n",
      "        Train: (min)  [867.762146 17.255148 2.690000]\n",
      "        Val:   (mean) [5578.792759 40.617376 3.628780]\n",
      "        Val:   (max)  [28869.587891 92.210930 4.068000]\n",
      "        Val:   (min)  [322.487854 10.511339 3.084000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.6729109287s\n",
      "Epoch 114:\n",
      "    101120:  [12.617397 0.009797 0.535470 0.020822 4.115346] [12.617397 2.939128 5.354704 0.208220 4.115346] 2.20010018349 \n",
      "    Total time for epoch: 160.754498005s\n",
      "    ----------------\n",
      "    Code entropy: 1.8639136315\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3088.3025, 36.65826, 3.074]\n",
      "    SA1 (arg):    [3223.3655, 37.500427, 2.997]\n",
      "    SX383:        [1778.7676, 26.163818, 3.113]\n",
      "    SX383 (arg):  [1862.4418, 26.877613, 3.066]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5226.941178 41.647046 3.359600]\n",
      "        Train: (max)  [19029.316406 85.715439 3.863000]\n",
      "        Train: (min)  [889.848206 17.168222 2.777000]\n",
      "        Val:   (mean) [5693.327681 41.435902 3.480620]\n",
      "        Val:   (max)  [29073.021484 97.494011 3.833000]\n",
      "        Val:   (min)  [335.039154 10.742467 2.988000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.3450698853s\n",
      "Epoch 115:\n",
      "    101120:  [11.929543 0.008013 0.539144 0.020377 3.930480] [11.929543 2.403851 5.391440 0.203771 3.930480] 2.20010018349 \n",
      "    Total time for epoch: 160.662184s\n",
      "    ----------------\n",
      "    Code entropy: 1.93060442236\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2957.1401, 35.976059, 3.184]\n",
      "    SA1 (arg):    [3077.1086, 36.796761, 3.119]\n",
      "    SX383:        [1674.5012, 25.145964, 3.135]\n",
      "    SX383 (arg):  [1740.6384, 25.700867, 3.088]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4584.364421 38.349133 3.432420]\n",
      "        Train: (max)  [16136.811523 75.063309 4.145000]\n",
      "        Train: (min)  [501.867462 14.874752 2.822000]\n",
      "        Val:   (mean) [5315.613517 41.624242 3.535780]\n",
      "        Val:   (max)  [19075.755859 84.145996 3.950000]\n",
      "        Val:   (min)  [579.652161 12.948586 2.922000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.1881868839s\n",
      "Epoch 116:\n",
      "    101120:  [12.720659 0.009383 0.542623 0.021512 4.264307] [12.720659 2.815001 5.426230 0.215121 4.264307] 2.20010018349 \n",
      "    Total time for epoch: 160.245961905s\n",
      "    ----------------\n",
      "    Code entropy: 1.91206074594\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3035.5913, 36.488419, 3.129]\n",
      "    SA1 (arg):    [3149.3818, 37.253307, 3.07]\n",
      "    SX383:        [1718.4647, 25.560198, 3.078]\n",
      "    SX383 (arg):  [1775.9854, 26.102541, 3.038]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5463.046857 40.180640 3.347100]\n",
      "        Train: (max)  [26514.519531 92.291435 3.998000]\n",
      "        Train: (min)  [588.938782 15.849556 2.863000]\n",
      "        Val:   (mean) [7254.761033 47.542693 3.466840]\n",
      "        Val:   (max)  [28922.486328 96.790352 4.065000]\n",
      "        Val:   (min)  [508.891113 13.158985 2.442000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.7683928013s\n",
      "Epoch 117:\n",
      "    101120:  [11.866289 0.008208 0.517994 0.020928 4.014756] [11.866289 2.462311 5.179943 0.209279 4.014756] 2.20010018349 \n",
      "    Total time for epoch: 159.879304886s\n",
      "    ----------------\n",
      "    Code entropy: 1.88358711082\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3014.6333, 36.236519, 3.185]\n",
      "    SA1 (arg):    [3114.916, 36.895195, 3.124]\n",
      "    SX383:        [1684.1748, 24.990437, 3.194]\n",
      "    SX383 (arg):  [1738.5994, 25.514509, 3.137]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6343.594949 44.630272 3.436500]\n",
      "        Train: (max)  [25329.312500 101.752937 3.972000]\n",
      "        Train: (min)  [923.998413 17.732107 2.763000]\n",
      "        Val:   (mean) [5154.587612 40.770670 3.560960]\n",
      "        Val:   (max)  [22176.953125 94.469170 3.910000]\n",
      "        Val:   (min)  [329.357727 10.528317 3.053000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.3966770172s\n",
      "Epoch 118:\n",
      "    101120:  [12.493361 0.008900 0.548278 0.020804 4.132550] [12.493361 2.669991 5.482778 0.208042 4.132550] 2.20010018349 \n",
      "    Total time for epoch: 160.799192905s\n",
      "    ----------------\n",
      "    Code entropy: 1.88874527821\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2969.8406, 36.060867, 3.149]\n",
      "    SA1 (arg):    [3100.1514, 36.897175, 3.069]\n",
      "    SX383:        [1647.5725, 25.23255, 3.126]\n",
      "    SX383 (arg):  [1708.056, 25.793018, 3.077]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4772.318145 39.032085 3.428400]\n",
      "        Train: (max)  [26327.675781 88.310814 3.940000]\n",
      "        Train: (min)  [496.409058 15.105030 2.725000]\n",
      "        Val:   (mean) [5848.229639 43.729157 3.545340]\n",
      "        Val:   (max)  [18487.052734 85.713326 4.096000]\n",
      "        Val:   (min)  [512.473328 13.864658 3.141000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.2954180241s\n",
      "Epoch 119:\n",
      "    101120:  [12.033989 0.008311 0.537807 0.020407 3.958677] [12.033989 2.493175 5.378072 0.204065 3.958677] 2.20010018349 \n",
      "    Total time for epoch: 161.157892942s\n",
      "    ----------------\n",
      "    Code entropy: 1.95061483011\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3023.3206, 36.620182, 3.101]\n",
      "    SA1 (arg):    [3152.2168, 37.498569, 3.028]\n",
      "    SX383:        [1680.7382, 25.604343, 3.099]\n",
      "    SX383 (arg):  [1761.8059, 26.278458, 3.054]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5538.943134 43.042777 3.358900]\n",
      "        Train: (max)  [25983.945312 103.964218 3.858000]\n",
      "        Train: (min)  [981.100464 20.270941 2.867000]\n",
      "        Val:   (mean) [5752.704453 43.041076 3.561880]\n",
      "        Val:   (max)  [27021.148438 96.696548 4.106000]\n",
      "        Val:   (min)  [522.779480 14.084803 3.014000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.2594029903s\n",
      "Epoch 120:\n",
      "    101120:  [12.325847 0.008754 0.563177 0.019860 3.869137] [12.325847 2.626346 5.631769 0.198595 3.869137] 2.20010018349 \n",
      "    Total time for epoch: 160.668638945s\n",
      "    ----------------\n",
      "    Code entropy: 1.87450835342\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3299.5486, 37.753643, 3.143]\n",
      "    SA1 (arg):    [3416.2505, 38.489548, 3.084]\n",
      "    SX383:        [1944.6215, 26.569283, 3.143]\n",
      "    SX383 (arg):  [2000.6576, 27.056772, 3.107]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6001.693137 41.709412 3.402520]\n",
      "        Train: (max)  [35792.351562 96.562965 3.912000]\n",
      "        Train: (min)  [723.139648 15.992375 2.827000]\n",
      "        Val:   (mean) [6464.567413 42.612037 3.500100]\n",
      "        Val:   (max)  [32541.818359 99.228668 3.923000]\n",
      "        Val:   (min)  [354.854980 10.894148 3.003000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.4011008739s\n",
      "Epoch 121:\n",
      "    101120:  [12.450537 0.008929 0.539526 0.020879 4.167787] [12.450537 2.678707 5.395256 0.208786 4.167787] 2.20010018349 \n",
      "    Total time for epoch: 159.790159941s\n",
      "    ----------------\n",
      "    Code entropy: 1.91095109517\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2966.9858, 36.081543, 3.25]\n",
      "    SA1 (arg):    [3084.3662, 36.879639, 3.197]\n",
      "    SX383:        [1607.7485, 24.841784, 3.214]\n",
      "    SX383 (arg):  [1668.6698, 25.385286, 3.164]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5196.664060 39.853745 3.513520]\n",
      "        Train: (max)  [36040.191406 123.012245 4.022000]\n",
      "        Train: (min)  [570.512573 15.612247 2.959000]\n",
      "        Val:   (mean) [5857.818479 42.054975 3.597020]\n",
      "        Val:   (max)  [29065.531250 96.404640 4.142000]\n",
      "        Val:   (min)  [338.789337 10.730807 3.124000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.4531769753s\n",
      "Epoch 122:\n",
      "    101120:  [13.123009 0.010168 0.549741 0.020960 4.365493] [13.123009 3.050510 5.497408 0.209598 4.365493] 2.20010018349 \n",
      "    Total time for epoch: 160.641086102s\n",
      "    ----------------\n",
      "    Code entropy: 1.76166387092\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3014.5454, 36.410366, 3.122]\n",
      "    SA1 (arg):    [3138.4644, 37.151592, 3.063]\n",
      "    SX383:        [1693.8743, 25.478737, 3.151]\n",
      "    SX383 (arg):  [1760.6343, 26.036844, 3.11]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6083.564208 42.899271 3.385660]\n",
      "        Train: (max)  [30630.152344 92.182976 3.885000]\n",
      "        Train: (min)  [801.248596 16.648483 2.689000]\n",
      "        Val:   (mean) [5960.345552 42.875508 3.483840]\n",
      "        Val:   (max)  [28718.373047 86.357094 4.007000]\n",
      "        Val:   (min)  [347.588074 10.868820 2.292000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.3953609467s\n",
      "Epoch 123:\n",
      "    101120:  [12.260290 0.008429 0.579535 0.020092 3.735239] [12.260290 2.528785 5.795350 0.200917 3.735239] 2.10010027885 \n",
      "    Total time for epoch: 160.610435963s\n",
      "    ----------------\n",
      "    Code entropy: 1.79933362341\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3094.6169, 36.853661, 3.163]\n",
      "    SA1 (arg):    [3205.0249, 37.543316, 3.105]\n",
      "    SX383:        [1641.9337, 25.650055, 3.138]\n",
      "    SX383 (arg):  [1705.1581, 26.174774, 3.104]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4357.062284 38.678291 3.385660]\n",
      "        Train: (max)  [10211.786133 64.519730 3.803000]\n",
      "        Train: (min)  [750.252014 15.154894 2.788000]\n",
      "        Val:   (mean) [6236.444506 44.278525 3.464480]\n",
      "        Val:   (max)  [27830.501953 81.638954 3.999000]\n",
      "        Val:   (min)  [345.384674 10.927028 2.932000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.4074220657s\n",
      "Epoch 124:\n",
      "    101120:  [12.025159 0.008554 0.540202 0.020560 3.851205] [12.025159 2.566335 5.402021 0.205598 3.851205] 2.10010027885 \n",
      "    Total time for epoch: 160.734760046s\n",
      "    ----------------\n",
      "    Code entropy: 1.93580574468\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3067.7566, 36.487476, 3.161]\n",
      "    SA1 (arg):    [3157.1482, 37.117138, 3.111]\n",
      "    SX383:        [1697.6177, 25.38875, 3.169]\n",
      "    SX383 (arg):  [1759.0059, 25.938957, 3.109]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6228.221844 43.667260 3.390660]\n",
      "        Train: (max)  [38464.902344 88.447296 4.095000]\n",
      "        Train: (min)  [777.508667 18.241232 2.887000]\n",
      "        Val:   (mean) [6054.866943 43.540693 3.547160]\n",
      "        Val:   (max)  [26292.150391 96.900711 4.015000]\n",
      "        Val:   (min)  [350.739502 10.938777 3.120000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.5850698948s\n",
      "Epoch 125:\n",
      "    101120:  [12.326242 0.009161 0.533565 0.021151 4.030847] [12.326242 2.748234 5.335654 0.211507 4.030847] 2.10010027885 \n",
      "    Total time for epoch: 160.591232061s\n",
      "    ----------------\n",
      "    Code entropy: 1.96621594383\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2894.012, 35.419685, 3.233]\n",
      "    SA1 (arg):    [3004.5237, 36.149857, 3.165]\n",
      "    SX383:        [1557.8641, 24.319527, 3.311]\n",
      "    SX383 (arg):  [1612.7914, 24.832073, 3.268]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4483.876282 37.976761 3.530020]\n",
      "        Train: (max)  [20987.671875 84.957077 4.113000]\n",
      "        Train: (min)  [793.169495 16.585060 2.901000]\n",
      "        Val:   (mean) [5667.183144 42.444207 3.616840]\n",
      "        Val:   (max)  [22107.796875 94.100960 4.139000]\n",
      "        Val:   (min)  [331.518646 10.580421 2.869000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.8727688789s\n",
      "Epoch 126:\n",
      "    101120:  [11.688529 0.007747 0.537786 0.020079 3.785640] [11.688529 2.324243 5.377858 0.200789 3.785640] 2.10010027885 \n",
      "    Total time for epoch: 159.793782949s\n",
      "    ----------------\n",
      "    Code entropy: 1.90604992231\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2938.1555, 35.71159, 3.133]\n",
      "    SA1 (arg):    [3055.2297, 36.479908, 3.073]\n",
      "    SX383:        [1698.9819, 25.102621, 3.239]\n",
      "    SX383 (arg):  [1751.8309, 25.623941, 3.196]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4476.978400 38.804153 3.472860]\n",
      "        Train: (max)  [15503.377930 76.361549 3.857000]\n",
      "        Train: (min)  [565.131104 15.442525 2.534000]\n",
      "        Val:   (mean) [6247.401209 43.784914 3.597900]\n",
      "        Val:   (max)  [29799.904297 83.987007 4.015000]\n",
      "        Val:   (min)  [332.375397 10.658185 3.203000]\n",
      "    Best validation mean-PESQ seen: 3.58878\n",
      "    Total time for evaluation: 24.5634088516s\n",
      "Epoch 127:\n",
      "    101120:  [12.176107 0.008392 0.555689 0.020254 3.899145] [12.176107 2.517531 5.556890 0.202542 3.899145] 2.10010027885 \n",
      "    Total time for epoch: 160.671813011s\n",
      "    ----------------\n",
      "    Code entropy: 1.79836706444\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2816.2383, 34.821495, 3.215]\n",
      "    SA1 (arg):    [2928.8855, 35.558414, 3.108]\n",
      "    SX383:        [1530.9175, 24.144291, 3.161]\n",
      "    SX383 (arg):  [1588.5748, 24.667616, 3.108]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4718.518069 38.825557 3.386780]\n",
      "        Train: (max)  [22710.162109 86.613434 3.883000]\n",
      "        Train: (min)  [697.162231 16.663479 2.693000]\n",
      "        Val:   (mean) [5413.108347 42.509456 3.606700]\n",
      "        Val:   (max)  [18073.189453 80.608887 4.071000]\n",
      "        Val:   (min)  [1228.705688 19.945360 3.033000]\n",
      "    NEW best model! Validation mean-PESQ 3.6067\n",
      "    Saving model...\n",
      "    Total time for evaluation: 25.0471601486s\n",
      "Epoch 128:\n",
      "    101120:  [12.223152 0.008574 0.536590 0.021198 4.073156] [12.223152 2.572122 5.365896 0.211978 4.073156] 2.10010027885 \n",
      "    Total time for epoch: 160.653916121s\n",
      "    ----------------\n",
      "    Code entropy: 1.89248395813\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2841.3474, 34.930622, 3.192]\n",
      "    SA1 (arg):    [2935.6816, 35.572449, 3.138]\n",
      "    SX383:        [1584.4095, 24.151596, 3.239]\n",
      "    SX383 (arg):  [1637.0544, 24.675541, 3.191]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4640.720157 38.147375 3.443580]\n",
      "        Train: (max)  [23732.273438 98.333511 4.052000]\n",
      "        Train: (min)  [599.484741 15.025654 2.757000]\n",
      "        Val:   (mean) [5720.062625 42.146520 3.568140]\n",
      "        Val:   (max)  [29238.757812 92.222008 4.090000]\n",
      "        Val:   (min)  [327.188843 10.451429 2.438000]\n",
      "    Best validation mean-PESQ seen: 3.6067\n",
      "    Total time for evaluation: 24.0139269829s\n",
      "Epoch 129:\n",
      "    101120:  [12.640550 0.009264 0.533388 0.021895 4.308557] [12.640550 2.779162 5.333881 0.218949 4.308557] 2.10010027885 \n",
      "    Total time for epoch: 160.997401953s\n",
      "    ----------------\n",
      "    Code entropy: 2.11790070856\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2744.9404, 34.342045, 3.35]\n",
      "    SA1 (arg):    [2846.4941, 35.03688, 3.282]\n",
      "    SX383:        [1487.094, 23.61467, 3.338]\n",
      "    SX383 (arg):  [1548.9758, 24.188841, 3.269]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4694.381689 38.758013 3.494000]\n",
      "        Train: (max)  [21766.484375 86.629829 4.056000]\n",
      "        Train: (min)  [864.448364 18.756126 2.766000]\n",
      "        Val:   (mean) [5300.032335 40.589197 3.686060]\n",
      "        Val:   (max)  [27333.738281 80.586403 4.097000]\n",
      "        Val:   (min)  [316.903961 10.310027 3.141000]\n",
      "    Best validation mean-PESQ seen: 3.6067\n",
      "    Total time for evaluation: 25.1219000816s\n",
      "Epoch 130:\n",
      "    101120:  [11.786785 0.007824 0.546195 0.019294 3.784774] [11.786785 2.347120 5.461947 0.192944 3.784774] 2.20010018349 \n",
      "    Total time for epoch: 161.120033026s\n",
      "    ----------------\n",
      "    Code entropy: 1.93998978024\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3058.7969, 36.63002, 3.121]\n",
      "    SA1 (arg):    [3166.8472, 37.331112, 3.062]\n",
      "    SX383:        [1672.0028, 25.342955, 3.14]\n",
      "    SX383 (arg):  [1730.6523, 25.869783, 3.113]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4857.478035 38.897887 3.378120]\n",
      "        Train: (max)  [22649.085938 88.557640 3.935000]\n",
      "        Train: (min)  [648.188599 16.365496 2.640000]\n",
      "        Val:   (mean) [5190.666886 40.957507 3.556480]\n",
      "        Val:   (max)  [18339.125000 81.750877 3.942000]\n",
      "        Val:   (min)  [327.964966 10.636649 2.913000]\n",
      "    Best validation mean-PESQ seen: 3.6067\n",
      "    Total time for evaluation: 24.3453080654s\n",
      "Epoch 131:\n",
      "    101120:  [12.117073 0.008276 0.538625 0.019866 4.049226] [12.117073 2.482937 5.386250 0.198661 4.049226] 2.20010018349 \n",
      "    Total time for epoch: 160.199743032s\n",
      "    ----------------\n",
      "    Code entropy: 1.81828106937\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3055.4377, 36.489498, 3.245]\n",
      "    SA1 (arg):    [3141.4092, 37.042625, 3.2]\n",
      "    SX383:        [1689.0349, 25.11282, 3.279]\n",
      "    SX383 (arg):  [1746.6522, 25.596582, 3.229]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6083.338773 43.884232 3.553620]\n",
      "        Train: (max)  [25239.917969 87.138977 4.072000]\n",
      "        Train: (min)  [543.300110 15.473948 2.613000]\n",
      "        Val:   (mean) [6846.746791 44.982659 3.598060]\n",
      "        Val:   (max)  [29890.707031 93.225220 3.924000]\n",
      "        Val:   (min)  [606.740845 13.143547 2.995000]\n",
      "    Best validation mean-PESQ seen: 3.6067\n",
      "    Total time for evaluation: 24.3392601013s\n",
      "Epoch 132:\n",
      "    101120:  [12.729383 0.009488 0.532747 0.020301 4.352557] [12.729383 2.846346 5.327467 0.203014 4.352557] 2.20010018349 \n",
      "    Total time for epoch: 160.656769991s\n",
      "    ----------------\n",
      "    Code entropy: 1.79052775492\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2982.7502, 35.927731, 3.144]\n",
      "    SA1 (arg):    [3097.9839, 36.627777, 3.082]\n",
      "    SX383:        [1577.3048, 24.817036, 3.129]\n",
      "    SX383 (arg):  [1628.4543, 25.321001, 3.093]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6820.582557 46.455665 3.480560]\n",
      "        Train: (max)  [30469.744141 106.155045 4.000000]\n",
      "        Train: (min)  [807.599792 17.176552 2.817000]\n",
      "        Val:   (mean) [5797.280775 42.283248 3.518000]\n",
      "        Val:   (max)  [28588.142578 80.771179 4.086000]\n",
      "        Val:   (min)  [821.966003 15.908923 3.041000]\n",
      "    Best validation mean-PESQ seen: 3.6067\n",
      "    Total time for evaluation: 24.5300729275s\n",
      "Epoch 133:\n",
      "    101120:  [11.544018 0.007979 0.511748 0.019259 3.840398] [11.544018 2.393553 5.117477 0.192589 3.840398] 2.20010018349 \n",
      "    Total time for epoch: 160.545300961s\n",
      "    ----------------\n",
      "    Code entropy: 1.76363330264\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3080.2651, 36.518333, 3.183]\n",
      "    SA1 (arg):    [3178.4263, 37.148232, 3.131]\n",
      "    SX383:        [1566.1323, 24.764309, 3.213]\n",
      "    SX383 (arg):  [1611.5576, 25.164885, 3.17]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5751.088108 41.730540 3.455860]\n",
      "        Train: (max)  [35426.121094 121.525085 3.894000]\n",
      "        Train: (min)  [775.393921 17.565346 2.694000]\n",
      "        Val:   (mean) [5641.670790 41.405737 3.620200]\n",
      "        Val:   (max)  [27364.419922 85.356346 4.120000]\n",
      "        Val:   (min)  [578.971619 12.893259 3.082000]\n",
      "    NEW best model! Validation mean-PESQ 3.6202\n",
      "    Saving model...\n",
      "    Total time for evaluation: 24.8276159763s\n",
      "Epoch 134:\n",
      "    101120:  [12.705635 0.009899 0.521107 0.021328 4.311440] [12.705635 2.969839 5.211071 0.213284 4.311440] 2.10010027885 \n",
      "    Total time for epoch: 160.703949928s\n",
      "    ----------------\n",
      "    Code entropy: 1.85333636497\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2813.2708, 35.091503, 3.245]\n",
      "    SA1 (arg):    [2897.5325, 35.746265, 3.193]\n",
      "    SX383:        [1585.6886, 24.447306, 3.305]\n",
      "    SX383 (arg):  [1632.9733, 24.915699, 3.256]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6252.067040 43.993754 3.421040]\n",
      "        Train: (max)  [37668.128906 117.869644 4.022000]\n",
      "        Train: (min)  [540.728943 15.097690 1.867000]\n",
      "        Val:   (mean) [4569.518855 38.466872 3.616940]\n",
      "        Val:   (max)  [17712.542969 83.982460 4.209000]\n",
      "        Val:   (min)  [474.581604 13.282008 3.159000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.3938398361s\n",
      "Epoch 135:\n",
      "    101120:  [12.389531 0.009410 0.540642 0.019875 3.961269] [12.389531 2.823087 5.406422 0.198754 3.961269] 2.10010027885 \n",
      "    Total time for epoch: 160.844450951s\n",
      "    ----------------\n",
      "    Code entropy: 1.8957802011\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3019.366, 36.298767, 3.197]\n",
      "    SA1 (arg):    [3150.5925, 37.106365, 3.126]\n",
      "    SX383:        [1732.0583, 25.676016, 3.234]\n",
      "    SX383 (arg):  [1800.4724, 26.207846, 3.16]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5099.635630 41.811906 3.476500]\n",
      "        Train: (max)  [17162.966797 82.640182 4.004000]\n",
      "        Train: (min)  [1082.019897 19.508801 2.879000]\n",
      "        Val:   (mean) [6259.229816 43.980474 3.592540]\n",
      "        Val:   (max)  [27144.783203 94.746040 3.929000]\n",
      "        Val:   (min)  [328.050140 10.643515 3.144000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.647685051s\n",
      "Epoch 136:\n",
      "    101120:  [11.860559 0.007692 0.551259 0.019944 3.840994] [11.860559 2.307535 5.512586 0.199444 3.840994] 2.10010027885 \n",
      "    Total time for epoch: 159.844370127s\n",
      "    ----------------\n",
      "    Code entropy: 1.90123055227\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2875.7822, 35.174328, 3.296]\n",
      "    SA1 (arg):    [2974.0562, 35.836441, 3.234]\n",
      "    SX383:        [1612.3754, 24.401995, 3.285]\n",
      "    SX383 (arg):  [1658.0613, 24.821823, 3.221]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5708.150977 42.131901 3.524980]\n",
      "        Train: (max)  [26425.679688 95.089203 4.074000]\n",
      "        Train: (min)  [759.476868 17.549370 2.687000]\n",
      "        Val:   (mean) [5728.774393 41.737845 3.632240]\n",
      "        Val:   (max)  [28539.019531 83.637039 3.999000]\n",
      "        Val:   (min)  [600.170593 13.112650 3.078000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.4986279011s\n",
      "Epoch 137:\n",
      "    101120:  [12.264215 0.009391 0.507417 0.020588 4.166780] [12.264215 2.817384 5.074172 0.205879 4.166780] 2.10010027885 \n",
      "    Total time for epoch: 160.867507935s\n",
      "    ----------------\n",
      "    Code entropy: 1.96076959456\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2980.6577, 35.951935, 3.134]\n",
      "    SA1 (arg):    [3074.5474, 36.570034, 3.085]\n",
      "    SX383:        [1575.9209, 24.724287, 3.285]\n",
      "    SX383 (arg):  [1643.8291, 25.344965, 3.229]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4649.566621 38.077875 3.368840]\n",
      "        Train: (max)  [22927.638672 82.009239 4.056000]\n",
      "        Train: (min)  [764.208374 15.146305 2.855000]\n",
      "        Val:   (mean) [4990.085327 40.387631 3.597460]\n",
      "        Val:   (max)  [19118.394531 83.998451 4.143000]\n",
      "        Val:   (min)  [506.778198 12.900846 3.028000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.3498539925s\n",
      "Epoch 138:\n",
      "    101120:  [12.149446 0.008755 0.524099 0.020273 4.079123] [12.149446 2.626598 5.240994 0.202730 4.079123] 2.10010027885 \n",
      "    Total time for epoch: 160.182047129s\n",
      "    ----------------\n",
      "    Code entropy: 1.92738062502\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2837.5854, 35.214409, 3.211]\n",
      "    SA1 (arg):    [2925.8179, 35.803776, 3.148]\n",
      "    SX383:        [1609.8881, 24.509291, 3.261]\n",
      "    SX383 (arg):  [1669.2305, 25.002941, 3.214]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4805.265836 38.351034 3.521680]\n",
      "        Train: (max)  [23167.062500 86.900841 4.111000]\n",
      "        Train: (min)  [577.728333 15.548770 2.713000]\n",
      "        Val:   (mean) [5633.253223 42.297134 3.648640]\n",
      "        Val:   (max)  [27023.681641 81.275681 4.041000]\n",
      "        Val:   (min)  [312.344635 10.336302 3.210000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.4941649437s\n",
      "Epoch 139:\n",
      "    101120:  [12.129599 0.008512 0.529174 0.020864 4.075520] [12.129599 2.553691 5.291744 0.208644 4.075520] 2.10010027885 \n",
      "    Total time for epoch: 160.799950838s\n",
      "    ----------------\n",
      "    Code entropy: 1.96414496439\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2852.5728, 35.113934, 3.184]\n",
      "    SA1 (arg):    [2966.7, 35.873505, 3.144]\n",
      "    SX383:        [1590.5455, 24.469284, 3.125]\n",
      "    SX383 (arg):  [1645.0449, 24.936081, 3.086]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4964.880339 39.266996 3.395660]\n",
      "        Train: (max)  [23394.609375 88.540810 3.996000]\n",
      "        Train: (min)  [717.314331 16.608776 2.690000]\n",
      "        Val:   (mean) [5451.969981 40.462994 3.561780]\n",
      "        Val:   (max)  [27800.238281 80.514389 4.019000]\n",
      "        Val:   (min)  [331.572113 10.575468 2.573000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.3722438812s\n",
      "Epoch 140:\n",
      "    101120:  [12.399357 0.009790 0.490560 0.021190 4.344771] [12.399357 2.937083 4.905603 0.211900 4.344771] 2.10010027885 \n",
      "    Total time for epoch: 159.937484026s\n",
      "    ----------------\n",
      "    Code entropy: 1.89909550277\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2784.4534, 34.832779, 3.261]\n",
      "    SA1 (arg):    [2879.1755, 35.488987, 3.207]\n",
      "    SX383:        [1566.6876, 24.311117, 3.286]\n",
      "    SX383 (arg):  [1626.4524, 24.828161, 3.229]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5027.193208 40.759656 3.478680]\n",
      "        Train: (max)  [22470.507812 90.288170 3.914000]\n",
      "        Train: (min)  [642.363586 16.788342 2.770000]\n",
      "        Val:   (mean) [5499.735256 41.200921 3.635680]\n",
      "        Val:   (max)  [20932.628906 91.840538 4.156000]\n",
      "        Val:   (min)  [317.234192 10.384217 2.426000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.2223310471s\n",
      "Epoch 141:\n",
      "    101120:  [11.888058 0.008137 0.539967 0.019307 3.854363] [11.888058 2.440950 5.399671 0.193074 3.854363] 2.10010027885 \n",
      "    Total time for epoch: 160.871176958s\n",
      "    ----------------\n",
      "    Code entropy: 1.95874283664\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3113.5166, 36.814743, 3.163]\n",
      "    SA1 (arg):    [3204.1089, 37.466099, 3.098]\n",
      "    SX383:        [1788.0079, 26.305286, 3.245]\n",
      "    SX383 (arg):  [1861.9183, 26.875101, 3.201]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4839.452833 39.423085 3.429900]\n",
      "        Train: (max)  [23686.166016 96.500114 3.973000]\n",
      "        Train: (min)  [681.227783 16.547058 2.572000]\n",
      "        Val:   (mean) [5178.060822 40.832741 3.634160]\n",
      "        Val:   (max)  [19737.523438 88.049477 4.088000]\n",
      "        Val:   (min)  [327.709351 10.637265 2.916000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.6193819046s\n",
      "Epoch 142:\n",
      "    101120:  [12.804018 0.010067 0.518880 0.021393 4.381158] [12.804018 3.020125 5.188799 0.213935 4.381158] 2.10010027885 \n",
      "    Total time for epoch: 160.243811131s\n",
      "    ----------------\n",
      "    Code entropy: 1.887962212\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2826.2864, 35.439171, 3.171]\n",
      "    SA1 (arg):    [2911.7456, 36.031395, 3.116]\n",
      "    SX383:        [1625.355, 24.527655, 3.208]\n",
      "    SX383 (arg):  [1679.4854, 25.065382, 3.165]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5601.166034 40.475595 3.428840]\n",
      "        Train: (max)  [19670.957031 82.154243 3.906000]\n",
      "        Train: (min)  [624.293884 15.882658 2.866000]\n",
      "        Val:   (mean) [5739.231518 41.084004 3.558500]\n",
      "        Val:   (max)  [28998.611328 92.842560 4.022000]\n",
      "        Val:   (min)  [317.903717 10.424094 3.001000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.2099590302s\n",
      "Epoch 143:\n",
      "    101120:  [12.649042 0.010215 0.532236 0.020299 4.059072] [12.649042 3.064623 5.322355 0.202993 4.059072] 2.10010027885 \n",
      "    Total time for epoch: 160.827816963s\n",
      "    ----------------\n",
      "    Code entropy: 1.91434450632\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3063.4534, 36.825699, 3.069]\n",
      "    SA1 (arg):    [3175.7168, 37.515095, 3.036]\n",
      "    SX383:        [1675.5836, 25.542608, 3.109]\n",
      "    SX383 (arg):  [1735.1725, 26.062122, 3.042]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5398.741995 42.386183 3.418280]\n",
      "        Train: (max)  [22069.791016 100.909828 3.940000]\n",
      "        Train: (min)  [665.641724 16.523489 2.634000]\n",
      "        Val:   (mean) [5472.985443 41.809241 3.565960]\n",
      "        Val:   (max)  [27813.539062 83.735413 4.097000]\n",
      "        Val:   (min)  [570.928284 13.005413 3.024000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.2783720493s\n",
      "Epoch 144:\n",
      "    101120:  [11.917498 0.008182 0.538882 0.019437 3.879673] [11.917498 2.454630 5.388823 0.194371 3.879673] 2.10010027885 \n",
      "    Total time for epoch: 160.701620102s\n",
      "    ----------------\n",
      "    Code entropy: 1.93888074533\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2828.79, 35.279896, 3.208]\n",
      "    SA1 (arg):    [2947.9282, 36.077179, 3.155]\n",
      "    SX383:        [1587.1331, 24.359694, 3.299]\n",
      "    SX383 (arg):  [1647.324, 24.876324, 3.26]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5015.166611 40.624146 3.572560]\n",
      "        Train: (max)  [25348.589844 93.330437 4.054000]\n",
      "        Train: (min)  [728.784546 17.584417 2.863000]\n",
      "        Val:   (mean) [5072.732923 39.242183 3.615440]\n",
      "        Val:   (max)  [27693.365234 91.478638 4.091000]\n",
      "        Val:   (min)  [324.886810 10.496461 3.138000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.4337611198s\n",
      "Epoch 145:\n",
      "    101120:  [12.143724 0.008614 0.555666 0.019252 3.810202] [12.143724 2.584337 5.556662 0.192523 3.810202] 2.10010027885 \n",
      "    Total time for epoch: 160.696894169s\n",
      "    ----------------\n",
      "    Code entropy: 1.85001773339\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2973.6931, 36.286205, 3.068]\n",
      "    SA1 (arg):    [3064.4888, 36.956261, 3.022]\n",
      "    SX383:        [1578.0392, 24.653667, 3.245]\n",
      "    SX383 (arg):  [1647.2976, 25.242977, 3.192]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5523.507073 42.226995 3.375960]\n",
      "        Train: (max)  [16015.693359 85.483063 4.104000]\n",
      "        Train: (min)  [544.287781 15.301298 2.649000]\n",
      "        Val:   (mean) [5426.872519 42.614863 3.558200]\n",
      "        Val:   (max)  [18283.710938 82.247917 4.096000]\n",
      "        Val:   (min)  [328.874603 10.628671 2.941000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.8162748814s\n",
      "Epoch 146:\n",
      "    101120:  [12.158165 0.009152 0.549910 0.019039 3.723121] [12.158165 2.745551 5.499100 0.190392 3.723121] 2.10010027885 \n",
      "    Total time for epoch: 160.475709915s\n",
      "    ----------------\n",
      "    Code entropy: 1.81160443346\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3029.5671, 36.481407, 3.098]\n",
      "    SA1 (arg):    [3136.6204, 37.136654, 3.054]\n",
      "    SX383:        [1733.4541, 25.779716, 3.091]\n",
      "    SX383 (arg):  [1806.8761, 26.357498, 3.028]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5302.744318 41.221968 3.430800]\n",
      "        Train: (max)  [23624.189453 96.163193 4.018000]\n",
      "        Train: (min)  [586.097900 15.840721 2.754000]\n",
      "        Val:   (mean) [5326.318823 39.517364 3.526400]\n",
      "        Val:   (max)  [29553.453125 95.578125 3.911000]\n",
      "        Val:   (min)  [347.485199 10.849417 2.946000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.3220431805s\n",
      "Epoch 147:\n",
      "    101120:  [12.751074 0.010260 0.533600 0.020575 4.131374] [12.751074 3.077950 5.336002 0.205747 4.131374] 2.10010027885 \n",
      "    Total time for epoch: 160.302046061s\n",
      "    ----------------\n",
      "    Code entropy: 1.85541901532\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3065.8826, 36.554691, 3.155]\n",
      "    SA1 (arg):    [3155.6812, 37.176891, 3.11]\n",
      "    SX383:        [1766.6144, 26.159098, 3.143]\n",
      "    SX383 (arg):  [1832.954, 26.671846, 3.093]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6009.182664 42.011263 3.343680]\n",
      "        Train: (max)  [56982.941406 148.848541 3.903000]\n",
      "        Train: (min)  [936.012390 18.178514 2.656000]\n",
      "        Val:   (mean) [6096.018647 42.990438 3.525420]\n",
      "        Val:   (max)  [30102.986328 96.800644 4.104000]\n",
      "        Val:   (min)  [343.199432 10.763177 2.912000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.5722489357s\n",
      "Epoch 148:\n",
      "    101120:  [11.949694 0.009037 0.526859 0.019302 3.777121] [11.949694 2.710961 5.268594 0.193017 3.777121] 2.10010027885 \n",
      "    Total time for epoch: 160.249749899s\n",
      "    ----------------\n",
      "    Code entropy: 1.7770867334\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3026.8062, 36.056053, 3.145]\n",
      "    SA1 (arg):    [3137.7778, 36.768566, 3.089]\n",
      "    SX383:        [1694.1809, 24.892805, 3.174]\n",
      "    SX383 (arg):  [1748.3046, 25.338203, 3.12]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5992.807593 43.797685 3.461220]\n",
      "        Train: (max)  [23314.453125 95.368454 4.076000]\n",
      "        Train: (min)  [415.079071 13.366813 2.803000]\n",
      "        Val:   (mean) [4957.229982 39.557181 3.543920]\n",
      "        Val:   (max)  [18643.833984 84.111198 4.154000]\n",
      "        Val:   (min)  [347.103699 10.731246 2.693000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.3216621876s\n",
      "Epoch 149:\n",
      "    101120:  [11.607539 0.007468 0.537717 0.019876 3.791231] [11.607539 2.240382 5.377165 0.198762 3.791231] 2.10010027885 \n",
      "    Total time for epoch: 160.058809042s\n",
      "    ----------------\n",
      "    Code entropy: 1.89197746742\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2881.9688, 35.205429, 3.273]\n",
      "    SA1 (arg):    [2978.2754, 35.834915, 3.189]\n",
      "    SX383:        [1538.5702, 24.350735, 3.243]\n",
      "    SX383 (arg):  [1589.858, 24.80196, 3.208]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5617.697214 42.939925 3.424120]\n",
      "        Train: (max)  [16793.050781 80.627136 3.927000]\n",
      "        Train: (min)  [712.699646 17.284369 2.848000]\n",
      "        Val:   (mean) [5832.200237 41.525645 3.658880]\n",
      "        Val:   (max)  [26762.128906 91.992645 3.966000]\n",
      "        Val:   (min)  [334.721954 10.603456 3.235000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.0889830589s\n",
      "Epoch 150:\n",
      "    101120:  [11.811218 0.008206 0.523999 0.019671 3.912690] [11.811218 2.461821 5.239995 0.196711 3.912690] 2.10010027885 \n",
      "    Total time for epoch: 160.173509121s\n",
      "    ----------------\n",
      "    Code entropy: 1.92778283996\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2827.2344, 35.235443, 3.262]\n",
      "    SA1 (arg):    [2921.2048, 35.846901, 3.203]\n",
      "    SX383:        [1656.8243, 24.870783, 3.265]\n",
      "    SX383 (arg):  [1713.4578, 25.350075, 3.231]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4585.086589 37.541206 3.373920]\n",
      "        Train: (max)  [28605.199219 81.510193 3.896000]\n",
      "        Train: (min)  [556.522888 13.480339 2.921000]\n",
      "        Val:   (mean) [4528.423905 38.170068 3.624820]\n",
      "        Val:   (max)  [18402.611328 82.626785 4.158000]\n",
      "        Val:   (min)  [488.896912 13.030301 2.938000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.092911005s\n",
      "Epoch 151:\n",
      "    101120:  [12.394867 0.009037 0.520812 0.020251 4.273013] [12.394867 2.711227 5.208117 0.202512 4.273013] 2.10010027885 \n",
      "    Total time for epoch: 159.881865025s\n",
      "    ----------------\n",
      "    Code entropy: 1.83886089506\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2709.6106, 34.214455, 3.246]\n",
      "    SA1 (arg):    [2804.6816, 34.89959, 3.172]\n",
      "    SX383:        [1509.604, 23.995129, 3.204]\n",
      "    SX383 (arg):  [1559.5536, 24.451633, 3.152]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4926.403499 39.459810 3.426740]\n",
      "        Train: (max)  [16448.785156 77.281105 4.121000]\n",
      "        Train: (min)  [470.652222 14.467697 2.701000]\n",
      "        Val:   (mean) [4729.631703 37.589173 3.559780]\n",
      "        Val:   (max)  [27953.121094 75.408249 3.973000]\n",
      "        Val:   (min)  [456.629639 12.570315 2.397000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.4371750355s\n",
      "Epoch 152:\n",
      "    101120:  [12.200836 0.008503 0.556476 0.019918 3.886029] [12.200836 2.550864 5.564760 0.199184 3.886029] 2.10010027885 \n",
      "    Total time for epoch: 160.239082098s\n",
      "    ----------------\n",
      "    Code entropy: 1.95577906248\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3050.2061, 36.474911, 3.273]\n",
      "    SA1 (arg):    [3149.8442, 37.114243, 3.224]\n",
      "    SX383:        [1779.8408, 25.754927, 3.217]\n",
      "    SX383 (arg):  [1847.1606, 26.279776, 3.179]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6448.204023 43.725507 3.465220]\n",
      "        Train: (max)  [54047.160156 146.800308 4.291000]\n",
      "        Train: (min)  [747.207458 17.692648 2.538000]\n",
      "        Val:   (mean) [5439.159600 41.452399 3.674020]\n",
      "        Val:   (max)  [18374.410156 85.977501 4.084000]\n",
      "        Val:   (min)  [488.786682 13.029816 3.176000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.4307310581s\n",
      "Epoch 153:\n",
      "    101120:  [12.316139 0.008853 0.549562 0.019920 3.965273] [12.316139 2.656045 5.495619 0.199201 3.965273] 2.10010027885 \n",
      "    Total time for epoch: 160.106505871s\n",
      "    ----------------\n",
      "    Code entropy: 1.92215665985\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2800.4097, 34.570992, 3.203]\n",
      "    SA1 (arg):    [2929.7544, 35.369778, 3.132]\n",
      "    SX383:        [1834.4796, 25.058996, 3.241]\n",
      "    SX383 (arg):  [1881.3987, 25.501276, 3.201]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5085.663461 40.119515 3.503080]\n",
      "        Train: (max)  [24251.611328 99.095291 4.272000]\n",
      "        Train: (min)  [747.099182 16.645866 2.820000]\n",
      "        Val:   (mean) [5478.160885 40.611426 3.664860]\n",
      "        Val:   (max)  [31762.931641 81.951134 4.083000]\n",
      "        Val:   (min)  [636.981262 15.988834 3.324000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.367016077s\n",
      "Epoch 154:\n",
      "    101120:  [11.952444 0.008786 0.502630 0.020202 4.088286] [11.952444 2.635842 5.026296 0.202020 4.088286] 2.10010027885 \n",
      "    Total time for epoch: 159.444736958s\n",
      "    ----------------\n",
      "    Code entropy: 1.89812223668\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2947.1504, 35.593346, 3.303]\n",
      "    SA1 (arg):    [3045.635, 36.258591, 3.236]\n",
      "    SX383:        [1707.375, 25.263412, 3.302]\n",
      "    SX383 (arg):  [1758.8308, 25.722141, 3.259]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4468.126221 39.317805 3.550480]\n",
      "        Train: (max)  [15408.057617 81.205673 4.132000]\n",
      "        Train: (min)  [630.104370 16.394030 2.527000]\n",
      "        Val:   (mean) [5973.179951 44.498269 3.666060]\n",
      "        Val:   (max)  [21108.917969 93.732841 4.087000]\n",
      "        Val:   (min)  [591.460693 13.131944 3.039000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.1992018223s\n",
      "Epoch 155:\n",
      "    101120:  [12.705965 0.009927 0.517838 0.020520 4.344171] [12.705965 2.978215 5.178376 0.205204 4.344171] 2.10010027885 \n",
      "    Total time for epoch: 159.60766983s\n",
      "    ----------------\n",
      "    Code entropy: 1.9958457567\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2899.6221, 35.66357, 3.148]\n",
      "    SA1 (arg):    [3004.5352, 36.356441, 3.08]\n",
      "    SX383:        [1626.1952, 24.96092, 3.168]\n",
      "    SX383 (arg):  [1682.4309, 25.463747, 3.119]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5248.336915 40.442924 3.455200]\n",
      "        Train: (max)  [24515.585938 85.667305 3.946000]\n",
      "        Train: (min)  [514.484009 15.192568 2.788000]\n",
      "        Val:   (mean) [5743.065862 42.087525 3.635160]\n",
      "        Val:   (max)  [27706.132812 81.849770 4.099000]\n",
      "        Val:   (min)  [573.252502 12.876966 3.088000]\n",
      "    Best validation mean-PESQ seen: 3.6202\n",
      "    Total time for evaluation: 24.3638420105s\n",
      "Epoch 156:\n",
      "    101120:  [12.934429 0.009820 0.568743 0.019085 4.110185] [12.934429 2.945961 5.687432 0.190850 4.110185] 2.20010018349 \n",
      "    Total time for epoch: 161.330132008s\n",
      "    ----------------\n",
      "    Code entropy: 1.82183562392\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3015.8403, 36.506382, 3.161]\n",
      "    SA1 (arg):    [3130.6772, 37.247356, 3.128]\n",
      "    SX383:        [1603.6449, 25.164236, 3.215]\n",
      "    SX383 (arg):  [1675.1705, 25.666836, 3.169]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5753.293146 43.490589 3.490080]\n",
      "        Train: (max)  [26388.621094 104.143295 4.042000]\n",
      "        Train: (min)  [758.531799 16.347126 2.694000]\n",
      "        Val:   (mean) [5464.320593 42.247982 3.653200]\n",
      "        Val:   (max)  [26834.304688 85.991493 4.110000]\n",
      "        Val:   (min)  [1356.971313 22.026722 3.189000]\n",
      "    NEW best model! Validation mean-PESQ 3.6532\n",
      "    Saving model...\n",
      "    Total time for evaluation: 26.0422749519s\n",
      "Epoch 157:\n",
      "    101120:  [11.795986 0.007357 0.561931 0.018724 3.782293] [11.795986 2.207141 5.619309 0.187244 3.782293] 2.20010018349 \n",
      "    Total time for epoch: 161.598747015s\n",
      "    ----------------\n",
      "    Code entropy: 1.94570611279\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2876.6807, 35.445198, 3.225]\n",
      "    SA1 (arg):    [2979.9678, 36.095959, 3.161]\n",
      "    SX383:        [1539.1268, 24.346621, 3.284]\n",
      "    SX383 (arg):  [1587.97, 24.824972, 3.218]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6127.533733 43.359977 3.412140]\n",
      "        Train: (max)  [29415.195312 105.552872 3.922000]\n",
      "        Train: (min)  [552.197571 15.412259 2.883000]\n",
      "        Val:   (mean) [6255.444833 43.267112 3.594080]\n",
      "        Val:   (max)  [27305.761719 94.168083 4.096000]\n",
      "        Val:   (min)  [626.950806 15.929945 3.143000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.4158158302s\n",
      "Epoch 158:\n",
      "    101120:  [12.513264 0.008715 0.559547 0.020028 4.103036] [12.513264 2.614486 5.595466 0.200277 4.103036] 2.20010018349 \n",
      "    Total time for epoch: 162.707329035s\n",
      "    ----------------\n",
      "    Code entropy: 1.85704626817\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2781.8513, 34.968616, 3.235]\n",
      "    SA1 (arg):    [2891.8511, 35.737553, 3.169]\n",
      "    SX383:        [1524.9115, 24.310377, 3.194]\n",
      "    SX383 (arg):  [1579.265, 24.801226, 3.143]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5223.087665 41.414991 3.461600]\n",
      "        Train: (max)  [15994.064453 82.835892 3.934000]\n",
      "        Train: (min)  [725.726257 16.868145 2.612000]\n",
      "        Val:   (mean) [5026.883710 38.805977 3.652080]\n",
      "        Val:   (max)  [26740.414062 81.392784 4.047000]\n",
      "        Val:   (min)  [320.989929 10.462549 3.271000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.4609439373s\n",
      "Epoch 159:\n",
      "    101120:  [12.383420 0.008615 0.553811 0.019807 4.062781] [12.383420 2.584458 5.538115 0.198066 4.062781] 2.20010018349 \n",
      "    Total time for epoch: 161.046346903s\n",
      "    ----------------\n",
      "    Code entropy: 1.77786429753\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2965.2776, 35.921185, 3.135]\n",
      "    SA1 (arg):    [3064.593, 36.526894, 3.083]\n",
      "    SX383:        [1560.4045, 24.625591, 3.178]\n",
      "    SX383 (arg):  [1611.8396, 25.071983, 3.138]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5522.057310 41.893678 3.455540]\n",
      "        Train: (max)  [20576.570312 85.637886 3.949000]\n",
      "        Train: (min)  [1241.507935 21.743443 2.838000]\n",
      "        Val:   (mean) [5619.195647 41.802428 3.544900]\n",
      "        Val:   (max)  [26552.519531 77.983360 3.960000]\n",
      "        Val:   (min)  [324.515930 10.608171 2.971000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.5308880806s\n",
      "Epoch 160:\n",
      "    101120:  [12.455843 0.008930 0.539762 0.019667 4.182422] [12.455843 2.679136 5.397620 0.196666 4.182422] 2.20010018349 \n",
      "    Total time for epoch: 161.055161953s\n",
      "    ----------------\n",
      "    Code entropy: 1.90072430701\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2926.9319, 35.729645, 3.181]\n",
      "    SA1 (arg):    [3017.8591, 36.342495, 3.121]\n",
      "    SX383:        [1579.5322, 24.95183, 3.196]\n",
      "    SX383 (arg):  [1642.4932, 25.500313, 3.141]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5185.540725 39.532417 3.408640]\n",
      "        Train: (max)  [27374.554688 85.916679 4.008000]\n",
      "        Train: (min)  [851.476074 16.875048 2.657000]\n",
      "        Val:   (mean) [6266.622239 44.479422 3.529200]\n",
      "        Val:   (max)  [26942.494141 95.645935 3.934000]\n",
      "        Val:   (min)  [574.236084 13.003004 2.365000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.5058422089s\n",
      "Epoch 161:\n",
      "    101120:  [12.340754 0.008730 0.543632 0.019411 4.091259] [12.340754 2.619062 5.436323 0.194109 4.091259] 2.20010018349 \n",
      "    Total time for epoch: 156.170392036s\n",
      "    ----------------\n",
      "    Code entropy: 1.92555750768\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2953.7148, 35.861198, 3.126]\n",
      "    SA1 (arg):    [3047.6787, 36.45018, 3.063]\n",
      "    SX383:        [1699.4675, 25.528273, 3.084]\n",
      "    SX383 (arg):  [1753.2075, 26.01457, 3.046]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6205.877598 44.595259 3.366020]\n",
      "        Train: (max)  [23313.371094 88.766975 3.930000]\n",
      "        Train: (min)  [1156.027100 22.031397 2.683000]\n",
      "        Val:   (mean) [5388.740734 39.792895 3.506020]\n",
      "        Val:   (max)  [28270.814453 85.628342 4.067000]\n",
      "        Val:   (min)  [332.089478 10.695124 3.028000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.4386451244s\n",
      "Epoch 162:\n",
      "    101120:  [11.939651 0.008860 0.496904 0.019132 4.121193] [11.939651 2.658105 4.969037 0.191316 4.121193] 2.20010018349 \n",
      "    Total time for epoch: 161.373229027s\n",
      "    ----------------\n",
      "    Code entropy: 1.85876971805\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2991.292, 35.838436, 3.152]\n",
      "    SA1 (arg):    [3089.4827, 36.460854, 3.102]\n",
      "    SX383:        [1603.1611, 24.774479, 3.279]\n",
      "    SX383 (arg):  [1653.7385, 25.248156, 3.232]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5270.304547 41.619766 3.480940]\n",
      "        Train: (max)  [23313.042969 95.270508 4.060000]\n",
      "        Train: (min)  [909.554382 16.961731 2.906000]\n",
      "        Val:   (mean) [4829.551295 38.703653 3.606420]\n",
      "        Val:   (max)  [21332.236328 93.525269 3.989000]\n",
      "        Val:   (min)  [331.017120 10.645412 3.188000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 23.9420771599s\n",
      "Epoch 163:\n",
      "    101120:  [13.121019 0.010036 0.576488 0.019607 4.149297] [13.121019 3.010770 5.764880 0.196073 4.149297] 2.20010018349 \n",
      "    Total time for epoch: 161.318105936s\n",
      "    ----------------\n",
      "    Code entropy: 1.78850224143\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3249.3992, 37.458618, 3.22]\n",
      "    SA1 (arg):    [3372.1807, 38.247581, 3.156]\n",
      "    SX383:        [1656.4341, 25.238264, 3.194]\n",
      "    SX383 (arg):  [1708.8961, 25.692719, 3.146]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5031.283159 40.447898 3.449080]\n",
      "        Train: (max)  [26310.917969 104.366173 3.972000]\n",
      "        Train: (min)  [586.393555 15.887921 2.946000]\n",
      "        Val:   (mean) [5289.438124 41.447285 3.532220]\n",
      "        Val:   (max)  [20076.046875 85.949570 3.928000]\n",
      "        Val:   (min)  [347.497650 10.775570 2.980000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.5854351521s\n",
      "Epoch 164:\n",
      "    101120:  [12.186348 0.008349 0.561070 0.019475 3.876195] [12.186348 2.504700 5.610704 0.194747 3.876195] 2.20010018349 \n",
      "    Total time for epoch: 160.375204086s\n",
      "    ----------------\n",
      "    Code entropy: 1.81962838676\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3059.595, 36.593796, 3.061]\n",
      "    SA1 (arg):    [3152.6033, 37.184818, 3.017]\n",
      "    SX383:        [1746.2117, 25.504435, 3.125]\n",
      "    SX383 (arg):  [1806.8322, 26.031908, 3.088]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4659.781855 39.439702 3.398080]\n",
      "        Train: (max)  [16661.115234 84.309784 4.271000]\n",
      "        Train: (min)  [778.657715 16.632689 2.719000]\n",
      "        Val:   (mean) [5630.280343 42.620231 3.505540]\n",
      "        Val:   (max)  [19439.242188 85.534111 4.093000]\n",
      "        Val:   (min)  [712.512695 15.783786 2.293000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.1179292202s\n",
      "Epoch 165:\n",
      "    101120:  [12.442372 0.009035 0.546107 0.019774 4.073108] [12.442372 2.710457 5.461071 0.197737 4.073108] 2.20010018349 \n",
      "    Total time for epoch: 161.787616014s\n",
      "    ----------------\n",
      "    Code entropy: 1.85612083483\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2926.5383, 35.889538, 3.204]\n",
      "    SA1 (arg):    [3018.3865, 36.459568, 3.162]\n",
      "    SX383:        [1765.5869, 25.513832, 3.102]\n",
      "    SX383 (arg):  [1817.469, 26.000486, 3.067]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4921.162308 40.738106 3.520940]\n",
      "        Train: (max)  [12211.106445 66.743294 4.069000]\n",
      "        Train: (min)  [745.264771 17.765160 2.919000]\n",
      "        Val:   (mean) [6092.791980 43.135594 3.591760]\n",
      "        Val:   (max)  [27612.031250 95.385895 4.063000]\n",
      "        Val:   (min)  [584.755127 13.129839 3.034000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.6344301701s\n",
      "Epoch 166:\n",
      "    101120:  [12.563202 0.009241 0.565092 0.018585 3.954031] [12.563202 2.772403 5.650918 0.185849 3.954031] 2.20010018349 \n",
      "    Total time for epoch: 161.30883503s\n",
      "    ----------------\n",
      "    Code entropy: 1.83902018714\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3239.865, 37.318703, 3.08]\n",
      "    SA1 (arg):    [3328.4858, 37.938122, 3.034]\n",
      "    SX383:        [1693.6488, 25.38868, 3.18]\n",
      "    SX383 (arg):  [1750.9363, 25.861675, 3.138]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5337.730210 40.732263 3.352460]\n",
      "        Train: (max)  [26391.312500 89.081139 3.982000]\n",
      "        Train: (min)  [740.811707 15.652740 2.715000]\n",
      "        Val:   (mean) [6295.541484 43.956338 3.560100]\n",
      "        Val:   (max)  [28959.712891 98.001602 4.044000]\n",
      "        Val:   (min)  [345.630615 10.864838 2.927000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.4592828751s\n",
      "Epoch 167:\n",
      "    101120:  [12.482853 0.009056 0.549919 0.019264 4.074167] [12.482853 2.716859 5.499190 0.192636 4.074167] 2.20010018349 \n",
      "    Total time for epoch: 161.041428804s\n",
      "    ----------------\n",
      "    Code entropy: 1.82894883395\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3166.6943, 37.077175, 3.107]\n",
      "    SA1 (arg):    [3272.3379, 37.747025, 3.038]\n",
      "    SX383:        [1625.5116, 25.02437, 3.131]\n",
      "    SX383 (arg):  [1677.4847, 25.493912, 3.093]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6144.459462 42.503209 3.328740]\n",
      "        Train: (max)  [29511.857422 102.161011 3.856000]\n",
      "        Train: (min)  [733.137085 16.696236 2.819000]\n",
      "        Val:   (mean) [4819.418800 38.980501 3.586280]\n",
      "        Val:   (max)  [26979.257812 78.700912 4.142000]\n",
      "        Val:   (min)  [498.607666 13.065657 2.655000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.4255139828s\n",
      "Epoch 168:\n",
      "    101120:  [12.366756 0.009008 0.568345 0.018294 3.797897] [12.366756 2.702465 5.683451 0.182944 3.797897] 2.20010018349 \n",
      "    Total time for epoch: 161.565574884s\n",
      "    ----------------\n",
      "    Code entropy: 1.75677709547\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3028.6494, 36.429695, 3.112]\n",
      "    SA1 (arg):    [3117.8579, 37.008881, 3.057]\n",
      "    SX383:        [1750.9766, 25.470589, 3.203]\n",
      "    SX383 (arg):  [1799.3789, 25.916615, 3.151]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6672.067778 44.715154 3.341360]\n",
      "        Train: (max)  [30597.734375 84.744507 3.922000]\n",
      "        Train: (min)  [828.383484 15.327404 2.504000]\n",
      "        Val:   (mean) [5766.028628 42.690973 3.544300]\n",
      "        Val:   (max)  [22795.753906 95.605263 3.937000]\n",
      "        Val:   (min)  [506.781250 13.300432 2.900000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.3161489964s\n",
      "Epoch 169:\n",
      "    101120:  [12.387416 0.009672 0.517131 0.019919 4.115377] [12.387416 2.901539 5.171306 0.199194 4.115377] 2.10010027885 \n",
      "    Total time for epoch: 161.928042889s\n",
      "    ----------------\n",
      "    Code entropy: 2.06312313431\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2865.6348, 35.082867, 3.25]\n",
      "    SA1 (arg):    [2950.9482, 35.706165, 3.205]\n",
      "    SX383:        [1547.1295, 24.239035, 3.281]\n",
      "    SX383 (arg):  [1604.2115, 24.702572, 3.23]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5019.043162 39.126171 3.540360]\n",
      "        Train: (max)  [33906.476562 118.100494 4.088000]\n",
      "        Train: (min)  [634.376892 16.783518 2.718000]\n",
      "        Val:   (mean) [5573.218325 41.347971 3.665960]\n",
      "        Val:   (max)  [25659.603516 92.025337 4.086000]\n",
      "        Val:   (min)  [456.716370 13.162833 3.313000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.2436311245s\n",
      "Epoch 170:\n",
      "    101120:  [11.905643 0.008331 0.515115 0.019445 4.060817] [11.905643 2.499226 5.151150 0.194449 4.060817] 2.20010018349 \n",
      "    Total time for epoch: 159.274909973s\n",
      "    ----------------\n",
      "    Code entropy: 1.79323882359\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3021.458, 36.208469, 3.066]\n",
      "    SA1 (arg):    [3133.2266, 36.879528, 3.002]\n",
      "    SX383:        [1602.5817, 25.296064, 3.234]\n",
      "    SX383 (arg):  [1666.4778, 25.849926, 3.194]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5861.610663 43.065924 3.454160]\n",
      "        Train: (max)  [24781.287109 101.843620 4.018000]\n",
      "        Train: (min)  [769.052490 17.796907 2.806000]\n",
      "        Val:   (mean) [5472.047811 42.239967 3.603160]\n",
      "        Val:   (max)  [18733.710938 84.528748 4.071000]\n",
      "        Val:   (min)  [333.376892 10.706677 2.632000]\n",
      "    Best validation mean-PESQ seen: 3.6532\n",
      "    Total time for evaluation: 24.3226709366s\n",
      "Epoch 171:\n",
      "    101120:  [12.719048 0.009513 0.551714 0.019073 4.157193] [12.719048 2.853979 5.517143 0.190733 4.157193] 2.20010018349 \n",
      "    Total time for epoch: 160.134891033s\n",
      "    ----------------\n",
      "    Code entropy: 1.85944280377\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2899.23, 35.420731, 3.205]\n",
      "    SA1 (arg):    [2987.5708, 36.023968, 3.133]\n",
      "    SX383:        [1594.6112, 24.775356, 3.305]\n",
      "    SX383 (arg):  [1647.5258, 25.301699, 3.249]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4007.041252 35.473750 3.506500]\n",
      "        Train: (max)  [18869.394531 81.669586 3.932000]\n",
      "        Train: (min)  [623.819885 16.194099 2.937000]\n",
      "        Val:   (mean) [4909.990611 39.932271 3.656940]\n",
      "        Val:   (max)  [18895.449219 82.722511 4.008000]\n",
      "        Val:   (min)  [494.508148 13.637066 2.385000]\n",
      "    NEW best model! Validation mean-PESQ 3.65694\n",
      "    Saving model...\n",
      "    Total time for evaluation: 24.5422530174s\n",
      "Epoch 172:\n",
      "    101120:  [12.678074 0.009319 0.568599 0.019190 4.004396] [12.678074 2.795791 5.685992 0.191896 4.004396] 2.20010018349 \n",
      "    Total time for epoch: 160.17462492s\n",
      "    ----------------\n",
      "    Code entropy: 1.76053132045\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2987.3833, 36.064331, 3.211]\n",
      "    SA1 (arg):    [3092.2605, 36.74461, 3.161]\n",
      "    SX383:        [1645.9855, 25.035275, 3.175]\n",
      "    SX383 (arg):  [1703.3462, 25.504927, 3.124]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5646.476714 42.262844 3.446440]\n",
      "        Train: (max)  [24354.042969 96.368538 4.074000]\n",
      "        Train: (min)  [633.213379 16.284210 2.743000]\n",
      "        Val:   (mean) [5618.260259 42.257031 3.624020]\n",
      "        Val:   (max)  [22552.947266 95.779228 4.002000]\n",
      "        Val:   (min)  [573.845459 12.958467 3.165000]\n",
      "    Best validation mean-PESQ seen: 3.65694\n",
      "    Total time for evaluation: 24.7613730431s\n",
      "Epoch 173:\n",
      "    101120:  [11.854010 0.008277 0.525546 0.018515 3.930365] [11.854010 2.483042 5.255456 0.185147 3.930365] 2.10010027885 \n",
      "    Total time for epoch: 159.971531868s\n",
      "    ----------------\n",
      "    Code entropy: 1.94903208989\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2813.3123, 34.817303, 3.353]\n",
      "    SA1 (arg):    [2890.3965, 35.32597, 3.3]\n",
      "    SX383:        [1664.0657, 24.650288, 3.341]\n",
      "    SX383 (arg):  [1703.7139, 24.985853, 3.315]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5419.473083 41.871437 3.552600]\n",
      "        Train: (max)  [22333.939453 89.877037 4.098000]\n",
      "        Train: (min)  [1329.791504 20.735815 2.954000]\n",
      "        Val:   (mean) [4761.820153 38.501438 3.703080]\n",
      "        Val:   (max)  [13492.386719 75.407715 4.126000]\n",
      "        Val:   (min)  [469.065308 12.830674 3.175000]\n",
      "    Best validation mean-PESQ seen: 3.65694\n",
      "    Total time for evaluation: 24.3858201504s\n",
      "Epoch 174:\n",
      "    101120:  [12.462009 0.009656 0.523526 0.019216 4.137726] [12.462009 2.896861 5.235259 0.192163 4.137726] 2.10010027885 \n",
      "    Total time for epoch: 159.938973904s\n",
      "    ----------------\n",
      "    Code entropy: 1.86094933279\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2884.6836, 35.487549, 3.247]\n",
      "    SA1 (arg):    [2986.7429, 36.098183, 3.198]\n",
      "    SX383:        [1565.1195, 24.579393, 3.271]\n",
      "    SX383 (arg):  [1610.6515, 25.012272, 3.216]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5651.476272 42.487137 3.485200]\n",
      "        Train: (max)  [17504.943359 82.117889 4.079000]\n",
      "        Train: (min)  [710.677612 16.920153 2.594000]\n",
      "        Val:   (mean) [4871.076863 38.790415 3.702220]\n",
      "        Val:   (max)  [22135.263672 94.169594 4.066000]\n",
      "        Val:   (min)  [341.438843 10.625067 2.478000]\n",
      "    NEW best model! Validation mean-PESQ 3.70222\n",
      "    Saving model...\n",
      "    Total time for evaluation: 24.743710041s\n",
      "Epoch 175:\n",
      "    101120:  [12.148628 0.009191 0.504267 0.019515 4.153370] [12.148628 2.757437 5.042671 0.195150 4.153370] 2.10010027885 \n",
      "    Total time for epoch: 159.83476305s\n",
      "    ----------------\n",
      "    Code entropy: 1.9702545633\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2860.5754, 35.143551, 3.221]\n",
      "    SA1 (arg):    [2961.0305, 35.750301, 3.17]\n",
      "    SX383:        [1647.4948, 24.847464, 3.242]\n",
      "    SX383 (arg):  [1692.8213, 25.25209, 3.197]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4944.558916 40.627563 3.494920]\n",
      "        Train: (max)  [25534.904297 101.987434 4.121000]\n",
      "        Train: (min)  [452.006805 14.255522 2.790000]\n",
      "        Val:   (mean) [4568.239377 37.777570 3.638940]\n",
      "        Val:   (max)  [17371.478516 80.098595 3.982000]\n",
      "        Val:   (min)  [319.229523 10.391778 3.022000]\n",
      "    Best validation mean-PESQ seen: 3.70222\n",
      "    Total time for evaluation: 24.666795969s\n",
      "Epoch 176:\n",
      "    101120:  [13.851622 0.010919 0.636020 0.018890 4.026819] [13.851622 3.275704 6.360202 0.188897 4.026819] 2.10010027885 \n",
      "    Total time for epoch: 159.62329483s\n",
      "    ----------------\n",
      "    Code entropy: 1.77043350808\n",
      "    Updated tau from 2.10010027885 to 2.00010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4057.2273, 41.128506, 2.699]\n",
      "    SA1 (arg):    [4159.9399, 41.744316, 2.664]\n",
      "    SX383:        [2541.6917, 28.55439, 3.098]\n",
      "    SX383 (arg):  [2588.5439, 28.936739, 3.054]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [9200.996326 47.194807 3.007140]\n",
      "        Train: (max)  [45602.535156 103.551514 3.749000]\n",
      "        Train: (min)  [1264.368774 21.551022 2.255000]\n",
      "        Val:   (mean) [7979.786761 47.746972 3.236920]\n",
      "        Val:   (max)  [30104.970703 95.097969 3.702000]\n",
      "        Val:   (min)  [606.998474 14.718184 2.610000]\n",
      "    Best validation mean-PESQ seen: 3.70222\n",
      "    Total time for evaluation: 24.5185341835s\n",
      "Epoch 177:\n",
      "    101120:  [11.684679 0.007415 0.549556 0.019177 3.772796] [11.684679 2.224557 5.495559 0.191767 3.772796] 2.00010037422 \n",
      "    Total time for epoch: 156.369853973s\n",
      "    ----------------\n",
      "    Code entropy: 1.84575085601\n",
      "    Tau stays at 2.00010037422\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2818.9202, 34.848244, 3.271]\n",
      "    SA1 (arg):    [2926.9092, 35.526699, 3.225]\n",
      "    SX383:        [1583.0022, 24.571577, 3.26]\n",
      "    SX383 (arg):  [1636.7917, 25.072781, 3.204]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4477.774158 38.235252 3.541160]\n",
      "        Train: (max)  [16904.998047 79.239372 4.198000]\n",
      "        Train: (min)  [798.284058 17.341885 2.954000]\n",
      "        Val:   (mean) [5215.834812 39.976990 3.710300]\n",
      "        Val:   (max)  [25893.660156 80.301552 4.133000]\n",
      "        Val:   (min)  [300.091675 10.171950 3.095000]\n",
      "    NEW best model! Validation mean-PESQ 3.7103\n",
      "    Saving model...\n",
      "    Total time for evaluation: 24.2654540539s\n",
      "Epoch 178:\n",
      "    101120:  [12.087525 0.009291 0.508301 0.019329 4.023911] [12.087525 2.787316 5.083013 0.193286 4.023911] 2.00010037422 \n",
      "    Total time for epoch: 161.18986392s\n",
      "    ----------------\n",
      "    Code entropy: 2.00076002172\n",
      "    Updated tau from 2.00010037422 to 2.10010037422\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2701.3772, 34.141945, 3.181]\n",
      "    SA1 (arg):    [2781.1558, 34.686707, 3.122]\n",
      "    SX383:        [1594.5546, 24.157633, 3.3]\n",
      "    SX383 (arg):  [1645.7474, 24.624262, 3.233]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5033.101509 37.713422 3.510560]\n",
      "        Train: (max)  [35982.578125 87.775368 4.095000]\n",
      "        Train: (min)  [727.215637 16.586796 2.617000]\n",
      "        Val:   (mean) [4725.074868 38.576341 3.700600]\n",
      "        Val:   (max)  [16931.775391 79.601021 4.001000]\n",
      "        Val:   (min)  [302.723572 10.164395 3.187000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.9360501766s\n",
      "Epoch 179:\n",
      "    101120:  [12.220652 0.009200 0.527812 0.018916 3.993457] [12.220652 2.759912 5.278124 0.189159 3.993457] 2.10010027885 \n",
      "    Total time for epoch: 157.001394033s\n",
      "    ----------------\n",
      "    Code entropy: 1.92659155643\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2981.8792, 35.579384, 3.19]\n",
      "    SA1 (arg):    [3077.5078, 36.235653, 3.152]\n",
      "    SX383:        [1682.661, 25.225197, 3.2]\n",
      "    SX383 (arg):  [1740.0269, 25.710178, 3.145]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5213.507401 41.627269 3.563960]\n",
      "        Train: (max)  [21440.279297 98.675179 4.098000]\n",
      "        Train: (min)  [554.315063 13.487106 2.893000]\n",
      "        Val:   (mean) [5972.573364 43.180812 3.678940]\n",
      "        Val:   (max)  [27338.814453 85.125305 4.231000]\n",
      "        Val:   (min)  [469.302368 13.175061 3.267000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.0239698887s\n",
      "Epoch 180:\n",
      "    101120:  [12.400342 0.009099 0.541578 0.019483 4.060069] [12.400342 2.729665 5.415776 0.194832 4.060069] 2.10010027885 \n",
      "    Total time for epoch: 157.099372149s\n",
      "    ----------------\n",
      "    Code entropy: 1.81106452386\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2848.7002, 34.879128, 3.293]\n",
      "    SA1 (arg):    [2935.1099, 35.51342, 3.248]\n",
      "    SX383:        [1576.505, 24.344173, 3.285]\n",
      "    SX383 (arg):  [1641.1857, 24.919987, 3.217]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5702.023488 42.068394 3.553760]\n",
      "        Train: (max)  [22706.656250 89.624214 4.139000]\n",
      "        Train: (min)  [555.140320 15.359701 2.990000]\n",
      "        Val:   (mean) [5412.962655 41.773994 3.629580]\n",
      "        Val:   (max)  [20575.074219 91.258453 4.039000]\n",
      "        Val:   (min)  [553.115784 12.628086 2.537000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.210777998s\n",
      "Epoch 181:\n",
      "    101120:  [12.086040 0.008408 0.530016 0.019922 4.064262] [12.086040 2.522395 5.300165 0.199219 4.064262] 2.10010027885 \n",
      "    Total time for epoch: 158.725129843s\n",
      "    ----------------\n",
      "    Code entropy: 1.979477822\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2831.7332, 35.300682, 3.202]\n",
      "    SA1 (arg):    [2929.054, 35.941772, 3.17]\n",
      "    SX383:        [1555.2159, 24.482267, 3.242]\n",
      "    SX383 (arg):  [1609.2864, 24.968971, 3.198]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4729.120408 38.687659 3.458860]\n",
      "        Train: (max)  [16579.992188 80.353439 4.009000]\n",
      "        Train: (min)  [582.352783 15.094781 2.850000]\n",
      "        Val:   (mean) [5314.503267 40.153820 3.605840]\n",
      "        Val:   (max)  [28431.068359 79.138893 4.200000]\n",
      "        Val:   (min)  [317.084686 10.412849 3.149000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 25.0295958519s\n",
      "Epoch 182:\n",
      "    101120:  [12.919348 0.009905 0.520695 0.019152 4.549331] [12.919348 2.971541 5.206952 0.191524 4.549331] 2.20010018349 \n",
      "    Total time for epoch: 162.87012291s\n",
      "    ----------------\n",
      "    Code entropy: 1.94545164758\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2838.7507, 35.053894, 3.263]\n",
      "    SA1 (arg):    [2948.2764, 35.694, 3.186]\n",
      "    SX383:        [1525.7576, 24.172462, 3.316]\n",
      "    SX383 (arg):  [1577.8344, 24.64776, 3.274]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4641.293937 38.992535 3.564920]\n",
      "        Train: (max)  [17239.923828 80.069664 4.042000]\n",
      "        Train: (min)  [827.004761 17.007862 3.037000]\n",
      "        Val:   (mean) [4245.746981 36.806037 3.711260]\n",
      "        Val:   (max)  [12734.707031 72.891975 4.189000]\n",
      "        Val:   (min)  [309.288116 10.159324 3.164000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.6394920349s\n",
      "Epoch 183:\n",
      "    101120:  [12.168116 0.009149 0.539745 0.018329 3.842728] [12.168116 2.744650 5.397453 0.183285 3.842728] 2.20010018349 \n",
      "    Total time for epoch: 160.102518082s\n",
      "    ----------------\n",
      "    Code entropy: 1.8272079041\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3070.9888, 36.638069, 3.174]\n",
      "    SA1 (arg):    [3182.5479, 37.407131, 3.118]\n",
      "    SX383:        [1651.6943, 25.284504, 3.182]\n",
      "    SX383 (arg):  [1699.125, 25.714951, 3.132]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4801.262128 39.435930 3.514440]\n",
      "        Train: (max)  [21303.792969 99.206078 4.005000]\n",
      "        Train: (min)  [614.258484 16.090666 2.971000]\n",
      "        Val:   (mean) [4892.850962 40.233631 3.632680]\n",
      "        Val:   (max)  [17816.689453 84.703064 4.144000]\n",
      "        Val:   (min)  [571.826904 12.960957 2.450000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.7471091747s\n",
      "Epoch 184:\n",
      "    101120:  [12.382169 0.008317 0.564999 0.018836 4.048675] [12.382169 2.495142 5.649993 0.188360 4.048675] 2.20010018349 \n",
      "    Total time for epoch: 159.192332029s\n",
      "    ----------------\n",
      "    Code entropy: 1.88963857875\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2854.4958, 35.378807, 3.111]\n",
      "    SA1 (arg):    [2982.5754, 36.151485, 3.05]\n",
      "    SX383:        [1614.6465, 24.92362, 3.143]\n",
      "    SX383 (arg):  [1667.8688, 25.427393, 3.079]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5012.580065 39.583935 3.298100]\n",
      "        Train: (max)  [19955.347656 74.296234 3.955000]\n",
      "        Train: (min)  [555.160583 13.581958 2.713000]\n",
      "        Val:   (mean) [5530.145889 41.650543 3.485640]\n",
      "        Val:   (max)  [18604.894531 84.427437 4.082000]\n",
      "        Val:   (min)  [318.157745 10.466972 2.989000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.4390180111s\n",
      "Epoch 185:\n",
      "    101120:  [12.013493 0.008726 0.516584 0.018821 4.041659] [12.013493 2.617775 5.165843 0.188214 4.041659] 2.20010018349 \n",
      "    Total time for epoch: 161.073214054s\n",
      "    ----------------\n",
      "    Code entropy: 1.81112712009\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3128.5127, 37.191021, 3.086]\n",
      "    SA1 (arg):    [3236.3452, 37.79557, 3.036]\n",
      "    SX383:        [1847.1268, 26.690369, 3.109]\n",
      "    SX383 (arg):  [1903.5326, 27.167591, 3.066]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5595.608126 41.836808 3.386320]\n",
      "        Train: (max)  [26681.478516 93.940598 3.892000]\n",
      "        Train: (min)  [798.884705 17.427725 2.568000]\n",
      "        Val:   (mean) [5935.248842 43.407532 3.506420]\n",
      "        Val:   (max)  [19047.644531 87.189667 3.929000]\n",
      "        Val:   (min)  [523.599915 13.434360 2.925000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.6742019653s\n",
      "Epoch 186:\n",
      "    101120:  [12.200558 0.008736 0.536725 0.018560 4.026849] [12.200558 2.620864 5.367248 0.185597 4.026849] 2.20010018349 \n",
      "    Total time for epoch: 157.241353989s\n",
      "    ----------------\n",
      "    Code entropy: 1.82640427956\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3133.8486, 36.521484, 3.116]\n",
      "    SA1 (arg):    [3224.1238, 37.140881, 3.079]\n",
      "    SX383:        [1650.8218, 25.320349, 3.177]\n",
      "    SX383 (arg):  [1702.3895, 25.765379, 3.135]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6263.293193 43.970698 3.418680]\n",
      "        Train: (max)  [25761.734375 90.051666 4.013000]\n",
      "        Train: (min)  [600.293457 15.909966 2.756000]\n",
      "        Val:   (mean) [4794.986641 38.737231 3.535920]\n",
      "        Val:   (max)  [22657.318359 95.210808 3.989000]\n",
      "        Val:   (min)  [339.129089 10.626847 3.018000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.5669131279s\n",
      "Epoch 187:\n",
      "    101120:  [11.437946 0.007930 0.505756 0.017532 3.825953] [11.437946 2.379113 5.057565 0.175317 3.825953] 2.20010018349 \n",
      "    Total time for epoch: 157.438594103s\n",
      "    ----------------\n",
      "    Code entropy: 1.88483794066\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2989.0242, 36.003998, 3.138]\n",
      "    SA1 (arg):    [3083.5913, 36.598621, 3.075]\n",
      "    SX383:        [1648.4878, 24.861795, 3.216]\n",
      "    SX383 (arg):  [1690.4556, 25.272657, 3.177]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4008.491866 36.106747 3.398600]\n",
      "        Train: (max)  [18089.398438 82.970741 3.930000]\n",
      "        Train: (min)  [585.368530 15.625430 2.881000]\n",
      "        Val:   (mean) [6586.497698 45.382761 3.480760]\n",
      "        Val:   (max)  [19142.576172 83.998741 4.062000]\n",
      "        Val:   (min)  [323.520020 10.434978 2.961000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.5167701244s\n",
      "Epoch 188:\n",
      "    101120:  [12.603487 0.009238 0.545531 0.018782 4.189062] [12.603487 2.771304 5.455306 0.187816 4.189062] 2.20010018349 \n",
      "    Total time for epoch: 157.773427963s\n",
      "    ----------------\n",
      "    Code entropy: 1.88078795097\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2878.9788, 34.858185, 3.292]\n",
      "    SA1 (arg):    [2965.8728, 35.416519, 3.235]\n",
      "    SX383:        [1652.1445, 24.760378, 3.308]\n",
      "    SX383 (arg):  [1696.2231, 25.161314, 3.255]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6944.647437 46.373891 3.486860]\n",
      "        Train: (max)  [30223.523438 105.728867 4.143000]\n",
      "        Train: (min)  [809.859985 16.240934 2.657000]\n",
      "        Val:   (mean) [6100.656328 42.980823 3.650140]\n",
      "        Val:   (max)  [26054.597656 91.361176 4.037000]\n",
      "        Val:   (min)  [313.121887 10.348394 3.149000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.459841013s\n",
      "Epoch 189:\n",
      "    101120:  [12.839471 0.009851 0.559046 0.019058 4.103198] [12.839471 2.955234 5.590458 0.190580 4.103198] 2.20010018349 \n",
      "    Total time for epoch: 159.416778803s\n",
      "    ----------------\n",
      "    Code entropy: 1.79925815666\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3068.8074, 36.414326, 3.094]\n",
      "    SA1 (arg):    [3167.6147, 37.002666, 3.068]\n",
      "    SX383:        [1638.2817, 25.337477, 3.166]\n",
      "    SX383 (arg):  [1693.1467, 25.793476, 3.114]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5717.012755 41.148378 3.398820]\n",
      "        Train: (max)  [25301.671875 96.498421 3.902000]\n",
      "        Train: (min)  [595.662231 15.771470 2.702000]\n",
      "        Val:   (mean) [5409.530798 41.800660 3.580260]\n",
      "        Val:   (max)  [18954.058594 83.087128 3.955000]\n",
      "        Val:   (min)  [487.957520 13.642223 3.156000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.4355919361s\n",
      "Epoch 190:\n",
      "    101120:  [12.419195 0.009123 0.533773 0.019559 4.149068] [12.419195 2.736809 5.337729 0.195588 4.149068] 2.20010018349 \n",
      "    Total time for epoch: 157.969391108s\n",
      "    ----------------\n",
      "    Code entropy: 1.87880850386\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2806.259, 34.922459, 3.26]\n",
      "    SA1 (arg):    [2884.3279, 35.462807, 3.195]\n",
      "    SX383:        [1609.8788, 24.52331, 3.224]\n",
      "    SX383 (arg):  [1659.3619, 24.99972, 3.176]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5531.010785 41.916908 3.506100]\n",
      "        Train: (max)  [27359.544922 102.045959 4.114000]\n",
      "        Train: (min)  [703.405823 16.631079 2.793000]\n",
      "        Val:   (mean) [5843.612158 41.903517 3.686260]\n",
      "        Val:   (max)  [27605.962891 91.112663 4.094000]\n",
      "        Val:   (min)  [309.014069 10.281630 3.097000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.193600893s\n",
      "Epoch 191:\n",
      "    101120:  [12.347387 0.008855 0.531626 0.018615 4.188413] [12.347387 2.656566 5.316257 0.186151 4.188413] 2.20010018349 \n",
      "    Total time for epoch: 159.600772858s\n",
      "    ----------------\n",
      "    Code entropy: 1.92031698016\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2778.1648, 34.715923, 3.328]\n",
      "    SA1 (arg):    [2871.9319, 35.380272, 3.261]\n",
      "    SX383:        [1513.9746, 24.093006, 3.449]\n",
      "    SX383 (arg):  [1562.5383, 24.535809, 3.385]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5817.977495 44.212417 3.548500]\n",
      "        Train: (max)  [23559.931641 88.173843 4.084000]\n",
      "        Train: (min)  [706.406799 17.302279 2.870000]\n",
      "        Val:   (mean) [5234.853427 39.770824 3.732560]\n",
      "        Val:   (max)  [25901.384766 91.678383 4.098000]\n",
      "        Val:   (min)  [320.378845 10.450176 3.254000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.3513610363s\n",
      "Epoch 192:\n",
      "    101120:  [12.321972 0.008807 0.549167 0.017972 4.008554] [12.321972 2.642030 5.491669 0.179719 4.008554] 2.20010018349 \n",
      "    Total time for epoch: 158.276619911s\n",
      "    ----------------\n",
      "    Code entropy: 1.76681858355\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3064.499, 36.267284, 3.252]\n",
      "    SA1 (arg):    [3147.4138, 36.822601, 3.183]\n",
      "    SX383:        [1660.8263, 25.583721, 3.156]\n",
      "    SX383 (arg):  [1700.301, 25.952782, 3.117]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5076.969958 40.016300 3.461720]\n",
      "        Train: (max)  [22303.005859 86.761185 3.921000]\n",
      "        Train: (min)  [756.819153 17.100939 2.908000]\n",
      "        Val:   (mean) [6014.303676 43.353951 3.634000]\n",
      "        Val:   (max)  [28342.886719 84.993004 4.052000]\n",
      "        Val:   (min)  [494.028839 13.547905 3.173000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.3719468117s\n",
      "Epoch 193:\n",
      "    101120:  [12.044765 0.008167 0.543704 0.019026 3.967311] [12.044765 2.450155 5.437043 0.190257 3.967311] 2.10010027885 \n",
      "    Total time for epoch: 157.732945919s\n",
      "    ----------------\n",
      "    Code entropy: 1.96550758546\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2817.2815, 34.914017, 3.194]\n",
      "    SA1 (arg):    [2895.9785, 35.46981, 3.145]\n",
      "    SX383:        [1525.6331, 24.395693, 3.255]\n",
      "    SX383 (arg):  [1577.3386, 24.825993, 3.224]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [4989.192317 41.594959 3.513820]\n",
      "        Train: (max)  [15765.392578 75.542442 4.185000]\n",
      "        Train: (min)  [975.060669 20.584692 2.807000]\n",
      "        Val:   (mean) [5721.153380 41.552565 3.655800]\n",
      "        Val:   (max)  [27661.388672 91.999260 4.105000]\n",
      "        Val:   (min)  [320.795898 10.415436 2.986000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.2841210365s\n",
      "Epoch 194:\n",
      "    101120:  [12.109343 0.008729 0.540687 0.018762 3.896013] [12.109343 2.618836 5.406868 0.187625 3.896013] 2.10010027885 \n",
      "    Total time for epoch: 159.993816853s\n",
      "    ----------------\n",
      "    Code entropy: 1.81665931314\n",
      "    Tau stays at 2.10010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2936.6829, 35.629936, 3.209]\n",
      "    SA1 (arg):    [3026.4038, 36.207672, 3.151]\n",
      "    SX383:        [1619.5483, 24.997585, 3.148]\n",
      "    SX383 (arg):  [1673.0928, 25.480824, 3.091]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6325.221544 44.306409 3.476580]\n",
      "        Train: (max)  [37321.226562 117.435944 4.073000]\n",
      "        Train: (min)  [866.414246 19.447460 2.765000]\n",
      "        Val:   (mean) [5940.066172 44.351829 3.640360]\n",
      "        Val:   (max)  [21342.658203 93.095779 4.082000]\n",
      "        Val:   (min)  [321.237213 10.588469 2.970000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.1727020741s\n",
      "Epoch 195:\n",
      "    101120:  [12.301874 0.008778 0.537748 0.018717 4.103686] [12.301874 2.633536 5.377484 0.187168 4.103686] 2.10010027885 \n",
      "    Total time for epoch: 159.704672813s\n",
      "    ----------------\n",
      "    Code entropy: 1.9752200674\n",
      "    Updated tau from 2.10010027885 to 2.20010027885\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2915.5425, 35.514782, 3.203]\n",
      "    SA1 (arg):    [2994.1184, 36.065525, 3.149]\n",
      "    SX383:        [1672.6665, 24.838585, 3.272]\n",
      "    SX383 (arg):  [1723.5963, 25.243885, 3.21]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5425.298007 41.944821 3.460660]\n",
      "        Train: (max)  [22855.912109 87.894783 3.949000]\n",
      "        Train: (min)  [840.829712 16.818481 1.872000]\n",
      "        Val:   (mean) [5756.745708 41.319995 3.626780]\n",
      "        Val:   (max)  [30122.679688 82.090576 4.097000]\n",
      "        Val:   (min)  [668.546570 15.356240 3.180000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 23.9167439938s\n",
      "Epoch 196:\n",
      "    101120:  [12.605491 0.009108 0.568545 0.018636 4.001233] [12.605491 2.732456 5.685445 0.186356 4.001233] 2.20010018349 \n",
      "    Total time for epoch: 157.939872026s\n",
      "    ----------------\n",
      "    Code entropy: 1.83515764557\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3028.8516, 35.904507, 3.198]\n",
      "    SA1 (arg):    [3108.5854, 36.450459, 3.16]\n",
      "    SX383:        [1664.8784, 24.980766, 3.262]\n",
      "    SX383 (arg):  [1718.2095, 25.482929, 3.195]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5915.016959 43.907555 3.482300]\n",
      "        Train: (max)  [31671.529297 116.308846 4.028000]\n",
      "        Train: (min)  [667.245483 14.590426 2.674000]\n",
      "        Val:   (mean) [5884.457817 43.056001 3.607700]\n",
      "        Val:   (max)  [26412.277344 85.314537 3.936000]\n",
      "        Val:   (min)  [594.555542 13.132705 3.053000]\n",
      "    Best validation mean-PESQ seen: 3.7103\n",
      "    Total time for evaluation: 24.2771630287s\n",
      "Epoch 197:\n",
      "    101120:  [12.277750 0.008645 0.556571 0.018414 3.934510] [12.277750 2.593390 5.565713 0.184138 3.934510] 2.20010018349 \n",
      "    Total time for epoch: 158.363986015s\n",
      "    ----------------\n",
      "    Code entropy: 1.77975626704\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3007.3855, 36.19585, 3.208]\n",
      "    SA1 (arg):    [3115.1624, 36.908466, 3.152]\n",
      "    SX383:        [1638.1722, 24.954588, 3.213]\n",
      "    SX383 (arg):  [1687.5933, 25.346666, 3.177]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5532.195833 40.694600 3.427380]\n",
      "        Train: (max)  [23023.105469 95.547623 3.994000]\n",
      "        Train: (min)  [639.502869 16.063084 2.725000]\n",
      "        Val:   (mean) [5260.493027 41.635753 3.719900]\n",
      "        Val:   (max)  [21754.994141 94.532074 4.138000]\n",
      "        Val:   (min)  [671.430359 16.021544 3.317000]\n",
      "    NEW best model! Validation mean-PESQ 3.7199\n",
      "    Saving model...\n",
      "    Total time for evaluation: 25.0933940411s\n",
      "Epoch 198:\n",
      "    101120:  [12.121115 0.008819 0.510915 0.018064 4.185572] [12.121115 2.645757 5.109146 0.180641 4.185572] 2.20010018349 \n",
      "    Total time for epoch: 157.914989948s\n",
      "    ----------------\n",
      "    Code entropy: 1.94390597731\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [2753.572, 34.798229, 3.134]\n",
      "    SA1 (arg):    [2840.0, 35.437939, 3.088]\n",
      "    SX383:        [1575.52, 24.400536, 3.302]\n",
      "    SX383 (arg):  [1620.3754, 24.851915, 3.261]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5716.828964 42.742807 3.434660]\n",
      "        Train: (max)  [20216.386719 89.428627 4.103000]\n",
      "        Train: (min)  [912.985046 17.056747 2.536000]\n",
      "        Val:   (mean) [5424.582563 41.350111 3.668540]\n",
      "        Val:   (max)  [20671.527344 91.658768 4.177000]\n",
      "        Val:   (min)  [311.545624 10.275361 3.148000]\n",
      "    Best validation mean-PESQ seen: 3.7199\n",
      "    Total time for evaluation: 24.3948571682s\n",
      "Epoch 199:\n",
      "    101120:  [12.230286 0.008375 0.547313 0.018341 4.061108] [12.230286 2.512638 5.473132 0.183408 4.061108] 2.20010018349 \n",
      "    Total time for epoch: 158.446082115s\n",
      "    ----------------\n",
      "    Code entropy: 1.80351785557\n",
      "    Tau stays at 2.20010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3035.4126, 36.352943, 3.118]\n",
      "    SA1 (arg):    [3129.7271, 37.022129, 3.072]\n",
      "    SX383:        [1676.4517, 25.308077, 3.24]\n",
      "    SX383 (arg):  [1722.9432, 25.68589, 3.192]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [5663.647850 41.507791 3.502940]\n",
      "        Train: (max)  [21637.582031 99.424164 4.173000]\n",
      "        Train: (min)  [540.632202 13.532613 2.758000]\n",
      "        Val:   (mean) [6158.254376 42.748344 3.626320]\n",
      "        Val:   (max)  [27647.425781 94.839302 4.096000]\n",
      "        Val:   (min)  [334.425201 10.702106 3.121000]\n",
      "    Best validation mean-PESQ seen: 3.7199\n",
      "    Total time for evaluation: 24.4575650692s\n",
      "Epoch 200:\n",
      "    101120:  [12.670495 0.009869 0.545871 0.018170 4.069336] [12.670495 2.960747 5.458710 0.181702 4.069336] 2.20010018349 \n",
      "    Total time for epoch: 158.663529158s\n",
      "    ----------------\n",
      "    Code entropy: 1.70218652724\n",
      "    Updated tau from 2.20010018349 to 2.10010018349\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [3035.7114, 36.466167, 3.098]\n",
      "    SA1 (arg):    [3130.4319, 37.077248, 3.066]\n",
      "    SX383:        [1700.7814, 25.498125, 3.058]\n",
      "    SX383 (arg):  [1757.3789, 25.987049, 3.016]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [6340.288318 45.343857 3.381940]\n",
      "        Train: (max)  [18841.021484 87.649467 3.839000]\n",
      "        Train: (min)  [766.744934 17.565350 2.897000]\n",
      "        Val:   (mean) [6644.455676 45.973479 3.506160]\n",
      "        Val:   (max)  [22071.078125 94.478706 4.073000]\n",
      "        Val:   (min)  [599.590942 13.251657 2.617000]\n",
      "    Best validation mean-PESQ seen: 3.7199\n",
      "    Total time for evaluation: 24.0503849983s\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "lead = \"    \"\n",
    "best_val_pesq = 0.0\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print \"Epoch \" + str(epoch) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "               \n",
    "        # train autoencoder\n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.zeros((nbatch, WINDOW_SIZE, NBINS))] * n_code       \n",
    "\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau),\n",
    "        \n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # estimate code entropy from random samples (if quantization is on)\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        NUM = 200\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        code = encoder.predict(X_train[rows, :], verbose = 0)\n",
    "        probs = np.reshape(code, (code.shape[0] * code.shape[1], NBINS))\n",
    "        hist = np.sum(probs, axis = 0)\n",
    "        hist /= np.sum(hist)\n",
    "\n",
    "        entropy = 0\n",
    "        for i in hist:\n",
    "            if (i < 1e-4): continue\n",
    "            entropy += i * math.log(i, 2)\n",
    "        entropy = -entropy\n",
    "\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Code entropy:\", entropy\n",
    "        \n",
    "        if (epoch >= EPOCHS_BEFORE_TAU):\n",
    "            old_tau = K.get_value(tau)\n",
    "            \n",
    "            if (entropy < TARGET_ENTROPY - TARGET_ENTROPY_FUZZ):\n",
    "                new_tau = old_tau - tau_add_rate\n",
    "                K.set_value(tau, new_tau)\n",
    "                print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "            elif (entropy > TARGET_ENTROPY + TARGET_ENTROPY_FUZZ):\n",
    "                new_tau = old_tau + tau_add_rate\n",
    "                K.set_value(tau, new_tau)\n",
    "                print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "            else:\n",
    "                print lead + \"Tau stays at\", old_tau\n",
    "        \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                              autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SA1:         \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SA1 (arg):   \", metrics\n",
    "    \n",
    "    metrics_tst = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SX383:       \", metrics_tst\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SX383 (arg): \", metrics\n",
    "    \n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        val_pesq = evaluate_training(autoencoder, lead)\n",
    "        if (val_pesq > best_val_pesq and entropy <= TARGET_ENTROPY):\n",
    "            print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "\n",
    "            print lead + \"Saving model...\"\n",
    "            save_model()\n",
    "            best_val_pesq = val_pesq\n",
    "\n",
    "            #curr_lr = model.optimizer.lr.get_value()\n",
    "            #K.set_value(model.optimizer.lr, curr_lr * 0.98)\n",
    "            #print lead + \"Decreased learning rate from\", curr_lr, \"to\", curr_lr * 0.98\n",
    "        else:\n",
    "            print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "    else:\n",
    "        print lead + \"    (Not saving model yet)\"\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "        \n",
    "    # ---------------------------------------------------------\n",
    "    # turn quantization on after a certain # of epochs\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) == 0):\n",
    "        if (epoch >= EPOCHS_BEFORE_QUANT):\n",
    "            print lead + \"----------------\"\n",
    "            print lead + \"Turning quantization on!\"\n",
    "            \n",
    "            random_windows = []\n",
    "            for i in xrange(0, NUM_QUANT_VECS):\n",
    "                w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "                random_windows.append(train_processed[w_idx])\n",
    "            \n",
    "            random_windows = np.array(random_windows)\n",
    "            print lead + \"    Selecting random code vectors for clustering...\"\n",
    "            encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "            encoded_windows = encoded_windows[:, :, :VEC_SIZE]            \n",
    "            encoded_windows = np.reshape(encoded_windows, (-1, VEC_SIZE))\n",
    "            \n",
    "            print lead + \"    K means clustering for bins initialization...\"\n",
    "            km = MiniBatchKMeans(n_clusters = NBINS).fit(encoded_windows)\n",
    "            K.set_value(QUANT_BINS, km.cluster_centers_)\n",
    "            K.set_value(QUANTIZATION_ON, True)\n",
    "            \n",
    "            cluster_score = np.sqrt(np.median(np.min(km.transform(encoded_windows), axis = 1)))\n",
    "            print lead + \"    Done. Cluster score:\", cluster_score\n",
    "            \n",
    "            curr_lr = model.optimizer.lr.get_value()\n",
    "            K.set_value(model.optimizer.lr, curr_lr / 2.0)\n",
    "            print lead + \"Decreased learning rate from\", curr_lr, \"to\", curr_lr / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Selecting random code vectors for clustering...\n",
      "        K means clustering for bins initialization...\n",
      "        Done. Cluster score: 0.0388937\n"
     ]
    }
   ],
   "source": [
    "nqv = 5000\n",
    "vs = 1\n",
    "nb = 16\n",
    "\n",
    "random_windows = []\n",
    "for i in xrange(0, nqv):\n",
    "    w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "    random_windows.append(train_processed[w_idx])\n",
    "\n",
    "random_windows = np.array(random_windows)\n",
    "print lead + \"    Selecting random code vectors for clustering...\"\n",
    "encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "encoded_windows = encoded_windows[:, :, :vs]            \n",
    "encoded_windows = np.reshape(encoded_windows, (-1, vs))\n",
    "\n",
    "# subtract mean from bins before clustering\n",
    "bins_mean = np.mean(encoded_windows, axis = 0)\n",
    "mean_subtracted = encoded_windows - bins_mean\n",
    "\n",
    "print lead + \"    K means clustering for bins initialization...\"\n",
    "km = MiniBatchKMeans(n_clusters = nb).fit(mean_subtracted)\n",
    "\n",
    "cluster_score = np.sqrt(np.mean(np.min(km.transform(mean_subtracted), axis = 1)))\n",
    "print lead + \"    Done. Cluster score:\", cluster_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:240: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    model = load_model('best_model.h5', KERAS_LOAD_MAP)\n",
    "    autoencoder = load_model('best_auto.h5', KERAS_LOAD_MAP)\n",
    "    encoder = autoencoder.layers[1]\n",
    "    decoder = autoencoder.layers[2]\n",
    "    QUANT_BINS = K.variable(np.load('best_quant_bins.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         3007.39\n",
      "Avg err:     36.1959\n",
      "PESQ:        3.208\n",
      "MSE:         3115.16\n",
      "Avg err:     36.9085\n",
      "PESQ:        3.152\n",
      "MSE:         1638.17\n",
      "Avg err:     24.9546\n",
      "PESQ:        3.213\n",
      "MSE:         1687.59\n",
      "Avg err:     25.3467\n",
      "PESQ:        3.177\n",
      "MSE:         1.50475e+06\n",
      "Avg err:     834.573\n",
      "PESQ:        3.044\n",
      "MSE:         1.51288e+06\n",
      "Avg err:     838.697\n",
      "PESQ:        3.031\n"
     ]
    }
   ],
   "source": [
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder)\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder)\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder)\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder, argmax = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9856/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "all_embed = encoder.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2UX+bngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb63af83ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of distribution: 1.85149312103\n",
      "Bins:\n",
      "CudaNdarray([[0.292937]\n",
      " [2.676219]\n",
      " [-2.577726]\n",
      " [1.454840]\n",
      " [1.327387]\n",
      " [-1.548935]\n",
      " [1.722313]\n",
      " [-1.009677]\n",
      " [2.143440]\n",
      " [-2.130440]\n",
      " [3.228236]\n",
      " [-3.217024]\n",
      " [1.187864]\n",
      " [2.913730]\n",
      " [1.994187]\n",
      " [-0.714015]\n",
      " [-2.413305]\n",
      " [0.706548]\n",
      " [-0.385035]\n",
      " [-1.981590]\n",
      " [1.037246]\n",
      " [0.519770]\n",
      " [1.588157]\n",
      " [2.470838]\n",
      " [-1.293278]\n",
      " [2.294805]\n",
      " [-0.017610]\n",
      " [1.854640]\n",
      " [-2.259988]\n",
      " [-2.810944]\n",
      " [-1.781455]\n",
      " [0.876079]])\n"
     ]
    }
   ],
   "source": [
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    probs = np.reshape(all_embed, (all_embed.shape[0] * all_embed.shape[1], NBINS))\n",
    "    hist = np.sum(probs, axis = 0)\n",
    "    hist /= np.sum(hist)\n",
    "\n",
    "    sample_hist_bins = np.linspace(0, NBINS - 1, NBINS)\n",
    "    plt.bar(sample_hist_bins, hist, align = 'center', width = 1)\n",
    "    plt.show()\n",
    "\n",
    "    entropy = 0\n",
    "    for i in hist:\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "    print \"Entropy of distribution:\", entropy\n",
    "\n",
    "    print \"Bins:\"\n",
    "    print QUANT_BINS.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAFkCAYAAAC0KZhSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb63132db10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(np.array(QUANT_BINS.eval()).flatten()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocess_waveform(data)\n",
    "windows = extract_windows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed = np.reshape(windows, (windows.shape[0], WINDOW_SIZE, 1))\n",
    "embed = encoder.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "recons = decoder.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(323.475158691)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc[-1].SOFTMAX_TEMP.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 0.999846 1.000000 1.000000 1.000000 1.000000 0.999984 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 0.999999\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 0.999993 1.000000 1.000000 1.000000 0.976721\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 0.999998 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 0.999999 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 0.999883 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 0.940015 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 0.999997 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 0.657593 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 0.999998 1.000000\n",
      " 0.999998 0.999308 1.000000 1.000000 1.000000 0.999559 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 0.999999 1.000000 0.966043 1.000000 0.996652 0.999999 1.000000\n",
      " 0.999985 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 0.999998\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 1.000000 0.563137 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 0.999994 1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 0.997169 1.000000 1.000000 1.000000]\n",
      "[ 0 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26  0 26\n",
      " 26 26 26 26 26 26 26 26 26 26 26  0 15 21 15  0 26 26  0 26 20  7 18 18 18\n",
      " 26 18  0  0 26 26  0 26  0 26 26 26  0 26 17 15 26 18 26 18 26 26  0 26 26\n",
      " 17 26  0 18  0  0 21 15 26 18 15 18 15  0 26 26 26 26 26  0 18 26 26 26 18\n",
      " 26 26 26 26 26 26 17 26  0 26 26 26 26 26  0 26 15 26 18 26 18 18 26 26 18\n",
      " 26 26 26 26 26 18  0 26 12 15 17  0  0 26 26 18  0 18 26 26 26 26 26 18 26\n",
      " 21 26 26  0 21 17 26 26 26 26 26 26 18 26 26 26 26 26 26 26 26 18 26 18  3\n",
      " 15  0 31  0 26 26 15  0 26 18 26 26 26  0 26 26 20 26 26  0 26  0 26 26 26\n",
      " 26 18 26 26 26 26 26 26  0 26 26 26  7 22 18 26 31 26  0 26 15 26  0 15 26\n",
      " 26 26 17 26 18 20 26 26 26 26 26  0 26 26 26 26 26 26 26 26  0 26 26 18 26\n",
      " 26 15  7 22  7 31]\n",
      "0.98046875\n"
     ]
    }
   ],
   "source": [
    "max_pct = np.max(embed[25], axis = -1)\n",
    "print max_pct\n",
    "print np.argmax(embed[25], axis = -1)\n",
    "print np.sum(max_pct > 0.98) / float(max_pct.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995578\n",
      "0.976388113839\n"
     ]
    }
   ],
   "source": [
    "embed_max = np.max(embed, axis = -1)\n",
    "print np.mean(embed_max)\n",
    "print np.sum(embed_max > 0.98) / float(embed_max.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFkCAYAAACNTikJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nigxCCCGExAJFBiGEEEJi4f8DANliPGypdgIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb63129f310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFkCAYAAACNTikJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noeAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb626af1dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code (argmax)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFkCAYAAACNTikJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAkCRQYhhBBCgkCRQQghhJAg/P9M9wpSdNGUMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb62699ff90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code (non-argmax)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFkCAYAAACNTikJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkUEIIYSQXPj/Ad81RCxIZRVDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb626933250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6265ad690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4ziO4ziF4YqF4ziO4ziF8X9YGScQh9imCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6264f0990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 25\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "print \"Original\"\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "print \"Reconstruction\"\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    print \"Code (argmax)\"\n",
    "    argmax_code_vec = embed[idx]\n",
    "    embed_sum = np.sum(embed[idx], axis = -1)\n",
    "    argmax_code_vec = np.eye(NBINS)[np.argmax(argmax_code_vec, axis = -1)]\n",
    "    argmax_code_vec[embed_sum < 0.95] = np.zeros(NBINS)\n",
    "    argmax_code_vec = unquantize_vec(argmax_code_vec).eval()\n",
    "    plt.plot(argmax_code_vec)\n",
    "    plt.show()\n",
    "    \n",
    "    print \"Code (non-argmax)\"\n",
    "    na_code_vec = embed[idx]\n",
    "    na_code_vec = unquantize_vec(na_code_vec).eval()\n",
    "    plt.plot(na_code_vec)\n",
    "    plt.show()\n",
    "    \n",
    "    print \"Difference\"\n",
    "    plt.plot(abs(argmax_code_vec - na_code_vec))\n",
    "    plt.show()\n",
    "else:\n",
    "    print \"Code (pre-quantization)\"\n",
    "    code_vec = embed[idx][:, :VEC_SIZE].flatten()\n",
    "    plt.plot(code_vec)\n",
    "    plt.show()\n",
    "    \n",
    "print \"Error\"\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
