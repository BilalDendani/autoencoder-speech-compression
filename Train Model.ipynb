{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import load_model\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import *\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from utility import *\n",
    "from pesq import *\n",
    "from noise import *\n",
    "from consts import *\n",
    "from nn_blocks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# number of speech files for train, val, and test\n",
    "TRAIN_SIZE = 1000\n",
    "VAL_SIZE = 100\n",
    "TEST_SIZE = 500\n",
    "\n",
    "# during training, we evaluate PESQ and RMSE and such on full speech files every epoch, which\n",
    "# is kind of expensive. so instead of selecting the full training and validation set, we\n",
    "# randomly select this many waveforms\n",
    "TRAIN_EVALUATE = 50\n",
    "VAL_EVALUATE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101814, 512, 1)\n",
      "6.41179e-06\n",
      "0.103588\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE, 1))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = (WINDOW_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.activations import softmax\n",
    "\n",
    "# softmax hardness variable\n",
    "tau = K.variable(1500.0, name = \"hardness\")\n",
    "anneal_rate = 1.01\n",
    "max_tau = 1500.00\n",
    "\n",
    "VEC_SIZE = 4\n",
    "BINS_INIT = np.mgrid[-1:1:4j, -1:1:4j, -1:1:4j, -1:1:4j].reshape(VEC_SIZE, -1).T\n",
    "QUANT_BINS = K.variable(BINS_INIT)\n",
    "\n",
    "def unquantize_batch(one_hot):\n",
    "    out = T.tensordot(one_hot, QUANT_BINS, axes = [2, 0])\n",
    "    out = K.reshape(out, (out.shape[0], out.shape[1] * VEC_SIZE))\n",
    "    return out\n",
    "\n",
    "def unquantize_vec(one_hot):\n",
    "    out = T.tensordot(one_hot, QUANT_BINS, axes = [1, 0])\n",
    "    out = K.reshape(out, (WINDOW_SIZE,))\n",
    "    return out\n",
    "\n",
    "class SoftmaxQuantization(Layer):\n",
    "    def __init__(self, shared_bins, **kwargs):\n",
    "        super(SoftmaxQuantization, self).__init__(**kwargs)\n",
    "        self.bins = shared_bins\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = [self.bins]\n",
    "        super(SoftmaxQuantization, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        # x is an array: [BATCH x WINDOW_SIZE]\n",
    "        # x_r becomes: [BATCH x (WINDOW_SIZE / VEC_SIZE) x NBINS x VEC_SIZE]\n",
    "        x_r = K.reshape(x, (-1, x.shape[1] / VEC_SIZE, 1, VEC_SIZE))\n",
    "        x_r = K.repeat_elements(x_r, self.bins.shape[0], -2)\n",
    "\n",
    "        # quant_bins is an array: [NBINS x VEC_SIZE] \n",
    "        # q_r becomes: [BATCH x (WINDOW_SIZE / VEC_SIZE) x NBINS x VEC_SIZE]\n",
    "        q_r = K.reshape(self.bins, (1, 1, self.bins.shape[0], VEC_SIZE))\n",
    "        q_r = K.repeat_elements(q_r, x_r.shape[0], 0)\n",
    "        q_r = K.repeat_elements(q_r, x_r.shape[1], 1)\n",
    "\n",
    "        # get L2 distance from each element to each of the bins\n",
    "        dist = K.sqrt(K.sum(K.square(x_r - q_r), axis = -1) + K.epsilon())\n",
    "\n",
    "        # turn into softmax probabilities, which we return\n",
    "        probs = softmax(tau * -dist)\n",
    "        return probs\n",
    "        \n",
    "        '''\n",
    "        # hard probabilities if tau >= max, or if we're at test time\n",
    "        hard = K.one_hot(K.argmax(probs), NBINS)\n",
    "        \n",
    "        train = probs\n",
    "        test = hard\n",
    "        return K.in_train_phase(train, test)\n",
    "        '''\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] / VEC_SIZE, NBINS)\n",
    "\n",
    "\n",
    "class SoftmaxDequantization(Layer):\n",
    "    def __init__(self, shared_bins, **kwargs):\n",
    "        super(SoftmaxDequantization, self).__init__(**kwargs)\n",
    "        self.bins = shared_bins\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "        super(SoftmaxDequantization, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        out = T.tensordot(x, self.bins, axes = [2, 0])\n",
    "        out = K.reshape(out, (out.shape[0], out.shape[1] * VEC_SIZE))\n",
    "        return out\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.08273085  0.12518668  0.08273085  0.03636978  0.04605361  0.03636978\n",
      "    0.12518668  0.3401851   0.12518668]\n",
      "  [ 0.07229083  0.18911795  0.18911795  0.0469379   0.08606448  0.08606448\n",
      "    0.0618268   0.1342898   0.1342898 ]\n",
      "  [ 0.10682777  0.29029619  0.10682777  0.07059818  0.10682777  0.07059818\n",
      "    0.07059818  0.10682777  0.07059818]]\n",
      "\n",
      " [[ 0.0423767   0.09639489  0.14586283  0.05365994  0.14586283  0.39637095\n",
      "    0.02343521  0.0423767   0.05365994]\n",
      "  [ 0.14586283  0.09639489  0.0423767   0.05365994  0.0423767   0.02343521\n",
      "    0.39637095  0.14586283  0.05365994]\n",
      "  [ 0.10682777  0.29029619  0.10682777  0.07059818  0.10682777  0.07059818\n",
      "    0.07059818  0.10682777  0.07059818]]\n",
      "\n",
      " [[ 0.10682777  0.29029619  0.10682777  0.07059818  0.10682777  0.07059818\n",
      "    0.07059818  0.10682777  0.07059818]\n",
      "  [ 0.10682777  0.29029619  0.10682777  0.07059818  0.10682777  0.07059818\n",
      "    0.07059818  0.10682777  0.07059818]\n",
      "  [ 0.10682777  0.29029619  0.10682777  0.07059818  0.10682777  0.07059818\n",
      "    0.07059818  0.10682777  0.07059818]]]\n",
      "[[  0.00000000e+00   4.71765305e-01   2.28416687e-01   1.11339536e-01\n",
      "    0.00000000e+00  -2.77555756e-17]\n",
      " [  4.76421872e-01  -4.76421872e-01  -4.76421872e-01   4.76421872e-01\n",
      "    0.00000000e+00  -2.77555756e-17]\n",
      " [  0.00000000e+00  -2.77555756e-17   0.00000000e+00  -2.77555756e-17\n",
      "    0.00000000e+00  -2.77555756e-17]]\n"
     ]
    }
   ],
   "source": [
    "bin_size = 2\n",
    "bins = [[-1, 0], [0, 0], [1, 0], [-1, -1], [0, -1], [1, -1], [-1, 1], [0, 1], [1, 1]]\n",
    "bins = np.array(bins)\n",
    "\n",
    "wnds = [[0.0, 1.0, 0.5, 0.25, 0.0, 0.0], [1.0, -1.0, -1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
    "wnds = np.array(wnds)\n",
    "\n",
    "x_r = K.reshape(wnds, (-1, wnds.shape[1] / bin_size, 1, bin_size))\n",
    "x_r = K.repeat_elements(x_r, bins.shape[0], -2)\n",
    "\n",
    "q_r = K.reshape(bins, (1, 1, bins.shape[0], bin_size))\n",
    "q_r = K.repeat_elements(q_r, x_r.shape[0], 0)\n",
    "q_r = K.repeat_elements(q_r, x_r.shape[1], 1)\n",
    "\n",
    "dists = K.sqrt(K.sum(K.square(x_r - q_r), axis = -1) + K.epsilon())\n",
    "probs = softmax(-dists)\n",
    "\n",
    "print probs.eval()\n",
    "\n",
    "recons = T.tensordot(probs, bins, axes = [2, 0])\n",
    "recons = K.reshape(recons, (recons.shape[0], recons.shape[1] * bin_size))\n",
    "print recons.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    NCHAN = 32\n",
    "    FILT_SIZE = 9\n",
    "    OUT_CHAN = 1\n",
    "    \n",
    "    TIMES_DOWNSAMPLE = 0\n",
    "    NUM_RES_BLOCKS = 5\n",
    "    DILATION_LIMIT = 8\n",
    "       \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = enc_input\n",
    "    \n",
    "    enc = Reshape(dim, input_shape = dim)(enc)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    enc = channel_increase_block(NCHAN, FILT_SIZE)(enc)\n",
    "        \n",
    "    # residual blocks\n",
    "    dilation_rate = 1\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        enc = residual_block(NCHAN, FILT_SIZE, 2)(enc)\n",
    "        if (dilation_rate < DILATION_LIMIT):\n",
    "            dilation_rate *= 2\n",
    "            \n",
    "    # downsampling blocks\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE): \n",
    "        enc = downsample_block(NCHAN, FILT_SIZE)(enc)\n",
    "    \n",
    "    # decrease back down to 1 channel\n",
    "    enc = channel_decrease_block(NCHAN, FILT_SIZE)(enc)\n",
    "    enc = Reshape((WINDOW_SIZE,))(enc)\n",
    "    \n",
    "    # softmax quantization\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc)\n",
    "    enc.name = 'encoder'\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (WINDOW_SIZE / VEC_SIZE, NBINS))\n",
    "    dec = dec_input\n",
    "    \n",
    "    dec = SoftmaxDequantization()(dec)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    dec = Reshape((WINDOW_SIZE, 1))(dec)\n",
    "    dec = channel_increase_block(NCHAN, FILT_SIZE)(dec)\n",
    "    \n",
    "    # upsampling blocks\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE):\n",
    "        dec = upsample_block(NCHAN, FILT_SIZE)(dec)\n",
    "    \n",
    "    # residual blocks\n",
    "    dilation_rate = 1\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        dec = residual_block(NCHAN, FILT_SIZE, 2)(dec)\n",
    "        if (dilation_rate < DILATION_LIMIT):\n",
    "            dilation_rate *= 2\n",
    "    \n",
    "    # decrease back down to 1 channel\n",
    "    dec = channel_decrease_block(NCHAN, FILT_SIZE)(dec)\n",
    "    dec = Activation('tanh')(dec)\n",
    "    #dec = Lambda(lambda x : K.clip(x, -1.0, 1.0))(dec)\n",
    "    \n",
    "    dec = Model(inputs = dec_input, outputs = dec)\n",
    "    dec.name = 'decoder'\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# perceptual model: takes a clean window and \"dirty\" window, and computes\n",
    "# a perceptual score between them\n",
    "#     (0.0 to 1.0, where 0 is completely garbage and 1 is perfect)\n",
    "# perceptual score is based off PESQ in this case\n",
    "# ---------------------------------------------------------------------------\n",
    "def perceptual_model_structure(dim):\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    NCHAN = 32\n",
    "    FILT_SIZE = 7\n",
    "    DENSE_SIZE = 32\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # shared Siamese structure applied to both inputs\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    def siamese_half():\n",
    "        inp = Input(shape = (WINDOW_SIZE, 1))\n",
    "        ret = Reshape((WINDOW_SIZE, 1))(inp)\n",
    "\n",
    "        ret = channel_increase_block(NCHAN, FILT_SIZE)(ret)\n",
    "\n",
    "        ret = downsample_block(NCHAN, FILT_SIZE)(ret)\n",
    "        ret = downsample_block(NCHAN, FILT_SIZE)(ret)\n",
    "        ret = residual_block(NCHAN, FILT_SIZE)(ret)\n",
    "        ret = residual_block(NCHAN, FILT_SIZE)(ret)\n",
    "        ret = residual_block(NCHAN, FILT_SIZE)(ret)\n",
    "\n",
    "        ret = channel_decrease_block(NCHAN, FILT_SIZE)(ret)\n",
    "\n",
    "        ret = Flatten()(ret)\n",
    "        ret = Dense(DENSE_SIZE, activation = 'linear', kernel_initializer = W_INIT)(ret)\n",
    "\n",
    "        return Model(inputs = inp, outputs = ret)\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # combined model\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    input_orig = Input(shape = dim)\n",
    "    input_dirty = Input(shape = dim)\n",
    "\n",
    "    base_network = siamese_half()\n",
    "    processed_a = base_network(input_orig)\n",
    "    processed_b = base_network(input_dirty)\n",
    "\n",
    "    #'''\n",
    "    def func(vects):\n",
    "        x, y = vects\n",
    "        return x - y\n",
    "\n",
    "    def shape(shapes):\n",
    "        shape1, shape2 = shapes\n",
    "        return shape1\n",
    "\n",
    "    out = Lambda(func, output_shape = shape)([processed_a, processed_b])\n",
    "    #'''\n",
    "\n",
    "    \n",
    "    #out = EuclideanDistance()([processed_a, processed_b])\n",
    "    out = Dense(1, activation = 'sigmoid', kernel_initializer = W_INIT)(out)\n",
    "    \n",
    "    model = Model(inputs = [input_orig, input_dirty], outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    NCHAN = 32\n",
    "    FILT_SIZE = 7\n",
    "    DENSE_SIZE = 32\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # model\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dsc_input = Input(shape = dim)\n",
    "    dsc = Reshape(dim, input_shape = dim)(dsc_input)\n",
    "    \n",
    "    dsc = channel_increase_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    \n",
    "    dsc = downsample_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    dsc = downsample_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE)(dsc)\n",
    "    dsc = residual_block(NCHAN, FILT_SIZE)(dsc)\n",
    "\n",
    "    dsc = channel_decrease_block(NCHAN, FILT_SIZE)(dsc)\n",
    "\n",
    "    dsc = Flatten()(dsc)\n",
    "    \n",
    "    dsc = Dense(DENSE_SIZE, activation = 'linear', kernel_initializer = W_INIT)(dsc)\n",
    "    dsc = activation()(dsc)\n",
    "\n",
    "    # sigmoid output (probability of window being real or reconstructed)\n",
    "    dsc = Dense(1, activation = 'sigmoid', kernel_initializer = W_INIT)(dsc)\n",
    "\n",
    "    dsc = Model(inputs = dsc_input, outputs = dsc)\n",
    "    return dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can compute the entropy of a batch directly\n",
    "def code_entropy(placeholder, code):\n",
    "    all_onehots = K.reshape(code, (code.shape[0] * code.shape[1], NBINS))\n",
    "    onehot_hist = K.sum(all_onehots, axis = 0)\n",
    "    onehot_hist /= K.sum(onehot_hist)\n",
    "\n",
    "    entropy = -K.sum(onehot_hist * K.log(onehot_hist + K.epsilon()) / K.log(2.0))\n",
    "    return entropy\n",
    "\n",
    "def code_sparsity(placeholder, code):\n",
    "    return K.mean(K.sum(K.sqrt(code + K.epsilon()), axis = -1), axis = -1) - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:33: DeprecationWarning: Division of two integer types with x / y is deprecated, please use x // y for an integer division.\n"
     ]
    }
   ],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = input_dim)\n",
    "ac_enc, ac_dec = autoencoder_structure(input_dim)\n",
    "ac_embedding = ac_enc(ac_input)\n",
    "ac_reconstructed = ac_dec(ac_embedding)\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct perceptual model\n",
    "perceptual_model = perceptual_model_structure(input_dim)\n",
    "perceptual_model.name = 'perceptual'\n",
    "perceptual_model.layers[2].name = 'perceptual_siamese_half'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct discriminator\n",
    "dsc_input = Input(shape = input_dim)\n",
    "dsc_struct = discriminator_structure(input_dim)\n",
    "dsc_label = dsc_struct(dsc_input)\n",
    "discriminator = Model(inputs = [dsc_input], outputs = [dsc_label])\n",
    "discriminator.name = 'discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 128, 256)          112609    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 512, 1)            111585    \n",
      "=================================================================\n",
      "Total params: 224,194.0\n",
      "Trainable params: 224,194.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, 1)                 76642     \n",
      "=================================================================\n",
      "Total params: 76,642.0\n",
      "Trainable params: 76,642.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "perceptual_siamese_half (Model)  (None, 32)            91009                                        \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 32)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             33                                           \n",
      "====================================================================================================\n",
      "Total params: 91,042.0\n",
      "Trainable params: 91,042.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 128, 256)          112609    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 512, 1)            111585    \n",
      "_________________________________________________________________\n",
      "perceptual (Model)           (None, 1)                 91042     \n",
      "=================================================================\n",
      "Total params: 315,236.0\n",
      "Trainable params: 315,236.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile perceptual model\n",
    "perceptual_model.compile(loss = 'mae', optimizer = Adam(lr = 0.001))\n",
    "\n",
    "# compile discriminator\n",
    "make_trainable(perceptual_model, False)\n",
    "discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = 0.001))\n",
    "make_trainable(perceptual_model, True)\n",
    "\n",
    "# compile overall autoencoder model\n",
    "ac_dsc_label = discriminator(ac_reconstructed)\n",
    "ac_percept_score = perceptual_model([ac_input, ac_reconstructed])\n",
    "\n",
    "loss_weights = [300.0, 1.0, 1.0]\n",
    "loss_functions = ['mae', 'mae', code_sparsity]\n",
    "n_recons = 1\n",
    "n_percept = 1\n",
    "n_discrim = 0\n",
    "n_code = 1\n",
    "assert(n_recons + n_percept + n_discrim + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))\n",
    "\n",
    "make_trainable(discriminator, False)\n",
    "make_trainable(perceptual_model, False)\n",
    "model = Model(inputs = [ac_input], outputs = [ac_reconstructed] * n_recons + \\\n",
    "                                            [ac_percept_score] * n_percept + \\\n",
    "                                            [ac_dsc_label] * n_discrim + \\\n",
    "                                            [ac_embedding] * n_code)\n",
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam(lr = 0.00075))\n",
    "make_trainable(discriminator, True)\n",
    "make_trainable(perceptual_model, True)\n",
    "\n",
    "\n",
    "\n",
    "autoencoder.summary()\n",
    "discriminator.summary()\n",
    "perceptual_model.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create pairs for the discriminator, given the autoencoder and a batch\n",
    "def create_discrim_pairs(autoencoder, batch):\n",
    "    num = batch.shape[0]\n",
    "    generated = autoencoder.predict(batch)\n",
    "    \n",
    "    X = interleave([batch, generated])\n",
    "    y = interleave([np.ones(num), np.zeros(num)])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test discriminator, given the autoencoder and a set of samples (speech windows, not\n",
    "# necessarily in any order)\n",
    "def test_discriminator(discriminator, autoencoder, orig_samples, verbose = True):\n",
    "    X, y = create_discrim_pairs(autoencoder, orig_samples)\n",
    "    \n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "    \n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Discriminator evaluation: %0.02f\"%(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model on a set of speech windows (which should originally have been extracted in\n",
    "# order from some speech waveform)\n",
    "def test_model_on_windows(orig_windows, wparams, autoencoder, argmax = False):\n",
    "    # first, get desired reconstruction\n",
    "    desired = reconstruct_from_windows(orig_windows, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocess_waveform(desired, wparams)\n",
    "    desired = np.clip(desired, -32767, 32767)\n",
    "    \n",
    "    # then, run NN on windows to get our model's reconstruction\n",
    "    transformed = np.reshape(orig_windows, (orig_windows.shape[0], WINDOW_SIZE, 1))\n",
    "    enc = autoencoder.layers[1]\n",
    "    embed = enc.predict(transformed, batch_size = 128, verbose = 0)\n",
    "    if (argmax):\n",
    "        for wnd in xrange(0, embed.shape[0]):\n",
    "            max_idxs = np.argmax(embed[wnd], axis = -1)\n",
    "            embed[wnd] = np.eye(NBINS)[max_idxs]\n",
    "    \n",
    "    dec = autoencoder.layers[2]\n",
    "    autoencOutput = dec.predict(embed, batch_size = 128, verbose = 0)\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    recons = reconstruct_from_windows(autoencOutput, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocess_waveform(recons, wparams)\n",
    "    recons = np.clip(recons, -32767, 32767)\n",
    "    \n",
    "    # compute PESQ between desired and reconstructed waveforms\n",
    "    pesq = run_pesq_waveforms(desired, recons)\n",
    "    \n",
    "    # return some metrics, as well as the two waveforms\n",
    "    metrics = [\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired),\n",
    "        pesq\n",
    "    ]\n",
    "    \n",
    "    return metrics, desired, recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model given the filename for a .wav file\n",
    "def test_model_on_wav(wave_filename, prefix, autoencoder,\n",
    "                      lead = \"\", save_recons = True, verbose = True,\n",
    "                      argmax = False):\n",
    "    [rate, data] = sciwav.read(wave_filename)\n",
    "    data = data.astype(np.float32)\n",
    "    processed_wave, wparams = preprocess_waveform(data)\n",
    "    windows = extract_windows(processed_wave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "    metrics, desired, recons = test_model_on_windows(windows, wparams, autoencoder, argmax)\n",
    "    \n",
    "    if (save_recons):\n",
    "        outFilename = prefix + \"_output.wav\"\n",
    "        sciwav.write(outFilename, SAMPLE_RATE, recons.astype(np.int16))\n",
    "    \n",
    "    if (verbose):\n",
    "        print lead + \"MSE:        \", metrics[0]\n",
    "        print lead + \"Avg err:    \", metrics[1]\n",
    "        print lead + \"PESQ:       \", metrics[2]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    train_eval_idxs = random.sample(range(0, len(train_windows) - 1), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_windows) - 1), VAL_EVALUATE)\n",
    "    \n",
    "    train_metrics = []\n",
    "    for idx in train_eval_idxs:\n",
    "        windows = train_windows[idx]\n",
    "        wparams = train_wparams[idx]\n",
    "        metrics, _, _ = test_model_on_windows(windows, wparams, autoencoder)\n",
    "        \n",
    "        train_metrics.append(metrics)\n",
    "        \n",
    "    val_metrics = []\n",
    "    for idx in val_eval_idxs:\n",
    "        windows = val_windows[idx]\n",
    "        wparams = val_wparams[idx]\n",
    "        metrics, _, _ = test_model_on_windows(windows, wparams, autoencoder)\n",
    "        \n",
    "        val_metrics.append(metrics)\n",
    "    \n",
    "    train_metrics = np.array(train_metrics)\n",
    "    val_metrics = np.array(val_metrics)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    os.system('rm ./best_model.h5')\n",
    "    os.system('rm ./best_auto.h5')\n",
    "    os.system('rm ./best_discrim.h5')\n",
    "    os.system('rm ./best_percept.h5')\n",
    "    \n",
    "    model.save('./best_model.h5')\n",
    "    autoencoder.save('./best_auto.h5')\n",
    "    discriminator.save('./best_discrim.h5')\n",
    "    perceptual_model.save('./best_percept.h5')\n",
    "\n",
    "    f = h5py.File('./best_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 375, 512, 1)\n",
      "(375,)\n"
     ]
    }
   ],
   "source": [
    "def update_train_structure(X, y, wnd, cor, prm, val = None):\n",
    "    if (val is None):\n",
    "        pesq = run_pesq_windows(wnd, cor, prm, prm)\n",
    "        scaled = (pesq - 1.0) / 3.5\n",
    "        scaled = np.clip(scaled, 0.0, 1.0)\n",
    "    else:\n",
    "        scaled = val\n",
    "    \n",
    "    for i in xrange(0, wnd.shape[0]):\n",
    "        X[0].append(wnd[i])\n",
    "        X[1].append(cor[i])\n",
    "        y.append(scaled)\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "def generate_pesq_traindata():\n",
    "    X = [[], []]\n",
    "    y = []\n",
    "    \n",
    "    # get random waveform from training set\n",
    "    idx = random.randint(0, TRAIN_SIZE - 1)\n",
    "    \n",
    "    wnd = train_windows[idx]\n",
    "    prm = train_wparams[idx]\n",
    "    \n",
    "    # autoencoder prediction\n",
    "    wnd = np.reshape(wnd, (-1, WINDOW_SIZE, 1))\n",
    "    cor = autoencoder.predict(wnd, verbose = 0)\n",
    "    X, y = update_train_structure(X, y, wnd, cor, prm)\n",
    "    \n",
    "    # linear mix of prediction and original\n",
    "    amt = random.uniform(0.25, 0.75)\n",
    "    cor = cor * amt + wnd * (1.0 - amt)\n",
    "    X, y = update_train_structure(X, y, wnd, cor, prm)\n",
    "    \n",
    "    # random type of noise, at random amount\n",
    "    noise = random.choice(noise_types)\n",
    "    noise_func = noise[0]\n",
    "    noise_prm = random.choice(noise[1])\n",
    "    \n",
    "    wnd = np.reshape(wnd, (-1, WINDOW_SIZE))\n",
    "    cor = noise_func(wnd, noise_prm)\n",
    "    wnd = np.reshape(wnd, (-1, WINDOW_SIZE, 1))\n",
    "    cor = np.reshape(cor, (-1, WINDOW_SIZE, 1))\n",
    "    \n",
    "    X, y = update_train_structure(X, y, wnd, cor, prm)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "pesq_train_X, pesq_train_y = generate_pesq_traindata()\n",
    "print pesq_train_X.shape\n",
    "print pesq_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         1.61034e+06\n",
      "Avg err:     1204.89\n",
      "PESQ:        1.067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1610336.1, 1204.8873, 1.067]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get untrained baseline for model\n",
    "test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_res_uninit_\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    1280: no discrim 0.317066669464  [17.900555 0.058298 0.312913 0.098167] [17.900555 17.489473 0.312913 0.098167] 1500.0"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0d89bbe229b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# train autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_recons\u001b[0m \u001b[0;34m+\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_percept\u001b[0m \u001b[0;34m+\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_discrim\u001b[0m \u001b[0;34m+\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOW_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNBINS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# update tau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "DSC_CLIP_WEIGHTS = False\n",
    "DSC_CLAMP_RANGE = 0.01\n",
    "DSC_TIMES_TRAIN = 1\n",
    "\n",
    "PESQ_TIMES_TRAIN = 1\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "\n",
    "best_val_pesq = 0.0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"no auto\"]\n",
    "        d_loss = \"no discrim\"\n",
    "        p_loss = \"no pesq\"\n",
    "        \n",
    "        # train perceptual model\n",
    "        if (n_percept > 0):\n",
    "            # get 128 random sample-label pairs for this batch\n",
    "            nsamples = pesq_train_y.shape[0]\n",
    "            p = np.random.permutation(nsamples)\n",
    "            if (nsamples > BATCH_SIZE):\n",
    "                p = p[:BATCH_SIZE]\n",
    "            pesq_batch_X = [pesq_train_X[0, p], pesq_train_X[1, p]]\n",
    "            pesq_batch_y = pesq_train_y[p]\n",
    "                 \n",
    "            for k in xrange(0, PESQ_TIMES_TRAIN):\n",
    "                p_loss = perceptual_model.train_on_batch(pesq_batch_X, pesq_batch_y)\n",
    "\n",
    "        # train discriminator\n",
    "        if (n_discrim > 0):\n",
    "            discrim_batch_X, discrim_batch_y =  create_discrim_pairs(autoencoder, batch)\n",
    "           \n",
    "            for k in xrange(0, DSC_TIMES_TRAIN):\n",
    "                d_loss = discriminator.train_on_batch(discrim_batch_X, discrim_batch_y)  \n",
    "                \n",
    "        # train autoencoder\n",
    "        a_y = [batch] * n_recons + \\\n",
    "                [np.ones(nbatch)] * n_percept + \\\n",
    "                [np.ones(nbatch)] * n_discrim + \\\n",
    "                [np.zeros((nbatch, WINDOW_SIZE, NBINS))] * n_code\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # update tau\n",
    "        K.set_value(tau, np.min([K.get_value(tau) * anneal_rate, max_tau]))\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + \\\n",
    "                                             str(d_loss) + \" \" + \\\n",
    "                                             str(p_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau),\n",
    "                \n",
    "            if (n_percept > 0):\n",
    "                pesq_train_X, pesq_train_y = generate_pesq_traindata()\\\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"   \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    if (n_discrim > 0):\n",
    "        NUM = 200\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        d_acc = test_discriminator(discriminator, autoencoder,\n",
    "                                   X_train[rows, :], verbose = False)\n",
    "\n",
    "        print lead + \"Evaluated the discriminator: \" + str(d_acc)\n",
    "        elapsed = time.time() - startTime\n",
    "        print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    else:\n",
    "        print lead + \"No discriminator\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # generate code histogram from random samples\n",
    "    # ---------------------------------------------------------\n",
    "    '''\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    code = ac_enc.predict(X_train[rows, :], verbose = 0)\n",
    "    \n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Code histogram:\"\n",
    "    scalars = code.flatten()\n",
    "    \n",
    "    b = np.linspace(-1.0, 1.0, NBINS + 1)\n",
    "    hist = np.histogram(scalars, bins = b)\n",
    "    sample_hist_probs = hist[0].astype('float32')\n",
    "    sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "    entropy = 0\n",
    "    for i in sample_hist_probs:\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "    \n",
    "    print \"       Entropy:\", entropy\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    if (K.get_value(tau) >= max_tau):\n",
    "        val_pesq = evaluate_training(autoencoder, lead)\n",
    "        if (val_pesq > best_val_pesq):\n",
    "            print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "            print lead + \"Saving model...\"\n",
    "            save_model()\n",
    "            best_val_pesq = val_pesq\n",
    "        else:\n",
    "            print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "    else:\n",
    "        print lead + \"    (Not saving model yet)\"\n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_res_reg_train_epoch\" + str(epoch+1),\n",
    "                              autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "    print lead + \"SA1:        \", metrics\n",
    "    metrics_tst = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_res_reg_train_epoch\" + str(epoch+1),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "    print lead + \"SX383:      \", metrics_tst\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'Quantize' : Quantize,\n",
    "                  'StochasticQuantize' : StochasticQuantize,\n",
    "                  'StochasticQuantizeLayer' : StochasticQuantizeLayer,\n",
    "                  'NBINS' : NBINS,\n",
    "                  'entropy_estimate' : entropy_estimate,\n",
    "                  'rmse' : rmse,\n",
    "                  'EuclideanDistance': EuclideanDistance,\n",
    "                  'QUANT_BINS' : QUANT_BINS,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:33: DeprecationWarning: Division of two integer types with x / y is deprecated, please use x // y for an integer division.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Graph disconnected: cannot obtain value for tensor /input_6 at layer \"input_6\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c02ede165752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKERAS_LOAD_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_auto.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKERAS_LOAD_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_discrim.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKERAS_LOAD_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mperceptual_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_percept.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKERAS_LOAD_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    291\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/layers/__init__.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     44\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    139\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 140\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   2341\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 2343\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   2344\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/layers/__init__.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     44\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    139\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 140\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2389\u001b[0m             \u001b[0mlayer_output_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                                 \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                                 \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                                 str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1705\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                         \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Graph disconnected: cannot obtain value for tensor /input_6 at layer \"input_6\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "model = load_model('best_model.h5', KERAS_LOAD_MAP)\n",
    "\n",
    "autoencoder = load_model('best_auto.h5', KERAS_LOAD_MAP)\n",
    "discriminator = load_model('best_discrim.h5', KERAS_LOAD_MAP)\n",
    "perceptual_model = load_model('best_percept.h5', KERAS_LOAD_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "\n",
    "d_acc = test_discriminator(discriminator, autoencoder,\n",
    "                           X_train[rows, :], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final_\", autoencoder)\n",
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final_\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final_\", autoencoder)\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final_\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final_\", autoencoder)\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final_\", autoencoder, argmax = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_embed = ac_enc.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = np.reshape(all_embed, (all_embed.shape[0] * all_embed.shape[1], NBINS))\n",
    "hist = np.sum(probs, axis = 0)\n",
    "hist /= np.sum(hist)\n",
    "\n",
    "sample_hist_bins = np.linspace(0, NBINS - 1, NBINS)\n",
    "plt.bar(sample_hist_bins, hist, align = 'center', width = 1)\n",
    "plt.show()\n",
    "\n",
    "print \"Bins:\", quant_bins.eval()\n",
    "\n",
    "entropy = 0\n",
    "for i in hist:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print \"Entropy of distribution:\", entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocess_waveform(data)\n",
    "windows = extract_windows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed = np.reshape(windows, (windows.shape[0], WINDOW_SIZE, 1))\n",
    "embed = ac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recons = ac_dec.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.max(embed[31], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 30\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(unquantize_vec(embed[idx]).eval())\n",
    "plt.show()\n",
    "\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
