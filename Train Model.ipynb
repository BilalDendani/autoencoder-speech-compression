{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from utility import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.regularizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import load_model\n",
    "from keras.losses import *\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import *\n",
    "from scipy.fftpack import dct, idct\n",
    "from keras.activations import softmax\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import scipy.io.wavfile as sciwav\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)\n",
    "\n",
    "# increase recursion limit for adaptive VQ\n",
    "import sys\n",
    "sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# control amount of GPU memory used\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# external custom code I wrote\n",
    "from load_data import *\n",
    "from windowing import *\n",
    "from pesq import *\n",
    "from consts import *\n",
    "from nn_blocks import *\n",
    "from transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# number of speech files for train, val, and test\n",
    "TRAIN_SIZE = 1000\n",
    "VAL_SIZE = 100\n",
    "TEST_SIZE = 500\n",
    "\n",
    "# during training, we evaluate PESQ and RMSE and such on full speech files every epoch, which\n",
    "# is kind of expensive. so instead of selecting the full training and validation set, we\n",
    "# randomly select this many waveforms\n",
    "TRAIN_EVALUATE = 100\n",
    "VAL_EVALUATE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "[train_paths, val_paths, test_paths], \\\n",
    "[train_waveforms, val_waveforms, test_waveforms], \\\n",
    "[train_procwave, val_procwave, test_procwave], \\\n",
    "[train_wparams, val_wparams, test_wparams], \\\n",
    "[train_windows, val_windows, test_windows] = load_data(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101814, 512, 1)\n",
      "6.41179e-06\n",
      "0.103588\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# flatten all of the train windows into vectors\n",
    "train_processed = np.array([i for z in train_windows for i in z])\n",
    "train_processed = np.reshape(train_processed, (train_processed.shape[0], WINDOW_SIZE, 1))\n",
    "\n",
    "# randomly shuffle data, if we want to\n",
    "if (RANDOM_SHUFFLE):\n",
    "    train_processed = np.random.permutation(train_processed)\n",
    "    \n",
    "print train_processed.shape\n",
    "print np.mean(train_processed, axis=None)\n",
    "print np.std(train_processed, axis=None)\n",
    "print np.min(train_processed, axis = None)\n",
    "print np.max(train_processed, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = (WINDOW_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# softmax hardness variable\n",
    "tau = K.variable(0.0001, name = \"hardness\")\n",
    "\n",
    "NBINS = 32\n",
    "VEC_SIZE = 1\n",
    "\n",
    "# initially, quantization is not on\n",
    "QUANT_BINS = K.zeros((NBINS, VEC_SIZE), name = 'QUANT_BINS')\n",
    "QUANTIZATION_ON = K.variable(False, name = 'QUANTIZATION_ON')\n",
    "\n",
    "DOWNSAMPLE_FACTOR = 4\n",
    "CHANNEL_SIZE = WINDOW_SIZE / DOWNSAMPLE_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unquantize_batch(one_hot):\n",
    "    out = K.dot(K.variable(one_hot), QUANT_BINS)\n",
    "    out = K.reshape(out, (out.shape[0], -1))\n",
    "    return K.eval(out)\n",
    "\n",
    "def unquantize_vec(one_hot):\n",
    "    out = K.dot(K.variable(one_hot), QUANT_BINS)\n",
    "    out = K.reshape(out, (-1,))\n",
    "    return K.eval(out)\n",
    "\n",
    "class SoftmaxQuantization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftmaxQuantization, self).__init__(**kwargs)\n",
    "   \n",
    "    def build(self, input_shape):\n",
    "        self.SOFTMAX_TEMP = K.variable(256.0)\n",
    "        self.trainable_weights = [QUANT_BINS,\n",
    "                                  self.SOFTMAX_TEMP]\n",
    "        super(SoftmaxQuantization, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        # x is an array: [BATCH x WINDOW_SIZE]\n",
    "        # x_r becomes: [BATCH x (WINDOW_SIZE / VEC_SIZE) x 1 x VEC_SIZE]\n",
    "        x_r = K.reshape(x, (-1, x.shape[1] // VEC_SIZE, 1, VEC_SIZE))\n",
    "\n",
    "        # quant_bins is an array: [NBINS x VEC_SIZE] \n",
    "        # q_r becomes: [1 x 1 x NBINS x VEC_SIZE]\n",
    "        q_r = K.reshape(QUANT_BINS, (1, 1, QUANT_BINS.shape[0], VEC_SIZE))\n",
    "\n",
    "        # get L2 distance from each element to each of the bins\n",
    "        # dist is: [BATCH x (WINDOW_SIZE / VEC_SIZE) x NBINS]\n",
    "        dist = K.sqrt(K.sum(K.square(x_r - q_r), axis = -1) + K.epsilon())\n",
    "\n",
    "        # turn into softmax probabilities, which we return\n",
    "        probs = softmax(self.SOFTMAX_TEMP * -dist)\n",
    "        \n",
    "        # if quantization isn't on yet, we just return the original vector x, reshaped\n",
    "        # and padded to the right shape\n",
    "        #     (this is a bad hack and I hope there is a better way to do this)\n",
    "        quant_on = probs\n",
    "        quant_off = K.zeros_like(probs)[:, :, VEC_SIZE:]\n",
    "        quant_off = K.concatenate([K.reshape(x, (-1, x.shape[1] // VEC_SIZE, VEC_SIZE)),\n",
    "                                   quant_off], axis = 2)\n",
    "        \n",
    "        return K.switch(QUANTIZATION_ON, quant_on, quant_off)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] // VEC_SIZE, NBINS)\n",
    "\n",
    "\n",
    "class SoftmaxDequantization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftmaxDequantization, self).__init__(**kwargs)\n",
    "        self.supports_masking = False\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "        super(SoftmaxDequantization, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        out = K.dot(x, QUANT_BINS)\n",
    "        out = K.reshape(out, (-1, out.shape[1] * VEC_SIZE))\n",
    "        \n",
    "        quant_on = out\n",
    "        quant_off = K.reshape(x[:, :, :VEC_SIZE], (-1, x.shape[1] * VEC_SIZE))\n",
    "        return K.switch(QUANTIZATION_ON, quant_on, quant_off)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_MFCC_COEFFS = 64\n",
    "\n",
    "# precompute Mel filterbank\n",
    "MEL_FILTERBANK_NPY = melFilterBank(NUM_MFCC_COEFFS).transpose()\n",
    "MEL_FILTERBANK = K.variable(MEL_FILTERBANK_NPY)\n",
    "\n",
    "# we precompute matrices for MFCC calculation\n",
    "DFT_REAL, DFT_IMAG = generate_dft_mats(WINDOW_SIZE)\n",
    "MFCC_DCT = generate_dct_mat(NUM_MFCC_COEFFS)\n",
    "MFCC_WND_FUNC = K.variable(sig.hann(WINDOW_SIZE))\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE\n",
    "#     this returns an array M x N where each window has been replaced\n",
    "#     by some perceptual transform (in this case, MFCC coeffs)\n",
    "def perceptual_transform(x):\n",
    "    powerSpectrum = K.square(theano_dft_mag(x, DFT_REAL, DFT_IMAG))\n",
    "    filteredSpectrum = K.dot(powerSpectrum, MEL_FILTERBANK)\n",
    "    logSpectrum = K.log(filteredSpectrum + K.epsilon())\n",
    "    \n",
    "    #mfccs = theano_dct(logSpectrum, MFCC_DCT)[:, 1:-16]\n",
    "    return logSpectrum\n",
    "\n",
    "# perceptual loss function\n",
    "def perceptual_distance(y_true, y_pred):\n",
    "    y_true = K.reshape(y_true, (-1, WINDOW_SIZE))\n",
    "    y_pred = K.reshape(y_pred, (-1, WINDOW_SIZE))\n",
    "    \n",
    "    pvec_true = perceptual_transform(y_true)\n",
    "    pvec_pred = perceptual_transform(y_pred)\n",
    "    \n",
    "    return rmse(pvec_true, pvec_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):   \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # parameters\n",
    "    # - - - - - - - - - - - - - - - - - - - - -   \n",
    "    NCHAN = 48\n",
    "    FILT_SIZE = 15\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # encoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = enc_input\n",
    "    \n",
    "    enc = Reshape(dim, input_shape = dim)(enc)  \n",
    "    \n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1,\n",
    "                         operation = 'channel_change')(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1,\n",
    "                         operation = 'downsample')(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1,\n",
    "                         operation = 'downsample')(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(NCHAN, FILT_SIZE, 1)(enc)\n",
    "    enc = residual_block(1, FILT_SIZE, 1,\n",
    "                         operation = 'channel_change')(enc)\n",
    "    \n",
    "    enc = Reshape((CHANNEL_SIZE,))(enc)\n",
    "    \n",
    "    # softmax quantization\n",
    "    enc = SoftmaxQuantization()(enc)\n",
    "    \n",
    "    enc = Model(inputs = enc_input, outputs = enc)\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    # decoder\n",
    "    # - - - - - - - - - - - - - - - - - - - - -\n",
    "    dec_input = Input(shape = (CHANNEL_SIZE / VEC_SIZE, NBINS))\n",
    "    dec = dec_input\n",
    "    \n",
    "    dec = SoftmaxDequantization()(dec)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    dec = Reshape((CHANNEL_SIZE, 1))(dec)\n",
    "    \n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1,\n",
    "                         operation = 'channel_change')(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1)(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1,\n",
    "                         operation = 'upsample')(dec)\n",
    "    dec = residual_block(NCHAN, FILT_SIZE, 1,\n",
    "                         operation = 'upsample')(dec)\n",
    "    dec = residual_block(1, FILT_SIZE, 1,\n",
    "                         operation = 'channel_change')(dec)\n",
    "\n",
    "    dec = Activation('tanh')(dec)    \n",
    "    dec = Model(inputs = dec_input, outputs = dec)\n",
    "    \n",
    "    # return both encoder and decoder\n",
    "    return enc, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can compute the entropy of a batch directly\n",
    "def code_entropy(placeholder, code):\n",
    "    all_onehots = K.reshape(code, (-1, NBINS))\n",
    "    onehot_hist = K.sum(all_onehots, axis = 0)\n",
    "    onehot_hist /= K.sum(onehot_hist)\n",
    "\n",
    "    entropy = -K.sum(onehot_hist * K.log(onehot_hist + K.epsilon()) / K.log(2.0))\n",
    "    loss = tau * entropy\n",
    "    return K.switch(QUANTIZATION_ON, loss, loss - loss)\n",
    "\n",
    "def code_sparsity(placeholder, code):\n",
    "    sparsity = K.mean(K.sum(K.sqrt(code + K.epsilon()), axis = -1), axis = -1) - 1.0\n",
    "    return K.switch(QUANTIZATION_ON, sparsity, sparsity - sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map for load_model\n",
    "KERAS_LOAD_MAP = {'PhaseShiftUp1D' : PhaseShiftUp1D,\n",
    "                  'LinearUpSampling1D' : LinearUpSampling1D,\n",
    "                  'ChannelResize1D' : ChannelResize1D,\n",
    "                  'code_entropy' : code_entropy,\n",
    "                  'code_sparsity' : code_sparsity,\n",
    "                  'rmse' : rmse,\n",
    "                  'SoftmaxQuantization' : SoftmaxQuantization,\n",
    "                  'SoftmaxDequantization' : SoftmaxDequantization,\n",
    "                  'NBINS' : NBINS,\n",
    "                  'QUANT_BINS' : QUANT_BINS,\n",
    "                  'VEC_SIZE' : VEC_SIZE,\n",
    "                  'MEL_FILTERBANK' : MEL_FILTERBANK,\n",
    "                  'DFT_REAL' : DFT_REAL,\n",
    "                  'DFT_IMAG' : DFT_IMAG,\n",
    "                  'MFCC_DCT' : MFCC_DCT,\n",
    "                  'MFCC_WND_FUNC' : MFCC_WND_FUNC,\n",
    "                  'theano_dft_mag' : theano_dft_mag,\n",
    "                  'theano_dct' : theano_dct,\n",
    "                  'perceptual_transform' : perceptual_transform,\n",
    "                  'perceptual_distance' : perceptual_distance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct autoencoder\n",
    "ac_input = Input(shape = input_dim)\n",
    "\n",
    "encoder, decoder = autoencoder_structure(input_dim)\n",
    "ac_reconstructed = decoder(encoder(ac_input))\n",
    "autoencoder = Model(inputs = [ac_input], outputs = [ac_reconstructed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "loss_weights = [30.0, 1.0, 3.0, 1.0]\n",
    "loss_functions = [rmse, perceptual_distance, code_sparsity, code_entropy]\n",
    "n_recons = 2\n",
    "n_code = 2\n",
    "assert(n_recons + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py:1511: UserWarning: The list of outputs passed to the model is redundant. All outputs should only appear once. Found: [<tf.Tensor 'model_2_1/activation_1/Tanh:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'model_2_1/activation_1/Tanh:0' shape=(?, 512, 1) dtype=float32>, <tf.Tensor 'model_1_1/softmax_quantization_1/cond/Merge:0' shape=(?, 128, 32) dtype=float32>, <tf.Tensor 'model_1_1/softmax_quantization_1/cond/Merge:0' shape=(?, 128, 32) dtype=float32>]\n",
      "  ' Found: ' + str(self.outputs))\n"
     ]
    }
   ],
   "source": [
    "# model specification\n",
    "model_input = Input(shape = input_dim)\n",
    "model_embedding = encoder(model_input)\n",
    "model_reconstructed = decoder(model_embedding)\n",
    "\n",
    "model = Model(inputs = [model_input], outputs = [model_reconstructed] * n_recons + \\\n",
    "                                            [model_embedding] * n_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 128, 32)           453078.0  \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 512, 1)            757653    \n",
      "=================================================================\n",
      "Total params: 1,210,731\n",
      "Trainable params: 1,210,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adadelta())\n",
    "\n",
    "#autoencoder.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model on a set of speech windows (which should originally have been extracted in\n",
    "# order from some speech waveform)\n",
    "def test_model_on_windows(orig_windows, wparams, autoencoder, argmax = False):\n",
    "    # first, get desired reconstruction\n",
    "    desired = reconstruct_from_windows(orig_windows, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocess_waveform(desired, wparams)\n",
    "    desired = np.clip(desired, -32767, 32767)\n",
    "    \n",
    "    # then, run NN on windows to get our model's reconstruction\n",
    "    transformed = np.reshape(orig_windows, (orig_windows.shape[0], WINDOW_SIZE, 1))\n",
    "    enc = autoencoder.layers[1]\n",
    "    embed = enc.predict(transformed, batch_size = 128, verbose = 0)\n",
    "    if (argmax):\n",
    "        for wnd in xrange(0, embed.shape[0]):\n",
    "            max_idxs = np.argmax(embed[wnd], axis = -1)\n",
    "            embed[wnd] = np.eye(NBINS)[max_idxs]\n",
    "    \n",
    "    dec = autoencoder.layers[2]\n",
    "    autoencOutput = dec.predict(embed, batch_size = 128, verbose = 0)\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    recons = reconstruct_from_windows(autoencOutput, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocess_waveform(recons, wparams)\n",
    "    recons = np.clip(recons, -32767, 32767)\n",
    "    \n",
    "    # compute PESQ between desired and reconstructed waveforms\n",
    "    pesq = run_pesq_waveforms(desired, recons)\n",
    "    \n",
    "    # return some metrics, as well as the two waveforms\n",
    "    metrics = [\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired),\n",
    "        pesq\n",
    "    ]\n",
    "    \n",
    "    return metrics, desired, recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model given the filename for a .wav file\n",
    "def test_model_on_wav(wave_filename, prefix, autoencoder,\n",
    "                      lead = \"\", save_recons = True, verbose = True,\n",
    "                      argmax = False):\n",
    "    [rate, data] = sciwav.read(wave_filename)\n",
    "    data = data.astype(np.float32)\n",
    "    processed_wave, wparams = preprocess_waveform(data)\n",
    "    windows = extract_windows(processed_wave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "    metrics, desired, recons = test_model_on_windows(windows, wparams, autoencoder, argmax)\n",
    "    \n",
    "    if (save_recons):\n",
    "        outFilename = prefix + \"_output.wav\"\n",
    "        sciwav.write(outFilename, SAMPLE_RATE, recons.astype(np.int16))\n",
    "    \n",
    "    if (verbose):\n",
    "        print lead + \"MSE:        \", metrics[0]\n",
    "        print lead + \"Avg err:    \", metrics[1]\n",
    "        print lead + \"PESQ:       \", metrics[2]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_model(prefix = 'best'):\n",
    "    os.system('rm ./' + prefix + '_model.h5')\n",
    "    os.system('rm ./' + prefix + '_auto.h5')\n",
    "    os.system('rm ./' + prefix + '_quant_bins.npy')\n",
    "    \n",
    "    model.save('./' + prefix + '_model.h5')\n",
    "    autoencoder.save('./' + prefix + '_auto.h5')\n",
    "    np.save('./' + prefix + '_quant_bins.npy', K.eval(QUANT_BINS))\n",
    "    \n",
    "    f = h5py.File('best_model.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         67226.6\n",
      "Avg err:     132.512\n",
      "PESQ:        1.577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[67226.57, 132.51186, 1.577]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get untrained baseline for model\n",
    "test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_uninit\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_training(autoencoder, lead = \"\"):\n",
    "    train_eval_idxs = random.sample(range(0, len(train_windows)), TRAIN_EVALUATE)\n",
    "    val_eval_idxs = random.sample(range(0, len(val_windows)), VAL_EVALUATE)\n",
    "    \n",
    "    train_metrics = []\n",
    "    for idx in train_eval_idxs:\n",
    "        windows = train_windows[idx]\n",
    "        wparams = train_wparams[idx]\n",
    "        metrics, _, _ = test_model_on_windows(windows, wparams, autoencoder,\n",
    "                                              argmax = True)\n",
    "        \n",
    "        train_metrics.append(metrics)\n",
    "        \n",
    "    val_metrics = []\n",
    "    for idx in val_eval_idxs:\n",
    "        windows = val_windows[idx]\n",
    "        wparams = val_wparams[idx]\n",
    "        metrics, _, _ = test_model_on_windows(windows, wparams, autoencoder,\n",
    "                                              argmax = True)\n",
    "        \n",
    "        val_metrics.append(metrics)\n",
    "    \n",
    "    train_metrics = np.array(train_metrics)\n",
    "    val_metrics = np.array(val_metrics)\n",
    "    \n",
    "    print lead + \"Format: [MSE, avg err, PESQ]\"\n",
    "    print lead + \"    Train: (mean)\", np.mean(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (max) \", np.max(train_metrics, axis = 0)\n",
    "    print lead + \"    Train: (min) \", np.min(train_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (mean)\", np.mean(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (max) \", np.max(val_metrics, axis = 0)\n",
    "    print lead + \"    Val:   (min) \", np.min(val_metrics, axis = 0)\n",
    "    \n",
    "    # returns mean PESQ on validation\n",
    "    return np.mean(val_metrics, axis = 0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target entropy: 3.75\n"
     ]
    }
   ],
   "source": [
    "X_train = np.copy(train_processed)\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 100\n",
    "EPOCHS_BEFORE_QUANT = 10\n",
    "NUM_QUANT_VECS = 5000\n",
    "\n",
    "ORIG_BITRATE = 256.00\n",
    "TARGET_BITRATE = 16.00\n",
    "PRE_ENTROPY_RATE = ORIG_BITRATE / DOWNSAMPLE_FACTOR / VEC_SIZE\n",
    "\n",
    "TARGET_ENTROPY = (TARGET_BITRATE / PRE_ENTROPY_RATE * 16.0)\n",
    "TARGET_ENTROPY *= (STEP_SIZE / float(WINDOW_SIZE))\n",
    "TARGET_ENTROPY_FUZZ = 0.1\n",
    "\n",
    "TAU_INCREASE_RATE = 0.0125\n",
    "MIN_TAU = 0.0125\n",
    "\n",
    "#LR_CHANGE_EPOCHS = [EPOCHS_BEFORE_QUANT, 25, 50, 75]\n",
    "#LR_CHANGE_MULT = 0.5\n",
    "\n",
    "MAX_LR = 1.0\n",
    "MIN_LR = 0.1\n",
    "T_i = 1.0\n",
    "T_cur = 0.0\n",
    "\n",
    "best_val_pesq = 0.0\n",
    "\n",
    "print \"Target entropy:\", TARGET_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    101120:  [1.206546 0.009773 0.913345 0.000000 0.000000] [1.206546 0.293201 0.913345 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 85.2044270039s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [9781.8193, 44.93988, 3.006]\n",
      "    SX383:        [7015.1655, 33.251202, 2.635]\n",
      "        (Not saving model yet)\n",
      "Epoch 2:\n",
      "    101120:  [1.171672 0.012968 0.782623 0.000000 0.000000] [1.171672 0.389048 0.782623 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 78.9752509594s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [9015.248, 43.803139, 3.257]\n",
      "    SX383:        [6777.0747, 32.489822, 2.769]\n",
      "        (Not saving model yet)\n",
      "Epoch 3:\n",
      "    101120:  [1.252748 0.014460 0.818943 0.000000 0.000000] [1.252748 0.433806 0.818943 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 78.6901140213s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [8076.1689, 42.792278, 3.353]\n",
      "    SX383:        [6542.6978, 31.909708, 2.904]\n",
      "        (Not saving model yet)\n",
      "Epoch 4:\n",
      "    101120:  [1.131312 0.013510 0.726000 0.000000 0.000000] [1.131312 0.405312 0.726000 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 78.7728030682s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [7366.0742, 41.857994, 3.393]\n",
      "    SX383:        [6314.0137, 31.44804, 2.98]\n",
      "        (Not saving model yet)\n",
      "Epoch 5:\n",
      "    101120:  [1.116793 0.011688 0.766155 0.000000 0.000000] [1.116793 0.350638 0.766155 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 78.9182870388s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [6476.1465, 40.25943, 3.532]\n",
      "    SX383:        [5994.5737, 30.703484, 3.188]\n",
      "        (Not saving model yet)\n",
      "Epoch 6:\n",
      "    101120:  [1.084436 0.012504 0.709305 0.000000 0.000000] [1.084436 0.375131 0.709305 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 79.130920887s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [6022.8203, 39.474236, 3.613]\n",
      "    SX383:        [5826.1372, 30.311464, 3.249]\n",
      "        (Not saving model yet)\n",
      "Epoch 7:\n",
      "    101120:  [0.952267 0.009871 0.656138 0.000000 0.000000] [0.952267 0.296128 0.656138 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 79.5105509758s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5666.8145, 38.744404, 3.617]\n",
      "    SX383:        [5713.5303, 30.01096, 3.263]\n",
      "        (Not saving model yet)\n",
      "Epoch 8:\n",
      "    101120:  [0.926636 0.010716 0.605155 0.000000 0.000000] [0.926636 0.321481 0.605155 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 79.4877061844s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5341.0332, 37.897495, 3.673]\n",
      "    SX383:        [5506.0283, 29.342989, 3.418]\n",
      "        (Not saving model yet)\n",
      "Epoch 9:\n",
      "    101120:  [0.997392 0.011917 0.639885 0.000000 0.000000] [0.997392 0.357508 0.639885 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 79.8028109074s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [5159.7349, 37.416168, 3.713]\n",
      "    SX383:        [5285.0483, 28.962889, 3.435]\n",
      "        (Not saving model yet)\n",
      "Epoch 10:\n",
      "    101120:  [1.031665 0.012277 0.663343 0.000000 0.000000] [1.031665 0.368322 0.663343 0.000000 0.000000] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 78.8486618996s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [4969.9922, 36.990696, 3.72]\n",
      "    SX383:        [5145.2856, 28.618673, 3.42]\n",
      "        (Not saving model yet)\n",
      "    ----------------\n",
      "    Turning quantization on!\n",
      "        Selecting random code vectors for clustering...\n",
      "        K means clustering for bins initialization...\n",
      "        Done. Cluster score: 0.0586027\n",
      "Epoch 11:\n",
      "    101120:  [1.636192 0.014570 0.752383 0.148757 0.000430] [1.636192 0.437108 0.752383 0.446270 0.000430] 0.0001 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 79.5427291393s\n",
      "    ----------------\n",
      "    Code entropy: 3.89244705234\n",
      "    Updated tau from 0.0001 to 0.0125999999975\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [7067.167, 41.979847, 2.882]\n",
      "    SA1 (arg):    [7315.874, 44.08556, 2.608]\n",
      "    SX383:        [6732.9712, 33.219982, 2.961]\n",
      "    SX383 (arg):  [6821.1318, 34.474228, 2.731]\n",
      "    Format: [MSE, avg err, PESQ]\n",
      "        Train: (mean) [19252.342009 62.631488 2.758920]\n",
      "        Train: (max)  [139647.593750 168.660782 3.525000]\n",
      "        Train: (min)  [1289.660156 18.122629 1.841000]\n",
      "        Val:   (mean) [16185.280051 56.708719 2.818500]\n",
      "        Val:   (max)  [126282.507812 129.620773 3.447000]\n",
      "        Val:   (min)  [670.625549 13.054179 1.933000]\n",
      "    Best validation mean-PESQ seen: 0.0\n",
      "Epoch 12:\n",
      "    101120:  [1.522809 0.013882 0.742297 0.106815 0.043597] [1.522809 0.416471 0.742297 0.320444 0.043597] 0.0126 0.100088 0.993718592965 1.0 \n",
      "    Total time for epoch: 79.7693488598s\n",
      "    ----------------\n",
      "    Code entropy: 3.41755116048\n",
      "    Updated tau from 0.0126 to 0.0125\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    SA1:          [6432.9019, 43.596371, 2.876]\n",
      "    SA1 (arg):    [6781.6538, 46.132092, 2.612]\n",
      "    SX383:        [6231.0156, 33.57082, 2.935]\n",
      "    SX383 (arg):  [6341.4229, 35.017887, 2.76]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b0b49b18d315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQUANTIZATION_ON\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mval_pesq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_pesq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_pesq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mTARGET_ENTROPY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mlead\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"NEW best model! Validation mean-PESQ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pesq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9c77f37fe1c9>\u001b[0m in \u001b[0;36mevaluate_training\u001b[0;34m(autoencoder, lead)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_wparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         metrics, _, _ = test_model_on_windows(windows, wparams, autoencoder,\n\u001b[0;32m---> 10\u001b[0;31m                                               argmax = True)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d6d863dd5feb>\u001b[0m in \u001b[0;36mtest_model_on_windows\u001b[0;34m(orig_windows, wparams, autoencoder, argmax)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# compute PESQ between desired and reconstructed waveforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpesq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pesq_waveforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# return some metrics, as well as the two waveforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sri/Desktop/autoencoder-speech-compression/pesq.pyc\u001b[0m in \u001b[0;36mrun_pesq_waveforms\u001b[0;34m(clean_wav, dirty_wav)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msciwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_wav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msciwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirty_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAMPLE_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirty_wav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mpesq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pesq_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirty_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rm \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclean_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rm \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdirty_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sri/Desktop/autoencoder-speech-compression/pesq.pyc\u001b[0m in \u001b[0;36mrun_pesq_filenames\u001b[0;34m(clean, to_eval)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpesq_regex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\(MOS-LQO\\):  = ([0-9]+\\.[0-9]+)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mpesq_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./PESQ +16000 +wb \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mto_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mregex_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpesq_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpesq_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "lead = \"    \"\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print \"Epoch \" + str(epoch) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    num_batches = len(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    T_cur = 0.0\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        # perform cosine annealing on learning rate\n",
    "        T_cur += 1.0 / float(num_batches)        \n",
    "        lr = MIN_LR + 0.5 * (MAX_LR - MIN_LR) * (1 + math.cos(T_cur / T_i * 3.14159))\n",
    "        K.set_value(model.optimizer.lr, lr)\n",
    "        \n",
    "        # train autoencoder\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.zeros((nbatch, WINDOW_SIZE, NBINS))] * n_code       \n",
    "\n",
    "        a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know what's going on\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau), K.get_value(model.optimizer.lr), T_cur, T_i,\n",
    "             \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # estimate code entropy from random samples (if quantization is on)\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        NUM = 500\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        code = encoder.predict(X_train[rows, :], verbose = 0)\n",
    "        probs = np.reshape(code, (code.shape[0] * code.shape[1], NBINS))\n",
    "        hist = np.sum(probs, axis = 0)\n",
    "        hist /= np.sum(hist)\n",
    "\n",
    "        entropy = 0\n",
    "        for i in hist:\n",
    "            if (i < 1e-4): continue\n",
    "            entropy += i * math.log(i, 2)\n",
    "        entropy = -entropy\n",
    "\n",
    "        print lead + \"----------------\"\n",
    "        print lead + \"Code entropy:\", entropy\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # handle updating entropy weight (tau)\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        old_tau = K.get_value(tau)\n",
    "\n",
    "        if (entropy < TARGET_ENTROPY - TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau - TAU_INCREASE_RATE\n",
    "            if (new_tau <= MIN_TAU):\n",
    "                new_tau = MIN_TAU\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        elif (entropy > TARGET_ENTROPY + TARGET_ENTROPY_FUZZ):\n",
    "            new_tau = old_tau + TAU_INCREASE_RATE\n",
    "\n",
    "            K.set_value(tau, new_tau)\n",
    "            print lead + \"Updated tau from\", old_tau, \"to\", new_tau\n",
    "        else:\n",
    "            print lead + \"Tau stays at\", old_tau\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on training/validation data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    \n",
    "    metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                              autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SA1:         \", metrics\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SA1.wav\", \"./train_output/SA1_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SA1 (arg):   \", metrics\n",
    "    \n",
    "    metrics_tst = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = False)\n",
    "    print lead + \"SX383:       \", metrics_tst\n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        metrics = test_model_on_wav(\"./SX383.wav\", \"./train_output/SX383_train_epoch\" + str(epoch),\n",
    "                                  autoencoder, lead = lead, verbose = False, argmax = True)\n",
    "        print lead + \"SX383 (arg): \", metrics\n",
    "    \n",
    "    if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "        val_pesq = evaluate_training(autoencoder, lead)\n",
    "        if (val_pesq > best_val_pesq and entropy <= TARGET_ENTROPY):\n",
    "            print lead + \"NEW best model! Validation mean-PESQ\", val_pesq\n",
    "\n",
    "            print lead + \"Saving model...\"\n",
    "            save_model()\n",
    "            best_val_pesq = val_pesq\n",
    "            patience_epoch = epoch\n",
    "        else:\n",
    "            print lead + \"Best validation mean-PESQ seen:\", best_val_pesq\n",
    "    else:\n",
    "        print lead + \"    (Not saving model yet)\"\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "        \n",
    "    # ---------------------------------------------------------\n",
    "    # turn quantization on after a certain # of epochs\n",
    "    # ---------------------------------------------------------\n",
    "    if (K.get_value(QUANTIZATION_ON) == 0):\n",
    "        if (epoch == EPOCHS_BEFORE_QUANT):\n",
    "            print lead + \"----------------\"\n",
    "            print lead + \"Turning quantization on!\"\n",
    "            \n",
    "            random_windows = []\n",
    "            for i in xrange(0, NUM_QUANT_VECS):\n",
    "                w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "                random_windows.append(train_processed[w_idx])\n",
    "            \n",
    "            random_windows = np.array(random_windows)\n",
    "            print lead + \"    Selecting random code vectors for clustering...\"\n",
    "            encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "            encoded_windows = encoded_windows[:, :, :VEC_SIZE]            \n",
    "            encoded_windows = np.reshape(encoded_windows, (-1, VEC_SIZE))\n",
    "            \n",
    "            print lead + \"    K means clustering for bins initialization...\"\n",
    "            km = MiniBatchKMeans(n_clusters = NBINS).fit(encoded_windows)\n",
    "            K.set_value(QUANT_BINS, km.cluster_centers_)\n",
    "            K.set_value(QUANTIZATION_ON, True)\n",
    "            \n",
    "            cluster_score = np.sqrt(np.median(np.min(km.transform(encoded_windows), axis = 1)))\n",
    "            print lead + \"    Done. Cluster score:\", cluster_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Selecting random code vectors for clustering...\n",
      "        K means clustering for bins initialization...\n",
      "        Done. Cluster score: 0.0612562\n"
     ]
    }
   ],
   "source": [
    "nqv = 5000\n",
    "vs = 1\n",
    "nb = 16\n",
    "\n",
    "random_windows = []\n",
    "for i in xrange(0, nqv):\n",
    "    w_idx = random.randint(0, train_processed.shape[0] - 1)\n",
    "    random_windows.append(train_processed[w_idx])\n",
    "\n",
    "random_windows = np.array(random_windows)\n",
    "print lead + \"    Selecting random code vectors for clustering...\"\n",
    "encoded_windows = encoder.predict(random_windows, batch_size = 128, verbose = 0)\n",
    "encoded_windows = encoded_windows[:, :, :vs]            \n",
    "encoded_windows = np.reshape(encoded_windows, (-1, vs))\n",
    "\n",
    "# subtract mean from bins before clustering\n",
    "bins_mean = np.mean(encoded_windows, axis = 0)\n",
    "mean_subtracted = encoded_windows - bins_mean\n",
    "\n",
    "print lead + \"    K means clustering for bins initialization...\"\n",
    "km = MiniBatchKMeans(n_clusters = nb).fit(mean_subtracted)\n",
    "\n",
    "cluster_score = np.sqrt(np.mean(np.min(km.transform(mean_subtracted), axis = 1)))\n",
    "print lead + \"    Done. Cluster score:\", cluster_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = load_model('best_model.h5', KERAS_LOAD_MAP)\n",
    "    autoencoder = load_model('best_auto.h5', KERAS_LOAD_MAP)\n",
    "    encoder = autoencoder.layers[1]\n",
    "    decoder = autoencoder.layers[2]\n",
    "    QUANT_BINS = K.variable(np.load('best_quant_bins.npy'))\n",
    "    QUANTIZATION_ON = K.variable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in xrange(0, len(enc)):\n",
    "#    print i, enc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:         6432.9\n",
      "Avg err:     43.5964\n",
      "PESQ:        2.876\n"
     ]
    }
   ],
   "source": [
    "test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder)\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    test_model_on_wav(\"./SA1.wav\", \"SA1_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder)\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    test_model_on_wav(\"./SX383.wav\", \"SX383_final\", autoencoder, argmax = True)\n",
    "\n",
    "test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder)\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    test_model_on_wav(\"./fiveYears.wav\", \"fy_final\", autoencoder, argmax = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_embed = encoder.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    probs = np.reshape(all_embed, (all_embed.shape[0] * all_embed.shape[1], NBINS))\n",
    "    hist = np.sum(probs, axis = 0)\n",
    "    hist /= np.sum(hist)\n",
    "\n",
    "    sample_hist_bins = np.linspace(0, NBINS - 1, NBINS)\n",
    "    plt.bar(sample_hist_bins, hist, align = 'center', width = 1)\n",
    "    plt.show()\n",
    "\n",
    "    entropy = 0\n",
    "    for i in hist:\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "    print \"Entropy of distribution:\", entropy\n",
    "\n",
    "    print \"Bins:\"\n",
    "    print K.eval(QUANT_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.sort(np.array(K.eval(QUANT_BINS)).flatten()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocess_waveform(data)\n",
    "windows = extract_windows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed = np.reshape(windows, (windows.shape[0], WINDOW_SIZE, 1))\n",
    "embed = encoder.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recons = decoder.predict(embed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.eval(enc[-1].SOFTMAX_TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_pct = np.max(embed[25], axis = -1)\n",
    "print max_pct\n",
    "print np.argmax(embed[25], axis = -1)\n",
    "print np.sum(max_pct > 0.98) / float(max_pct.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_max = np.max(embed, axis = -1)\n",
    "print np.mean(embed_max)\n",
    "print np.sum(embed_max > 0.98) / float(embed_max.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 25\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "print \"Original\"\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "print \"Reconstruction\"\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "if (K.get_value(QUANTIZATION_ON) > 0):\n",
    "    print \"Code (argmax)\"\n",
    "    argmax_code_vec = embed[idx]\n",
    "    embed_sum = np.sum(embed[idx], axis = -1)\n",
    "    argmax_code_vec = np.eye(NBINS)[np.argmax(argmax_code_vec, axis = -1)]\n",
    "    argmax_code_vec[embed_sum < 0.95] = np.zeros(NBINS)\n",
    "    argmax_code_vec = unquantize_vec(argmax_code_vec)\n",
    "    plt.plot(argmax_code_vec)\n",
    "    plt.show()\n",
    "    \n",
    "    print \"Code (non-argmax)\"\n",
    "    na_code_vec = embed[idx]\n",
    "    na_code_vec = unquantize_vec(na_code_vec)\n",
    "    plt.plot(na_code_vec)\n",
    "    plt.show()\n",
    "    \n",
    "    print \"Difference\"\n",
    "    plt.plot(abs(argmax_code_vec - na_code_vec))\n",
    "    plt.show()\n",
    "else:\n",
    "    print \"Code (pre-quantization)\"\n",
    "    code_vec = embed[idx][:, :VEC_SIZE].flatten()\n",
    "    plt.plot(code_vec)\n",
    "    plt.show()\n",
    "    \n",
    "print \"Error\"\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
