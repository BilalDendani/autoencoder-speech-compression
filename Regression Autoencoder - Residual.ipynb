{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):   \n",
    "    return waveform, ()\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    # scale window between -1 and 1\n",
    "    processed = np.copy(windows)\n",
    "   \n",
    "    mn = np.min(processed, axis = 1)\n",
    "    mx = np.max(processed, axis = 1)\n",
    "\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "\n",
    "    for i in xrange(0, processed.shape[0]):\n",
    "        processed[i] /= maxabs[i]\n",
    "    #processed *= 0.98\n",
    "   \n",
    "    #processed = (processed + 1.0) / 2.0\n",
    "   \n",
    "    return processed, (maxabs,)\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    # scale window from [-1, 1] to [-32768, 32768]\n",
    "    scl = params[0]\n",
    "   \n",
    "    unprocessed = np.copy(windows)\n",
    "    #unprocessed /= 0.98\n",
    "   \n",
    "    #nprocessed = (unprocessed * 2.0) - 1.0\n",
    "   \n",
    "    for i in xrange(0, unprocessed.shape[0]):\n",
    "        unprocessed[i] *= scl[i]\n",
    "\n",
    "    return unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(processedWaveforms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (101135, 512)\n",
      "Max:  17885.0\n",
      "Min:  -17139.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (101135, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101135, 512, 1)\n",
      "0.0179514\n",
      "0.286117\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PhaseShift1D(Layer):\n",
    "    \"\"\" PhaseShift1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShift1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShift1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UniformNoise(Layer):\n",
    "    def __init__(self, scale, clip = None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.scale = scale\n",
    "        self.clip = clip\n",
    "        self.uses_learning_phase = True\n",
    "        super(UniformNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        noise_x = x + K.random_uniform(shape = K.shape(x),\n",
    "                                       low = -self.scale,\n",
    "                                       high = self.scale)\n",
    "        if (self.clip is not None):\n",
    "            noise_x = K.clip(noise_x, -1.0, 1.0)\n",
    "        return K.in_train_phase(noise_x, x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale}\n",
    "        base_config = super(UniformNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FixedGaussianNoise(Layer):\n",
    "    def __init__(self, scale, size, clip = None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.uses_learning_phase = True\n",
    "        self.scale = scale\n",
    "        self.size = size\n",
    "        self.noise = None\n",
    "        super(FixedGaussianNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if (self.noise is None):\n",
    "            self.noise = K.variable(np.random.normal(0.0, self.scale, self.size))\n",
    "        \n",
    "        return x + self.noise[:x.shape[0]]\n",
    "        #return K.in_train_phase(x + self.noise[:x.shape[0]], x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale, 'size': self.size}\n",
    "        base_config = super(FixedGaussianNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FixedUniformNoise(Layer):\n",
    "    def __init__(self, scale, size, clip = None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.uses_learning_phase = True\n",
    "        self.scale = scale\n",
    "        self.size = size\n",
    "        self.noise = None\n",
    "        super(FixedUniformNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if (self.noise is None):\n",
    "            self.noise = K.variable(np.random.uniform(-self.scale, self.scale, self.size))\n",
    "        \n",
    "        return x + self.noise[:x.shape[0]]\n",
    "        #return K.in_train_phase(x + self.noise[:x.shape[0]], x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale, 'size': self.size}\n",
    "        base_config = super(FixedUniformNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_16 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)        (None, 1)             234081      input_16[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 234081\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_16 (Model)                 (None, 256)           0           input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_17 (Model)                 (None, 512, 1)        0           model_16[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1403554\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_16 (Model)                 (None, 256)           626049      input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_17 (Model)                 (None, 512, 1)        777505      model_16[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)        (None, 1)             0           model_17[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1637635\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import softmax, sigmoid\n",
    "\n",
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# we generate a new optimizer of the same kind for every model\n",
    "# we train\n",
    "def opti():\n",
    "    return Adam()\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 256\n",
    "\n",
    "\n",
    "tau = K.variable(1.0, name = 'temperature')\n",
    "anneal_rate = 0.02\n",
    "min_temperature = 0.1\n",
    "\n",
    "def annealed_tanh(y):\n",
    "    #noise = K.random_normal(K.shape(y), 0.0, 0.05)\n",
    "    #return K.tanh((y + noise) / tau)\n",
    "    return K.tanh(y / tau)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def encoder_residual_block(output_dim = 64, filt_size = 5, subsample = True):\n",
    "    def f(input):\n",
    "        stride = 1\n",
    "        if (subsample):\n",
    "            stride = 2\n",
    "        \n",
    "        conv1 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    conv1 = MaxPooling1D(2)(conv1)\n",
    "        #conv1 = SpatialDropout1D(0.1)(conv1)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        #conv2 = SpatialDropout1D(0.1)(conv2)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(output_dim, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    shortcut = MaxPooling1D(2)(shortcut)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        return LeakyReLU(0.3)(m)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def decoder_residual_block(output_dim = 64, filt_size = 5, upsample = True):\n",
    "    def f(input):\n",
    "        nfilts = output_dim\n",
    "        if (upsample):\n",
    "            nfilts = output_dim * 2\n",
    "\n",
    "        conv1 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(nfilts, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 bias = True)(input)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        r = LeakyReLU(0.3)(m)\n",
    "        if (upsample):\n",
    "            return PhaseShift1D(2)(r)\n",
    "        else:\n",
    "            return r\n",
    "    \n",
    "    return f\n",
    "#'''\n",
    "\n",
    "def hard_tanh(x):\n",
    "    return K.clip(x, -1.0, 1.0)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc_input = Input(shape = dim)\n",
    "    \n",
    "    # corrupt input slightly as a form of regularization\n",
    "    #enc = GaussianDropout(0.05, input_shape = dim)(enc_input)\n",
    "\n",
    "    # (512x1) => (512x48)\n",
    "    #enc = encoder_residual_block(48, 9, False)(enc_input)\n",
    "\n",
    "    # (512x48) => (256x48)\n",
    "    enc = encoder_residual_block(128, 5, True)(enc_input)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    enc = encoder_residual_block(128, 5, False)(enc)\n",
    "\n",
    "    # (256x48) => (128x48)\n",
    "    enc = encoder_residual_block(128, 5, False)(enc)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    enc = encoder_residual_block(128, 5, False)(enc)\n",
    "    \n",
    "    # (256x48) => (128x48)\n",
    "    #enc = encoder_residual_block(64, 5, True)(enc)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    #enc = encoder_residual_block(48, 5, False)(enc)\n",
    "\n",
    "    # (128x48) => (128)\n",
    "    enc = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'linear',\n",
    "                              bias = True)(enc)\n",
    "    enc = FixedGaussianNoise(scale = 3.0, size = (128, bottleneck_size, 1))(enc)\n",
    "    enc = Activation('tanh')(enc)\n",
    "    #enc = Lambda(annealed_tanh)(enc)\n",
    "\n",
    "    enc = Reshape((bottleneck_size,))(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #dec_input = Input(shape = (bottleneck_size, num_cats))\n",
    "    dec_input = Input(shape = (bottleneck_size,))\n",
    "    dec = Reshape((256, 1,))(dec_input)\n",
    "    \n",
    "    # (64x1) => (64x48)\n",
    "    #dec = decoder_residual_block(64, 5, False)(dec)\n",
    "    \n",
    "    # (64x48) => (128x48)\n",
    "    #dec = decoder_residual_block(48, 5, True)(dec)\n",
    "    \n",
    "    # (64x1) => (64x48)\n",
    "    dec = decoder_residual_block(128, 5, False)(dec)\n",
    "    \n",
    "    # (64x48) => (128x48)\n",
    "    dec = decoder_residual_block(128, 5, False)(dec)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    dec = decoder_residual_block(128, 5, False)(dec)\n",
    "    \n",
    "    # (128x48) => (256x48)\n",
    "    dec = decoder_residual_block(96, 5, True)(dec)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    #dec = decoder_residual_block(48, 9, False)(dec)\n",
    "\n",
    "    # (512x48) => (512x1)\n",
    "    dec = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'tanh',\n",
    "                              bias = True)(dec)\n",
    "    #dec = LeakyReLU(0.3)(dec)\n",
    "    \n",
    "    #dec = Reshape((WINDOW_SIZE,))(dec)\n",
    "    #dec = Dense(WINDOW_SIZE, activation = 'tanh', init = 'identity')(dec)\n",
    "    #dec = Reshape((WINDOW_SIZE, 1,))(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "\n",
    "    dsc.add(Convolution1D(48, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Flatten())\n",
    "    \n",
    "    dsc.add(Dense(64, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    dsc.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return dsc\n",
    "\n",
    "\n",
    "# construct autoencoder to be used in adversarial training (AAC - Adversarial AutoenCoder)\n",
    "# uhhhh... whoops i screwed up the acronym\n",
    "aac_input = Input(shape = input_dim)\n",
    "aac_enc, aac_dec = autoencoder_structure(input_dim)\n",
    "aac_embedding = aac_enc(aac_input)\n",
    "aac_reconstructed = aac_dec(aac_embedding)\n",
    "\n",
    "aac_autoencoder = Model(input = [aac_input], output = [aac_reconstructed])\n",
    "aac_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "\n",
    "\n",
    "# construct discriminator: regular\n",
    "regdsc_input_dim = (WINDOW_SIZE, 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(regdsc_input)\n",
    "aac_reg_label = regdsc_struct(aac_reconstructed)\n",
    "\n",
    "def code_sparsity_constraint(placeholder, code):\n",
    "    scaled = (code + 1.0) / 2.0\n",
    "    return K.mean(scaled, axis = -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def code_binary_constraint(placeholder, code):\n",
    "    return K.mean(K.abs(1.0 - K.abs(code)), axis = -1)\n",
    "\n",
    "def code_balance_constraint(placeholder, code):\n",
    "    var = K.var(code, axis = -1) + 0.001\n",
    "    return 1.0 / var\n",
    "    #return K.abs(K.sum(code, axis = -1)) / float(bottleneck_size)\n",
    "\n",
    "\n",
    "def code_laplacian_constraint(placeholder, code):\n",
    "    return K.mean(K.abs(code), axis = -1)\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [350.0, 1.0, 0.5]#, 0.5]\n",
    "n_discrim = 1\n",
    "n_code = 1\n",
    "lmult = len(loss_weights) - n_discrim - n_code\n",
    "\n",
    "\n",
    "make_trainable(aac_autoencoder, False)\n",
    "\n",
    "aac_discrim_reg = Model(input = [regdsc_input], output = [regdsc_label])\n",
    "aac_discrim_reg.compile(loss = ['binary_crossentropy'], optimizer = opti())\n",
    "aac_discrim_reg.summary()\n",
    "\n",
    "aac_autoencoder.summary()\n",
    "\n",
    "make_trainable(aac_discrim_reg, False)\n",
    "make_trainable(aac_autoencoder, True)\n",
    "model = Model(input = [aac_input], output = [aac_reconstructed] * lmult + \\\n",
    "                                            [aac_reg_label] + \\\n",
    "                                            [aac_embedding] * n_code)\n",
    "model.compile(loss = ['mean_squared_error', \\\n",
    "                      'binary_crossentropy', \\\n",
    "                      code_sparsity_constraint],#  code_variance],\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    #sciwav.write(prefix + \"_res_desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = BATCH_SIZE, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    \n",
    "    sciwav.write(prefix + \"_output.wav\", rate, recons.astype(np.int16))\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired)\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interleave two numpy arrays of the same size along the first axis\n",
    "def interleave(a, b):    \n",
    "    r = np.empty(a.shape)\n",
    "    r = np.repeat(r, 2, axis = 0)\n",
    "    \n",
    "    r[::2] = a\n",
    "    r[1::2] = b\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    1280: 0.323277175426  ['autoencoder not training'] 0.980000019073 \n",
      "    Terminating epoch early (don't wanna overfit!)\n",
      "\n",
      "    Total time for epoch: 14.0098059177s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 99.25% d_acc\n",
      "    Total time for evaluation: 1.35137414932s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4.0254 -2.09324\n",
      "    MSE:      154617.0\n",
      "    Avg err:  210.228\n",
      "    Total time for evaluation: 0.304653167725s\n",
      "\n",
      "Epoch 2:\n",
      "    1280: 0.523180782795  [10.124340 0.025354 1.250535] [10.124340 8.873805 1.250535] 0.248084321618"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-7043a0c35bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlmult\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_discrim\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# train discriminator(s) on what the autoencoder now generates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train autoencoder, if discriminator accuracy is greater than 70%\n",
    "        if (epoch > 0):\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            make_trainable(aac_discrim_reg, False)\n",
    "            \n",
    "            a_y = [batch] * lmult + \\\n",
    "                  [np.ones(nbatch)] * n_discrim + \\\n",
    "                  [np.zeros((nbatch, bottleneck_size))] * n_code\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # train discriminator(s) on what the autoencoder now generates\n",
    "        generated = aac_autoencoder.predict(batch)\n",
    "        discrim_batch_X = interleave(batch, generated)\n",
    "        discrim_batch_y = interleave(np.ones(nbatch), np.zeros(nbatch))\n",
    "        \n",
    "        make_trainable(aac_autoencoder, False)\n",
    "        make_trainable(aac_discrim_reg, True)\n",
    "        d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        if (epoch == 0 and d_loss < 0.2):\n",
    "            print \"\"\n",
    "            print lead + \"Terminating epoch early (don't wanna overfit!)\"\n",
    "            break\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau),\n",
    "            #K.set_value(tau, np.max([K.get_value(tau) * np.exp(-anneal_rate * (epoch + 1)), min_temperature]))\n",
    "            K.set_value(tau, np.max([K.get_value(tau) * (1 - anneal_rate), min_temperature]))\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "    d_X = np.concatenate((X_train[rows, :], generated))\n",
    "    d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "    d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                               d_X, d_y, verbose = False)\n",
    "\n",
    "    print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.save('model_reg_adversary.h5')\n",
    "aac_autoencoder.save('auto_reg_adversary.h5')\n",
    "aac_discrim_reg.save('discrim_reg_adversary.h5')\n",
    "\n",
    "import h5py\n",
    "f = h5py.File('model_reg_adversary.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D}\\n\\nmodel = load_model('model_reg_adversary.h5', objs)\\naac_autoencoder = load_model('auto_reg_adversary.h5', objs)\\naac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\\n\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D}\n",
    "\n",
    "model = load_model('model_reg_adversary.h5', objs)\n",
    "aac_autoencoder = load_model('auto_reg_adversary.h5', objs)\n",
    "aac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluated the discriminator: 65.5% d_acc\n"
     ]
    }
   ],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "d_X = np.concatenate((X_train[rows, :], generated))\n",
    "d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                           d_X, d_y, verbose = False)\n",
    "\n",
    "print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  4707.68 -2827.53\n",
      "./SA1.WAV  mse:  21083.6\n",
      "./SA1.WAV  avg err:  77.635\n",
      "(93, 512)\n",
      "93/93 [==============================] - 0s\n",
      "(93, 512, 1)\n",
      "(93, 512)\n",
      "Max/min desired: 2961.0 -3057.0\n",
      "Max/min recons:  3006.17 -2368.73\n",
      "./SX383.WAV  mse:  14399.1\n",
      "./SX383.WAV  avg err:  65.9646\n",
      "(181, 512)\n",
      "181/181 [==============================] - 0s     \n",
      "(181, 512, 1)\n",
      "(181, 512)\n",
      "Max/min desired: 24636.0 -20122.0\n",
      "Max/min recons:  20127.0 -14468.8\n",
      "./fiveYears.wav  mse:  5.30841e+06\n",
      "./fiveYears.wav  avg err:  1695.69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24636.0, -20122.0, 20126.951, -14468.784, 5308414.0, 1695.6877]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_reg_\", aac_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 12s    \n"
     ]
    }
   ],
   "source": [
    "all_embed = aac_enc.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalars = all_embed.flatten()\n",
    "log_scalars = np.log((scalars + 1.0) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e7c5ae850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = np.histogram(scalars, bins = 101)\n",
    "sample_hist_probs = hist[0].astype('float32')\n",
    "sample_hist_bins = hist[1].astype('float32')\n",
    "sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "sample_hist_width = 1 * (sample_hist_bins[1] - sample_hist_bins[0])\n",
    "sample_hist_centers = (sample_hist_bins[:-1] + sample_hist_bins[1:]) / 2\n",
    "plt.bar(sample_hist_centers, sample_hist_probs, align='center', width=sample_hist_width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(log_scalars, bins=100)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980528\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# we model the code as a zero-centered Laplacian distribution\n",
    "#beta = np.mean(np.abs(scalars))\n",
    "#print beta\n",
    "\n",
    "# we want to \"cut off\" at a certain probability\n",
    "#cutoff_p = 0.01\n",
    "#clipval = beta * math.log(1.0 / (2.0 * beta * cutoff_p))\n",
    "#if (clipval > 1.0): clipval = 1.0\n",
    "#print clipval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.000000 -0.937500 -0.875000 -0.812500 -0.750000 -0.687500 -0.625000\n",
      " -0.562500 -0.500000 -0.437500 -0.375000 -0.312500 -0.250000 -0.187500\n",
      " -0.125000 -0.062500 0.000000 0.062500 0.125000 0.187500 0.250000 0.312500\n",
      " 0.375000 0.437500 0.500000 0.562500 0.625000 0.687500 0.750000 0.812500\n",
      " 0.875000 0.937500 1.000000]\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "#bins = np.linspace(0.0, 1.0, 200)\n",
    "\n",
    "#bins = np.round(bins * 32.0).astype('int')\n",
    "#s = set(bins)\n",
    "#bins = np.array(sorted(list(s))) / 32.0\n",
    "#bins = (bins * 2.0 - 1.0) * clipval\n",
    "#print bins\n",
    "\n",
    "#print len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.WAV\")\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = aac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.972101 1.000000 0.999715 -1.000000 0.960690 -1.000000 -1.000000\n",
      " -0.999999 -0.955066 1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 -1.000000 0.999403 1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000 1.000000 1.000000\n",
      " 0.993895 -0.999926 0.999995 1.000000 1.000000 -1.000000 -1.000000 0.978342\n",
      " 1.000000 1.000000 0.999995 -1.000000 -0.011042 1.000000 1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 0.999998 1.000000 1.000000 0.998448\n",
      " -0.951313 1.000000 1.000000 -1.000000 -1.000000 -0.999891 -1.000000\n",
      " 1.000000 1.000000 -1.000000 1.000000 -1.000000 1.000000 -0.999967 0.995854\n",
      " 1.000000 0.999982 -1.000000 1.000000 1.000000 -1.000000 -0.967195\n",
      " -1.000000 1.000000 1.000000 1.000000 -1.000000 -0.727779 0.999993 0.785629\n",
      " -0.997460 1.000000 -1.000000 -1.000000 -0.994344 -0.974762 0.971130\n",
      " -1.000000 1.000000 1.000000 -1.000000 0.571754 0.999647 -1.000000 1.000000\n",
      " 1.000000 -0.999999 -1.000000 -1.000000 -0.999930 1.000000 -1.000000\n",
      " -1.000000 -1.000000 -0.999999 1.000000 1.000000 -1.000000 -0.999995\n",
      " 1.000000 1.000000 -0.999999 -1.000000 -0.996722 1.000000 -1.000000\n",
      " 0.999999 1.000000 -1.000000 1.000000 1.000000 -0.999926 1.000000 -1.000000\n",
      " 0.999984 1.000000 -1.000000 0.999998 1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 -0.990400 -1.000000 -1.000000 0.999996 1.000000\n",
      " -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " -0.979355 1.000000 -1.000000 1.000000 -0.999994 -1.000000 -1.000000\n",
      " 0.962432 0.998772 0.772024 -1.000000 1.000000 1.000000 -1.000000 0.996837\n",
      " -1.000000 -0.999901 -1.000000 -1.000000 1.000000 -0.021611 -1.000000\n",
      " 0.999662 -0.832763 -1.000000 0.392450 -1.000000 -1.000000 0.999991\n",
      " 1.000000 -1.000000 -0.835034 -0.909843 -0.999999 0.999998 -1.000000\n",
      " 1.000000 0.963549 -1.000000 1.000000 -0.999946 -1.000000 0.999998\n",
      " -0.999814 -1.000000 1.000000 -0.999996 -0.969879 0.999839 -1.000000\n",
      " -1.000000 -1.000000 1.000000 -1.000000 -1.000000 0.999983 -0.998822\n",
      " 1.000000 -1.000000 -0.999528 1.000000 -1.000000 1.000000 -1.000000\n",
      " 0.999570 1.000000 -0.389817 -0.394139 0.999628 -1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 -1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000 0.227931]\n",
      "[ 1  1  1 -1  1 -1 -1 -1 -1  1 -1  1  1  1  1  1 -1  1  1 -1 -1 -1  1 -1  1\n",
      "  1 -1  1 -1  1  1 -1  1 -1 -1 -1 -1  1  1  1 -1 -1 -1  1  1  1 -1  1  1  1\n",
      " -1 -1  1  1  1  1 -1  0  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1  1 -1  1  1  1\n",
      "  1 -1  1  1 -1 -1 -1 -1  1  1 -1  1 -1  1 -1  1  1  1 -1  1  1 -1 -1 -1  1\n",
      "  1  1 -1 -1  1  1 -1  1 -1 -1 -1 -1  1 -1  1  1 -1  1  1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1 -1 -1 -1  1  1 -1 -1  1  1 -1 -1 -1  1 -1  1  1 -1  1  1 -1  1 -1\n",
      "  1  1 -1  1  1 -1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1  1 -1 -1  1 -1  1\n",
      " -1 -1 -1  1  1  1 -1  1  1 -1  1 -1 -1 -1 -1  1  0 -1  1 -1 -1  0 -1 -1  1\n",
      "  1 -1 -1 -1 -1  1 -1  1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1  1 -1\n",
      " -1  1 -1  1 -1 -1  1 -1  1 -1  1  1  0  0  1 -1 -1  1  1 -1 -1  1 -1 -1 -1\n",
      "  1  1 -1 -1 -1  0]\n",
      "394\n",
      "[1.000000 1.000000 1.000000 -1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 -1.000000 1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000 1.000000 1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 1.000000 -1.000000 -1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 -1.000000 -0.000000 1.000000 1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 1.000000 -1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 1.000000 -1.000000 -1.000000 1.000000 1.000000\n",
      " -1.000000 1.000000 -1.000000 -1.000000 -1.000000 -1.000000 1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 -1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 -1.000000 -1.000000 -1.000000 1.000000 1.000000\n",
      " -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " -1.000000 1.000000 -1.000000 1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000\n",
      " -1.000000 -1.000000 -1.000000 -1.000000 1.000000 -0.000000 -1.000000\n",
      " 1.000000 -1.000000 -1.000000 0.000000 -1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 -1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 1.000000 -1.000000 -1.000000 1.000000\n",
      " -1.000000 -1.000000 1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " -1.000000 -1.000000 1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " 1.000000 -1.000000 -1.000000 1.000000 -1.000000 1.000000 -1.000000\n",
      " 1.000000 1.000000 -0.000000 -0.000000 1.000000 -1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 -1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000 0.000000]\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "print embed[0]\n",
    "\n",
    "r = np.round(r)\n",
    "\n",
    "qnt = r[0].astype('int')\n",
    "print qnt\n",
    "\n",
    "ent = 1\n",
    "nbits = ent\n",
    "for i in xrange(1, len(qnt)):\n",
    "    if (qnt[i] == qnt[i - 1]):\n",
    "        nbits += 1\n",
    "    else:\n",
    "        nbits += (ent + 1)\n",
    "print nbits\n",
    "    \n",
    "r = r * clipval\n",
    "\n",
    "\n",
    "print r[0]\n",
    "\n",
    "autoencOutput = aac_dec.predict(r, batch_size = BATCH_SIZE, verbose = 1)\n",
    "print autoencOutput.shape\n",
    "autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "\n",
    "print autoencOutput.shape\n",
    "recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "\n",
    "wav = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "wav = unpreprocessWaveform(wav, wparams)\n",
    "\n",
    "sciwav.write(\"tst_output_reg.wav\", rate, wav.astype(np.int16))\n",
    "\n",
    "idx = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.000000 0.000000 1.000000]\n",
      "[1667982  892018]\n",
      "[-1.000000 0.000000 1.000000]\n",
      "[0.651555 0.348445]\n",
      "0.932671204154\n"
     ]
    }
   ],
   "source": [
    "b = np.linspace(-1.0, 1.0, 3)\n",
    "print b\n",
    "\n",
    "h = np.histogram(scalars, bins = b)\n",
    "print h[0]\n",
    "print h[1]\n",
    "h = h[0].astype('float32')\n",
    "h = h / h.sum()\n",
    "print h\n",
    "\n",
    "entropy = 0\n",
    "for i in h:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
