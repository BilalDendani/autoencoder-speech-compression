{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n",
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA1.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX339.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1059.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1689.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX429.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX69.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX159.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI2319.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA2.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX249.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX221.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA1.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX41.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1751.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1725.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX401.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX24.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA2.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1121.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX131.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA1.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX336.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1236.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI606.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1866.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX156.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA2.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX426.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX246.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX66.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA1.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1233.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI603.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX333.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX153.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1863.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX243.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA2.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX423.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX63.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA1.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX434.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX74.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX254.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI1064.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX344.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX164.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA2.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI582.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI2324.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX82.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1041.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX442.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA1.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1702.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX262.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX172.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX352.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA2.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1072.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI669.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA1.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX39.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX309.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1929.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX129.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1299.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX219.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX399.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA2.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI2325.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX435.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX75.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA1.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1695.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX345.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1065.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX255.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX165.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA2.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI2290.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA1.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI650.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI1660.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX220.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX310.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX40.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX400.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA2.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX130.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX149.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA1.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI2309.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX419.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX239.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX329.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1679.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX59.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA2.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1049.WAV\r",
      "100: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI520.WAV\r",
      "101: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA1.WAV\r",
      "102: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX160.WAV\r",
      "103: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX340.WAV\r",
      "104: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI2035.WAV\r",
      "105: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX250.WAV\r",
      "106: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX430.WAV\r",
      "107: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX70.WAV\r",
      "108: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA2.WAV\r",
      "109: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI1780.WAV\r",
      "110: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA1.WAV\r",
      "111: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX65.WAV\r",
      "112: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX425.WAV\r",
      "113: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1685.WAV\r",
      "114: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1055.WAV\r",
      "115: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX335.WAV\r",
      "116: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA2.WAV\r",
      "117: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX245.WAV\r",
      "118: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI2315.WAV\r",
      "119: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX155.WAV\r",
      "120: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA1.WAV\r",
      "121: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX339.WAV\r",
      "122: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI879.WAV\r",
      "123: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX429.WAV\r",
      "124: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI1509.WAV\r",
      "125: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX69.WAV\r",
      "126: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX159.WAV\r",
      "127: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI2139.WAV\r",
      "128: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA2.WAV\r",
      "129: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX249.WAV\r",
      "130: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX166.WAV\r",
      "131: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA1.WAV\r",
      "132: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX346.WAV\r",
      "133: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI2326.WAV\r",
      "134: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1696.WAV\r",
      "135: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX256.WAV\r",
      "136: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1066.WAV\r",
      "137: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA2.WAV\r",
      "138: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX76.WAV\r",
      "139: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX436.WAV\r",
      "140: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX56.WAV\r",
      "141: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA1.WAV\r",
      "142: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI866.WAV\r",
      "143: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX146.WAV\r",
      "144: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX326.WAV\r",
      "145: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI2126.WAV\r",
      "146: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX416.WAV\r",
      "147: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX236.WAV\r",
      "148: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI1760.WAV\r",
      "149: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA2.WAV\r",
      "150: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX82.WAV\r",
      "151: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX442.WAV\r",
      "152: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA1.WAV\r",
      "153: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI2062.WAV\r",
      "154: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI1432.WAV\r",
      "155: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX262.WAV\r",
      "156: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI802.WAV\r",
      "157: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX172.WAV\r",
      "158: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX352.WAV\r",
      "159: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA2.WAV\r",
      "160: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX311.WAV\r",
      "161: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA1.WAV\r",
      "162: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI2274.WAV\r",
      "163: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX114.WAV\r",
      "164: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX384.WAV\r",
      "165: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX294.WAV\r",
      "166: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1014.WAV\r",
      "167: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA2.WAV\r",
      "168: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1644.WAV\r",
      "169: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX204.WAV\r",
      "170: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX42.WAV\r",
      "171: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX222.WAV\r",
      "172: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA1.WAV\r",
      "173: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX312.WAV\r",
      "174: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI1572.WAV\r",
      "175: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI942.WAV\r",
      "176: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX132.WAV\r",
      "177: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA2.WAV\r",
      "178: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI2202.WAV\r",
      "179: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX402.WAV\r",
      "180: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX149.WAV\r",
      "181: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA1.WAV\r",
      "182: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1949.WAV\r",
      "183: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI689.WAV\r",
      "184: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1319.WAV\r",
      "185: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX419.WAV\r",
      "186: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX239.WAV\r",
      "187: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX329.WAV\r",
      "188: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX59.WAV\r",
      "189: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA2.WAV\r",
      "190: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1187.WAV\r",
      "191: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX17.WAV\r",
      "192: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX107.WAV\r",
      "193: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA1.WAV\r",
      "194: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI630.WAV\r",
      "195: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1817.WAV\r",
      "196: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX287.WAV\r",
      "197: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX197.WAV\r",
      "198: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA2.WAV\r",
      "199: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX377.WAV\r",
      "200: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX248.WAV\r",
      "201: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX428.WAV\r",
      "202: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA1.WAV\r",
      "203: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI2318.WAV\r",
      "204: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX68.WAV\r",
      "205: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1058.WAV\r",
      "206: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX338.WAV\r",
      "207: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX158.WAV\r",
      "208: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1688.WAV\r",
      "209: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA2.WAV\r",
      "210: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI534.WAV\r",
      "211: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI1164.WAV\r",
      "212: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA1.WAV\r",
      "213: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX354.WAV\r",
      "214: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX174.WAV\r",
      "215: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX264.WAV\r",
      "216: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI797.WAV\r",
      "217: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX444.WAV\r",
      "218: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX84.WAV\r",
      "219: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA2.WAV\r",
      "220: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA1.WAV\r",
      "221: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX39.WAV\r",
      "222: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI2199.WAV\r",
      "223: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX309.WAV\r",
      "224: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI1569.WAV\r",
      "225: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX129.WAV\r",
      "226: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX219.WAV\r",
      "227: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI939.WAV\r",
      "228: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX399.WAV\r",
      "229: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA2.WAV\r",
      "230: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI1609.WAV\r",
      "231: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX30.WAV\r",
      "232: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX169.WAV\r",
      "233: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA1.WAV\r",
      "234: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX439.WAV\r",
      "235: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI979.WAV\r",
      "236: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX259.WAV\r",
      "237: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA2.WAV\r",
      "238: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI2239.WAV\r",
      "239: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX79.WAV\r",
      "240: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX42.WAV\r",
      "241: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX222.WAV\r",
      "242: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2112.WAV\r",
      "243: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA1.WAV\r",
      "244: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX312.WAV\r",
      "245: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2026.WAV\r",
      "246: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX132.WAV\r",
      "247: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA2.WAV\r",
      "248: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI1482.WAV\r",
      "249: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX402.WAV\r",
      "250: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX81.WAV\r",
      "251: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA1.WAV\r",
      "252: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX351.WAV\r",
      "253: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI2331.WAV\r",
      "254: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX27.WAV\r",
      "255: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1071.WAV\r",
      "256: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX441.WAV\r",
      "257: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX261.WAV\r",
      "258: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1701.WAV\r",
      "259: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA2.WAV\r",
      "260: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA1.WAV\r",
      "261: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX241.WAV\r",
      "262: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX331.WAV\r",
      "263: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX61.WAV\r",
      "264: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX151.WAV\r",
      "265: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1681.WAV\r",
      "266: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX421.WAV\r",
      "267: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI2311.WAV\r",
      "268: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA2.WAV\r",
      "269: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1051.WAV\r",
      "270: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX167.WAV\r",
      "271: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX437.WAV\r",
      "272: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA1.WAV\r",
      "273: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX77.WAV\r",
      "274: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX257.WAV\r",
      "275: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX347.WAV\r",
      "276: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI1607.WAV\r",
      "277: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA2.WAV\r",
      "278: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI977.WAV\r",
      "279: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI2237.WAV\r",
      "280: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI1485.WAV\r",
      "281: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA1.WAV\r",
      "282: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI855.WAV\r",
      "283: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX225.WAV\r",
      "284: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX405.WAV\r",
      "285: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA2.WAV\r",
      "286: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX45.WAV\r",
      "287: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX315.WAV\r",
      "288: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX135.WAV\r",
      "289: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI2115.WAV\r",
      "290: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1068.WAV\r",
      "291: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA1.WAV\r",
      "292: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX78.WAV\r",
      "293: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX202.WAV\r",
      "294: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX258.WAV\r",
      "295: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX168.WAV\r",
      "296: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1698.WAV\r",
      "297: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI2328.WAV\r",
      "298: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA2.WAV\r",
      "299: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX348.WAV\r",
      "300: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI579.WAV\r",
      "301: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA1.WAV\r",
      "302: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX39.WAV\r",
      "303: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX309.WAV\r",
      "304: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX129.WAV\r",
      "305: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX219.WAV\r",
      "306: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX399.WAV\r",
      "307: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1839.WAV\r",
      "308: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA2.WAV\r",
      "309: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1209.WAV\r",
      "310: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA1.WAV\r",
      "311: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX161.WAV\r",
      "312: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX71.WAV\r",
      "313: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX431.WAV\r",
      "314: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX341.WAV\r",
      "315: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI611.WAV\r",
      "316: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX251.WAV\r",
      "317: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1241.WAV\r",
      "318: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA2.WAV\r",
      "319: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1871.WAV\r",
      "320: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA1.WAV\r",
      "321: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX355.WAV\r",
      "322: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX445.WAV\r",
      "323: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX265.WAV\r",
      "324: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX85.WAV\r",
      "325: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1165.WAV\r",
      "326: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1802.WAV\r",
      "327: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX175.WAV\r",
      "328: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI535.WAV\r",
      "329: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA2.WAV\r",
      "330: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX62.WAV\r",
      "331: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI872.WAV\r",
      "332: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA1.WAV\r",
      "333: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI2132.WAV\r",
      "334: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI588.WAV\r",
      "335: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX152.WAV\r",
      "336: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX332.WAV\r",
      "337: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX242.WAV\r",
      "338: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA2.WAV\r",
      "339: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX422.WAV\r",
      "340: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA1.WAV\r",
      "341: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI1671.WAV\r",
      "342: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX321.WAV\r",
      "343: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2332.WAV\r",
      "344: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX141.WAV\r",
      "345: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX231.WAV\r",
      "346: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX411.WAV\r",
      "347: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX51.WAV\r",
      "348: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA2.WAV\r",
      "349: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2301.WAV\r",
      "350: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA1.WAV\r",
      "351: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX433.WAV\r",
      "352: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX343.WAV\r",
      "353: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX73.WAV\r",
      "354: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX163.WAV\r",
      "355: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI793.WAV\r",
      "356: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI1913.WAV\r",
      "357: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA2.WAV\r",
      "358: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX253.WAV\r",
      "359: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI2053.WAV\r",
      "360: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX234.WAV\r",
      "361: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA1.WAV\r",
      "362: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX324.WAV\r",
      "363: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2225.WAV\r",
      "364: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2304.WAV\r",
      "365: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI1674.WAV\r",
      "366: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX54.WAV\r",
      "367: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX414.WAV\r",
      "368: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX144.WAV\r",
      "369: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA2.WAV\r",
      "370: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA1.WAV\r",
      "371: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX235.WAV\r",
      "372: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX145.WAV\r",
      "373: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX55.WAV\r",
      "374: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX325.WAV\r",
      "375: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX415.WAV\r",
      "376: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI685.WAV\r",
      "377: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1315.WAV\r",
      "378: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA2.WAV\r",
      "379: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1945.WAV\r",
      "380: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA1.WAV\r",
      "381: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1295.WAV\r",
      "382: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI538.WAV\r",
      "383: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1798.WAV\r",
      "384: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX268.WAV\r",
      "385: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX178.WAV\r",
      "386: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA2.WAV\r",
      "387: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX448.WAV\r",
      "388: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX358.WAV\r",
      "389: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX88.WAV\r",
      "390: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX127.WAV\r",
      "391: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA1.WAV\r",
      "392: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX217.WAV\r",
      "393: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI847.WAV\r",
      "394: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX307.WAV\r",
      "395: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1477.WAV\r",
      "396: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX397.WAV\r",
      "397: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA2.WAV\r",
      "398: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX37.WAV\r",
      "399: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1313.WAV\r",
      "400: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA1.WAV\r",
      "401: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1005.WAV\r",
      "402: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX15.WAV\r",
      "403: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1342.WAV\r",
      "404: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX285.WAV\r",
      "405: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1635.WAV\r",
      "406: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX105.WAV\r",
      "407: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX195.WAV\r",
      "408: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA2.WAV\r",
      "409: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX375.WAV\r",
      "410: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI961.WAV\r",
      "411: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA1.WAV\r",
      "412: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX241.WAV\r",
      "413: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI1591.WAV\r",
      "414: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX331.WAV\r",
      "415: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX61.WAV\r",
      "416: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX151.WAV\r",
      "417: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX421.WAV\r",
      "418: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA2.WAV\r",
      "419: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI511.WAV\r",
      "420: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1251.WAV\r",
      "421: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX17.WAV\r",
      "422: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX107.WAV\r",
      "423: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA1.WAV\r",
      "424: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1457.WAV\r",
      "425: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX287.WAV\r",
      "426: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI827.WAV\r",
      "427: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX197.WAV\r",
      "428: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA2.WAV\r",
      "429: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX377.WAV\r",
      "430: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA1.WAV\r",
      "431: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1888.WAV\r",
      "432: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX268.WAV\r",
      "433: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI628.WAV\r",
      "434: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX178.WAV\r",
      "435: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA2.WAV\r",
      "436: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX448.WAV\r",
      "437: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX358.WAV\r",
      "438: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX88.WAV\r",
      "439: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1258.WAV\r",
      "440: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX157.WAV\r",
      "441: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA1.WAV\r",
      "442: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX337.WAV\r",
      "443: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX67.WAV\r",
      "444: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1687.WAV\r",
      "445: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI2317.WAV\r",
      "446: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX427.WAV\r",
      "447: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA2.WAV\r",
      "448: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1057.WAV\r",
      "449: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX247.WAV\r",
      "450: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA1.WAV\r",
      "451: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1170.WAV\r",
      "452: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX270.WAV\r",
      "453: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1800.WAV\r",
      "454: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX360.WAV\r",
      "455: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX450.WAV\r",
      "456: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX90.WAV\r",
      "457: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI540.WAV\r",
      "458: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA2.WAV\r",
      "459: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX180.WAV\r",
      "460: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX435.WAV\r",
      "461: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX75.WAV\r",
      "462: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA1.WAV\r",
      "463: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI1605.WAV\r",
      "464: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX345.WAV\r",
      "465: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX255.WAV\r",
      "466: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI975.WAV\r",
      "467: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX165.WAV\r",
      "468: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI2235.WAV\r",
      "469: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA2.WAV\r",
      "470: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI539.WAV\r",
      "471: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA1.WAV\r",
      "472: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1169.WAV\r",
      "473: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX359.WAV\r",
      "474: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX449.WAV\r",
      "475: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX179.WAV\r",
      "476: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX269.WAV\r",
      "477: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA2.WAV\r",
      "478: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1799.WAV\r",
      "479: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX89.WAV\r",
      "480: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA1.WAV\r",
      "481: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX32.WAV\r",
      "482: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX212.WAV\r",
      "483: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX392.WAV\r",
      "484: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1652.WAV\r",
      "485: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX302.WAV\r",
      "486: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX122.WAV\r",
      "487: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI2282.WAV\r",
      "488: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1022.WAV\r",
      "489: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA2.WAV\r",
      "490: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA1.WAV\r",
      "491: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX161.WAV\r",
      "492: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX217.WAV\r",
      "493: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1747.WAV\r",
      "494: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1117.WAV\r",
      "495: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX366.WAV\r",
      "496: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX397.WAV\r",
      "497: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA2.WAV\r",
      "498: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX37.WAV\r",
      "499: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI487.WAV\r",
      "500: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX237.WAV\r",
      "501: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SA1.WAV\r",
      "502: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX277.WAV\r",
      "503: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX147.WAV\r",
      "504: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI1137.WAV\r",
      "505: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX417.WAV\r",
      "506: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI507.WAV\r",
      "507: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI1767.WAV\r",
      "508: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SA2.WAV\r",
      "509: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX57.WAV\r",
      "510: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI882.WAV\r",
      "511: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SA1.WAV\r",
      "512: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX252.WAV\r",
      "513: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX342.WAV\r",
      "514: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI1512.WAV\r",
      "515: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI2142.WAV\r",
      "516: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX162.WAV\r",
      "517: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX72.WAV\r",
      "518: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX432.WAV\r",
      "519: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SA2.WAV\r",
      "520: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI1575.WAV\r",
      "521: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SA1.WAV\r",
      "522: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX225.WAV\r",
      "523: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX405.WAV\r",
      "524: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI945.WAV\r",
      "525: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SA2.WAV\r",
      "526: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX45.WAV\r",
      "527: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX315.WAV\r",
      "528: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX135.WAV\r",
      "529: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI2205.WAV\r",
      "530: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX62.WAV\r",
      "531: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SA1.WAV\r",
      "532: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI1682.WAV\r",
      "533: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX152.WAV\r",
      "534: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX332.WAV\r",
      "535: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI1052.WAV\r",
      "536: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX242.WAV\r",
      "537: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI2312.WAV\r",
      "538: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SA2.WAV\r",
      "539: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX422.WAV\r",
      "540: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SA1.WAV\r",
      "541: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX220.WAV\r",
      "542: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI850.WAV\r",
      "543: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI1480.WAV\r",
      "544: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX310.WAV\r",
      "545: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI2110.WAV\r",
      "546: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX40.WAV\r",
      "547: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX400.WAV\r",
      "548: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SA2.WAV\r",
      "549: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX130.WAV\r",
      "550: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI1234.WAV\r",
      "551: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX64.WAV\r",
      "552: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI604.WAV\r",
      "553: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SA1.WAV\r",
      "554: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI1864.WAV\r",
      "555: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX334.WAV\r",
      "556: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX244.WAV\r",
      "557: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX424.WAV\r",
      "558: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SA2.WAV\r",
      "559: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX154.WAV\r",
      "560: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI2267.WAV\r",
      "561: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX17.WAV\r",
      "562: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX107.WAV\r",
      "563: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SA1.WAV\r",
      "564: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI1007.WAV\r",
      "565: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX287.WAV\r",
      "566: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX197.WAV\r",
      "567: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SA2.WAV\r",
      "568: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI1637.WAV\r",
      "569: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX377.WAV\r",
      "570: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX149.WAV\r",
      "571: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SA1.WAV\r",
      "572: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI1589.WAV\r",
      "573: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX419.WAV\r",
      "574: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX239.WAV\r",
      "575: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX329.WAV\r",
      "576: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX59.WAV\r",
      "577: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI2219.WAV\r",
      "578: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI2216.WAV\r",
      "579: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SA2.WAV\r",
      "580: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI2281.WAV\r",
      "581: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SA1.WAV\r",
      "582: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX121.WAV\r",
      "583: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX391.WAV\r",
      "584: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI1021.WAV\r",
      "585: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX211.WAV\r",
      "586: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI1349.WAV\r",
      "587: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX301.WAV\r",
      "588: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SA2.WAV\r",
      "589: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX31.WAV\r",
      "590: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SA1.WAV\r",
      "591: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX241.WAV\r",
      "592: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI1771.WAV\r",
      "593: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX331.WAV\r",
      "594: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX61.WAV\r",
      "595: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI2221.WAV\r",
      "596: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX151.WAV\r",
      "597: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX421.WAV\r",
      "598: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SA2.WAV\r",
      "599: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI1141.WAV\r",
      "600: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SA1.WAV\r",
      "601: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX136.WAV\r",
      "602: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX406.WAV\r",
      "603: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI2206.WAV\r",
      "604: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI946.WAV\r",
      "605: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX316.WAV\r",
      "606: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX226.WAV\r",
      "607: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX46.WAV\r",
      "608: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI1576.WAV\r",
      "609: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SA2.WAV\r",
      "610: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SA1.WAV\r",
      "611: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX121.WAV\r",
      "612: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX391.WAV\r",
      "613: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX211.WAV\r",
      "614: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI2101.WAV\r",
      "615: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI1471.WAV\r",
      "616: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX301.WAV\r",
      "617: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SA2.WAV\r",
      "618: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI841.WAV\r",
      "619: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX31.WAV\r",
      "620: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI1443.WAV\r",
      "621: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SA1.WAV\r",
      "622: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX273.WAV\r",
      "623: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI2073.WAV\r",
      "624: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI1525.WAV\r",
      "625: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX183.WAV\r",
      "626: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX93.WAV\r",
      "627: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX3.WAV\r",
      "628: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SA2.WAV\r",
      "629: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX363.WAV\r",
      "630: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SA1.WAV\r",
      "631: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX270.WAV\r",
      "632: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI2340.WAV\r",
      "633: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX360.WAV\r",
      "634: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX450.WAV\r",
      "635: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX90.WAV\r",
      "636: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI1080.WAV\r",
      "637: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SA2.WAV\r",
      "638: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI1710.WAV\r",
      "639: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX180.WAV\r",
      "640: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX169.WAV\r",
      "641: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA1.WAV\r",
      "642: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX439.WAV\r",
      "643: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX259.WAV\r",
      "644: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI529.WAV\r",
      "645: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA2.WAV\r",
      "646: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX79.WAV\r",
      "647: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI1159.WAV\r",
      "648: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX349.WAV\r",
      "649: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI1789.WAV\r",
      "650: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SA1.WAV\r",
      "651: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX355.WAV\r",
      "652: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX445.WAV\r",
      "653: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX265.WAV\r",
      "654: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX85.WAV\r",
      "655: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI2144.WAV\r",
      "656: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX175.WAV\r",
      "657: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI2065.WAV\r",
      "658: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SA2.WAV\r",
      "659: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI1435.WAV\r",
      "660: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI2011.WAV\r",
      "661: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SA1.WAV\r",
      "662: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX121.WAV\r",
      "663: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX391.WAV\r",
      "664: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI661.WAV\r",
      "665: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX211.WAV\r",
      "666: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI1921.WAV\r",
      "667: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX301.WAV\r",
      "668: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SA2.WAV\r",
      "669: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX31.WAV\r",
      "670: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SA1.WAV\r",
      "671: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX32.WAV\r",
      "672: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI505.WAV\r",
      "673: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX212.WAV\r",
      "674: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX392.WAV\r",
      "675: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI757.WAV\r",
      "676: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX302.WAV\r",
      "677: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI2102.WAV\r",
      "678: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX122.WAV\r",
      "679: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SA2.WAV\r",
      "680: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX42.WAV\r",
      "681: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX222.WAV\r",
      "682: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SA1.WAV\r",
      "683: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX312.WAV\r",
      "684: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1694.WAV\r",
      "685: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1212.WAV\r",
      "686: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX132.WAV\r",
      "687: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SA2.WAV\r",
      "688: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1842.WAV\r",
      "689: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX402.WAV\r",
      "690: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX237.WAV\r",
      "691: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SA1.WAV\r",
      "692: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI2307.WAV\r",
      "693: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX147.WAV\r",
      "694: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX327.WAV\r",
      "695: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX417.WAV\r",
      "696: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI1047.WAV\r",
      "697: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SA2.WAV\r",
      "698: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI1677.WAV\r",
      "699: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX57.WAV\r",
      "700: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SA1.WAV\r",
      "701: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX160.WAV\r",
      "702: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX340.WAV\r",
      "703: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI2230.WAV\r",
      "704: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX250.WAV\r",
      "705: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX430.WAV\r",
      "706: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX70.WAV\r",
      "707: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SA2.WAV\r",
      "708: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI506.WAV\r",
      "709: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI1600.WAV\r",
      "710: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI682.WAV\r",
      "711: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SA1.WAV\r",
      "712: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI710.WAV\r",
      "713: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX434.WAV\r",
      "714: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX74.WAV\r",
      "715: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX254.WAV\r",
      "716: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI1604.WAV\r",
      "717: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX344.WAV\r",
      "718: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX164.WAV\r",
      "719: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SA2.WAV\r",
      "720: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA1.WAV\r",
      "721: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX336.WAV\r",
      "722: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1326.WAV\r",
      "723: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1956.WAV\r",
      "724: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1655.WAV\r",
      "725: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX156.WAV\r",
      "726: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA2.WAV\r",
      "727: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX426.WAV\r",
      "728: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX246.WAV\r",
      "729: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX66.WAV\r",
      "730: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SA1.WAV\r",
      "731: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX232.WAV\r",
      "732: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX142.WAV\r",
      "733: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX412.WAV\r",
      "734: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX52.WAV\r",
      "735: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1672.WAV\r",
      "736: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1705.WAV\r",
      "737: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1042.WAV\r",
      "738: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SA2.WAV\r",
      "739: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX322.WAV\r",
      "740: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX167.WAV\r",
      "741: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX17.WAV\r",
      "742: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX437.WAV\r",
      "743: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SA1.WAV\r",
      "744: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX77.WAV\r",
      "745: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI1787.WAV\r",
      "746: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX257.WAV\r",
      "747: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI527.WAV\r",
      "748: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI1157.WAV\r",
      "749: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SA2.WAV\r",
      "750: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX62.WAV\r",
      "751: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI612.WAV\r",
      "752: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SA1.WAV\r",
      "753: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI1772.WAV\r",
      "754: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI512.WAV\r",
      "755: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX152.WAV\r",
      "756: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX332.WAV\r",
      "757: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX242.WAV\r",
      "758: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SA2.WAV\r",
      "759: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX422.WAV\r",
      "760: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI1666.WAV\r",
      "761: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SA1.WAV\r",
      "762: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX136.WAV\r",
      "763: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX406.WAV\r",
      "764: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX316.WAV\r",
      "765: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX226.WAV\r",
      "766: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX46.WAV\r",
      "767: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI1036.WAV\r",
      "768: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SA2.WAV\r",
      "769: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI2296.WAV\r",
      "770: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA1.WAV\r",
      "771: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX240.WAV\r",
      "772: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI780.WAV\r",
      "773: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI1410.WAV\r",
      "774: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX60.WAV\r",
      "775: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI2040.WAV\r",
      "776: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA2.WAV\r",
      "777: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX420.WAV\r",
      "778: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX330.WAV\r",
      "779: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX150.WAV\r",
      "780: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI1763.WAV\r",
      "781: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SA1.WAV\r",
      "782: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX354.WAV\r",
      "783: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX174.WAV\r",
      "784: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI1434.WAV\r",
      "785: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX264.WAV\r",
      "786: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX444.WAV\r",
      "787: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX84.WAV\r",
      "788: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SA2.WAV\r",
      "789: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI804.WAV\r",
      "790: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SA1.WAV\r",
      "791: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI1102.WAV\r",
      "792: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI472.WAV\r",
      "793: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX112.WAV\r",
      "794: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX202.WAV\r",
      "795: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX22.WAV\r",
      "796: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX292.WAV\r",
      "797: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI1732.WAV\r",
      "798: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX382.WAV\r",
      "799: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SA2.WAV\r",
      "800: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SA1.WAV\r",
      "801: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI1291.WAV\r",
      "802: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX121.WAV\r",
      "803: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI1381.WAV\r",
      "804: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX391.WAV\r",
      "805: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX211.WAV\r",
      "806: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX301.WAV\r",
      "807: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SA2.WAV\r",
      "808: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI751.WAV\r",
      "809: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX31.WAV\r",
      "810: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX311.WAV\r",
      "811: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX221.WAV\r",
      "812: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI1844.WAV\r",
      "813: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA1.WAV\r",
      "814: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI1571.WAV\r",
      "815: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX41.WAV\r",
      "816: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI2201.WAV\r",
      "817: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX401.WAV\r",
      "818: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA2.WAV\r",
      "819: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX131.WAV\r",
      "820: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX248.WAV\r",
      "821: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX428.WAV\r",
      "822: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA1.WAV\r",
      "823: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX68.WAV\r",
      "824: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1778.WAV\r",
      "825: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI518.WAV\r",
      "826: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX338.WAV\r",
      "827: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1148.WAV\r",
      "828: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX158.WAV\r",
      "829: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA2.WAV\r",
      "830: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1779.WAV\r",
      "831: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SA1.WAV\r",
      "832: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1149.WAV\r",
      "833: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX339.WAV\r",
      "834: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX429.WAV\r",
      "835: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX69.WAV\r",
      "836: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX159.WAV\r",
      "837: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI2075.WAV\r",
      "838: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SA2.WAV\r",
      "839: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX249.WAV\r",
      "840: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX111.WAV\r",
      "841: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI921.WAV\r",
      "842: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA1.WAV\r",
      "843: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX21.WAV\r",
      "844: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX201.WAV\r",
      "845: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI1402.WAV\r",
      "846: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA2.WAV\r",
      "847: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI2181.WAV\r",
      "848: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX291.WAV\r",
      "849: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX381.WAV\r",
      "850: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX248.WAV\r",
      "851: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX428.WAV\r",
      "852: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SA1.WAV\r",
      "853: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX68.WAV\r",
      "854: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX338.WAV\r",
      "855: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX158.WAV\r",
      "856: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI1418.WAV\r",
      "857: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI788.WAV\r",
      "858: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SA2.WAV\r",
      "859: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI2048.WAV\r",
      "860: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX271.WAV\r",
      "861: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SA1.WAV\r",
      "862: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX91.WAV\r",
      "863: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX451.WAV\r",
      "864: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI991.WAV\r",
      "865: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX181.WAV\r",
      "866: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SA2.WAV\r",
      "867: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI2251.WAV\r",
      "868: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI1621.WAV\r",
      "869: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX361.WAV\r",
      "870: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX167.WAV\r",
      "871: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI1697.WAV\r",
      "872: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX437.WAV\r",
      "873: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA1.WAV\r",
      "874: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX77.WAV\r",
      "875: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX257.WAV\r",
      "876: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI2327.WAV\r",
      "877: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX24.WAV\r",
      "878: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA2.WAV\r",
      "879: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI1067.WAV\r",
      "880: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX234.WAV\r",
      "881: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SA1.WAV\r",
      "882: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX324.WAV\r",
      "883: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI774.WAV\r",
      "884: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI2034.WAV\r",
      "885: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI717.WAV\r",
      "886: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX54.WAV\r",
      "887: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX414.WAV\r",
      "888: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX144.WAV\r",
      "889: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SA2.WAV\r",
      "890: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SA1.WAV\r",
      "891: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI1192.WAV\r",
      "892: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX112.WAV\r",
      "893: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX202.WAV\r",
      "894: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX22.WAV\r",
      "895: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX292.WAV\r",
      "896: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI562.WAV\r",
      "897: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX382.WAV\r",
      "898: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI1822.WAV\r",
      "899: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SA2.WAV\r",
      "900: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI1554.WAV\r",
      "901: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SA1.WAV\r",
      "902: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX114.WAV\r",
      "903: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX384.WAV\r",
      "904: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX294.WAV\r",
      "905: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI675.WAV\r",
      "906: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI924.WAV\r",
      "907: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX24.WAV\r",
      "908: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SA2.WAV\r",
      "909: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX204.WAV\r",
      "910: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SA1.WAV\r",
      "911: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX114.WAV\r",
      "912: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX384.WAV\r",
      "913: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX294.WAV\r",
      "914: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI744.WAV\r",
      "915: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX24.WAV\r",
      "916: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI2004.WAV\r",
      "917: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI1374.WAV\r",
      "918: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SA2.WAV\r",
      "919: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX204.WAV\r",
      "920: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI2067.WAV\r",
      "921: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SA1.WAV\r",
      "922: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX87.WAV\r",
      "923: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX357.WAV\r",
      "924: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX447.WAV\r",
      "925: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX177.WAV\r",
      "926: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI1533.WAV\r",
      "927: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX267.WAV\r",
      "928: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SA2.WAV\r",
      "929: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI1437.WAV\r",
      "930: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX271.WAV\r",
      "931: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI1837.WAV\r",
      "932: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SA1.WAV\r",
      "933: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI1261.WAV\r",
      "934: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX91.WAV\r",
      "935: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI631.WAV\r",
      "936: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX451.WAV\r",
      "937: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX181.WAV\r",
      "938: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SA2.WAV\r",
      "939: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX361.WAV\r",
      "940: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI2036.WAV\r",
      "941: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX56.WAV\r",
      "942: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SA1.WAV\r",
      "943: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX146.WAV\r",
      "944: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX326.WAV\r",
      "945: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI1271.WAV\r",
      "946: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX416.WAV\r",
      "947: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX236.WAV\r",
      "948: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI1406.WAV\r",
      "949: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SA2.WAV\r",
      "950: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI798.WAV\r",
      "951: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SA1.WAV\r",
      "952: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX78.WAV\r",
      "953: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI2058.WAV\r",
      "954: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX258.WAV\r",
      "955: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX438.WAV\r",
      "956: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX168.WAV\r",
      "957: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SA2.WAV\r",
      "958: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI1428.WAV\r",
      "959: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX348.WAV\r",
      "960: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI792.WAV\r",
      "961: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SA1.WAV\r",
      "962: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX252.WAV\r",
      "963: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX342.WAV\r",
      "964: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI2052.WAV\r",
      "965: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX162.WAV\r",
      "966: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX72.WAV\r",
      "967: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX432.WAV\r",
      "968: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SA2.WAV\r",
      "969: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI1954.WAV\r",
      "970: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX127.WAV\r",
      "971: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA1.WAV\r",
      "972: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX217.WAV\r",
      "973: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI648.WAV\r",
      "974: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX307.WAV\r",
      "975: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1657.WAV\r",
      "976: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX397.WAV\r",
      "977: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA2.WAV\r",
      "978: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX37.WAV\r",
      "979: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1027.WAV\r",
      "980: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI1865.WAV\r",
      "981: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SA1.WAV\r",
      "982: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX65.WAV\r",
      "983: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX425.WAV\r",
      "984: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI605.WAV\r",
      "985: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI1235.WAV\r",
      "986: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX335.WAV\r",
      "987: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SA2.WAV\r",
      "988: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX245.WAV\r",
      "989: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX155.WAV\r",
      "990: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA1.WAV\r",
      "991: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI2096.WAV\r",
      "992: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX116.WAV\r",
      "993: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI836.WAV\r",
      "994: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX26.WAV\r",
      "995: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX386.WAV\r",
      "996: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI1466.WAV\r",
      "997: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA2.WAV\r",
      "998: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX206.WAV\r",
      "999: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX296.WAV\r"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):   \n",
    "    return waveform, ()\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    # scale window between -1 and 1\n",
    "    processed = np.copy(windows)\n",
    "   \n",
    "    mn = np.min(processed, axis = 1)\n",
    "    mx = np.max(processed, axis = 1)\n",
    "\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "\n",
    "    for i in xrange(0, processed.shape[0]):\n",
    "        processed[i] /= maxabs[i]\n",
    "    #processed *= 0.98\n",
    "   \n",
    "    #processed = (processed + 1.0) / 2.0\n",
    "   \n",
    "    return processed, (maxabs,)\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    # scale window from [-1, 1] to [-32768, 32768]\n",
    "    scl = params[0]\n",
    "   \n",
    "    unprocessed = np.copy(windows)\n",
    "    #unprocessed /= 0.98\n",
    "   \n",
    "    #nprocessed = (unprocessed * 2.0) - 1.0\n",
    "   \n",
    "    for i in xrange(0, unprocessed.shape[0]):\n",
    "        unprocessed[i] *= scl[i]\n",
    "\n",
    "    return unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(processedWaveforms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (101135, 512)\n",
      "Max:  17885.0\n",
      "Min:  -17139.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (101135, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101135, 512, 1)\n",
      "0.0179514\n",
      "0.286117\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Binarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Binarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(x)\n",
    "        z[0][z[0] < 0] = -1\n",
    "        z[0][z[0] >= 0] = 1\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        # (i don't think there's a mathematical justification for this?)\n",
    "        g = output_gradients[0]\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StochasticBinarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StochasticBinarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        prob_thresh = (x + 1.0) / 2.0\n",
    "        probs = np.random.random_sample(x.shape)\n",
    "        res = np.greater(probs, prob_thresh)\n",
    "        res = res.astype('float32') * 2.0 - 1.0\n",
    "        res = -res\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(res)\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged (since expected value\n",
    "        # is just x)\n",
    "        return [output_gradients[0]]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QuantizeProbabilities(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, num_bins):\n",
    "        super(QuantizeProbabilities, self).__init__()\n",
    "        self.num_bins = num_bins\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.round(x * (self.num_bins - 1)) / float(self.num_bins - 1)\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        #     \"straight-through\" estimator\n",
    "        g = output_gradients[0]\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotArgmax(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        super(OneHotArgmax, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        m = np.repeat(np.max(x, axis = 2).reshape(x.shape[0], x.shape[1], 1), x.shape[2], axis = 2)\n",
    "        one = x - m\n",
    "        one[one >= 0] = 1\n",
    "        one[one < 0] = 0\n",
    "        z[0] = one\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        g = output_gradients[0]\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PhaseShift1D(Layer):\n",
    "    \"\"\" PhaseShift1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShift1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShift1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UniformNoise(Layer):\n",
    "    def __init__(self, scale, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.scale = scale\n",
    "        self.uses_learning_phase = True\n",
    "        super(UniformNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        noise_x = x + K.random_uniform(shape = K.shape(x),\n",
    "                                       low = -self.scale,\n",
    "                                       high = self.scale)\n",
    "        return K.in_train_phase(noise_x, x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale}\n",
    "        base_config = super(UniformNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_76 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_19 (Sequential)       (None, 1)             234081      input_76[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 234081\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_73 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_91 (Model)                 (None, 128)           0           input_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_92 (Model)                 (None, 512, 1)        0           model_91[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 795618\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_73 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_91 (Model)                 (None, 128)           352801      input_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_92 (Model)                 (None, 512, 1)        442817      model_91[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "sequential_19 (Sequential)       (None, 1)             0           model_92[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1029699\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import softmax, sigmoid\n",
    "\n",
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# we generate a new optimizer of the same kind for every model\n",
    "# we train\n",
    "def opti():\n",
    "    return Adam()\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 128\n",
    "num_cats = 2\n",
    "\n",
    "# softmax \"upsampling\" initialization\n",
    "# identity matrix repeated, plus uniform noise\n",
    "def categorical_upsampling(input_dim, var_dim):\n",
    "    def init(shape, name = None):\n",
    "        assert(shape[-1] == input_dim * var_dim)\n",
    "        \n",
    "        random_additive = np.random.uniform(-0.1, 0.1, shape)\n",
    "        ident = np.eye(input_dim).repeat(var_dim, axis = 1)\n",
    "        random_multiplicative = np.random.normal(1.0, 0.1, shape)\n",
    "        \n",
    "        return K.variable(ident * random_multiplicative + random_additive)\n",
    "    \n",
    "    return init\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gumbel-Max sampling \n",
    "tau = K.variable(2.0, name=\"temperature\")\n",
    "anneal_rate = 0.01\n",
    "min_temperature = 0.1\n",
    "\n",
    "'''\n",
    "def sampling(logits_y):\n",
    "    u = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "    gumbel_noise = -K.log(-K.log(u + 1e-20) + 1e-20)\n",
    "\n",
    "    probs = K.sigmoid((gumbel_noise + logits_y) / tau)\n",
    "    return probs\n",
    "'''\n",
    "\n",
    "#discrete_values = K.variable([0.0, 1.0])\n",
    "def sampling(logits_y):\n",
    "    # gumbel noise\n",
    "    #u = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "    #gumbel_noise = -K.log(-K.log(u + 1e-20) + 1e-20)\n",
    "    \n",
    "    # calculate softmax probabilities and retrieve expected value\n",
    "    final_probs = softmax(K.reshape(logits_y, (-1, bottleneck_size, num_cats)) / tau)\n",
    "    \n",
    "    return final_probs\n",
    "    \n",
    "    # final output is expected value\n",
    "    #expected = T.dot(final_probs, discrete_values)\n",
    "    #return expected\n",
    "\n",
    "\n",
    "\n",
    "def encoder_residual_block(output_dim = 64, filt_size = 5, subsample = True):\n",
    "    def f(input):\n",
    "        stride = 1\n",
    "        #if (subsample):\n",
    "        #    stride = 2\n",
    "        \n",
    "        conv1 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          subsample_length = stride, bias = True)(input)\n",
    "        if (subsample):\n",
    "            conv1 = MaxPooling1D(2)(conv1)\n",
    "        #conv1 = SpatialDropout1D(0.1)(conv1)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        #conv2 = SpatialDropout1D(0.1)(conv2)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(output_dim, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 subsample_length = stride, bias = True)(input)\n",
    "        if (subsample):\n",
    "            shortcut = MaxPooling1D(2)(shortcut)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        return LeakyReLU(0.3)(m)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def decoder_residual_block(output_dim = 64, filt_size = 5, upsample = True):\n",
    "    def f(input):\n",
    "        nfilts = output_dim\n",
    "        if (upsample):\n",
    "            nfilts = output_dim * 2\n",
    "\n",
    "        conv1 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(nfilts, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 bias = True)(input)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        r = LeakyReLU(0.3)(m)\n",
    "        if (upsample):\n",
    "            return PhaseShift1D(2)(r)\n",
    "        else:\n",
    "            return r\n",
    "    \n",
    "    return f\n",
    "#'''\n",
    "\n",
    "def hard_tanh(x):\n",
    "    return K.clip(x, -1.0, 1.0)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc_input = Input(shape = dim)\n",
    "    \n",
    "    # corrupt input slightly as a form of regularization\n",
    "    #enc = GaussianDropout(0.05, input_shape = dim)(enc_input)\n",
    "\n",
    "    # (512x1) => (512x48)\n",
    "    #enc = encoder_residual_block(48, 9, False)(enc_input)\n",
    "\n",
    "    # (512x48) => (256x48)\n",
    "    enc = encoder_residual_block(96, 5, True)(enc_input)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    enc = encoder_residual_block(96, 5, False)(enc)\n",
    "\n",
    "    # (256x48) => (128x48)\n",
    "    enc = encoder_residual_block(96, 5, True)(enc)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    enc = encoder_residual_block(96, 5, False)(enc)\n",
    "\n",
    "    # (128x48) => (128)\n",
    "    enc = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'tanh',#'linear',\n",
    "                              bias = True)(enc)\n",
    "    #enc = LeakyReLU(0.3)(enc)\n",
    "    enc = Reshape((bottleneck_size,))(enc)\n",
    "    #enc = Dense(bottleneck_size, activation = 'sigmoid', init = 'identity')(enc)\n",
    "    #enc = Dense(bottleneck_size * num_cats,\n",
    "    #            init = categorical_upsampling(bottleneck_size, num_cats),\n",
    "    #            activation = 'linear')(enc)\n",
    "    #enc = (Lambda(sampling, output_shape=(bottleneck_size, num_cats)))(enc)\n",
    "    #enc = UniformNoise(1.0 / 32.0)(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #dec_input = Input(shape = (bottleneck_size, num_cats))\n",
    "    dec_input = Input(shape = (bottleneck_size,))\n",
    "    dec = Reshape((128, 1,))(dec_input)\n",
    "    #dec = UniformNoise(1.0 / 32.0)(dec)\n",
    "    \n",
    "    #dec = Convolution1D(1, 1, border_mode = 'same',\n",
    "    #                          init = 'he_uniform', activation = 'linear',\n",
    "    #                          bias = True)(dec_input)\n",
    "    \n",
    "    #dec = Reshape((128,))(dec)\n",
    "    #dec = Dense(bottleneck_size, activation = 'linear', init = 'identity')(dec_input)\n",
    "    #dec = LeakyReLU(0.3)(dec)\n",
    "    #dec = Reshape((128, 1,))(dec)\n",
    "    \n",
    "    # (64x1) => (64x48)\n",
    "    dec = decoder_residual_block(96, 5, False)(dec)\n",
    "    \n",
    "    # (64x48) => (128x48)\n",
    "    dec = decoder_residual_block(64, 5, True)(dec)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    dec = decoder_residual_block(96, 5, False)(dec)\n",
    "    \n",
    "    # (128x48) => (256x48)\n",
    "    dec = decoder_residual_block(64, 5, True)(dec)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    #dec = decoder_residual_block(48, 9, False)(dec)\n",
    "\n",
    "    # (512x48) => (512x1)\n",
    "    dec = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'tanh',\n",
    "                              bias = True)(dec)\n",
    "    #dec = LeakyReLU(0.3)(dec)\n",
    "    \n",
    "    #dec = Reshape((WINDOW_SIZE,))(dec)\n",
    "    #dec = Dense(WINDOW_SIZE, activation = 'tanh', init = 'identity')(dec)\n",
    "    #dec = Reshape((WINDOW_SIZE, 1,))(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "\n",
    "    dsc.add(Convolution1D(48, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Flatten())\n",
    "    \n",
    "    dsc.add(Dense(64, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    dsc.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return dsc\n",
    "\n",
    "\n",
    "# construct autoencoder to be used in adversarial training (AAC - Adversarial AutoenCoder)\n",
    "# uhhhh... whoops i screwed up the acronym\n",
    "aac_input = Input(shape = input_dim)\n",
    "aac_enc, aac_dec = autoencoder_structure(input_dim)\n",
    "aac_embedding = aac_enc(aac_input)\n",
    "#aac_embedding_quant = Lambda(lambda x : QuantizeProbabilities(4)(x))(aac_embedding)\n",
    "aac_reconstructed = aac_dec(aac_embedding)\n",
    "\n",
    "aac_autoencoder = Model(input = [aac_input], output = [aac_reconstructed])\n",
    "aac_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "\n",
    "\n",
    "# construct discriminator: regular\n",
    "regdsc_input_dim = (WINDOW_SIZE, 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(regdsc_input)\n",
    "aac_reg_label = regdsc_struct(aac_reconstructed)\n",
    "\n",
    "\n",
    "\n",
    "def prob_quantization_loss(placeholder, code):\n",
    "    loss = K.minimum(code, 1.0 - code)\n",
    "    loss_weight = 10.0\n",
    "\n",
    "    return K.switch(tau < 0.25, loss * loss_weight, \\\n",
    "                                K.zeros_like(code))\n",
    "\n",
    "\n",
    "def code_variance(placeholder, code):\n",
    "    #noise = K.random_uniform(K.shape(code), -(1.0 / 32.0), (1.0 / 32.0))\n",
    "    #return K.var(code + noise, axis = -1)\n",
    "    return K.mean(K.abs(code), axis = -1)\n",
    "\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [350.0, 1.0, 2.5]\n",
    "n_discrim = 1\n",
    "n_code = 1\n",
    "lmult = len(loss_weights) - n_discrim - n_code\n",
    "\n",
    "\n",
    "make_trainable(aac_autoencoder, False)\n",
    "\n",
    "aac_discrim_reg = Model(input = [regdsc_input], output = [regdsc_label])\n",
    "aac_discrim_reg.compile(loss = ['binary_crossentropy'], optimizer = opti())\n",
    "aac_discrim_reg.summary()\n",
    "\n",
    "aac_autoencoder.summary()\n",
    "\n",
    "make_trainable(aac_discrim_reg, False)\n",
    "make_trainable(aac_autoencoder, True)\n",
    "model = Model(input = [aac_input], output = [aac_reconstructed] * lmult + \\\n",
    "                                            [aac_reg_label] + \\\n",
    "                                            [aac_embedding] * n_code)\n",
    "model.compile(loss = ['mean_squared_error', \\\n",
    "                      'binary_crossentropy', \\\n",
    "                      code_variance],#  prob_quantization_loss],\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    #sciwav.write(prefix + \"_res_desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = BATCH_SIZE, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    \n",
    "    sciwav.write(prefix + \"_output.wav\", rate, recons.astype(np.int16))\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired)\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interleave two numpy arrays of the same size along the first axis\n",
    "def interleave(a, b):    \n",
    "    r = np.empty(a.shape)\n",
    "    r = np.repeat(r, 2, axis = 0)\n",
    "    \n",
    "    r[::2] = a\n",
    "    r[1::2] = b\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    1280: 0.250830620527  ['autoencoder not training'] \n",
      "    Terminating epoch early (don't wanna overfit!)\n",
      "\n",
      "    Total time for epoch: 13.2241749763s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 99.5% d_acc\n",
      "    Total time for evaluation: 1.24840807915s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  0.0014262 -0.00221186\n",
      "    MSE:      154618.0\n",
      "    Avg err:  210.222\n",
      "    Total time for evaluation: 0.234609127045s\n",
      "\n",
      "Epoch 2:\n",
      "    1280: 0.472931325436  [8.697842 0.021077 1.263557 0.022981] [8.697842 7.376831 1.263557 0.057453] \n",
      "    Total time for epoch: 703.877268076s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.75% d_acc\n",
      "    Total time for evaluation: 0.459809064865s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4291.25 -2666.68\n",
      "    MSE:      10135.6\n",
      "    Avg err:  48.1551\n",
      "    Total time for evaluation: 0.235558986664s\n",
      "\n",
      "Epoch 3:\n",
      "    1280: 0.57935833931  [5.986005 0.013807 1.077523 0.030401] [5.986005 4.832479 1.077523 0.076003] \n",
      "    Total time for epoch: 682.241165876s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 65.25% d_acc\n",
      "    Total time for evaluation: 0.461714029312s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4362.56 -3191.44\n",
      "    MSE:      9623.85\n",
      "    Avg err:  53.058\n",
      "    Total time for evaluation: 0.235266923904s\n",
      "\n",
      "Epoch 4:\n",
      "    1280: 0.494878321886  [6.114783 0.014450 0.985256 0.028828] [6.114783 5.057457 0.985256 0.072070] \n",
      "    Total time for epoch: 682.548367977s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 68.5% d_acc\n",
      "    Total time for evaluation: 0.461517810822s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4453.49 -3418.03\n",
      "    MSE:      6413.09\n",
      "    Avg err:  41.0552\n",
      "    Total time for evaluation: 0.233777999878s\n",
      "\n",
      "Epoch 5:\n",
      "    1280: 0.531789302826  [5.217951 0.012157 0.902855 0.024003] [5.217951 4.255089 0.902855 0.060007] \n",
      "    Total time for epoch: 683.344293118s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 74.25% d_acc\n",
      "    Total time for evaluation: 0.459996938705s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4404.93 -3201.98\n",
      "    MSE:      6469.68\n",
      "    Avg err:  40.1278\n",
      "    Total time for evaluation: 0.234167814255s\n",
      "\n",
      "Epoch 6:\n",
      "    1280: 0.530395746231  [5.745225 0.012165 1.430210 0.022959] [5.745225 4.257619 1.430210 0.057396] \n",
      "    Total time for epoch: 683.13251996s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 71.75% d_acc\n",
      "    Total time for evaluation: 0.462281942368s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4516.6 -3215.79\n",
      "    MSE:      6999.67\n",
      "    Avg err:  42.2952\n",
      "    Total time for evaluation: 0.235383033752s\n",
      "\n",
      "Epoch 7:\n",
      "    1280: 0.499804198742  [5.056562 0.011384 1.010767 0.024617] [5.056562 3.984253 1.010767 0.061542] \n",
      "    Total time for epoch: 683.342256069s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 64.5% d_acc\n",
      "    Total time for evaluation: 0.461796045303s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4637.84 -3448.35\n",
      "    MSE:      8090.77\n",
      "    Avg err:  44.6534\n",
      "    Total time for evaluation: 0.234126806259s\n",
      "\n",
      "Epoch 8:\n",
      "    1280: 0.544443190098  [5.223238 0.011299 1.210270 0.023340] [5.223238 3.954618 1.210270 0.058350]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-0c7b4a4ce5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlmult\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_discrim\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# train discriminator(s) on what the autoencoder now generates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train autoencoder, if discriminator accuracy is greater than 70%\n",
    "        if (epoch > 0):\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            make_trainable(aac_discrim_reg, False)\n",
    "            \n",
    "            a_y = [batch] * lmult + \\\n",
    "                  [np.ones(nbatch)] * n_discrim + \\\n",
    "                  [np.zeros((nbatch, bottleneck_size))] * n_code\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # train discriminator(s) on what the autoencoder now generates\n",
    "        generated = aac_autoencoder.predict(batch)\n",
    "        discrim_batch_X = interleave(batch, generated)\n",
    "        discrim_batch_y = interleave(np.ones(nbatch), np.zeros(nbatch))\n",
    "        \n",
    "        make_trainable(aac_autoencoder, False)\n",
    "        make_trainable(aac_discrim_reg, True)\n",
    "        d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        if (epoch == 0 and d_loss < 0.2):\n",
    "            print \"\"\n",
    "            print lead + \"Terminating epoch early (don't wanna overfit!)\"\n",
    "            break\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "            #print K.get_value(tau),\n",
    "            #K.set_value(tau, np.max([K.get_value(tau) * np.exp(-anneal_rate * (epoch + 1)), min_temperature]))\n",
    "            #K.set_value(tau, np.min([K.get_value(tau) * (1 + anneal_rate), max_temperature]))\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "    d_X = np.concatenate((X_train[rows, :], generated))\n",
    "    d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "    d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                               d_X, d_y, verbose = False)\n",
    "\n",
    "    print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"decoder_input = Input(shape = (bottleneck_size,))\\ndecoder_reconstructed = aac_dec(decoder_input)\\ndecoder_reg_label = regdsc_struct(decoder_reconstructed)\\n\\ndecoder = Model(input = [decoder_input], output = [decoder_reconstructed, decoder_reg_label])\\ndecoder.compile(loss = ['mean_squared_error', 'binary_crossentropy'],\\n              loss_weights = [350, 1],\\n              optimizer = Adam())\\ndecoder.summary()\\n\""
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''decoder_input = Input(shape = (bottleneck_size,))\n",
    "decoder_reconstructed = aac_dec(decoder_input)\n",
    "decoder_reg_label = regdsc_struct(decoder_reconstructed)\n",
    "\n",
    "decoder = Model(input = [decoder_input], output = [decoder_reconstructed, decoder_reg_label])\n",
    "decoder.compile(loss = ['mean_squared_error', 'binary_crossentropy'],\n",
    "              loss_weights = [350, 1],\n",
    "              optimizer = Adam())\n",
    "decoder.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nXc_train = aac_enc.predict(X_train, batch_size = BATCH_SIZE, verbose = 1)\\n'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Xc_train = aac_enc.predict(X_train, batch_size = BATCH_SIZE, verbose = 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUM_EPOCHS = 5\\n\\nlead = \"    \"\\nd_loss = 0.0\\na_losses = []\\nd_acc = 0.0\\ndiscrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\\n\\nfor epoch in range(NUM_EPOCHS):\\n    print \"Epoch \" + str(epoch + 1) + \":\"\\n\\n    # present batches randomly each epoch\\n    lis = range(0, ntrain, BATCH_SIZE)\\n    random.shuffle(lis)\\n    \\n    # keep track of start time and current batch #\\n    i = 0\\n    startTime = time.time()\\n    for idx in lis:\\n        batch_code = Xc_train[idx:idx+BATCH_SIZE, :]\\n        batch_recons = X_train[idx:idx+BATCH_SIZE, :, :]\\n        nbatch = batch_code.shape[0]\\n        \\n        a_losses = [\"autoencoder not training\"]\\n        d_loss = \"discriminator not training\"\\n        \\n        # train decoder\\n        make_trainable(aac_autoencoder, True)\\n        make_trainable(aac_discrim_reg, False)\\n\\n        a_y = [batch_recons, np.ones(nbatch)]\\n        a_losses = decoder.train_on_batch(batch_code, a_y)\\n        \\n        # train discriminator(s) on what the decoder now generates\\n        generated = aac_dec.predict(batch_code)\\n        discrim_batch_X = interleave(batch_recons, generated)\\n        discrim_batch_y = interleave(np.ones(nbatch), np.zeros(nbatch))\\n        \\n        make_trainable(aac_autoencoder, False)\\n        make_trainable(aac_discrim_reg, True)\\n        d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\\n        \\n        # print statistics every 10 batches so we know stuff is still going down\\n        if (i % 10 == 0):\\n            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\\n            print printStr,\\n            \\n            loss_arr = np.asarray(a_losses)\\n            print loss_arr,\\n            \\n            if (len(loss_arr) > 1):\\n                for i in xrange(0, len(loss_weights)):\\n                    loss_arr[i + 1] *= loss_weights[i]\\n                print loss_arr,\\n            \\n        i += 1\\n    print \"\"\\n    \\n    # print elapsed time for epoch\\n    elapsed = time.time() - startTime\\n    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\\n    \\n    \\n    # ---------------------------------------------------------\\n    # evaluate discriminator on random samples every epoch\\n    # ---------------------------------------------------------\\n    startTime = time.time()\\n    print lead + \"----------------\"\\n\\n    NUM = 200\\n    rows = np.random.randint(Xc_train.shape[0], size = NUM)\\n    generated = aac_dec.predict(Xc_train[rows, :], verbose = 0)\\n    d_X = np.concatenate((X_train[rows, :], generated))\\n    d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\\n    d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\\n                               d_X, d_y, verbose = False)\\n\\n    print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\\n    elapsed = time.time() - startTime\\n    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\\n    \\n    \\n    # ---------------------------------------------------------\\n    # evaluate autoencoder on real data every epoch\\n    # ---------------------------------------------------------\\n    startTime = time.time()\\n    print lead + \"----------------\"\\n    \\n    print lead + \"Evaluating autoencoder...\"\\n    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_dec_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\\n    \\n    print lead + \"Max/min desired:\", metrics[0], metrics[1]\\n    print lead + \"Max/min recons: \", metrics[2], metrics[3]\\n    print lead + \"MSE:     \", metrics[4]\\n    print lead + \"Avg err: \", metrics[5]\\n    elapsed = time.time() - startTime\\n    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\\n    \\n    print \"\"\\n'"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''NUM_EPOCHS = 5\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch_code = Xc_train[idx:idx+BATCH_SIZE, :]\n",
    "        batch_recons = X_train[idx:idx+BATCH_SIZE, :, :]\n",
    "        nbatch = batch_code.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train decoder\n",
    "        make_trainable(aac_autoencoder, True)\n",
    "        make_trainable(aac_discrim_reg, False)\n",
    "\n",
    "        a_y = [batch_recons, np.ones(nbatch)]\n",
    "        a_losses = decoder.train_on_batch(batch_code, a_y)\n",
    "        \n",
    "        # train discriminator(s) on what the decoder now generates\n",
    "        generated = aac_dec.predict(batch_code)\n",
    "        discrim_batch_X = interleave(batch_recons, generated)\n",
    "        discrim_batch_y = interleave(np.ones(nbatch), np.zeros(nbatch))\n",
    "        \n",
    "        make_trainable(aac_autoencoder, False)\n",
    "        make_trainable(aac_discrim_reg, True)\n",
    "        d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(Xc_train.shape[0], size = NUM)\n",
    "    generated = aac_dec.predict(Xc_train[rows, :], verbose = 0)\n",
    "    d_X = np.concatenate((X_train[rows, :], generated))\n",
    "    d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "    d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                               d_X, d_y, verbose = False)\n",
    "\n",
    "    print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_dec_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    print \"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('model_reg_adversary.h5')\n",
    "aac_autoencoder.save('auto_reg_adversary.h5')\n",
    "aac_discrim_reg.save('discrim_reg_adversary.h5')\n",
    "\n",
    "import h5py\n",
    "f = h5py.File('model_reg_adversary.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D}\\n\\nmodel = load_model('model_reg_adversary.h5', objs)\\naac_autoencoder = load_model('auto_reg_adversary.h5', objs)\\naac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\\n\""
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D}\n",
    "\n",
    "model = load_model('model_reg_adversary.h5', objs)\n",
    "aac_autoencoder = load_model('auto_reg_adversary.h5', objs)\n",
    "aac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluated the discriminator: 71.75% d_acc\n"
     ]
    }
   ],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "d_X = np.concatenate((X_train[rows, :], generated))\n",
    "d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                           d_X, d_y, verbose = False)\n",
    "\n",
    "print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  4568.22 -3226.72\n",
      "./SA1.WAV  mse:  6197.2\n",
      "./SA1.WAV  avg err:  38.2354\n",
      "(93, 512)\n",
      "93/93 [==============================] - 0s\n",
      "(93, 512, 1)\n",
      "(93, 512)\n",
      "Max/min desired: 2961.0 -3057.0\n",
      "Max/min recons:  2853.72 -2790.82\n",
      "./SX383.WAV  mse:  2483.68\n",
      "./SX383.WAV  avg err:  26.5283\n",
      "(181, 512)\n",
      "181/181 [==============================] - 0s     \n",
      "(181, 512, 1)\n",
      "(181, 512)\n",
      "Max/min desired: 24636.0 -20122.0\n",
      "Max/min recons:  22215.5 -16842.8\n",
      "./fiveYears.wav  mse:  1.68074e+06\n",
      "./fiveYears.wav  avg err:  912.661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24636.0, -20122.0, 22215.518, -16842.814, 1680739.5, 912.66064]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_reg_\", aac_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 11s    \n"
     ]
    }
   ],
   "source": [
    "all_embed = aac_enc.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalars = all_embed.flatten()\n",
    "log_scalars = np.log((scalars + 1.0) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3e136e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scalars, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0269749\n",
      "0.202982787391\n"
     ]
    }
   ],
   "source": [
    "# we model the code as a zero-centered Laplacian distribution\n",
    "beta = np.mean(np.abs(scalars))\n",
    "print beta\n",
    "\n",
    "# we want to \"cut off\" at a certain probability\n",
    "cutoff_p = 0.01\n",
    "clipval = beta * math.log(1.0 / (2.0 * beta * cutoff_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.202983 -0.190296 -0.177610 -0.164924 -0.152237 -0.139551 -0.126864\n",
      " -0.114178 -0.101491 -0.088805 -0.076119 -0.063432 -0.050746 -0.038059\n",
      " -0.025373 -0.012686 0.000000 0.012686 0.025373 0.038059 0.050746 0.063432\n",
      " 0.076119 0.088805 0.101491 0.114178 0.126864 0.139551 0.152237 0.164924\n",
      " 0.177610 0.190296 0.202983]\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-1.0, 1.0, 200)\n",
    "\n",
    "x = np.round(x * 16.0).astype('int')\n",
    "s = set(x)\n",
    "print np.array(sorted(list(s))) / 16.0 * clipval\n",
    "print len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.WAV\")\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = aac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.027550 0.027873 0.018470 0.004683 0.010108 0.017071 0.030624 0.089289\n",
      " 0.047530 0.042331 0.023023 0.010664 0.025311 0.024715 0.014613 0.034672\n",
      " 0.036772 0.009722 -0.012701 0.028977 0.044850 0.009954 0.035082 0.037520\n",
      " 0.041404 0.039259 0.012839 0.039504 0.034187 0.030872 0.042880 0.007132\n",
      " 0.013992 0.020762 0.004329 0.024389 0.016941 0.034748 0.037562 0.042275\n",
      " 0.021197 0.001990 0.020891 0.025046 0.017392 0.025063 0.042658 0.034171\n",
      " 0.023575 0.006082 0.033465 0.037905 0.025188 0.031877 0.029405 0.009219\n",
      " 0.006763 0.009305 0.021811 0.013534 0.023061 0.025335 0.012631 0.019037\n",
      " 0.010121 -0.006449 0.025745 0.027975 0.031157 0.017920 0.022020 0.021651\n",
      " 0.022787 0.029960 0.031593 0.028830 0.015962 0.025774 0.019685 0.014462\n",
      " 0.012405 0.012537 0.029675 0.006206 -0.019854 0.006510 0.008313 0.019259\n",
      " 0.008915 0.007336 0.002990 0.008133 0.019240 0.011899 0.003375 0.000958\n",
      " 0.006855 0.010411 0.006873 -0.004086 0.008285 0.007520 0.006569 0.008294\n",
      " 0.016877 0.027424 0.022403 0.016365 0.016074 0.024442 0.013426 0.003641\n",
      " 0.018351 0.001440 0.012077 0.012576 0.021806 0.010841 0.017188 0.035387\n",
      " 0.024190 0.017486 0.024505 0.019288 0.007934 0.003050 0.019975 0.005359]\n",
      "[0.025373 0.025373 0.012686 0.000000 0.012686 0.012686 0.025373 0.088805\n",
      " 0.050746 0.038059 0.025373 0.012686 0.025373 0.025373 0.012686 0.038059\n",
      " 0.038059 0.012686 -0.012686 0.025373 0.050746 0.012686 0.038059 0.038059\n",
      " 0.038059 0.038059 0.012686 0.038059 0.038059 0.025373 0.038059 0.012686\n",
      " 0.012686 0.025373 0.000000 0.025373 0.012686 0.038059 0.038059 0.038059\n",
      " 0.025373 0.000000 0.025373 0.025373 0.012686 0.025373 0.038059 0.038059\n",
      " 0.025373 0.000000 0.038059 0.038059 0.025373 0.038059 0.025373 0.012686\n",
      " 0.012686 0.012686 0.025373 0.012686 0.025373 0.025373 0.012686 0.025373\n",
      " 0.012686 -0.012686 0.025373 0.025373 0.025373 0.012686 0.025373 0.025373\n",
      " 0.025373 0.025373 0.025373 0.025373 0.012686 0.025373 0.025373 0.012686\n",
      " 0.012686 0.012686 0.025373 0.000000 -0.025373 0.012686 0.012686 0.025373\n",
      " 0.012686 0.012686 0.000000 0.012686 0.025373 0.012686 0.000000 0.000000\n",
      " 0.012686 0.012686 0.012686 -0.000000 0.012686 0.012686 0.012686 0.012686\n",
      " 0.012686 0.025373 0.025373 0.012686 0.012686 0.025373 0.012686 0.000000\n",
      " 0.012686 0.000000 0.012686 0.012686 0.025373 0.012686 0.012686 0.038059\n",
      " 0.025373 0.012686 0.025373 0.025373 0.012686 0.000000 0.025373 0.000000]\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "r = np.clip(embed, -clipval, clipval)\n",
    "r = r / clipval\n",
    "r = np.round(r * 16.0) / 16.0\n",
    "r = r * clipval\n",
    "\n",
    "print embed[0]\n",
    "print r[0]\n",
    "\n",
    "autoencOutput = aac_dec.predict(r, batch_size = BATCH_SIZE, verbose = 1)\n",
    "print autoencOutput.shape\n",
    "autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "\n",
    "print autoencOutput.shape\n",
    "recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "\n",
    "wav = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "wav = unpreprocessWaveform(wav, wparams)\n",
    "\n",
    "sciwav.write(\"tst_output_reg.wav\", rate, wav.astype(np.int16))\n",
    "\n",
    "idx = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.202983 -0.190296 -0.177610 -0.164924 -0.152237 -0.139551 -0.126864\n",
      " -0.114178 -0.101491 -0.088805 -0.076119 -0.063432 -0.050746 -0.038059\n",
      " -0.025373 -0.012686 0.000000 0.012686 0.025373 0.038059 0.050746 0.063432\n",
      " 0.076119 0.088805 0.101491 0.114178 0.126864 0.139551 0.152237 0.164924\n",
      " 0.177610 0.190296 0.202983]\n",
      "[0.060147 0.073918 0.094296 0.117947 0.156913 0.191309 0.259051 0.332968\n",
      " 0.422015 0.558426 0.787404 1.130253 1.837934 3.356547 7.350439 20.893339\n",
      " 14.823828 8.463401 5.545172 3.797150 2.646025 1.906850 1.380473 0.989766\n",
      " 0.710522 0.464563 0.237746 0.121590 0.057615 0.031802 0.016797 0.008213]\n",
      "[-0.202983 -0.190296 -0.177610 -0.164924 -0.152237 -0.139551 -0.126864\n",
      " -0.114178 -0.101491 -0.088805 -0.076119 -0.063432 -0.050746 -0.038059\n",
      " -0.025373 -0.012686 0.000000 0.012686 0.025373 0.038059 0.050746 0.063432\n",
      " 0.076119 0.088805 0.101491 0.114178 0.126864 0.139551 0.152237 0.164924\n",
      " 0.177610 0.190296 0.202983]\n",
      "[0.000763 0.000938 0.001196 0.001496 0.001991 0.002427 0.003286 0.004224\n",
      " 0.005354 0.007084 0.009989 0.014339 0.023317 0.042583 0.093251 0.265062\n",
      " 0.188061 0.107370 0.070348 0.048172 0.033569 0.024191 0.017513 0.012557\n",
      " 0.009014 0.005894 0.003016 0.001543 0.000731 0.000403 0.000213 0.000104]\n",
      "3.45046062873\n"
     ]
    }
   ],
   "source": [
    "b = np.linspace(-clipval, clipval, 33)\n",
    "print b\n",
    "\n",
    "h = np.histogram(scalars, bins = b, density = True)\n",
    "print h[0]\n",
    "print h[1]\n",
    "h = h[0]\n",
    "h = h / h.sum()\n",
    "print h\n",
    "\n",
    "entropy = 0\n",
    "for i in h:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.1588649245e-05\n",
      "0.0256761508959\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAFkCAYAAAC0KZhSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3dd78f110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import laplace\n",
    "\n",
    "param = laplace.fit(scalars[:10000])\n",
    "plt.hist(scalars, bins=200, normed = 1)\n",
    "\n",
    "x = np.linspace(-1.0, 1.0, num = 100)\n",
    "pdf_fitted = laplace.pdf(x, param[0], param[1])\n",
    "plt.plot(x, pdf_fitted * 2.0,'r-')\n",
    "\n",
    "print param[0]\n",
    "print param[1]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
