{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.    1.  ]\n",
      " [-0.75  1.  ]\n",
      " [-1.    0.5 ]]\n"
     ]
    }
   ],
   "source": [
    "s = np.array([[-2, 2], [-3, 4], [-12, 6]]).astype('float32')\n",
    "\n",
    "mn = np.min(s, axis = 1)\n",
    "mx = np.max(s, axis = 1)\n",
    "\n",
    "maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "\n",
    "for i in xrange(0, s.shape[0]):\n",
    "    s[i] /= maxabs[i]\n",
    "\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):   \n",
    "    return waveform, ()\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    # scale window between -1 and 1\n",
    "    processed = np.copy(windows)\n",
    "   \n",
    "    mn = np.min(processed, axis = 1)\n",
    "    mx = np.max(processed, axis = 1)\n",
    "\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "\n",
    "    for i in xrange(0, processed.shape[0]):\n",
    "        processed[i] /= maxabs[i]\n",
    "    processed *= 0.98\n",
    "   \n",
    "    #processed = (processed + 1.0) / 2.0\n",
    "   \n",
    "    return processed, (maxabs,)\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    # scale window from [-1, 1] to [-32768, 32768]\n",
    "    scl = params[0]\n",
    "   \n",
    "    unprocessed = np.copy(windows)\n",
    "    unprocessed /= 0.98\n",
    "   \n",
    "    #nprocessed = (unprocessed * 2.0) - 1.0\n",
    "   \n",
    "    for i in xrange(0, unprocessed.shape[0]):\n",
    "        unprocessed[i] *= scl[i]\n",
    "\n",
    "    return unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(processedWaveforms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (203086, 512)\n",
      "Max:  17885.0\n",
      "Min:  -17139.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (203086, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203086, 512, 1)\n",
      "0.0184928\n",
      "0.28096\n",
      "-0.98\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Binarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Binarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(x)\n",
    "        z[0][z[0] < 0] = -1\n",
    "        z[0][z[0] >= 0] = 1\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        # (i don't think there's a mathematical justification for this?)\n",
    "        g = output_gradients[0]\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StochasticBinarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StochasticBinarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        prob_thresh = (x + 1.0) / 2.0\n",
    "        probs = np.random.random_sample(x.shape)\n",
    "        res = np.greater(probs, prob_thresh)\n",
    "        res = res.astype('float32') * 2.0 - 1.0\n",
    "        res = -res\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(res)\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged (since expected value\n",
    "        # is just x)\n",
    "        return [output_gradients[0]]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.100000 0.000000 0.600000 0.900000]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.1, 0.5, 0.6, 0.9])\n",
    "\n",
    "a[(a > 0.2) & (a < 0.6)] = 0\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Quantize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Quantize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(x)\n",
    "        z[0][z[0] < -0.5] = -1\n",
    "        z[0][z[0] > 0.5] = 1\n",
    "        z[0][(z[0] > -0.5) & (z[0] < 0)] = 0.0\n",
    "        z[0][(z[0] < 0.5) & (z[0] >= 0)] = 0.0\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        #     \"straight-through\" estimator\n",
    "        g = output_gradients[0]\n",
    "        g = (g * (T.gt(g, -1) * T.lt(g, 1)))\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.982349 0.307907 -0.776469 -0.997820 0.691836 -0.615329]\n",
      " [0.112066 0.760906 -0.640342 -0.275526 -0.027226 -0.034462]\n",
      " [-0.942956 0.583716 0.611643 -0.457133 -0.214127 -0.681998]\n",
      " [0.630336 -0.317181 0.288090 0.894566 -0.352252 0.619418]\n",
      " [-0.174802 -0.091286 0.082802 0.272072 -0.439580 0.150305]\n",
      " [0.789294 0.785343 0.113989 -0.466960 -0.510564 -0.956677]]\n",
      "[[-1.000000 0.000000 -1.000000 -1.000000 1.000000 -1.000000]\n",
      " [0.000000 1.000000 -1.000000 0.000000 0.000000 0.000000]\n",
      " [-1.000000 1.000000 1.000000 0.000000 0.000000 -1.000000]\n",
      " [1.000000 0.000000 0.000000 1.000000 0.000000 1.000000]\n",
      " [0.000000 0.000000 0.000000 0.000000 0.000000 0.000000]\n",
      " [1.000000 1.000000 0.000000 0.000000 -1.000000 -1.000000]]\n"
     ]
    }
   ],
   "source": [
    "# verify Binarize op works\n",
    "x = T.matrix()\n",
    "f = theano.function([x], Quantize()(x))\n",
    "inp = np.random.uniform(high = 1, low = -1, size = (6, 6)).astype('float32')\n",
    "\n",
    "print(inp)\n",
    "print(f(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct as scidct\n",
    "\n",
    "# ====================================================================\n",
    "#  DCT (Discrete Cosine Transform)\n",
    "# ====================================================================\n",
    "\n",
    "# generate square dct matrix\n",
    "#     how to use: generate n-by-n matrix M. then, if you have a signal w, then:\n",
    "#                 dct(w) = M * w\n",
    "#     where w must be n-by-1\n",
    "#\n",
    "#     backed by scipy\n",
    "def generate_dct_mat(n, norm = 'ortho'):\n",
    "    return (scidct(np.eye(n), norm = norm))\n",
    "\n",
    "# DCT matrix is precomputed at start of program\n",
    "dctMat = generate_dct_mat(WINDOW_SIZE)\n",
    "th_dctMat = K.variable(dctMat)\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE\n",
    "#     this returns an array M x WINDOW_SIZE where every one of the M samples has been independently\n",
    "#     filtered by the DCT\n",
    "def theano_dct(x, dctMat = None):\n",
    "    global th_dctMat\n",
    "    \n",
    "    if (dctMat is None):\n",
    "        dctMat = th_dctMat\n",
    "        \n",
    "    # reshape x into 2D array, and perform appropriate matrix operation\n",
    "    reshaped_x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "\n",
    "    result = T.tensordot(dctMat, reshaped_x, [[0], [2]])\n",
    "    result = result.reshape((result.shape[0], result.shape[2])).T\n",
    "\n",
    "    return result\n",
    "\n",
    "# M x WINDOW_SIZE x 1 => M x WINDOW_SIZE x 1\n",
    "def theano_batch_dct(x):\n",
    "    result = theano_dct(x)\n",
    "    reshaped_result = result.reshape((result.shape[0], result.shape[1], 1))\n",
    "\n",
    "    return reshaped_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PhaseShift1D(Layer):\n",
    "    \"\"\" PhaseShift1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShift1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShift1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_36 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)        (None, 1)             114593      input_36[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 114593\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_33 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_36 (Model)                 (None, 128)           0           input_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_37 (Model)                 (None, 512, 1)        0           model_36[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 361570\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_33 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_36 (Model)                 (None, 128)           197473      input_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_37 (Model)                 (None, 512, 1)        164097      model_36[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)        (None, 1)             0           model_37[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 476163\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# we generate a new optimizer of the same kind for every model\n",
    "# we train\n",
    "def opti():\n",
    "    return Adam()\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 128\n",
    "\n",
    "def encoder_residual_block(output_dim = 64, filt_size = 5, subsample = True):\n",
    "    def f(input):\n",
    "        stride = 1\n",
    "        if (subsample):\n",
    "            stride = 2\n",
    "        \n",
    "        conv1 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    conv1 = MaxPooling1D(2)(conv1)\n",
    "        conv1 = SpatialDropout1D(0.1)(conv1)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        conv2 = SpatialDropout1D(0.1)(conv2)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(output_dim, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    shortcut = MaxPooling1D(2)(shortcut)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        return LeakyReLU(0.3)(m)\n",
    "    \n",
    "    return f\n",
    "\n",
    "'''\n",
    "def decoder_residual_block(output_dim = 64, filt_size = 5, upsample = True):\n",
    "    def f(input):\n",
    "        x = input\n",
    "        if (upsample):\n",
    "            x = UpSampling1D(2)(x)\n",
    "\n",
    "        conv1 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(x)\n",
    "        conv1 = SpatialDropout1D(0.1)(conv1)\n",
    "        act1 = LeakyReLU(0.2)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        conv2 = SpatialDropout1D(0.1)(conv2)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(output_dim, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 bias = True)(x)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        return LeakyReLU(0.2)(m)\n",
    "    \n",
    "    return f\n",
    "\n",
    "'''\n",
    "def decoder_residual_block(output_dim = 64, filt_size = 5, upsample = True):\n",
    "    def f(input):\n",
    "        nfilts = output_dim\n",
    "        if (upsample):\n",
    "            nfilts = output_dim * 2\n",
    "\n",
    "        conv1 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(nfilts, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 bias = True)(input)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        r = LeakyReLU(0.3)(m)\n",
    "        if (upsample):\n",
    "            return PhaseShift1D(2)(r)\n",
    "        else:\n",
    "            return r\n",
    "    \n",
    "    return f\n",
    "#'''\n",
    "\n",
    "def hard_tanh(x):\n",
    "    return K.clip(x, -1.0, 1.0)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc_input = Input(shape = dim)\n",
    "    \n",
    "    # corrupt input slightly as a form of regularization\n",
    "    #enc = GaussianDropout(0.05, input_shape = dim)(enc_input)\n",
    "\n",
    "    # (512x1) => (256x48)\n",
    "    enc = encoder_residual_block(48, 9, True)(enc_input)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    enc = encoder_residual_block(48, 9, False)(enc)\n",
    "\n",
    "    # (256x48) => (128x48)\n",
    "    enc = encoder_residual_block(48, 9, True)(enc)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    enc = encoder_residual_block(48, 9, False)(enc)\n",
    "\n",
    "    # (128x48) => (128x48)\n",
    "    enc = encoder_residual_block(48, 9, False)(enc)\n",
    "\n",
    "    # (64x64) => (64)\n",
    "    enc = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'tanh',\n",
    "                              bias = True)(enc)\n",
    "    enc = Reshape((bottleneck_size,))(enc)\n",
    "    enc = Lambda(lambda x : Quantize()(x))(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_input = Input(shape = (bottleneck_size,))\n",
    "    \n",
    "    dec = Reshape((128, 1,), input_shape = (bottleneck_size,))(dec_input)\n",
    "    \n",
    "    # (128x1) => (128x32)\n",
    "    dec = decoder_residual_block(32, 9, False)(dec)\n",
    "    \n",
    "    # (128x32) => (128x32)\n",
    "    dec = decoder_residual_block(32, 9, False)(dec)\n",
    "    \n",
    "    # (128x32) => (256x32)\n",
    "    dec = decoder_residual_block(32, 9, True)(dec)\n",
    "    \n",
    "    # (256x32) => (256x32)\n",
    "    dec = decoder_residual_block(32, 9, False)(dec)\n",
    "    \n",
    "    # (256x32) => (512x32)\n",
    "    dec = decoder_residual_block(32, 9, True)(dec)\n",
    "    \n",
    "    # (512x32) => (512x32)\n",
    "    #dec = decoder_residual_block(32, 9, False)(dec)\n",
    "\n",
    "    # (512x32) => (512x1)\n",
    "    dec = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'tanh',\n",
    "                              bias = True)(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "\n",
    "    dsc.add(Convolution1D(32, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Flatten())\n",
    "    \n",
    "    dsc.add(Dense(48, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    dsc.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return dsc\n",
    "\n",
    "\n",
    "# plain autoencoder\n",
    "'''\n",
    "plain_input = Input(shape = input_dim)\n",
    "plain_enc, plain_dec = autoencoder_structure(input_dim)\n",
    "plain_embedding = plain_enc(plain_input)\n",
    "plain_reconstructed = plain_dec(plain_embedding)\n",
    "plain_autoencoder = Model(input = [plain_input], output = [plain_reconstructed])\n",
    "plain_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "'''\n",
    "# construct autoencoder to be used in adversarial training (AAC - Adversarial AutoenCoder)\n",
    "# uhhhh... whoops i screwed up the acronym\n",
    "aac_input = Input(shape = input_dim)\n",
    "aac_enc, aac_dec = autoencoder_structure(input_dim)\n",
    "aac_embedding = aac_enc(aac_input)\n",
    "#aac_embedding_binarized = BinarizeLayer()(aac_embedding)\n",
    "aac_reconstructed = aac_dec(aac_embedding)\n",
    "\n",
    "aac_autoencoder = Model(input = [aac_input], output = [aac_reconstructed])\n",
    "aac_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "\n",
    "\n",
    "# construct discriminator 1: fft-based\n",
    "'''\n",
    "fft_transform = Lambda(theano_batch_dft,\n",
    "                       output_shape = lambda x : (x[0], x[1] * 2, 1))\n",
    "\n",
    "fftdsc_input_dim = (WINDOW_SIZE * 2, 1)\n",
    "fftdsc_input = Input(shape = input_dim)\n",
    "fftdsc_struct = discriminator_structure(fftdsc_input_dim)\n",
    "\n",
    "fftdsc_label = fftdsc_struct(fft_transform(fftdsc_input))\n",
    "aac_fft_label = fftdsc_struct(fft_transform(aac_reconstructed))\n",
    "'''\n",
    "\n",
    "\n",
    "# construct discriminator 2: regular\n",
    "regdsc_input_dim = (WINDOW_SIZE, 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(regdsc_input)\n",
    "aac_reg_label = regdsc_struct(aac_reconstructed)\n",
    "\n",
    "\n",
    "'''\n",
    "nlvls = 8\n",
    "haar_transform = Lambda(lambda x: haar_multilevel(x, nlvls, True),\n",
    "                        output_shape = lambda x : (x[0], x[1], nlvls + 1))\n",
    "regdsc_input_dim = (WINDOW_SIZE, nlvls + 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(haar_transform(regdsc_input))\n",
    "aac_reg_label = regdsc_struct(haar_transform(aac_reconstructed))\n",
    "'''\n",
    "\n",
    "'''\n",
    "dct_transform = Lambda(theano_batch_dct,\n",
    "                       output_shape = lambda x : (x[0], x[1], 1))\n",
    "regdsc_input_dim = (WINDOW_SIZE, 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(dct_transform(regdsc_input))\n",
    "aac_reg_label = regdsc_struct(dct_transform(aac_reconstructed))\n",
    "'''\n",
    "\n",
    "\n",
    "def code_binary_loss(placeholder, code):\n",
    "    #minim = K.minimum(1.0 - K.abs(code), K.abs(code))\n",
    "    return 1.0 - K.abs(code)\n",
    "\n",
    "def code_variance_loss(placeholder, code):\n",
    "    variance = T.var(code + 0.0001, axis = 1)\n",
    "    inverse_var = 1.0 / (variance + 0.0001)\n",
    "    return inverse_var\n",
    "\n",
    "\n",
    "def upper_dct_loss(y_true, y_pred):\n",
    "    dct_true = theano_batch_dct(y_true)\n",
    "    dct_pred = theano_batch_dct(y_pred)\n",
    "    cutoff_idx = WINDOW_SIZE / 4\n",
    "    \n",
    "    # compute MSE in frequency domain\n",
    "    error = T.mean(T.sqr(dct_pred[:, cutoff_idx:] - dct_true[:, cutoff_idx:]), axis = 1)\n",
    "    return error\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [100.0, 2.0]\n",
    "n_discrim = 1\n",
    "n_code = 0\n",
    "lmult = len(loss_weights) - n_discrim - n_code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "make_trainable(aac_autoencoder, False)\n",
    "\n",
    "aac_discrim_reg = Model(input = [regdsc_input], output = [regdsc_label])\n",
    "aac_discrim_reg.compile(loss = ['binary_crossentropy'], optimizer = opti())\n",
    "aac_discrim_reg.summary()\n",
    "\n",
    "aac_autoencoder.summary()\n",
    "\n",
    "make_trainable(aac_discrim_reg, False)\n",
    "make_trainable(aac_autoencoder, True)\n",
    "model = Model(input = [aac_input], output = [aac_reconstructed] * lmult + \\\n",
    "                                            [aac_reg_label] + \\\n",
    "                                            [aac_embedding] * n_code)\n",
    "model.compile(loss = ['mean_squared_error', \\\n",
    "                      'binary_crossentropy', \\\n",
    "                     ],\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    #sciwav.write(prefix + \"_res_desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = BATCH_SIZE, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    \n",
    "    sciwav.write(prefix + \"_output.wav\", rate, recons.astype(np.int16))\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired)\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interleave two numpy arrays of the same size along the first axis\n",
    "def interleave(a, b):    \n",
    "    r = np.empty(a.shape)\n",
    "    r = np.repeat(r, 2, axis = 0)\n",
    "    \n",
    "    r[::2] = a\n",
    "    r[1::2] = b\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    1280: 0.595627307892  [4.599453 0.029016 0.848931] [4.599453 2.901591 1.697861] \n",
      "    Total time for epoch: 750.664128065s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 61.75% d_acc\n",
      "    Total time for evaluation: 1.05848002434s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4699.44 -3884.86\n",
      "    MSE:      28102.0\n",
      "    Avg err:  84.6243\n",
      "    Total time for evaluation: 0.116758108139s\n",
      "\n",
      "Epoch 2:\n",
      "    1280: 0.647861242294  [3.860081 0.023943 0.732881] [3.860081 2.394320 1.465761] \n",
      "    Total time for epoch: 713.930218935s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 63.5% d_acc\n",
      "    Total time for evaluation: 0.260028839111s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4432.8 -3018.13\n",
      "    MSE:      21910.1\n",
      "    Avg err:  77.7952\n",
      "    Total time for evaluation: 0.116559028625s\n",
      "\n",
      "Epoch 3:\n",
      "    1280: 0.650050580502  [4.734525 0.028285 0.953011] [4.734525 2.828503 1.906021] \n",
      "    Total time for epoch: 712.864099026s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 63.75% d_acc\n",
      "    Total time for evaluation: 0.258384943008s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4777.89 -3552.23\n",
      "    MSE:      22862.7\n",
      "    Avg err:  80.0711\n",
      "    Total time for evaluation: 0.117583990097s\n",
      "\n",
      "Epoch 4:\n",
      "    1280: 0.624744296074  [4.672519 0.028230 0.924780] [4.672519 2.822959 1.849560]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-2bba4e48ebda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlmult\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_discrim\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# train discriminator(s) on what the autoencoder now generates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train autoencoder, if discriminator accuracy is greater than 70%\n",
    "        if (epoch >= 0):\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            make_trainable(aac_discrim_reg, False)\n",
    "            \n",
    "            a_y = [batch] * lmult + \\\n",
    "                  [np.ones(nbatch)] * n_discrim + \\\n",
    "                  [np.zeros((nbatch, bottleneck_size))] * n_code\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # train discriminator(s) on what the autoencoder now generates\n",
    "        generated = aac_autoencoder.predict(batch)\n",
    "        discrim_batch_X = interleave(batch, generated)\n",
    "        discrim_batch_y = interleave(np.ones(nbatch), np.zeros(nbatch))\n",
    "        \n",
    "        make_trainable(aac_autoencoder, False)\n",
    "        make_trainable(aac_discrim_reg, True)\n",
    "        d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        if (epoch < 0 and d_loss < 0.2):\n",
    "            print \"\"\n",
    "            print lead + \"Terminating epoch early (don't wanna overfit!)\"\n",
    "            break\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "    d_X = np.concatenate((X_train[rows, :], generated))\n",
    "    d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "    d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                               d_X, d_y, verbose = False)\n",
    "\n",
    "    print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.save('model_reg_adversary.h5')\n",
    "aac_autoencoder.save('auto_reg_adversary.h5')\n",
    "aac_discrim_reg.save('discrim_reg_adversary.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D,\\n        'BinarizeLayer' : BinarizeLayer,\\n        'code_binary_loss' : code_binary_loss,\\n        'code_maximize_variance' : code_maximize_variance}\\n\\nmodel = load_model('model_reg_adversary.h5', objs)\\naac_autoencoder = load_model('auto_reg_adversary.h5', objs)\\naac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\\n\""
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D,\n",
    "        'BinarizeLayer' : BinarizeLayer,\n",
    "        'code_binary_loss' : code_binary_loss,\n",
    "        'code_maximize_variance' : code_maximize_variance}\n",
    "\n",
    "model = load_model('model_reg_adversary.h5', objs)\n",
    "aac_autoencoder = load_model('auto_reg_adversary.h5', objs)\n",
    "aac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluated the discriminator: 63.875% d_acc\n"
     ]
    }
   ],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "d_X = np.concatenate((X_train[rows, :], generated))\n",
    "d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                           d_X, d_y, verbose = False)\n",
    "\n",
    "print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  4676.88 -3760.37\n",
      "./SA1.WAV  mse:  20706.7\n",
      "./SA1.WAV  avg err:  77.9277\n",
      "(93, 512)\n",
      "93/93 [==============================] - 0s\n",
      "(93, 512, 1)\n",
      "(93, 512)\n",
      "Max/min desired: 2961.0 -3057.0\n",
      "Max/min recons:  2939.12 -2749.06\n",
      "./SX383.WAV  mse:  12240.2\n",
      "./SX383.WAV  avg err:  63.4815\n",
      "(181, 512)\n",
      "181/181 [==============================] - 0s     \n",
      "(181, 512, 1)\n",
      "(181, 512)\n",
      "Max/min desired: 24636.0 -20122.0\n",
      "Max/min recons:  24965.3 -17999.2\n",
      "./fiveYears.wav  mse:  5.50814e+06\n",
      "./fiveYears.wav  avg err:  1735.32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24636.0, -20122.0, 24965.309, -17999.203, 5508137.0, 1735.325]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_reg_\", aac_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.WAV\")\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = aac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000 0.000000 1.000000 1.000000 1.000000 0.000000 -1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 -1.000000 1.000000 1.000000 0.000000\n",
      " 0.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 0.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 0.000000 0.000000 0.000000 -1.000000\n",
      " -1.000000 0.000000 0.000000 0.000000 1.000000 1.000000 0.000000 0.000000\n",
      " 0.000000 -1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 -1.000000 0.000000 1.000000 1.000000\n",
      " 1.000000 0.000000 -1.000000 -1.000000 -1.000000 0.000000 0.000000 0.000000\n",
      " 1.000000 1.000000 1.000000 0.000000 -1.000000 -1.000000 -1.000000 0.000000\n",
      " 0.000000 1.000000 1.000000 1.000000 1.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 1.000000 1.000000 1.000000 1.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 1.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000]\n"
     ]
    }
   ],
   "source": [
    "idx = 45\n",
    "\n",
    "e = np.sign(embed)\n",
    "\n",
    "for i in xrange(0, embed.shape[0]):\n",
    "    num_pos = np.count_nonzero(e[idx] > 0)\n",
    "    num_neg = e[idx].shape[0] - num_pos\n",
    "    \n",
    "print embed[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95744/203086 [=============>................] - ETA: 48s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-1fc38c4f9e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maac_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1184\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_embed = aac_enc.predict(X_train, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.636428, -1.654416]), array([0.115110, 1.393575])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "\n",
    "# generate 300 random points\n",
    "data = np.random.normal(0.0, 2.0, (300, 2))\n",
    "\n",
    "clust = kmedoids(data, [0, 1])\n",
    "clust.process()\n",
    "clust.get_medoids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.neighbors import KDTree, NearestNeighbors\n",
    "\n",
    "skip = 1\n",
    "codebooks = []\n",
    "for i in xrange(0, all_embed.shape[1], skip):\n",
    "    #km = MiniBatchKMeans(n_clusters = 16, batch_size = 128, verbose = 0)\n",
    "    #km.fit(all_embed[:, i:i+skip])\n",
    "    #kmeans.append(km)\n",
    "    dat = all_embed[:, i:i+skip]\n",
    "    rnd = dat[np.random.choice(dat.shape[0], 500, replace=False), :]\n",
    "    init = np.random.choice(500, 4, replace = False)\n",
    "    \n",
    "    clust = kmedoids(rnd, init)\n",
    "    clust.process()\n",
    "    medoids = clust.get_medoids()\n",
    "    \n",
    "    nn = KDTree(medoids)\n",
    "    codebooks.append(nn)\n",
    "    print i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "[[0.989762]]\n",
      "(112, 128)\n"
     ]
    }
   ],
   "source": [
    "print codebooks[0].data.shape\n",
    "print np.asarray(codebooks[0].data)\n",
    "\n",
    "quantized_embed = None\n",
    "\n",
    "for i in xrange(0, embed.shape[1], skip):\n",
    "    nn = codebooks[i / skip]\n",
    "    \n",
    "    part = embed[:, i:i+skip]\n",
    "    cluster_idxs = nn.query(part, 1, False)\n",
    "    cluster_idxs = list(cluster_idxs.flatten())\n",
    "    \n",
    "    quantized_part = [nn.data[j] for j in cluster_idxs]\n",
    "    quantized_part = np.array(quantized_part)\n",
    "    \n",
    "    if (quantized_embed is None):\n",
    "        quantized_embed = quantized_part\n",
    "    else:\n",
    "        quantized_embed = np.concatenate((quantized_embed, quantized_part), axis = 1)\n",
    "    \n",
    "print quantized_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "autoencOutput = aac_dec.predict(quantized_embed, batch_size = BATCH_SIZE, verbose = 1)\n",
    "print autoencOutput.shape\n",
    "autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "\n",
    "print autoencOutput.shape\n",
    "recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "\n",
    "wav = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "wav = unpreprocessWaveform(wav, wparams)\n",
    "    \n",
    "sciwav.write(\"tst_output_reg_quant.wav\", rate, wav.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "quantized_embed = np.round(embed * 8.0) / 8.0\n",
    "\n",
    "autoencOutput = aac_dec.predict(quantized_embed, batch_size = BATCH_SIZE, verbose = 1)\n",
    "print autoencOutput.shape\n",
    "autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "\n",
    "print autoencOutput.shape\n",
    "recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "\n",
    "wav = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "wav = unpreprocessWaveform(wav, wparams)\n",
    "    \n",
    "sciwav.write(\"tst_output_reg.wav\", rate, wav.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
