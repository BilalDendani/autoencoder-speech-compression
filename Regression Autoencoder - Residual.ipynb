{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):   \n",
    "    return waveform, ()\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    # scale window between -1 and 1\n",
    "    processed = np.copy(windows)\n",
    "   \n",
    "    mn = np.min(processed, axis = 1)\n",
    "    mx = np.max(processed, axis = 1)\n",
    "\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "\n",
    "    for i in xrange(0, processed.shape[0]):\n",
    "        processed[i] /= maxabs[i]\n",
    "    #processed *= 0.98\n",
    "   \n",
    "    #processed = (processed + 1.0) / 2.0\n",
    "   \n",
    "    return processed, (maxabs,)\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    # scale window from [-1, 1] to [-32768, 32768]\n",
    "    scl = params[0]\n",
    "   \n",
    "    unprocessed = np.copy(windows)\n",
    "    #unprocessed /= 0.98\n",
    "   \n",
    "    #nprocessed = (unprocessed * 2.0) - 1.0\n",
    "   \n",
    "    for i in xrange(0, unprocessed.shape[0]):\n",
    "        unprocessed[i] *= scl[i]\n",
    "\n",
    "    return unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(processedWaveforms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (101135, 512)\n",
      "Max:  17885.0\n",
      "Min:  -17139.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (101135, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101135, 512, 1)\n",
      "0.0179514\n",
      "0.286117\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PhaseShift1D(Layer):\n",
    "    \"\"\" PhaseShift1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShift1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShift1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UniformNoise(Layer):\n",
    "    def __init__(self, scale, clip = None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.scale = scale\n",
    "        self.clip = clip\n",
    "        self.uses_learning_phase = True\n",
    "        super(UniformNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        noise_x = x + K.random_uniform(shape = K.shape(x),\n",
    "                                       low = -self.scale,\n",
    "                                       high = self.scale)\n",
    "        if (self.clip is not None):\n",
    "            noise_x = K.clip(noise_x, -1.0, 1.0)\n",
    "        return K.in_train_phase(noise_x, x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale}\n",
    "        base_config = super(UniformNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FixedGaussianNoise(Layer):\n",
    "    def __init__(self, scale, size, clip = None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.uses_learning_phase = True\n",
    "        self.scale = scale\n",
    "        self.size = size\n",
    "        self.noise = None\n",
    "        super(FixedGaussianNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if (self.noise is None):\n",
    "            self.noise = K.variable(np.random.normal(0.0, self.scale, self.size))\n",
    "        \n",
    "        #return x + self.noise[:x.shape[0]]\n",
    "        return K.in_train_phase(x + self.noise[:x.shape[0]], x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale, 'size': self.size}\n",
    "        base_config = super(FixedGaussianNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FixedUniformNoise(Layer):\n",
    "    def __init__(self, scale, size, clip = None, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.uses_learning_phase = True\n",
    "        self.scale = scale\n",
    "        self.size = size\n",
    "        self.noise = None\n",
    "        super(FixedUniformNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if (self.noise is None):\n",
    "            self.noise = K.variable(np.random.uniform(-self.scale, self.scale, self.size))\n",
    "        \n",
    "        #return x + self.noise[:x.shape[0]]\n",
    "        return K.in_train_phase(x + self.noise[:x.shape[0]], x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale, 'size': self.size}\n",
    "        base_config = super(FixedUniformNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_50 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)       (None, 1)             234081      input_50[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 234081\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_47 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_56 (Model)                 (None, 256)           0           input_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_57 (Model)                 (None, 512, 1)        0           model_56[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1403554\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_47 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_56 (Model)                 (None, 256)           626049      input_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "model_57 (Model)                 (None, 512, 1)        777505      model_56[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)       (None, 1)             0           model_57[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1637635\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import softmax, sigmoid\n",
    "\n",
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# we generate a new optimizer of the same kind for every model\n",
    "# we train\n",
    "def opti():\n",
    "    return Adam()\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 256\n",
    "\n",
    "\n",
    "tau = K.variable(1.0, name = 'temperature')\n",
    "anneal_rate = 0.02\n",
    "min_temperature = 0.05\n",
    "\n",
    "\n",
    "fixed_uniform_noise = K.variable(np.random.normal(0.0, 1.0, (1024, bottleneck_size, 1)))\n",
    "fixed_gumbel_noise = -K.log(-K.log(fixed_uniform_noise + 1e-20) + 1e-20)\n",
    "\n",
    "def sampling(positive_logits):\n",
    "    probs = K.sigmoid((fixed_gumbel_noise[:positive_logits.shape[0]] + -positive_logits) / tau)\n",
    "    scaled = probs * 2.0 - 1.0\n",
    "    return scaled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def annealed_tanh(y):\n",
    "    #noise = K.random_normal(K.shape(y), 0.0, 0.05)\n",
    "    #return K.tanh((y + noise) / tau)\n",
    "    return K.tanh(y / tau)\n",
    "\n",
    "def piecewise_tanh(y):\n",
    "    #noise = K.random_normal(K.shape(y), 0.0, 0.05)\n",
    "    #return K.tanh((y + noise) / tau)\n",
    "    return (1.0 - tau) * K.sign(y) + tau * K.tanh(y)\n",
    "\n",
    "\n",
    "\n",
    "def encoder_residual_block(output_dim = 64, filt_size = 5, subsample = True):\n",
    "    def f(input):\n",
    "        stride = 1\n",
    "        if (subsample):\n",
    "            stride = 2\n",
    "        \n",
    "        conv1 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    conv1 = MaxPooling1D(2)(conv1)\n",
    "        #conv1 = SpatialDropout1D(0.1)(conv1)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        #conv2 = SpatialDropout1D(0.1)(conv2)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(output_dim, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    shortcut = MaxPooling1D(2)(shortcut)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        return LeakyReLU(0.3)(m)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def decoder_residual_block(output_dim = 64, filt_size = 5, upsample = True):\n",
    "    def f(input):\n",
    "        nfilts = output_dim\n",
    "        if (upsample):\n",
    "            nfilts = output_dim * 2\n",
    "\n",
    "        conv1 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(nfilts, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 bias = True)(input)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        r = LeakyReLU(0.3)(m)\n",
    "        if (upsample):\n",
    "            return PhaseShift1D(2)(r)\n",
    "        else:\n",
    "            return r\n",
    "    \n",
    "    return f\n",
    "#'''\n",
    "\n",
    "fixed_gaussian_noise = K.variable(np.random.normal(0.0, 1.0, (1024, bottleneck_size, 1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc_input = Input(shape = dim)\n",
    "    \n",
    "    # corrupt input slightly as a form of regularization\n",
    "    #enc = GaussianDropout(0.05, input_shape = dim)(enc_input)\n",
    "\n",
    "    # (512x1) => (512x48)\n",
    "    #enc = encoder_residual_block(48, 9, False)(enc_input)\n",
    "\n",
    "    # (512x48) => (256x48)\n",
    "    enc = encoder_residual_block(128, 5, True)(enc_input)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    enc = encoder_residual_block(128, 5, False)(enc)\n",
    "\n",
    "    # (256x48) => (128x48)\n",
    "    enc = encoder_residual_block(128, 5, False)(enc)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    enc = encoder_residual_block(128, 5, False)(enc)\n",
    "    \n",
    "    # (256x48) => (128x48)\n",
    "    #enc = encoder_residual_block(64, 5, True)(enc)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    #enc = encoder_residual_block(48, 5, False)(enc)\n",
    "\n",
    "    # (128x48) => (128)\n",
    "    enc = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'linear',\n",
    "                              bias = True)(enc)\n",
    "    #enc = FixedGaussianNoise(scale = 2.0, size = (128, bottleneck_size, 1))(enc)\n",
    "    #enc = Lambda(lambda x : x + fixed_gaussian_noise[:x.shape[0]] * (1.0 - tau) * 4.0)(enc)\n",
    "    #enc = Activation('tanh')(enc)\n",
    "    #enc = Lambda(piecewise_tanh)(enc)\n",
    "    enc = Activation('relu')(enc)\n",
    "    enc = Lambda(sampling)(enc)\n",
    "\n",
    "    enc = Reshape((bottleneck_size,))(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #dec_input = Input(shape = (bottleneck_size, num_cats))\n",
    "    dec_input = Input(shape = (bottleneck_size,))\n",
    "    dec = Reshape((256, 1,))(dec_input)\n",
    "    \n",
    "    # (64x1) => (64x48)\n",
    "    #dec = decoder_residual_block(64, 5, False)(dec)\n",
    "    \n",
    "    # (64x48) => (128x48)\n",
    "    #dec = decoder_residual_block(48, 5, True)(dec)\n",
    "    \n",
    "    # (64x1) => (64x48)\n",
    "    dec = decoder_residual_block(128, 5, False)(dec)\n",
    "    \n",
    "    # (64x48) => (128x48)\n",
    "    dec = decoder_residual_block(128, 5, False)(dec)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    dec = decoder_residual_block(128, 5, False)(dec)\n",
    "    \n",
    "    # (128x48) => (256x48)\n",
    "    dec = decoder_residual_block(96, 5, True)(dec)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    #dec = decoder_residual_block(48, 9, False)(dec)\n",
    "\n",
    "    # (512x48) => (512x1)\n",
    "    dec = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'tanh',\n",
    "                              bias = True)(dec)\n",
    "    #dec = LeakyReLU(0.3)(dec)\n",
    "    \n",
    "    #dec = Reshape((WINDOW_SIZE,))(dec)\n",
    "    #dec = Dense(WINDOW_SIZE, activation = 'tanh', init = 'identity')(dec)\n",
    "    #dec = Reshape((WINDOW_SIZE, 1,))(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "\n",
    "    dsc.add(Convolution1D(48, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(48, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Flatten())\n",
    "    \n",
    "    dsc.add(Dense(64, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    dsc.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return dsc\n",
    "\n",
    "\n",
    "# construct autoencoder to be used in adversarial training (AAC - Adversarial AutoenCoder)\n",
    "# uhhhh... whoops i screwed up the acronym\n",
    "aac_input = Input(shape = input_dim)\n",
    "aac_enc, aac_dec = autoencoder_structure(input_dim)\n",
    "aac_embedding = aac_enc(aac_input)\n",
    "aac_reconstructed = aac_dec(aac_embedding)\n",
    "\n",
    "aac_autoencoder = Model(input = [aac_input], output = [aac_reconstructed])\n",
    "aac_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "\n",
    "\n",
    "# construct discriminator: regular\n",
    "regdsc_input_dim = (WINDOW_SIZE, 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(regdsc_input)\n",
    "aac_reg_label = regdsc_struct(aac_reconstructed)\n",
    "\n",
    "def code_sparsity_constraint(placeholder, code):\n",
    "    scaled = (code + 1.0) / 2.0\n",
    "    return K.mean(scaled, axis = -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def code_binary_constraint(placeholder, code):\n",
    "    #scaled = (code + 1.0) / 2.0\n",
    "    #eps = 0.01\n",
    "    #entropy = -((scaled + eps) * K.log(scaled + eps) + ((1.0 + eps) - scaled) * K.log((1.0 + eps) - scaled))\n",
    "    scaled = (code + 1.0) / 2.0\n",
    "    entropy = K.minimum(K.abs(scaled), K.abs(1.0 - scaled))\n",
    "    return K.mean(entropy, axis = -1)\n",
    "\n",
    "def code_balance_constraint(placeholder, code):\n",
    "    var = K.var(K.sign(code), axis = -1) + 0.001\n",
    "    return 1.0 / var\n",
    "    #return K.abs(K.sum(code, axis = -1)) / float(bottleneck_size)\n",
    "\n",
    "\n",
    "def code_laplacian_constraint(placeholder, code):\n",
    "    return K.mean(K.abs(code), axis = -1)\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [400.0, 1.0, 0.5]#, 0.5]\n",
    "n_discrim = 1\n",
    "n_code = 1\n",
    "lmult = len(loss_weights) - n_discrim - n_code\n",
    "\n",
    "\n",
    "make_trainable(aac_autoencoder, False)\n",
    "\n",
    "aac_discrim_reg = Model(input = [regdsc_input], output = [regdsc_label])\n",
    "aac_discrim_reg.compile(loss = ['binary_crossentropy'], optimizer = opti())\n",
    "aac_discrim_reg.summary()\n",
    "\n",
    "aac_autoencoder.summary()\n",
    "\n",
    "make_trainable(aac_discrim_reg, False)\n",
    "make_trainable(aac_autoencoder, True)\n",
    "model = Model(input = [aac_input], output = [aac_reconstructed] * lmult + \\\n",
    "                                            [aac_reg_label] + \\\n",
    "                                            [aac_embedding] * n_code)\n",
    "model.compile(loss = ['mean_squared_error', \\\n",
    "                      'binary_crossentropy', \\\n",
    "                      code_balance_constraint],#  code_variance],\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    #sciwav.write(prefix + \"_res_desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = BATCH_SIZE, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    \n",
    "    sciwav.write(prefix + \"_output.wav\", rate, recons.astype(np.int16))\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired)\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interleave two numpy arrays of the same size along the first axis\n",
    "def interleave(a, b):    \n",
    "    r = np.empty(a.shape)\n",
    "    r = np.repeat(r, 2, axis = 0)\n",
    "    \n",
    "    r[::2] = a\n",
    "    r[1::2] = b\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    1280: nan  [ nan  nan  nan  nan] [ nan  nan  nan  nan] 0.980000019073"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-01f58c897f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlmult\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_discrim\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# train discriminator(s) on what the autoencoder now generates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train autoencoder, if discriminator accuracy is greater than 70%\n",
    "        if (epoch >= 0):\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            make_trainable(aac_discrim_reg, False)\n",
    "            \n",
    "            a_y = [batch] * lmult + \\\n",
    "                  [np.ones(nbatch)] * n_discrim + \\\n",
    "                  [np.zeros((nbatch, bottleneck_size))] * n_code\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # train discriminator(s) on what the autoencoder now generates\n",
    "        generated = aac_autoencoder.predict(batch)\n",
    "        discrim_batch_X = interleave(batch, generated)\n",
    "        discrim_batch_y = interleave(np.ones(nbatch), np.zeros(nbatch))\n",
    "        \n",
    "        make_trainable(aac_autoencoder, False)\n",
    "        make_trainable(aac_discrim_reg, True)\n",
    "        d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        if (epoch < 0 and d_loss < 0.2):\n",
    "            print \"\"\n",
    "            print lead + \"Terminating epoch early (don't wanna overfit!)\"\n",
    "            break\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau),\n",
    "            #K.set_value(tau, np.max([K.get_value(tau) * np.exp(-anneal_rate * (epoch + 1)), min_temperature]))\n",
    "            K.set_value(tau, np.max([K.get_value(tau) * (1 - anneal_rate), min_temperature]))\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "    d_X = np.concatenate((X_train[rows, :], generated))\n",
    "    d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "    d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                               d_X, d_y, verbose = False)\n",
    "\n",
    "    print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.save('model_reg_adversary.h5')\n",
    "aac_autoencoder.save('auto_reg_adversary.h5')\n",
    "aac_discrim_reg.save('discrim_reg_adversary.h5')\n",
    "\n",
    "import h5py\n",
    "\n",
    "f = h5py.File('model_reg_adversary.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D}\\n\\nmodel = load_model('model_reg_adversary.h5', objs)\\naac_autoencoder = load_model('auto_reg_adversary.h5', objs)\\naac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\\n\""
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D}\n",
    "\n",
    "model = load_model('model_reg_adversary.h5', objs)\n",
    "aac_autoencoder = load_model('auto_reg_adversary.h5', objs)\n",
    "aac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluated the discriminator: 0.0% d_acc\n"
     ]
    }
   ],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "d_X = np.concatenate((X_train[rows, :], generated))\n",
    "d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                           d_X, d_y, verbose = False)\n",
    "\n",
    "print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  nan nan\n",
      "./SA1.WAV  mse:  nan\n",
      "./SA1.WAV  avg err:  nan\n",
      "(93, 512)\n",
      "93/93 [==============================] - 0s\n",
      "(93, 512, 1)\n",
      "(93, 512)\n",
      "Max/min desired: 2961.0 -3057.0\n",
      "Max/min recons:  nan nan\n",
      "./SX383.WAV  mse:  nan\n",
      "./SX383.WAV  avg err:  nan\n",
      "(181, 512)\n",
      "181/181 [==============================] - 0s     \n",
      "(181, 512, 1)\n",
      "(181, 512)\n",
      "Max/min desired: 24636.0 -20122.0\n",
      "Max/min recons:  nan nan\n",
      "./fiveYears.wav  mse:  nan\n",
      "./fiveYears.wav  avg err:  nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24636.0, -20122.0, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_reg_\", aac_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 11s    \n"
     ]
    }
   ],
   "source": [
    "all_embed = aac_enc.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalars = all_embed.flatten()\n",
    "log_scalars = np.log((scalars + 1.0) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "range parameter must be finite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-5c94afea628a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_hist_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_hist_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_hist_probs\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_hist_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         raise ValueError(\n\u001b[0;32m--> 505\u001b[0;31m             'range parameter must be finite.')\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mmn\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: range parameter must be finite."
     ]
    }
   ],
   "source": [
    "hist = np.histogram(scalars, bins = 101)\n",
    "sample_hist_probs = hist[0].astype('float32')\n",
    "sample_hist_bins = hist[1].astype('float32')\n",
    "sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "sample_hist_width = 1 * (sample_hist_bins[1] - sample_hist_bins[0])\n",
    "sample_hist_centers = (sample_hist_bins[:-1] + sample_hist_bins[1:]) / 2\n",
    "plt.bar(sample_hist_centers, sample_hist_probs, align='center', width=sample_hist_width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.WAV\")\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = aac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.202473650238\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.0\n",
    "sm = 0.0\n",
    "\n",
    "for i in xrange(0, len(sample_hist_centers)):\n",
    "    x = sample_hist_centers[i]\n",
    "    y = sample_hist_probs[i]\n",
    "    \n",
    "    sm += y\n",
    "    threshold += (y * x)\n",
    "\n",
    "threshold /= sm\n",
    "print threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.998425 -0.925622 -0.999917 0.999859 -1.000000 -0.999999 -0.999334\n",
      " -0.432579 -0.997930 0.981757 -0.999975 -0.817680 1.000000 0.999339\n",
      " 1.000000 1.000000 -1.000000 0.999998 1.000000 -0.357459 -0.999999\n",
      " -1.000000 -0.896772 -0.999982 1.000000 1.000000 -1.000000 0.384032\n",
      " -1.000000 1.000000 0.999976 -0.999997 0.999959 -0.980950 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 1.000000 1.000000 0.999995 -0.957042\n",
      " -0.999759 1.000000 0.985498 -0.968378 -0.808738 -0.991490 0.999999\n",
      " 0.999996 0.993323 -0.999870 -0.999725 0.990928 1.000000 1.000000 -0.999914\n",
      " -0.523642 0.998885 -0.563618 0.970053 -0.999906 -1.000000 -1.000000\n",
      " 1.000000 0.987035 -0.999672 -1.000000 -1.000000 0.752478 -0.922935\n",
      " -0.999965 0.992295 0.999674 0.060056 -0.993040 0.999554 0.985485 -0.999781\n",
      " 0.997017 0.999992 -0.999990 -1.000000 0.999971 0.993696 0.994374 0.101210\n",
      " 0.858292 -0.852245 -0.761576 0.999996 0.998801 0.998892 -0.999996 0.999025\n",
      " 0.999955 -0.999943 -0.999943 -1.000000 1.000000 0.956109 0.999994 0.999803\n",
      " -0.774294 0.996137 -0.530790 1.000000 0.999979 -0.999999 0.892846\n",
      " -1.000000 -0.991665 -0.999995 -0.999999 1.000000 -1.000000 0.991883\n",
      " 1.000000 -1.000000 0.985068 1.000000 1.000000 0.999968 -0.997880 -0.910176\n",
      " -0.999999 -0.857478 0.999763 -0.543564 -1.000000 -1.000000 0.999995\n",
      " 0.696847 -0.999954 0.651903 -0.973586 0.999867 -0.998258 0.497715 0.999970\n",
      " -0.448495 -0.999967 1.000000 0.896246 -0.987308 0.179139 0.999996\n",
      " -0.953672 0.829352 0.998473 1.000000 -0.239532 -0.999985 0.996654 0.999707\n",
      " -0.988730 -0.551650 -0.999980 -0.977186 0.999569 0.771228 -1.000000\n",
      " 1.000000 -0.999996 0.606924 0.999973 -1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 -0.997168 0.625667 0.904439 1.000000 0.999989 -0.999999\n",
      " 0.592816 -0.999949 0.999870 -1.000000 -1.000000 0.999999 -0.981212\n",
      " 1.000000 -0.999373 -0.999799 -0.807264 -0.999999 -0.988871 0.999109\n",
      " -0.998287 -0.874427 0.949805 -0.984229 0.999990 0.998659 -0.999996\n",
      " -1.000000 -0.968336 0.999509 1.000000 -0.791918 0.994637 -1.000000\n",
      " 0.992240 -0.999999 0.993708 0.999418 0.999998 0.999882 -0.021798 0.968283\n",
      " 0.999985 0.990069 0.289561 1.000000 -0.999025 0.999999 1.000000 -0.999029\n",
      " -1.000000 -0.999999 1.000000 0.734895 -1.000000 -0.999995 -0.700438\n",
      " -0.252930 -0.996167 -1.000000 0.987567 -0.999994 1.000000 -1.000000\n",
      " -0.997210 0.999891 0.997367 0.999996 1.000000 0.257958 -0.999813 1.000000\n",
      " 0.999999 -1.000000 0.983899 1.000000 -0.999983 -0.999997 -0.999993\n",
      " 0.997471 -0.471610 0.999925 0.999020 -0.999986 -0.994593]\n",
      "[-1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1  1  1  1  1 -1  1  1 -1 -1 -1 -1 -1  1\n",
      "  1 -1  1 -1  1  1 -1  1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1 -1 -1 -1  1  1\n",
      "  1 -1 -1  1  1  1 -1 -1  1 -1  1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1  1  1  1\n",
      " -1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1 -1  1\n",
      "  1  1  1 -1  1 -1  1  1 -1  1 -1 -1 -1 -1  1 -1  1  1 -1  1  1  1  1 -1 -1\n",
      " -1 -1  1 -1 -1 -1  1  1 -1  1 -1  1 -1  1  1 -1 -1  1  1 -1  1  1 -1  1  1\n",
      "  1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1  1 -1  1  1 -1 -1 -1 -1  1 -1  1  1  1\n",
      "  1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1 -1  1 -1  1  1 -1 -1 -1\n",
      "  1  1 -1  1 -1  1 -1  1  1  1  1 -1  1  1  1  1  1 -1  1  1 -1 -1 -1  1  1\n",
      " -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1  1  1  1  1 -1  1  1 -1  1  1 -1 -1 -1\n",
      "  1 -1  1  1 -1 -1]\n",
      "[-1.000000 -1.000000 -1.000000 1.000000 -1.000000 -1.000000 -1.000000\n",
      " -1.000000 -1.000000 1.000000 -1.000000 -1.000000 1.000000 1.000000\n",
      " 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 1.000000 1.000000 1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000 1.000000\n",
      " 1.000000 1.000000 -1.000000 -1.000000 1.000000 1.000000 1.000000 -1.000000\n",
      " -1.000000 1.000000 -1.000000 1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000\n",
      " 1.000000 1.000000 -1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " 1.000000 -1.000000 -1.000000 1.000000 1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 -1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000\n",
      " -1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000\n",
      " -1.000000 -1.000000 -1.000000 -1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000 -1.000000 -1.000000\n",
      " -1.000000 -1.000000 1.000000 -1.000000 -1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 1.000000 -1.000000 1.000000 -1.000000 1.000000 1.000000\n",
      " -1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000 1.000000\n",
      " -1.000000 1.000000 1.000000 1.000000 -1.000000 -1.000000 1.000000 1.000000\n",
      " -1.000000 -1.000000 -1.000000 -1.000000 1.000000 1.000000 -1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000\n",
      " -1.000000 1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000 -1.000000\n",
      " 1.000000 -1.000000 1.000000 -1.000000 -1.000000 1.000000 -1.000000\n",
      " 1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 1.000000\n",
      " -1.000000 -1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000\n",
      " -1.000000 -1.000000 1.000000 1.000000 -1.000000 1.000000 -1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 1.000000 1.000000 1.000000 -1.000000 1.000000 1.000000 -1.000000\n",
      " -1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000\n",
      " -1.000000 -1.000000 -1.000000 1.000000 -1.000000 1.000000 -1.000000\n",
      " -1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 -1.000000 1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000 -1.000000\n",
      " 1.000000 -1.000000 1.000000 1.000000 -1.000000 -1.000000]\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "print embed[0]\n",
    "\n",
    "v = 1.0 - K.get_value(tau)\n",
    "r = np.copy(embed)\n",
    "threshold = 0\n",
    "r[r < threshold] = -v\n",
    "r[r >= threshold] = v\n",
    "\n",
    "qnt = r[0].astype('int')\n",
    "print qnt\n",
    "\n",
    "print r[0]\n",
    "\n",
    "autoencOutput = aac_dec.predict(r, batch_size = BATCH_SIZE, verbose = 1)\n",
    "print autoencOutput.shape\n",
    "autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "\n",
    "print autoencOutput.shape\n",
    "recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "\n",
    "wav = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "wav = unpreprocessWaveform(wav, wparams)\n",
    "\n",
    "sciwav.write(\"tst_output_reg.wav\", rate, wav.astype(np.int16))\n",
    "\n",
    "idx = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.000000 0.000000 1.000000]\n",
      "[1544082 1015918]\n",
      "[-1.000000 0.000000 1.000000]\n",
      "[0.603157 0.396843]\n",
      "0.969073859175\n"
     ]
    }
   ],
   "source": [
    "b = np.linspace(-1.0, 1.0, 3)\n",
    "print b\n",
    "\n",
    "h = np.histogram(scalars, bins = b)\n",
    "print h[0]\n",
    "print h[1]\n",
    "h = h[0].astype('float32')\n",
    "h = h / h.sum()\n",
    "print h\n",
    "\n",
    "entropy = 0\n",
    "for i in h:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
