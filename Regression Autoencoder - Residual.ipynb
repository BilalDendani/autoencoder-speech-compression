{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):   \n",
    "    return waveform, ()\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    # scale window between -1 and 1\n",
    "    processed = np.copy(windows)\n",
    "   \n",
    "    mn = np.min(processed, axis = 1)\n",
    "    mx = np.max(processed, axis = 1)\n",
    "\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "\n",
    "    for i in xrange(0, processed.shape[0]):\n",
    "        processed[i] /= maxabs[i]\n",
    "    processed *= 0.98\n",
    "   \n",
    "    #processed = (processed + 1.0) / 2.0\n",
    "   \n",
    "    return processed, (maxabs,)\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    # scale window from [-1, 1] to [-32768, 32768]\n",
    "    scl = params[0]\n",
    "   \n",
    "    unprocessed = np.copy(windows)\n",
    "    unprocessed /= 0.98\n",
    "   \n",
    "    #nprocessed = (unprocessed * 2.0) - 1.0\n",
    "   \n",
    "    for i in xrange(0, unprocessed.shape[0]):\n",
    "        unprocessed[i] *= scl[i]\n",
    "\n",
    "    return unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(processedWaveforms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (203086, 512)\n",
      "Max:  17885.0\n",
      "Min:  -17139.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (203086, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203086, 512, 1)\n",
      "0.0184928\n",
      "0.28096\n",
      "-0.98\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Binarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Binarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(x)\n",
    "        z[0][z[0] < 0] = -1\n",
    "        z[0][z[0] >= 0] = 1\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        # (i don't think there's a mathematical justification for this?)\n",
    "        g = output_gradients[0]\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StochasticBinarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StochasticBinarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        prob_thresh = (x + 1.0) / 2.0\n",
    "        probs = np.random.random_sample(x.shape)\n",
    "        res = np.greater(probs, prob_thresh)\n",
    "        res = res.astype('float32') * 2.0 - 1.0\n",
    "        res = -res\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(res)\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged (since expected value\n",
    "        # is just x)\n",
    "        return [output_gradients[0]]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QuantizeProbabilities(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, num_bins):\n",
    "        super(QuantizeProbabilities, self).__init__()\n",
    "        self.num_bins = num_bins\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.round(x * (self.num_bins - 1)) / float(self.num_bins - 1)\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        #     \"straight-through\" estimator\n",
    "        g = output_gradients[0]\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotArgmax(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        super(OneHotArgmax, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        m = np.repeat(np.max(x, axis = 2).reshape(x.shape[0], x.shape[1], 1), x.shape[2], axis = 2)\n",
    "        one = x - m\n",
    "        one[one >= 0] = 1\n",
    "        one[one < 0] = 0\n",
    "        z[0] = one\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        g = output_gradients[0]\n",
    "        \n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PhaseShift1D(Layer):\n",
    "    \"\"\" PhaseShift1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShift1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShift1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 1)             114593      input_10[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 114593\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_6 (Model)                  (None, 128, 2)        0           input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_7 (Model)                  (None, 512, 1)        0           model_6[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 337717\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_6 (Model)                  (None, 128, 2)        186577      input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_7 (Model)                  (None, 512, 1)        151140      model_6[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 1)             0           model_7[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 452310\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import softmax, sigmoid\n",
    "\n",
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# we generate a new optimizer of the same kind for every model\n",
    "# we train\n",
    "def opti():\n",
    "    return Adam()\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 128\n",
    "num_cats = 2\n",
    "\n",
    "\n",
    "# softmax \"upsampling\" initialization\n",
    "# identity matrix repeated, plus uniform noise\n",
    "def categorical_upsampling(input_dim, var_dim):\n",
    "    def init(shape, name = None):\n",
    "        assert(shape[-1] == input_dim * var_dim)\n",
    "        \n",
    "        random_additive = np.random.uniform(-0.1, 0.1, shape)\n",
    "        ident = np.eye(input_dim).repeat(var_dim, axis = 1)\n",
    "        random_multiplicative = np.random.normal(1.0, 0.1, shape)\n",
    "        \n",
    "        return K.variable(ident * random_multiplicative + random_additive)\n",
    "    \n",
    "    return init\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gumbel-Max sampling \n",
    "tau = K.variable(2.0, name=\"temperature\")\n",
    "anneal_rate = 0.01\n",
    "min_temperature = 0.01\n",
    "\n",
    "'''\n",
    "def sampling(logits_y):\n",
    "    u = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "    gumbel_noise = -K.log(-K.log(u + 1e-20) + 1e-20)\n",
    "\n",
    "    probs = K.sigmoid((gumbel_noise + logits_y) / tau)\n",
    "    return probs\n",
    "'''\n",
    "\n",
    "#discrete_values = K.variable([0.0, 1.0])\n",
    "def sampling(logits_y):\n",
    "    # gumbel noise\n",
    "    #u = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "    #gumbel_noise = -K.log(-K.log(u + 1e-20) + 1e-20)\n",
    "    \n",
    "    # calculate softmax probabilities and retrieve expected value\n",
    "    final_probs = softmax(K.reshape(logits_y, (-1, bottleneck_size, num_cats)) / tau)\n",
    "    \n",
    "    return final_probs\n",
    "    \n",
    "    # final output is expected value\n",
    "    #expected = T.dot(final_probs, discrete_values)\n",
    "    #return expected\n",
    "\n",
    "\n",
    "\n",
    "def encoder_residual_block(output_dim = 64, filt_size = 5, subsample = True):\n",
    "    def f(input):\n",
    "        stride = 1\n",
    "        if (subsample):\n",
    "            stride = 2\n",
    "        \n",
    "        conv1 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    conv1 = MaxPooling1D(2)(conv1)\n",
    "        #conv1 = SpatialDropout1D(0.1)(conv1)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        #conv2 = SpatialDropout1D(0.1)(conv2)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(output_dim, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 subsample_length = stride, bias = True)(input)\n",
    "        #if (subsample):\n",
    "        #    shortcut = MaxPooling1D(2)(shortcut)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        return LeakyReLU(0.3)(m)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def decoder_residual_block(output_dim = 64, filt_size = 5, upsample = True):\n",
    "    def f(input):\n",
    "        nfilts = output_dim\n",
    "        if (upsample):\n",
    "            nfilts = output_dim * 2\n",
    "\n",
    "        conv1 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        act1 = LeakyReLU(0.3)(conv1)\n",
    "        \n",
    "        conv2 = Convolution1D(nfilts, filt_size, border_mode = 'same',\n",
    "                          init = 'he_uniform', activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        \n",
    "        residual = conv2\n",
    "        shortcut = Convolution1D(nfilts, 1, border_mode = 'same',\n",
    "                                 init = 'he_uniform', activation = 'linear',\n",
    "                                 bias = True)(input)\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        r = LeakyReLU(0.3)(m)\n",
    "        if (upsample):\n",
    "            return PhaseShift1D(2)(r)\n",
    "        else:\n",
    "            return r\n",
    "    \n",
    "    return f\n",
    "#'''\n",
    "\n",
    "def hard_tanh(x):\n",
    "    return K.clip(x, -1.0, 1.0)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc_input = Input(shape = dim)\n",
    "    \n",
    "    # corrupt input slightly as a form of regularization\n",
    "    #enc = GaussianDropout(0.05, input_shape = dim)(enc_input)\n",
    "\n",
    "    # (512x1) => (256x48)\n",
    "    enc = encoder_residual_block(48, 9, False)(enc_input)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    #enc = encoder_residual_block(48, 9, False)(enc)\n",
    "\n",
    "    # (256x48) => (128x48)\n",
    "    enc = encoder_residual_block(48, 9, True)(enc)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    enc = encoder_residual_block(48, 9, False)(enc)\n",
    "\n",
    "    # (128x48) => (64x48)\n",
    "    enc = encoder_residual_block(48, 9, True)(enc)\n",
    "\n",
    "    # (64x64) => (64)\n",
    "    enc = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'linear',\n",
    "                              bias = True)(enc)\n",
    "    enc = LeakyReLU(0.3)(enc)\n",
    "    #enc = Lambda(lambda x : K.sigmoid(tau * x))(enc)\n",
    "    enc = Reshape((bottleneck_size,))(enc)\n",
    "    enc = Dense(bottleneck_size * num_cats,\n",
    "                init = categorical_upsampling(bottleneck_size, num_cats),\n",
    "                activation = 'linear')(enc)\n",
    "    #enc = GumbelMaxSampling()(enc)\n",
    "    #enc = GaussianNoise(0.05)(enc)\n",
    "    #enc = Activation('tanh')(enc)\n",
    "    enc = (Lambda(sampling, output_shape=(bottleneck_size, num_cats)))(enc)\n",
    "    #enc = (Lambda(lambda x : QuantizeProbabilities(16)(x), output_shape=(bottleneck_size, num_cats)))(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_input = Input(shape = (bottleneck_size, num_cats))\n",
    "    \n",
    "    dec = Convolution1D(1, 1, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'linear',\n",
    "                              bias = True)(dec_input)\n",
    "    \n",
    "    dec = Reshape((128,))(dec)\n",
    "    dec = Dense(bottleneck_size, activation = 'linear', init = 'identity')(dec)\n",
    "    dec = LeakyReLU(0.3)(dec)\n",
    "    dec = Reshape((128, 1,))(dec)\n",
    "    \n",
    "    # (64x1) => (128x48)\n",
    "    dec = decoder_residual_block(32, 9, True)(dec)\n",
    "    \n",
    "    # (128x48) => (128x48)\n",
    "    dec = decoder_residual_block(32, 9, False)(dec)\n",
    "    \n",
    "    # (128x48) => (256x48)\n",
    "    dec = decoder_residual_block(32, 9, True)(dec)\n",
    "    \n",
    "    # (256x48) => (256x48)\n",
    "    dec = decoder_residual_block(32, 9, False)(dec)\n",
    "    \n",
    "    # (256x48) => (512x48)\n",
    "    #dec = decoder_residual_block(32, 9, False)(dec)\n",
    "    \n",
    "    # (512x48) => (512x48)\n",
    "    #dec = decoder_residual_block(32, 9, False)(dec)\n",
    "\n",
    "    # (512x48) => (512x1)\n",
    "    dec = Convolution1D(1, 9, border_mode = 'same',\n",
    "                              init = 'he_uniform', activation = 'tanh',\n",
    "                              bias = True)(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "\n",
    "    dsc.add(Convolution1D(32, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='valid', input_shape = dim,\n",
    "                                    init = 'uniform',\n",
    "                                    subsample_length = 2, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    \n",
    "    dsc.add(Flatten())\n",
    "    \n",
    "    dsc.add(Dense(48, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    dsc.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return dsc\n",
    "\n",
    "\n",
    "# construct autoencoder to be used in adversarial training (AAC - Adversarial AutoenCoder)\n",
    "# uhhhh... whoops i screwed up the acronym\n",
    "aac_input = Input(shape = input_dim)\n",
    "aac_enc, aac_dec = autoencoder_structure(input_dim)\n",
    "aac_embedding = aac_enc(aac_input)\n",
    "#aac_embedding_quant = Lambda(lambda x : QuantizeProbabilities(4)(x))(aac_embedding)\n",
    "aac_reconstructed = aac_dec(aac_embedding)\n",
    "\n",
    "aac_autoencoder = Model(input = [aac_input], output = [aac_reconstructed])\n",
    "aac_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "\n",
    "\n",
    "# construct discriminator: regular\n",
    "regdsc_input_dim = (WINDOW_SIZE, 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(regdsc_input)\n",
    "aac_reg_label = regdsc_struct(aac_reconstructed)\n",
    "\n",
    "\n",
    "\n",
    "def prob_quantization_loss(placeholder, code):\n",
    "    loss = K.minimum(code, 1.0 - code)\n",
    "    loss_weight = 10.0\n",
    "\n",
    "    return K.switch(tau < 0.25, loss * loss_weight, \\\n",
    "                                K.zeros_like(code))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [350.0, 1.0]\n",
    "n_discrim = 1\n",
    "n_code = 0\n",
    "lmult = len(loss_weights) - n_discrim - n_code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "make_trainable(aac_autoencoder, False)\n",
    "\n",
    "aac_discrim_reg = Model(input = [regdsc_input], output = [regdsc_label])\n",
    "aac_discrim_reg.compile(loss = ['binary_crossentropy'], optimizer = opti())\n",
    "aac_discrim_reg.summary()\n",
    "\n",
    "aac_autoencoder.summary()\n",
    "\n",
    "make_trainable(aac_discrim_reg, False)\n",
    "make_trainable(aac_autoencoder, True)\n",
    "model = Model(input = [aac_input], output = [aac_reconstructed] * lmult + \\\n",
    "                                            [aac_reg_label] + \\\n",
    "                                            [aac_embedding] * n_code)\n",
    "model.compile(loss = ['mean_squared_error', \\\n",
    "                      'binary_crossentropy', \\\n",
    "                     ],#  prob_quantization_loss],\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    #sciwav.write(prefix + \"_res_desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = BATCH_SIZE, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    \n",
    "    sciwav.write(prefix + \"_output.wav\", rate, recons.astype(np.int16))\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired)\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interleave two numpy arrays of the same size along the first axis\n",
    "def interleave(a, b):    \n",
    "    r = np.empty(a.shape)\n",
    "    r = np.repeat(r, 2, axis = 0)\n",
    "    \n",
    "    r[::2] = a\n",
    "    r[1::2] = b\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    1280: 0.501149356365  [7.408620 0.016820 1.521719] [7.408620 5.886900 1.521719] 0.344089895487 \n",
      "    Total time for epoch: 815.398489952s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 71.5% d_acc\n",
      "    Total time for evaluation: 2.15358710289s\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4177.64 -2923.8\n",
      "    MSE:      12605.4\n",
      "    Avg err:  58.0959\n",
      "    Total time for evaluation: 0.133603096008s\n",
      "\n",
      "Epoch 2:\n",
      "    1280: 0.556713700294  [5.926343 0.013644 1.151003] [5.926343 4.775341 1.151003] 0.0541037097573"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6c51475c449a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlmult\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_discrim\u001b[0m \u001b[0;34m+\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# train discriminator(s) on what the autoencoder now generates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train autoencoder, if discriminator accuracy is greater than 70%\n",
    "        if (epoch >= 0):\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            make_trainable(aac_discrim_reg, False)\n",
    "            \n",
    "            a_y = [batch] * lmult + \\\n",
    "                  [np.ones(nbatch)] * n_discrim + \\\n",
    "                  [np.zeros((nbatch, bottleneck_size, num_cats))] * n_code\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        # train discriminator(s) on what the autoencoder now generates\n",
    "        generated = aac_autoencoder.predict(batch)\n",
    "        discrim_batch_X = interleave(batch, generated)\n",
    "        discrim_batch_y = interleave(np.ones(nbatch), np.zeros(nbatch))\n",
    "        \n",
    "        make_trainable(aac_autoencoder, False)\n",
    "        make_trainable(aac_discrim_reg, True)\n",
    "        d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        if (epoch < 0 and d_loss < 0.2):\n",
    "            print \"\"\n",
    "            print lead + \"Terminating epoch early (don't wanna overfit!)\"\n",
    "            break\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "            print K.get_value(tau),\n",
    "            K.set_value(tau, np.max([K.get_value(tau) * np.exp(-anneal_rate * (epoch + 1)), min_temperature]))\n",
    "            #K.set_value(tau, np.min([K.get_value(tau) * (1 + anneal_rate), max_temperature]))\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "    d_X = np.concatenate((X_train[rows, :], generated))\n",
    "    d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "    d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                               d_X, d_y, verbose = False)\n",
    "\n",
    "    print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model.save('model_reg_adversary.h5')\\naac_autoencoder.save('auto_reg_adversary.h5')\\naac_discrim_reg.save('discrim_reg_adversary.h5')\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''model.save('model_reg_adversary.h5')\n",
    "aac_autoencoder.save('auto_reg_adversary.h5')\n",
    "aac_discrim_reg.save('discrim_reg_adversary.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D,\\n        'BinarizeLayer' : BinarizeLayer,\\n        'code_binary_loss' : code_binary_loss,\\n        'code_maximize_variance' : code_maximize_variance}\\n\\nmodel = load_model('model_reg_adversary.h5', objs)\\naac_autoencoder = load_model('auto_reg_adversary.h5', objs)\\naac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D,\n",
    "        'BinarizeLayer' : BinarizeLayer,\n",
    "        'code_binary_loss' : code_binary_loss,\n",
    "        'code_maximize_variance' : code_maximize_variance}\n",
    "\n",
    "model = load_model('model_reg_adversary.h5', objs)\n",
    "aac_autoencoder = load_model('auto_reg_adversary.h5', objs)\n",
    "aac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluated the discriminator: 72.625% d_acc\n"
     ]
    }
   ],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "d_X = np.concatenate((X_train[rows, :], generated))\n",
    "d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                           d_X, d_y, verbose = False)\n",
    "\n",
    "print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  4528.44 -2987.4\n",
      "./SA1.WAV  mse:  12414.9\n",
      "./SA1.WAV  avg err:  55.9701\n",
      "(93, 512)\n",
      "93/93 [==============================] - 0s\n",
      "(93, 512, 1)\n",
      "(93, 512)\n",
      "Max/min desired: 2961.0 -3057.0\n",
      "Max/min recons:  2859.69 -2652.09\n",
      "./SX383.WAV  mse:  5752.58\n",
      "./SX383.WAV  avg err:  40.7908\n",
      "(181, 512)\n",
      "181/181 [==============================] - 0s     \n",
      "(181, 512, 1)\n",
      "(181, 512)\n",
      "Max/min desired: 24636.0 -20122.0\n",
      "Max/min recons:  21431.6 -17516.6\n",
      "./fiveYears.wav  mse:  2.95299e+06\n",
      "./fiveYears.wav  avg err:  1219.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24636.0, -20122.0, 21431.572, -17516.637, 2952988.2, 1219.2957]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_reg_\", aac_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.WAV\")\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = aac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.649480 0.350520]\n",
      " [0.486485 0.513515]\n",
      " [0.561945 0.438055]\n",
      " [0.464455 0.535545]\n",
      " [0.599743 0.400257]\n",
      " [0.613211 0.386789]\n",
      " [0.655272 0.344728]\n",
      " [0.691473 0.308527]\n",
      " [0.463022 0.536978]\n",
      " [0.452715 0.547285]\n",
      " [0.528035 0.471965]\n",
      " [0.505902 0.494098]\n",
      " [0.555262 0.444738]\n",
      " [0.598373 0.401627]\n",
      " [0.525736 0.474264]\n",
      " [0.531259 0.468741]\n",
      " [0.565394 0.434606]\n",
      " [0.433938 0.566062]\n",
      " [0.423601 0.576399]\n",
      " [0.676604 0.323396]\n",
      " [0.690718 0.309282]\n",
      " [0.500715 0.499285]\n",
      " [0.557301 0.442699]\n",
      " [0.635570 0.364430]\n",
      " [0.483987 0.516013]\n",
      " [0.553902 0.446098]\n",
      " [0.507907 0.492093]\n",
      " [0.496926 0.503074]\n",
      " [0.627263 0.372737]\n",
      " [0.394495 0.605505]\n",
      " [0.562014 0.437986]\n",
      " [0.446421 0.553579]\n",
      " [0.495109 0.504891]\n",
      " [0.598407 0.401593]\n",
      " [0.570480 0.429520]\n",
      " [0.595832 0.404168]\n",
      " [0.658765 0.341235]\n",
      " [0.498896 0.501104]\n",
      " [0.626392 0.373608]\n",
      " [0.511221 0.488779]\n",
      " [0.474161 0.525840]\n",
      " [0.516441 0.483559]\n",
      " [0.575016 0.424984]\n",
      " [0.661143 0.338857]\n",
      " [0.579046 0.420954]\n",
      " [0.551811 0.448189]\n",
      " [0.607478 0.392522]\n",
      " [0.557611 0.442389]\n",
      " [0.476559 0.523441]\n",
      " [0.607474 0.392526]\n",
      " [0.567252 0.432749]\n",
      " [0.660813 0.339187]\n",
      " [0.417832 0.582168]\n",
      " [0.563997 0.436003]\n",
      " [0.483528 0.516472]\n",
      " [0.452063 0.547937]\n",
      " [0.559558 0.440442]\n",
      " [0.573234 0.426766]\n",
      " [0.582967 0.417033]\n",
      " [0.500179 0.499821]\n",
      " [0.585761 0.414239]\n",
      " [0.551020 0.448980]\n",
      " [0.500457 0.499543]\n",
      " [0.489361 0.510639]\n",
      " [0.571508 0.428492]\n",
      " [0.507058 0.492942]\n",
      " [0.555745 0.444255]\n",
      " [0.650661 0.349339]\n",
      " [0.492673 0.507327]\n",
      " [0.457186 0.542814]\n",
      " [0.482689 0.517311]\n",
      " [0.555448 0.444552]\n",
      " [0.623595 0.376405]\n",
      " [0.568212 0.431788]\n",
      " [0.557757 0.442243]\n",
      " [0.564633 0.435367]\n",
      " [0.539157 0.460843]\n",
      " [0.552628 0.447372]\n",
      " [0.558881 0.441119]\n",
      " [0.489182 0.510818]\n",
      " [0.531753 0.468247]\n",
      " [0.409627 0.590373]\n",
      " [0.499717 0.500283]\n",
      " [0.472869 0.527131]\n",
      " [0.421451 0.578549]\n",
      " [0.571127 0.428873]\n",
      " [0.612117 0.387883]\n",
      " [0.478891 0.521109]\n",
      " [0.539600 0.460400]\n",
      " [0.438098 0.561902]\n",
      " [0.516188 0.483812]\n",
      " [0.580430 0.419570]\n",
      " [0.441353 0.558647]\n",
      " [0.520117 0.479883]\n",
      " [0.490956 0.509044]\n",
      " [0.460308 0.539692]\n",
      " [0.523561 0.476439]\n",
      " [0.455207 0.544793]\n",
      " [0.506759 0.493241]\n",
      " [0.523401 0.476599]\n",
      " [0.536200 0.463800]\n",
      " [0.602515 0.397485]\n",
      " [0.497974 0.502026]\n",
      " [0.523818 0.476182]\n",
      " [0.583482 0.416518]\n",
      " [0.566445 0.433555]\n",
      " [0.529625 0.470375]\n",
      " [0.502842 0.497158]\n",
      " [0.489410 0.510590]\n",
      " [0.541644 0.458356]\n",
      " [0.448066 0.551934]\n",
      " [0.514326 0.485674]\n",
      " [0.572695 0.427305]\n",
      " [0.524454 0.475546]\n",
      " [0.528592 0.471408]\n",
      " [0.577690 0.422310]\n",
      " [0.549823 0.450177]\n",
      " [0.571344 0.428656]\n",
      " [0.540770 0.459230]\n",
      " [0.588626 0.411374]\n",
      " [0.545601 0.454399]\n",
      " [0.536131 0.463869]\n",
      " [0.502320 0.497680]\n",
      " [0.614504 0.385496]\n",
      " [0.477170 0.522830]\n",
      " [0.473887 0.526113]\n",
      " [0.649399 0.350601]\n",
      " [0.422935 0.577065]]\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "r = K.max(K.reshape(embed, (-1, bottleneck_size, 2)), axis=-1, keepdims=True)\n",
    "r = K.equal(K.reshape(embed, (-1, bottleneck_size, 2)), r)\n",
    "r = r.eval()\n",
    "\n",
    "#r = np.round(embed)\n",
    "print embed[0]\n",
    "#print r[0]\n",
    "\n",
    "autoencOutput = aac_dec.predict(r, batch_size = BATCH_SIZE, verbose = 1)\n",
    "print autoencOutput.shape\n",
    "autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "\n",
    "print autoencOutput.shape\n",
    "recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "\n",
    "wav = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "wav = unpreprocessWaveform(wav, wparams)\n",
    "    \n",
    "sciwav.write(\"tst_output_reg.wav\", rate, wav.astype(np.int16))\n",
    "\n",
    "idx = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.026407, -0.006301, -0.005199, -0.002332, 0.003140, -0.010068,\n",
      "        0.002300, 0.009853, 0.001155, -0.020291, 0.020618, -0.003820,\n",
      "        0.038830, 0.004768, -0.023819, -0.066617, -0.029880, -0.022022,\n",
      "        -0.029591, -0.019530, -0.022398, -0.028352, -0.003694, -0.004946,\n",
      "        -0.021778, -0.033549, -0.000278, -0.021422, 0.004698, -0.000766,\n",
      "        -0.010947, -0.017586, -0.026243, -0.040195, -0.018468, -0.004372,\n",
      "        0.023586, 0.039920, 0.018397, -0.020752, -0.001003, -0.043614,\n",
      "        -0.021103, -0.021255, -0.007967, -0.020176, -0.011804, -0.041300,\n",
      "        -0.023727, -0.020328, -0.021384, -0.032863, -0.000224, -0.001901,\n",
      "        -0.027614, -0.026962, -0.013652, -0.041255, -0.029561, -0.006839,\n",
      "        -0.032146, -0.045369, -0.017231, -0.005822, -0.011916, -0.010878,\n",
      "        -0.010292, -0.031443, -0.006313, -0.021364, -0.009375, -0.029958,\n",
      "        0.009647, -0.025238, -0.005584, -0.005350, 0.001364, -0.026042,\n",
      "        -0.025537, -0.027918, -0.038595, -0.033109, 0.005408, 0.001919,\n",
      "        -0.014574, -0.030608, -0.011648, -0.047095, 0.001717, -0.015193,\n",
      "        -0.000196, -0.011227, -0.005944, -0.029104, -0.014632, -0.026907,\n",
      "        -0.008880, -0.003904, 0.024744, 0.001584, 0.004156, -0.010197,\n",
      "        -0.018930, -0.054298, -0.007448, 0.010141, -0.014436, -0.028087,\n",
      "        -0.024236, -0.020740, -0.014728, -0.004528, 0.001152, -0.011542,\n",
      "        -0.001418, -0.017065, -0.007738, -0.025502, -0.016803, -0.016841,\n",
      "        -0.001936, -0.020310, -0.031814, -0.042674, -0.022252, -0.022349,\n",
      "        -0.024566, -0.022309, 0.002388, -0.012885, 0.022634, 0.021137,\n",
      "        0.003880, -0.007995, 0.008328, -0.024656, -0.031587, -0.030033,\n",
      "        -0.021587, -0.012483, -0.009996, -0.006323, -0.010002, -0.021813,\n",
      "        -0.000973, -0.027745, 0.004036, -0.010525, -0.017187, -0.029494,\n",
      "        -0.017931, -0.031719, 0.001740, -0.006584, -0.020427, -0.031633,\n",
      "        0.000030, -0.012519, 0.002358, 0.004653, -0.017253, -0.023998,\n",
      "        -0.009631, 0.009753, -0.037969, -0.037909, -0.022387, -0.016626,\n",
      "        0.010193, 0.026994, 0.015087, -0.000104, 0.002718, -0.021476,\n",
      "        -0.017634, -0.013153, -0.029740, -0.038158, -0.014684, -0.001485,\n",
      "        -0.012788, -0.016223, -0.002632, -0.019843, -0.024890, -0.012391,\n",
      "        -0.008721, -0.012991, 0.000115, 0.002034, 0.005431, 0.013869,\n",
      "        -0.005995, -0.010997, -0.010736, -0.001208, -0.001010, -0.002444,\n",
      "        -0.003394, -0.008361, 0.006229, -0.001464, 0.008716, -0.013343,\n",
      "        0.000714, 0.001144, 0.010581, 0.005524, -0.006766, -0.024642,\n",
      "        -0.002205, -0.016384, -0.014307, -0.020599, -0.017913, -0.018515,\n",
      "        -0.017547, -0.015300, -0.014451, -0.023305, -0.010879, 0.000178,\n",
      "        -0.002673, -0.005713, -0.005128, -0.020659, -0.012256, -0.017448,\n",
      "        -0.005281, -0.011353, -0.006465, -0.023080, -0.019025, -0.029630,\n",
      "        0.009481, -0.005757, 0.018479, 0.009812, -0.008247, -0.027248,\n",
      "        -0.016133, -0.025833, -0.012263, -0.019940, -0.016252, -0.016744,\n",
      "        -0.011455, -0.036183, -0.001870, 0.002976, 0.001747, 0.007291,\n",
      "        -0.008047, -0.040736, -0.012978, 0.003501]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "logit_output = K.function([model.layers[1].layers[0].input], [model.layers[1].layers[-2].output])\n",
    "\n",
    "logits = logit_output([[transformed[0]]])\n",
    "print logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CudaNdarray([[[[1.493956]\n",
      "   [-1.301944]]]])\n",
      "CudaNdarray([0.006829])\n"
     ]
    }
   ],
   "source": [
    "print model.layers[2].layers[1].weights[0].eval()\n",
    "print model.layers[2].layers[1].weights[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CudaNdarray([[1.365355 0.247365 -0.044743 ..., -0.018078 0.034547 -0.006794]\n",
      " [0.007955 1.120362 0.207719 ..., 0.090497 0.065630 -0.182380]\n",
      " [0.006915 0.130459 1.002491 ..., -0.080762 -0.144568 0.013299]\n",
      " ..., \n",
      " [0.019009 -0.093426 0.008402 ..., 0.933239 0.125922 0.153007]\n",
      " [-0.062852 -0.015699 0.083822 ..., 0.049544 1.143798 0.045510]\n",
      " [0.121907 0.136193 -0.016438 ..., 0.055595 0.129919 1.182899]])\n"
     ]
    }
   ],
   "source": [
    "print model.layers[2].layers[3].weights[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
