{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n",
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA1.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX339.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1059.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1689.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX429.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX69.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX159.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI2319.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA2.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX249.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX221.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA1.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX41.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1751.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1725.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX401.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX24.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA2.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1121.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX131.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA1.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX336.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1236.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI606.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1866.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX156.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA2.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX426.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX246.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX66.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA1.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1233.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI603.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX333.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX153.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1863.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX243.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA2.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX423.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX63.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA1.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX434.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX74.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX254.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI1064.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX344.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX164.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA2.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI582.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI2324.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX82.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1041.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX442.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA1.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1702.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX262.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX172.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX352.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA2.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1072.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI669.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA1.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX39.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX309.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1929.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX129.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1299.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX219.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX399.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA2.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI2325.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX435.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX75.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA1.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1695.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX345.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1065.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX255.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX165.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA2.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI2290.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA1.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI650.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI1660.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX220.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX310.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX40.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX400.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA2.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX130.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX149.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA1.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI2309.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX419.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX239.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX329.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1679.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX59.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA2.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1049.WAV\r",
      "100: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI520.WAV\r",
      "101: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA1.WAV\r",
      "102: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX160.WAV\r",
      "103: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX340.WAV\r",
      "104: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI2035.WAV\r",
      "105: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX250.WAV\r",
      "106: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX430.WAV\r",
      "107: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX70.WAV\r",
      "108: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA2.WAV\r",
      "109: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI1780.WAV\r",
      "110: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA1.WAV\r",
      "111: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX65.WAV\r",
      "112: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX425.WAV\r",
      "113: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1685.WAV\r",
      "114: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1055.WAV\r",
      "115: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX335.WAV\r",
      "116: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA2.WAV\r",
      "117: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX245.WAV\r",
      "118: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI2315.WAV\r",
      "119: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX155.WAV\r",
      "120: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA1.WAV\r",
      "121: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX339.WAV\r",
      "122: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI879.WAV\r",
      "123: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX429.WAV\r",
      "124: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI1509.WAV\r",
      "125: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX69.WAV\r",
      "126: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX159.WAV\r",
      "127: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI2139.WAV\r",
      "128: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA2.WAV\r",
      "129: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX249.WAV\r",
      "130: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX166.WAV\r",
      "131: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA1.WAV\r",
      "132: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX346.WAV\r",
      "133: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI2326.WAV\r",
      "134: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1696.WAV\r",
      "135: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX256.WAV\r",
      "136: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1066.WAV\r",
      "137: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA2.WAV\r",
      "138: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX76.WAV\r",
      "139: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX436.WAV\r",
      "140: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX56.WAV\r",
      "141: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA1.WAV\r",
      "142: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI866.WAV\r",
      "143: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX146.WAV\r",
      "144: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX326.WAV\r",
      "145: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI2126.WAV\r",
      "146: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX416.WAV\r",
      "147: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX236.WAV\r",
      "148: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI1760.WAV\r",
      "149: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA2.WAV\r",
      "150: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX82.WAV\r",
      "151: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX442.WAV\r",
      "152: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA1.WAV\r",
      "153: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI2062.WAV\r",
      "154: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI1432.WAV\r",
      "155: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX262.WAV\r",
      "156: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI802.WAV\r",
      "157: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX172.WAV\r",
      "158: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX352.WAV\r",
      "159: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA2.WAV\r",
      "160: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX311.WAV\r",
      "161: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA1.WAV\r",
      "162: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI2274.WAV\r",
      "163: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX114.WAV\r",
      "164: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX384.WAV\r",
      "165: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX294.WAV\r",
      "166: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1014.WAV\r",
      "167: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA2.WAV\r",
      "168: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1644.WAV\r",
      "169: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX204.WAV\r",
      "170: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX42.WAV\r",
      "171: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX222.WAV\r",
      "172: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA1.WAV\r",
      "173: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX312.WAV\r",
      "174: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI1572.WAV\r",
      "175: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI942.WAV\r",
      "176: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX132.WAV\r",
      "177: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA2.WAV\r",
      "178: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI2202.WAV\r",
      "179: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX402.WAV\r",
      "180: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX149.WAV\r",
      "181: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA1.WAV\r",
      "182: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1949.WAV\r",
      "183: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI689.WAV\r",
      "184: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1319.WAV\r",
      "185: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX419.WAV\r",
      "186: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX239.WAV\r",
      "187: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX329.WAV\r",
      "188: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX59.WAV\r",
      "189: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA2.WAV\r",
      "190: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1187.WAV\r",
      "191: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX17.WAV\r",
      "192: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX107.WAV\r",
      "193: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA1.WAV\r",
      "194: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI630.WAV\r",
      "195: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1817.WAV\r",
      "196: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX287.WAV\r",
      "197: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX197.WAV\r",
      "198: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA2.WAV\r",
      "199: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX377.WAV\r",
      "200: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX248.WAV\r",
      "201: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX428.WAV\r",
      "202: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA1.WAV\r",
      "203: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI2318.WAV\r",
      "204: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX68.WAV\r",
      "205: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1058.WAV\r",
      "206: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX338.WAV\r",
      "207: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX158.WAV\r",
      "208: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1688.WAV\r",
      "209: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA2.WAV\r",
      "210: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI534.WAV\r",
      "211: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI1164.WAV\r",
      "212: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA1.WAV\r",
      "213: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX354.WAV\r",
      "214: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX174.WAV\r",
      "215: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX264.WAV\r",
      "216: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI797.WAV\r",
      "217: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX444.WAV\r",
      "218: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX84.WAV\r",
      "219: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA2.WAV\r",
      "220: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA1.WAV\r",
      "221: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX39.WAV\r",
      "222: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI2199.WAV\r",
      "223: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX309.WAV\r",
      "224: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI1569.WAV\r",
      "225: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX129.WAV\r",
      "226: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX219.WAV\r",
      "227: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI939.WAV\r",
      "228: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX399.WAV\r",
      "229: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA2.WAV\r",
      "230: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI1609.WAV\r",
      "231: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX30.WAV\r",
      "232: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX169.WAV\r",
      "233: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA1.WAV\r",
      "234: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX439.WAV\r",
      "235: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI979.WAV\r",
      "236: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX259.WAV\r",
      "237: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA2.WAV\r",
      "238: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI2239.WAV\r",
      "239: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX79.WAV\r",
      "240: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX42.WAV\r",
      "241: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX222.WAV\r",
      "242: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2112.WAV\r",
      "243: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA1.WAV\r",
      "244: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX312.WAV\r",
      "245: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2026.WAV\r",
      "246: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX132.WAV\r",
      "247: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA2.WAV\r",
      "248: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI1482.WAV\r",
      "249: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX402.WAV\r",
      "250: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX81.WAV\r",
      "251: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA1.WAV\r",
      "252: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX351.WAV\r",
      "253: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI2331.WAV\r",
      "254: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX27.WAV\r",
      "255: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1071.WAV\r",
      "256: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX441.WAV\r",
      "257: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX261.WAV\r",
      "258: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1701.WAV\r",
      "259: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA2.WAV\r",
      "260: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA1.WAV\r",
      "261: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX241.WAV\r",
      "262: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX331.WAV\r",
      "263: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX61.WAV\r",
      "264: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX151.WAV\r",
      "265: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1681.WAV\r",
      "266: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX421.WAV\r",
      "267: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI2311.WAV\r",
      "268: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA2.WAV\r",
      "269: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1051.WAV\r",
      "270: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX167.WAV\r",
      "271: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX437.WAV\r",
      "272: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA1.WAV\r",
      "273: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX77.WAV\r",
      "274: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX257.WAV\r",
      "275: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX347.WAV\r",
      "276: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI1607.WAV\r",
      "277: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA2.WAV\r",
      "278: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI977.WAV\r",
      "279: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI2237.WAV\r",
      "280: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI1485.WAV\r",
      "281: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA1.WAV\r",
      "282: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI855.WAV\r",
      "283: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX225.WAV\r",
      "284: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX405.WAV\r",
      "285: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA2.WAV\r",
      "286: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX45.WAV\r",
      "287: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX315.WAV\r",
      "288: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX135.WAV\r",
      "289: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI2115.WAV\r",
      "290: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1068.WAV\r",
      "291: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA1.WAV\r",
      "292: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX78.WAV\r",
      "293: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX202.WAV\r",
      "294: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX258.WAV\r",
      "295: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX168.WAV\r",
      "296: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1698.WAV\r",
      "297: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI2328.WAV\r",
      "298: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA2.WAV\r",
      "299: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX348.WAV\r",
      "300: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI579.WAV\r",
      "301: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA1.WAV\r",
      "302: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX39.WAV\r",
      "303: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX309.WAV\r",
      "304: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX129.WAV\r",
      "305: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX219.WAV\r",
      "306: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX399.WAV\r",
      "307: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1839.WAV\r",
      "308: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA2.WAV\r",
      "309: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1209.WAV\r",
      "310: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA1.WAV\r",
      "311: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX161.WAV\r",
      "312: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX71.WAV\r",
      "313: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX431.WAV\r",
      "314: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX341.WAV\r",
      "315: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI611.WAV\r",
      "316: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX251.WAV\r",
      "317: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1241.WAV\r",
      "318: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA2.WAV\r",
      "319: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1871.WAV\r",
      "320: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA1.WAV\r",
      "321: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX355.WAV\r",
      "322: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX445.WAV\r",
      "323: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX265.WAV\r",
      "324: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX85.WAV\r",
      "325: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1165.WAV\r",
      "326: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1802.WAV\r",
      "327: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX175.WAV\r",
      "328: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI535.WAV\r",
      "329: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA2.WAV\r",
      "330: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX62.WAV\r",
      "331: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI872.WAV\r",
      "332: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA1.WAV\r",
      "333: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI2132.WAV\r",
      "334: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI588.WAV\r",
      "335: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX152.WAV\r",
      "336: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX332.WAV\r",
      "337: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX242.WAV\r",
      "338: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA2.WAV\r",
      "339: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX422.WAV\r",
      "340: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA1.WAV\r",
      "341: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI1671.WAV\r",
      "342: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX321.WAV\r",
      "343: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2332.WAV\r",
      "344: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX141.WAV\r",
      "345: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX231.WAV\r",
      "346: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX411.WAV\r",
      "347: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX51.WAV\r",
      "348: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA2.WAV\r",
      "349: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2301.WAV\r",
      "350: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA1.WAV\r",
      "351: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX433.WAV\r",
      "352: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX343.WAV\r",
      "353: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX73.WAV\r",
      "354: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX163.WAV\r",
      "355: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI793.WAV\r",
      "356: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI1913.WAV\r",
      "357: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA2.WAV\r",
      "358: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX253.WAV\r",
      "359: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI2053.WAV\r",
      "360: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX234.WAV\r",
      "361: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA1.WAV\r",
      "362: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX324.WAV\r",
      "363: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2225.WAV\r",
      "364: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2304.WAV\r",
      "365: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI1674.WAV\r",
      "366: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX54.WAV\r",
      "367: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX414.WAV\r",
      "368: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX144.WAV\r",
      "369: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA2.WAV\r",
      "370: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA1.WAV\r",
      "371: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX235.WAV\r",
      "372: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX145.WAV\r",
      "373: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX55.WAV\r",
      "374: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX325.WAV\r",
      "375: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX415.WAV\r",
      "376: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI685.WAV\r",
      "377: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1315.WAV\r",
      "378: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA2.WAV\r",
      "379: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1945.WAV\r",
      "380: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA1.WAV\r",
      "381: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1295.WAV\r",
      "382: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI538.WAV\r",
      "383: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1798.WAV\r",
      "384: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX268.WAV\r",
      "385: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX178.WAV\r",
      "386: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA2.WAV\r",
      "387: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX448.WAV\r",
      "388: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX358.WAV\r",
      "389: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX88.WAV\r",
      "390: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX127.WAV\r",
      "391: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA1.WAV\r",
      "392: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX217.WAV\r",
      "393: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI847.WAV\r",
      "394: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX307.WAV\r",
      "395: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1477.WAV\r",
      "396: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX397.WAV\r",
      "397: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA2.WAV\r",
      "398: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX37.WAV\r",
      "399: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1313.WAV\r",
      "400: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA1.WAV\r",
      "401: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1005.WAV\r",
      "402: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX15.WAV\r",
      "403: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1342.WAV\r",
      "404: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX285.WAV\r",
      "405: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1635.WAV\r",
      "406: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX105.WAV\r",
      "407: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX195.WAV\r",
      "408: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA2.WAV\r",
      "409: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX375.WAV\r",
      "410: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI961.WAV\r",
      "411: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA1.WAV\r",
      "412: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX241.WAV\r",
      "413: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI1591.WAV\r",
      "414: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX331.WAV\r",
      "415: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX61.WAV\r",
      "416: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX151.WAV\r",
      "417: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX421.WAV\r",
      "418: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA2.WAV\r",
      "419: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI511.WAV\r",
      "420: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1251.WAV\r",
      "421: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX17.WAV\r",
      "422: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX107.WAV\r",
      "423: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA1.WAV\r",
      "424: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1457.WAV\r",
      "425: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX287.WAV\r",
      "426: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI827.WAV\r",
      "427: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX197.WAV\r",
      "428: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA2.WAV\r",
      "429: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX377.WAV\r",
      "430: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA1.WAV\r",
      "431: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1888.WAV\r",
      "432: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX268.WAV\r",
      "433: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI628.WAV\r",
      "434: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX178.WAV\r",
      "435: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA2.WAV\r",
      "436: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX448.WAV\r",
      "437: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX358.WAV\r",
      "438: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX88.WAV\r",
      "439: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1258.WAV\r",
      "440: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX157.WAV\r",
      "441: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA1.WAV\r",
      "442: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX337.WAV\r",
      "443: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX67.WAV\r",
      "444: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1687.WAV\r",
      "445: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI2317.WAV\r",
      "446: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX427.WAV\r",
      "447: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA2.WAV\r",
      "448: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1057.WAV\r",
      "449: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX247.WAV\r",
      "450: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA1.WAV\r",
      "451: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1170.WAV\r",
      "452: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX270.WAV\r",
      "453: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1800.WAV\r",
      "454: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX360.WAV\r",
      "455: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX450.WAV\r",
      "456: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX90.WAV\r",
      "457: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI540.WAV\r",
      "458: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA2.WAV\r",
      "459: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX180.WAV\r",
      "460: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX435.WAV\r",
      "461: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX75.WAV\r",
      "462: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA1.WAV\r",
      "463: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI1605.WAV\r",
      "464: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX345.WAV\r",
      "465: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX255.WAV\r",
      "466: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI975.WAV\r",
      "467: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX165.WAV\r",
      "468: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI2235.WAV\r",
      "469: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA2.WAV\r",
      "470: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI539.WAV\r",
      "471: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA1.WAV\r",
      "472: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1169.WAV\r",
      "473: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX359.WAV\r",
      "474: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX449.WAV\r",
      "475: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX179.WAV\r",
      "476: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX269.WAV\r",
      "477: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA2.WAV\r",
      "478: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1799.WAV\r",
      "479: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX89.WAV\r",
      "480: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA1.WAV\r",
      "481: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX32.WAV\r",
      "482: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX212.WAV\r",
      "483: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX392.WAV\r",
      "484: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1652.WAV\r",
      "485: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX302.WAV\r",
      "486: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX122.WAV\r",
      "487: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI2282.WAV\r",
      "488: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1022.WAV\r",
      "489: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA2.WAV\r",
      "490: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA1.WAV\r",
      "491: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX161.WAV\r",
      "492: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX217.WAV\r",
      "493: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1747.WAV\r",
      "494: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1117.WAV\r",
      "495: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX366.WAV\r",
      "496: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX397.WAV\r",
      "497: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA2.WAV\r",
      "498: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX37.WAV\r",
      "499: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI487.WAV\r",
      "500: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX237.WAV\r",
      "501: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SA1.WAV\r",
      "502: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX277.WAV\r",
      "503: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX147.WAV\r",
      "504: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI1137.WAV\r",
      "505: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX417.WAV\r",
      "506: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI507.WAV\r",
      "507: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI1767.WAV\r",
      "508: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SA2.WAV\r",
      "509: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX57.WAV\r",
      "510: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI882.WAV\r",
      "511: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SA1.WAV\r",
      "512: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX252.WAV\r",
      "513: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX342.WAV\r",
      "514: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI1512.WAV\r",
      "515: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI2142.WAV\r",
      "516: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX162.WAV\r",
      "517: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX72.WAV\r",
      "518: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX432.WAV\r",
      "519: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SA2.WAV\r",
      "520: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI1575.WAV\r",
      "521: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SA1.WAV\r",
      "522: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX225.WAV\r",
      "523: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX405.WAV\r",
      "524: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI945.WAV\r",
      "525: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SA2.WAV\r",
      "526: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX45.WAV\r",
      "527: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX315.WAV\r",
      "528: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX135.WAV\r",
      "529: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI2205.WAV\r",
      "530: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX62.WAV\r",
      "531: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SA1.WAV\r",
      "532: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI1682.WAV\r",
      "533: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX152.WAV\r",
      "534: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX332.WAV\r",
      "535: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI1052.WAV\r",
      "536: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX242.WAV\r",
      "537: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI2312.WAV\r",
      "538: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SA2.WAV\r",
      "539: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX422.WAV\r",
      "540: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SA1.WAV\r",
      "541: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX220.WAV\r",
      "542: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI850.WAV\r",
      "543: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI1480.WAV\r",
      "544: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX310.WAV\r",
      "545: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI2110.WAV\r",
      "546: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX40.WAV\r",
      "547: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX400.WAV\r",
      "548: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SA2.WAV\r",
      "549: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX130.WAV\r",
      "550: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI1234.WAV\r",
      "551: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX64.WAV\r",
      "552: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI604.WAV\r",
      "553: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SA1.WAV\r",
      "554: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI1864.WAV\r",
      "555: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX334.WAV\r",
      "556: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX244.WAV\r",
      "557: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX424.WAV\r",
      "558: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SA2.WAV\r",
      "559: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX154.WAV\r",
      "560: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI2267.WAV\r",
      "561: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX17.WAV\r",
      "562: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX107.WAV\r",
      "563: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SA1.WAV\r",
      "564: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI1007.WAV\r",
      "565: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX287.WAV\r",
      "566: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX197.WAV\r",
      "567: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SA2.WAV\r",
      "568: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI1637.WAV\r",
      "569: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX377.WAV\r",
      "570: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX149.WAV\r",
      "571: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SA1.WAV\r",
      "572: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI1589.WAV\r",
      "573: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX419.WAV\r",
      "574: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX239.WAV\r",
      "575: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX329.WAV\r",
      "576: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX59.WAV\r",
      "577: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI2219.WAV\r",
      "578: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI2216.WAV\r",
      "579: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SA2.WAV\r",
      "580: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI2281.WAV\r",
      "581: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SA1.WAV\r",
      "582: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX121.WAV\r",
      "583: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX391.WAV\r",
      "584: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI1021.WAV\r",
      "585: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX211.WAV\r",
      "586: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI1349.WAV\r",
      "587: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX301.WAV\r",
      "588: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SA2.WAV\r",
      "589: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX31.WAV\r",
      "590: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SA1.WAV\r",
      "591: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX241.WAV\r",
      "592: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI1771.WAV\r",
      "593: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX331.WAV\r",
      "594: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX61.WAV\r",
      "595: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI2221.WAV\r",
      "596: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX151.WAV\r",
      "597: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX421.WAV\r",
      "598: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SA2.WAV\r",
      "599: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI1141.WAV\r",
      "600: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SA1.WAV\r",
      "601: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX136.WAV\r",
      "602: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX406.WAV\r",
      "603: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI2206.WAV\r",
      "604: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI946.WAV\r",
      "605: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX316.WAV\r",
      "606: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX226.WAV\r",
      "607: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX46.WAV\r",
      "608: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI1576.WAV\r",
      "609: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SA2.WAV\r",
      "610: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SA1.WAV\r",
      "611: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX121.WAV\r",
      "612: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX391.WAV\r",
      "613: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX211.WAV\r",
      "614: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI2101.WAV\r",
      "615: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI1471.WAV\r",
      "616: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX301.WAV\r",
      "617: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SA2.WAV\r",
      "618: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI841.WAV\r",
      "619: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX31.WAV\r",
      "620: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI1443.WAV\r",
      "621: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SA1.WAV\r",
      "622: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX273.WAV\r",
      "623: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI2073.WAV\r",
      "624: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI1525.WAV\r",
      "625: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX183.WAV\r",
      "626: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX93.WAV\r",
      "627: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX3.WAV\r",
      "628: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SA2.WAV\r",
      "629: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX363.WAV\r",
      "630: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SA1.WAV\r",
      "631: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX270.WAV\r",
      "632: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI2340.WAV\r",
      "633: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX360.WAV\r",
      "634: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX450.WAV\r",
      "635: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX90.WAV\r",
      "636: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI1080.WAV\r",
      "637: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SA2.WAV\r",
      "638: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI1710.WAV\r",
      "639: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX180.WAV\r",
      "640: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX169.WAV\r",
      "641: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA1.WAV\r",
      "642: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX439.WAV\r",
      "643: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX259.WAV\r",
      "644: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI529.WAV\r",
      "645: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA2.WAV\r",
      "646: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX79.WAV\r",
      "647: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI1159.WAV\r",
      "648: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX349.WAV\r",
      "649: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI1789.WAV\r",
      "650: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SA1.WAV\r",
      "651: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX355.WAV\r",
      "652: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX445.WAV\r",
      "653: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX265.WAV\r",
      "654: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX85.WAV\r",
      "655: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI2144.WAV\r",
      "656: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX175.WAV\r",
      "657: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI2065.WAV\r",
      "658: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SA2.WAV\r",
      "659: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI1435.WAV\r",
      "660: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI2011.WAV\r",
      "661: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SA1.WAV\r",
      "662: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX121.WAV\r",
      "663: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX391.WAV\r",
      "664: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI661.WAV\r",
      "665: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX211.WAV\r",
      "666: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI1921.WAV\r",
      "667: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX301.WAV\r",
      "668: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SA2.WAV\r",
      "669: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX31.WAV\r",
      "670: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SA1.WAV\r",
      "671: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX32.WAV\r",
      "672: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI505.WAV\r",
      "673: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX212.WAV\r",
      "674: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX392.WAV\r",
      "675: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI757.WAV\r",
      "676: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX302.WAV\r",
      "677: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI2102.WAV\r",
      "678: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX122.WAV\r",
      "679: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SA2.WAV\r",
      "680: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX42.WAV\r",
      "681: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX222.WAV\r",
      "682: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SA1.WAV\r",
      "683: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX312.WAV\r",
      "684: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1694.WAV\r",
      "685: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1212.WAV\r",
      "686: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX132.WAV\r",
      "687: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SA2.WAV\r",
      "688: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1842.WAV\r",
      "689: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX402.WAV\r",
      "690: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX237.WAV\r",
      "691: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SA1.WAV\r",
      "692: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI2307.WAV\r",
      "693: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX147.WAV\r",
      "694: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX327.WAV\r",
      "695: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX417.WAV\r",
      "696: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI1047.WAV\r",
      "697: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SA2.WAV\r",
      "698: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI1677.WAV\r",
      "699: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX57.WAV\r",
      "700: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SA1.WAV\r",
      "701: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX160.WAV\r",
      "702: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX340.WAV\r",
      "703: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI2230.WAV\r",
      "704: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX250.WAV\r",
      "705: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX430.WAV\r",
      "706: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX70.WAV\r",
      "707: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SA2.WAV\r",
      "708: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI506.WAV\r",
      "709: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI1600.WAV\r",
      "710: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI682.WAV\r",
      "711: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SA1.WAV\r",
      "712: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI710.WAV\r",
      "713: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX434.WAV\r",
      "714: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX74.WAV\r",
      "715: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX254.WAV\r",
      "716: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI1604.WAV\r",
      "717: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX344.WAV\r",
      "718: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX164.WAV\r",
      "719: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SA2.WAV\r",
      "720: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA1.WAV\r",
      "721: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX336.WAV\r",
      "722: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1326.WAV\r",
      "723: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1956.WAV\r",
      "724: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1655.WAV\r",
      "725: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX156.WAV\r",
      "726: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA2.WAV\r",
      "727: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX426.WAV\r",
      "728: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX246.WAV\r",
      "729: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX66.WAV\r",
      "730: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SA1.WAV\r",
      "731: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX232.WAV\r",
      "732: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX142.WAV\r",
      "733: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX412.WAV\r",
      "734: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX52.WAV\r",
      "735: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1672.WAV\r",
      "736: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1705.WAV\r",
      "737: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1042.WAV\r",
      "738: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SA2.WAV\r",
      "739: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX322.WAV\r",
      "740: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX167.WAV\r",
      "741: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX17.WAV\r",
      "742: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX437.WAV\r",
      "743: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SA1.WAV\r",
      "744: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX77.WAV\r",
      "745: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI1787.WAV\r",
      "746: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX257.WAV\r",
      "747: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI527.WAV\r",
      "748: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI1157.WAV\r",
      "749: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SA2.WAV\r",
      "750: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX62.WAV\r",
      "751: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI612.WAV\r",
      "752: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SA1.WAV\r",
      "753: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI1772.WAV\r",
      "754: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI512.WAV\r",
      "755: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX152.WAV\r",
      "756: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX332.WAV\r",
      "757: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX242.WAV\r",
      "758: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SA2.WAV\r",
      "759: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX422.WAV\r",
      "760: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI1666.WAV\r",
      "761: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SA1.WAV\r",
      "762: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX136.WAV\r",
      "763: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX406.WAV\r",
      "764: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX316.WAV\r",
      "765: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX226.WAV\r",
      "766: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX46.WAV\r",
      "767: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI1036.WAV\r",
      "768: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SA2.WAV\r",
      "769: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI2296.WAV\r",
      "770: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA1.WAV\r",
      "771: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX240.WAV\r",
      "772: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI780.WAV\r",
      "773: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI1410.WAV\r",
      "774: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX60.WAV\r",
      "775: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI2040.WAV\r",
      "776: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA2.WAV\r",
      "777: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX420.WAV\r",
      "778: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX330.WAV\r",
      "779: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX150.WAV\r",
      "780: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI1763.WAV\r",
      "781: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SA1.WAV\r",
      "782: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX354.WAV\r",
      "783: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX174.WAV\r",
      "784: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI1434.WAV\r",
      "785: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX264.WAV\r",
      "786: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX444.WAV\r",
      "787: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX84.WAV\r",
      "788: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SA2.WAV\r",
      "789: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI804.WAV\r",
      "790: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SA1.WAV\r",
      "791: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI1102.WAV\r",
      "792: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI472.WAV\r",
      "793: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX112.WAV\r",
      "794: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX202.WAV\r",
      "795: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX22.WAV\r",
      "796: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX292.WAV\r",
      "797: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI1732.WAV\r",
      "798: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX382.WAV\r",
      "799: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SA2.WAV\r",
      "800: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SA1.WAV\r",
      "801: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI1291.WAV\r",
      "802: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX121.WAV\r",
      "803: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI1381.WAV\r",
      "804: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX391.WAV\r",
      "805: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX211.WAV\r",
      "806: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX301.WAV\r",
      "807: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SA2.WAV\r",
      "808: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI751.WAV\r",
      "809: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX31.WAV\r",
      "810: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX311.WAV\r",
      "811: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX221.WAV\r",
      "812: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI1844.WAV\r",
      "813: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA1.WAV\r",
      "814: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI1571.WAV\r",
      "815: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX41.WAV\r",
      "816: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI2201.WAV\r",
      "817: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX401.WAV\r",
      "818: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA2.WAV\r",
      "819: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX131.WAV\r",
      "820: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX248.WAV\r",
      "821: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX428.WAV\r",
      "822: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA1.WAV\r",
      "823: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX68.WAV\r",
      "824: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1778.WAV\r",
      "825: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI518.WAV\r",
      "826: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX338.WAV\r",
      "827: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1148.WAV\r",
      "828: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX158.WAV\r",
      "829: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA2.WAV\r",
      "830: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1779.WAV\r",
      "831: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SA1.WAV\r",
      "832: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1149.WAV\r",
      "833: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX339.WAV\r",
      "834: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX429.WAV\r",
      "835: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX69.WAV\r",
      "836: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX159.WAV\r",
      "837: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI2075.WAV\r",
      "838: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SA2.WAV\r",
      "839: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX249.WAV\r",
      "840: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX111.WAV\r",
      "841: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI921.WAV\r",
      "842: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA1.WAV\r",
      "843: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX21.WAV\r",
      "844: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX201.WAV\r",
      "845: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI1402.WAV\r",
      "846: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA2.WAV\r",
      "847: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI2181.WAV\r",
      "848: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX291.WAV\r",
      "849: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX381.WAV\r",
      "850: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX248.WAV\r",
      "851: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX428.WAV\r",
      "852: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SA1.WAV\r",
      "853: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX68.WAV\r",
      "854: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX338.WAV\r",
      "855: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX158.WAV\r",
      "856: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI1418.WAV\r",
      "857: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI788.WAV\r",
      "858: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SA2.WAV\r",
      "859: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI2048.WAV\r",
      "860: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX271.WAV\r",
      "861: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SA1.WAV\r",
      "862: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX91.WAV\r",
      "863: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX451.WAV\r",
      "864: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI991.WAV\r",
      "865: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX181.WAV\r",
      "866: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SA2.WAV\r",
      "867: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI2251.WAV\r",
      "868: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI1621.WAV\r",
      "869: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX361.WAV\r",
      "870: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX167.WAV\r",
      "871: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI1697.WAV\r",
      "872: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX437.WAV\r",
      "873: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA1.WAV\r",
      "874: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX77.WAV\r",
      "875: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX257.WAV\r",
      "876: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI2327.WAV\r",
      "877: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX24.WAV\r",
      "878: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA2.WAV\r",
      "879: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI1067.WAV\r",
      "880: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX234.WAV\r",
      "881: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SA1.WAV\r",
      "882: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX324.WAV\r",
      "883: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI774.WAV\r",
      "884: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI2034.WAV\r",
      "885: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI717.WAV\r",
      "886: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX54.WAV\r",
      "887: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX414.WAV\r",
      "888: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX144.WAV\r",
      "889: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SA2.WAV\r",
      "890: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SA1.WAV\r",
      "891: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI1192.WAV\r",
      "892: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX112.WAV\r",
      "893: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX202.WAV\r",
      "894: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX22.WAV\r",
      "895: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX292.WAV\r",
      "896: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI562.WAV\r",
      "897: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX382.WAV\r",
      "898: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI1822.WAV\r",
      "899: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SA2.WAV\r",
      "900: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI1554.WAV\r",
      "901: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SA1.WAV\r",
      "902: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX114.WAV\r",
      "903: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX384.WAV\r",
      "904: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX294.WAV\r",
      "905: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI675.WAV\r",
      "906: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI924.WAV\r",
      "907: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX24.WAV\r",
      "908: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SA2.WAV\r",
      "909: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX204.WAV\r",
      "910: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SA1.WAV\r",
      "911: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX114.WAV\r",
      "912: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX384.WAV\r",
      "913: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX294.WAV\r",
      "914: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI744.WAV\r",
      "915: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX24.WAV\r",
      "916: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI2004.WAV\r",
      "917: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI1374.WAV\r",
      "918: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SA2.WAV\r",
      "919: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX204.WAV\r",
      "920: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI2067.WAV\r",
      "921: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SA1.WAV\r",
      "922: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX87.WAV\r",
      "923: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX357.WAV\r",
      "924: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX447.WAV\r",
      "925: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX177.WAV\r",
      "926: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI1533.WAV\r",
      "927: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX267.WAV\r",
      "928: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SA2.WAV\r",
      "929: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI1437.WAV\r",
      "930: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX271.WAV\r",
      "931: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI1837.WAV\r",
      "932: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SA1.WAV\r",
      "933: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI1261.WAV\r",
      "934: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX91.WAV\r",
      "935: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI631.WAV\r",
      "936: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX451.WAV\r",
      "937: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX181.WAV\r",
      "938: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SA2.WAV\r",
      "939: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX361.WAV\r",
      "940: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI2036.WAV\r",
      "941: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX56.WAV\r",
      "942: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SA1.WAV\r",
      "943: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX146.WAV\r",
      "944: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX326.WAV\r",
      "945: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI1271.WAV\r",
      "946: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX416.WAV\r",
      "947: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX236.WAV\r",
      "948: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI1406.WAV\r",
      "949: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SA2.WAV\r",
      "950: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI798.WAV\r",
      "951: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SA1.WAV\r",
      "952: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX78.WAV\r",
      "953: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI2058.WAV\r",
      "954: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX258.WAV\r",
      "955: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX438.WAV\r",
      "956: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX168.WAV\r",
      "957: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SA2.WAV\r",
      "958: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI1428.WAV\r",
      "959: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX348.WAV\r",
      "960: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI792.WAV\r",
      "961: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SA1.WAV\r",
      "962: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX252.WAV\r",
      "963: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX342.WAV\r",
      "964: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI2052.WAV\r",
      "965: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX162.WAV\r",
      "966: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX72.WAV\r",
      "967: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX432.WAV\r",
      "968: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SA2.WAV\r",
      "969: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI1954.WAV\r",
      "970: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX127.WAV\r",
      "971: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA1.WAV\r",
      "972: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX217.WAV\r",
      "973: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI648.WAV\r",
      "974: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX307.WAV\r",
      "975: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1657.WAV\r",
      "976: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX397.WAV\r",
      "977: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA2.WAV\r",
      "978: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX37.WAV\r",
      "979: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1027.WAV\r",
      "980: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI1865.WAV\r",
      "981: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SA1.WAV\r",
      "982: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX65.WAV\r",
      "983: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX425.WAV\r",
      "984: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI605.WAV\r",
      "985: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI1235.WAV\r",
      "986: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX335.WAV\r",
      "987: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SA2.WAV\r",
      "988: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX245.WAV\r",
      "989: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX155.WAV\r",
      "990: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA1.WAV\r",
      "991: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI2096.WAV\r",
      "992: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX116.WAV\r",
      "993: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI836.WAV\r",
      "994: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX26.WAV\r",
      "995: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX386.WAV\r",
      "996: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI1466.WAV\r",
      "997: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA2.WAV\r",
      "998: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX206.WAV\r",
      "999: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX296.WAV\r"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):   \n",
    "    return waveform, ()\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    # scale window between -1 and 1\n",
    "    processed = np.copy(windows)\n",
    "   \n",
    "    mn = np.min(processed, axis = 1)\n",
    "    mx = np.max(processed, axis = 1)\n",
    "\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "\n",
    "    for i in xrange(0, processed.shape[0]):\n",
    "        processed[i] /= maxabs[i]\n",
    "    #processed *= 0.98\n",
    "   \n",
    "    #processed = (processed + 1.0) / 2.0\n",
    "   \n",
    "    return processed, (maxabs,)\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    # scale window from [-1, 1] to [-32768, 32768]\n",
    "    scl = params[0]\n",
    "   \n",
    "    unprocessed = np.copy(windows)\n",
    "    #unprocessed /= 0.98\n",
    "   \n",
    "    #nprocessed = (unprocessed * 2.0) - 1.0\n",
    "   \n",
    "    for i in xrange(0, unprocessed.shape[0]):\n",
    "        unprocessed[i] *= scl[i]\n",
    "\n",
    "    return unprocessed\n",
    "#'''\n",
    "\n",
    "#'''\n",
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):\n",
    "    # scale window between -1 and 1\n",
    "    mn = np.min(waveform)\n",
    "    mx = np.max(waveform)\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "        \n",
    "    return np.copy(waveform) / maxabs, (maxabs,)\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return np.copy(waveform) * params[0]\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    return windows, ()\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    return windows\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(rawWaveforms[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (101135, 512)\n",
      "Max:  1.0\n",
      "Min:  -1.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (101135, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101135, 512, 1)\n",
      "9.77603e-07\n",
      "0.099766\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CodeRound(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, nbins):\n",
    "        self.nbins = nbins\n",
    "        super(CodeRound, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        s = (x + 1.0) / 2.0\n",
    "        s = np.round(s * float(self.nbins - 1)) / float(self.nbins - 1)\n",
    "        s = (s * 2.0) - 1.0\n",
    "        \n",
    "        z[0] = s\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        x, = input\n",
    "        g, = output_gradients\n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IntegerRound(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(IntegerRound, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        z[0] = np.round(x)\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        x, = input\n",
    "        g, = output_gradients\n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from scipy.ndimage import convolve1d\n",
    "\n",
    "class LowpassLayer(Layer):\n",
    "    \"\"\" Performs lowpass filter on input\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LowpassLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert(len(input_shape) == 3)\n",
    "        self.n = input_shape[1]\n",
    "\n",
    "        self.filt = np.eye(self.n)\n",
    "        self.filt = gaussian_filter1d(self.filt, 0.75)\n",
    "        self.filt = K.variable(self.filt)\n",
    "        \n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        out = T.tensordot(self.filt, x, axes = [0, 1])\n",
    "        out = K.permute_dimensions(out, (1, 0, 2))\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(LowpassLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhaseShiftUp1D(Layer):\n",
    "    \"\"\" PhaseShiftUp1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShiftUp1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShiftUp1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_upsample_1d(x):\n",
    "    r = T.repeat(x, 2, axis = 1)\n",
    "    s = T.roll(r, -1, axis = 1)\n",
    "    u = ((r[:, :-1] + s[:, :-1]) / 2.0)\n",
    "    u = T.concatenate((u, r[:, -1:]), axis = 1)\n",
    "    return u\n",
    "\n",
    "def linear_upsample_shape(shape):\n",
    "    return (shape[0], shape[1] * 2, shape[2])\n",
    "\n",
    "# linear upsampling \"layer\"\n",
    "def LinearUpSampling1D():\n",
    "    return Lambda(linear_upsample_1d, output_shape = linear_upsample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UniformNoise(Layer):\n",
    "    def __init__(self, scale, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.scale = scale\n",
    "        self.uses_learning_phase = True\n",
    "        super(UniformNoise, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        noise_x = x + K.random_uniform(shape = K.shape(x),\n",
    "                                       low = -self.scale,\n",
    "                                       high = self.scale)\n",
    "        return K.in_train_phase(noise_x, x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'scale': self.scale}\n",
    "        base_config = super(UniformNoise, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 1)             137361      input_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 137,361\n",
      "Trainable params: 137,361\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_6 (Model)                  (None, 128)           146401      input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_7 (Model)                  (None, 512, 1)        187969      model_6[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 334,370\n",
      "Trainable params: 334,370\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_6 (Model)                  (None, 128)           146401      input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_7 (Model)                  (None, 512, 1)        187969      model_6[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 1)             137361      model_7[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 471,731\n",
      "Trainable params: 471,731\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import softmax, sigmoid\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# ====================================================\n",
    "# PARAMETERS FOR AUTOENCODER STRUCTURE\n",
    "# ====================================================\n",
    "BNORM_GEN = False\n",
    "BNORM_DSC = False\n",
    "\n",
    "NBINS = 201\n",
    "TIMES_DOWNSAMPLE = 2\n",
    "\n",
    "NCHAN = 48\n",
    "FILT_SIZE = 9\n",
    "FILT_MID = FILT_SIZE / 2 + 1\n",
    "OUT_CHANS = 1\n",
    "\n",
    "NUM_RES_BLOCKS = 2\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = WINDOW_SIZE / int(2 ** TIMES_DOWNSAMPLE)\n",
    "\n",
    "res_init = 'glorot_normal'\n",
    "\n",
    "def activation():\n",
    "    return LeakyReLU(0.2)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# weight initializers\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# convolutional layers have weight matrices of shape:\n",
    "#     (filter_length, 1, input_dim, nb_filter)\n",
    "# and biases of size (nb_filter,)\n",
    "\n",
    "# weights for an \"replication convolution\" (which just\n",
    "# replicates the input across all channels)\n",
    "#     filter of length FILT_SIZE, going from 1 channel to NCHAN\n",
    "def replicate_conv():\n",
    "    weights = np.zeros((FILT_SIZE, 1, 1, NCHAN))\n",
    "    weights[FILT_MID] = np.ones((1, 1, NCHAN))\n",
    "    #weights += np.random.uniform(-0.005, 0.005, weights.shape)\n",
    "    biases = np.zeros((NCHAN,))\n",
    "    return [weights, biases]\n",
    "\n",
    "# weights for an \"average convolution\" (which just\n",
    "# replicates the input across all channels)\n",
    "#     filter of length 1, going from NCHAN channels to 1\n",
    "def average_conv(sz):\n",
    "    mid = sz / 2 + 1\n",
    "    if (sz == 1): mid = 0\n",
    "\n",
    "    weights = np.zeros((sz, 1, NCHAN, 1))\n",
    "    weights[mid] = np.ones((1, NCHAN, 1)) / float(NCHAN)\n",
    "    #weights += np.random.uniform(-0.005, 0.005, weights.shape)\n",
    "    biases = np.zeros((1,))\n",
    "    return [weights, biases]\n",
    "\n",
    "# weights for a \"identity\" convolution (by default,\n",
    "# does nothing to its input)\n",
    "#     filter of length FILT_SIZE, going from NCHAN to NCHAN\n",
    "#     (when combined with subsampling, this is a nearest-neighbor\n",
    "#      downsample)\n",
    "def identity_conv():\n",
    "    weights = np.zeros((FILT_SIZE, 1, NCHAN, NCHAN))\n",
    "    weights[FILT_MID, 0] = np.eye(NCHAN)\n",
    "    #weights += np.random.uniform(-0.005, 0.005, weights.shape)\n",
    "    biases = np.zeros((NCHAN,))\n",
    "    return [weights, biases]\n",
    "\n",
    "\n",
    "# weights for a \"phase shift up\" convolution (by default,\n",
    "# performs an upsample)\n",
    "#     filter of length FILT_SIZE, going from NCHAN to NCHAN * 2\n",
    "def shift_up_conv():\n",
    "    weights = np.zeros((FILT_SIZE, 1, NCHAN, NCHAN * 2))\n",
    "    weights[FILT_MID, 0] = np.repeat(np.eye(NCHAN), 2, axis = 1)\n",
    "    #weights += np.random.uniform(-0.01, 0.01, weights.shape)\n",
    "    biases = np.zeros((NCHAN * 2,))\n",
    "    return [weights, biases]\n",
    "\n",
    "# random identity weights, plus some noise\n",
    "def identity_mat(n):\n",
    "    weights = np.eye(n) + np.random.uniform(-0.01, 0.01, (n, n))\n",
    "    biases = np.zeros(n)\n",
    "    return [weights, biases]\n",
    "\n",
    "# weights for DCT and IDCT (can use in a Dense layer, perhaps)\n",
    "def dct_weights(n):\n",
    "    weights = dct(np.eye(n), norm = 'ortho')\n",
    "    biases = np.zeros(n)\n",
    "    return [weights, biases]\n",
    "\n",
    "def idct_weights(n):\n",
    "    weights = idct(np.eye(n), norm = 'ortho')\n",
    "    biases = np.zeros(n)\n",
    "    return [weights, biases]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# blocks of network\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# residual block, going from NCHAN to NCHAN channels\n",
    "def residual_block():\n",
    "    def f(input):\n",
    "        shortcut = input\n",
    "        \n",
    "        res = Convolution1D(NCHAN, FILT_SIZE, border_mode = 'same',\n",
    "                          init = res_init, activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        res = activation()(res)\n",
    "        if (BNORM_GEN): res = BatchNormalization(axis = 1)(res)\n",
    "        res = Convolution1D(NCHAN, FILT_SIZE, border_mode = 'same',\n",
    "                          init = res_init, activation = 'linear',\n",
    "                          bias = True)(res)\n",
    "        \n",
    "        m = merge([shortcut, res], mode = 'sum')\n",
    "        return m\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "# increase number of channels from 1 to NCHAN via convolution\n",
    "def channel_increase_block():\n",
    "    def f(input):\n",
    "        '''\n",
    "        shortcut = Lambda(lambda x : K.repeat_elements(x, NCHAN, axis = -1),\n",
    "                          output_shape = (lambda s : (s[0], s[1], NCHAN)))(input)\n",
    "        \n",
    "        res = Convolution1D(NCHAN, FILT_SIZE, border_mode = 'same',\n",
    "                              activation = 'linear',\n",
    "                              init = res_init,\n",
    "                              bias = True)(input)\n",
    "        if (BNORM_GEN): res = BatchNormalization(axis = 1)(res)\n",
    "        res = activation()(res)\n",
    "        \n",
    "        m = merge([shortcut, res], mode = 'sum')\n",
    "        return m\n",
    "        '''\n",
    "        \n",
    "        out = Convolution1D(NCHAN, FILT_SIZE, border_mode = 'same',\n",
    "                              activation = 'linear',\n",
    "                              init = res_init,\n",
    "                              bias = True)(input)\n",
    "        if (BNORM_GEN): out = BatchNormalization(axis = 1)(out)\n",
    "        out = activation()(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "# downsample the signal 2x\n",
    "def downsample_block():\n",
    "    def f(input):\n",
    "        shortcut = AveragePooling1D(2)(input)\n",
    "        \n",
    "        res = Convolution1D(NCHAN, FILT_SIZE, border_mode = 'same',\n",
    "                              init = res_init, activation = 'linear',\n",
    "                              subsample_length = 2, bias = True)(input)\n",
    "        if (BNORM_GEN): res = BatchNormalization(axis = 1)(res)\n",
    "        res = activation()(res)\n",
    "        \n",
    "        m = merge([shortcut, res], mode = 'sum')\n",
    "        return m\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "# upsample the signal 2x\n",
    "def upsample_block():\n",
    "    def f(input):\n",
    "        upsampled = LinearUpSampling1D()(input)\n",
    "        \n",
    "        res = Convolution1D(NCHAN * 2, FILT_SIZE, border_mode = 'same',\n",
    "                              init = res_init, activation = 'linear',\n",
    "                              bias = True)(input)\n",
    "        if (BNORM_GEN): res = BatchNormalization(axis = 1)(res)\n",
    "        res = activation()(res)\n",
    "        res = PhaseShiftUp1D(2)(res)\n",
    "        \n",
    "        m = merge([upsampled, res], mode = 'sum')\n",
    "        return m\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = Reshape(dim, input_shape = dim)(enc_input)\n",
    "    \n",
    "    #enc = Reshape((WINDOW_SIZE,))(enc)\n",
    "    #enc = Dense(WINDOW_SIZE, init = 'identity')(enc)\n",
    "    #enc = Reshape((WINDOW_SIZE, 1))(enc)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    enc = channel_increase_block()(enc)\n",
    "    \n",
    "    \n",
    "    # residual downsampling\n",
    "    down = enc\n",
    "    res = enc\n",
    "    \n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE):\n",
    "        down = AveragePooling1D(2)(down)\n",
    "        \n",
    "    \n",
    "    res = Convolution1D(NCHAN, FILT_SIZE, border_mode = 'same',\n",
    "                        init = res_init, activation = 'linear',\n",
    "                        bias = True)(res)\n",
    "    res = activation()(res)\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE): \n",
    "        res = downsample_block()(res)\n",
    "    \n",
    "    enc = merge([down, res], mode = 'sum') \n",
    "    \n",
    "    \n",
    "    # residual blocks\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        enc = residual_block()(enc)\n",
    "    \n",
    "    # convolution across feature maps\n",
    "    enc = Convolution1D(OUT_CHANS, FILT_SIZE, border_mode = 'same',\n",
    "                        weights = average_conv(FILT_SIZE), activation = 'linear',\n",
    "                        bias = True)(enc)\n",
    "    \n",
    "    enc = Reshape((bottleneck_size * OUT_CHANS,))(enc)\n",
    "    \n",
    "    enc = Activation('tanh')(enc)\n",
    "    enc = Lambda(lambda x : CodeRound(NBINS)(x))(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_input = Input(shape = (bottleneck_size * OUT_CHANS,))\n",
    "    dec = Reshape((bottleneck_size * OUT_CHANS,), input_shape = (bottleneck_size * OUT_CHANS,))(dec_input)\n",
    "    \n",
    "    dec = Reshape((bottleneck_size, OUT_CHANS,))(dec)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    dec = channel_increase_block()(dec)\n",
    "    \n",
    "    # residual blocks\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        dec = residual_block()(dec)\n",
    "        \n",
    "    # residual upsampling\n",
    "    up = dec\n",
    "    res = dec\n",
    "    \n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE):\n",
    "        up = LinearUpSampling1D()(up)\n",
    "    \n",
    "    res = Convolution1D(NCHAN, FILT_SIZE, border_mode = 'same',\n",
    "                        init = res_init, activation = 'linear',\n",
    "                        bias = True)(res)\n",
    "    res = activation()(res)\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE):\n",
    "        res = upsample_block()(res)\n",
    "    \n",
    "    dec = merge([up, res], mode = 'sum')\n",
    "    \n",
    "    # convolution across feature maps\n",
    "    dec = Convolution1D(1, FILT_SIZE, border_mode = 'same',\n",
    "                        weights = average_conv(FILT_SIZE), activation = 'linear',\n",
    "                        bias = True)(dec)\n",
    "    dec = Activation('tanh')(dec)\n",
    "    \n",
    "    #dec = Reshape((WINDOW_SIZE,))(dec)\n",
    "    #dec = Dense(WINDOW_SIZE, init = 'identity')(dec)\n",
    "    #dec = Reshape((WINDOW_SIZE, 1))(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "DSC_FILTS = 16\n",
    "DSC_DENSE = 16\n",
    "DSC_FILT_SIZE = 9\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    \n",
    "    for i in xrange(0, 3):\n",
    "        dsc.add(Convolution1D(DSC_FILTS * (2 ** i), DSC_FILT_SIZE, border_mode='same',\n",
    "                                        init = 'he_uniform',\n",
    "                                        input_shape = dim, activation = 'linear'))\n",
    "        if (BNORM_DSC): dsc.add(BatchNormalization(axis = 1))\n",
    "        dsc.add(LeakyReLU(0.3))\n",
    "\n",
    "        dsc.add(Convolution1D(DSC_FILTS * (2 ** i), DSC_FILT_SIZE, border_mode='same',\n",
    "                                        init = 'he_uniform',\n",
    "                                        activation = 'linear'))\n",
    "        if (BNORM_DSC): dsc.add(BatchNormalization(axis = 1))\n",
    "        dsc.add(LeakyReLU(0.3))\n",
    "        dsc.add(AveragePooling1D(2))\n",
    "        \n",
    "    dsc.add(Flatten())\n",
    "    \n",
    "    dsc.add(Dense(DSC_DENSE, init = 'he_uniform'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    #'''\n",
    "    \n",
    "    dsc.add(Dense(1, activation = 'linear', init = 'he_uniform'))\n",
    "    \n",
    "    return dsc, None\n",
    "\n",
    "\n",
    "# construct autoencoder to be used in adversarial training\n",
    "ac_input = Input(shape = input_dim)\n",
    "ac_enc, ac_dec = autoencoder_structure(input_dim)\n",
    "ac_embedding = ac_enc(ac_input)\n",
    "ac_reconstructed = ac_dec(ac_embedding)\n",
    "\n",
    "autoencoder = Model(input = [ac_input], output = [ac_reconstructed])\n",
    "autoencoder.compile(loss = 'mean_squared_error', optimizer = Adam())\n",
    "\n",
    "# construct discriminator: regular\n",
    "dsc_input_dim = (WINDOW_SIZE, 1)\n",
    "dsc_input = Input(shape = input_dim)\n",
    "dsc_struct, dscfeat_struct = discriminator_structure(dsc_input_dim)\n",
    "dsc_label = dsc_struct(dsc_input)\n",
    "ac_dsc_label = dsc_struct(ac_reconstructed)\n",
    "\n",
    "# get feature loss at intermediate layer of discriminator\n",
    "#dscfeat_inp = dscfeat_struct(ac_input)\n",
    "#dscfeat_rec = dscfeat_struct(ac_reconstructed)\n",
    "#dscfeat_mse = Lambda(mse_lambda, output_shape = (1,))([dscfeat_inp, dscfeat_rec])\n",
    "\n",
    "\n",
    "    \n",
    "# ------------------------------------------------------------------\n",
    "# PARZEN ENTROPY ESTIMATION\n",
    "# ------------------------------------------------------------------\n",
    "# the Parzen kernel is a zero-centered gaussian with bin-width standard deviation\n",
    "std = (1.0 / (NBINS - 1))\n",
    "norm = 1.0 / math.sqrt(2.0 * 3.14159 * std * std)\n",
    "den = (2.0 * std * std)\n",
    "\n",
    "def parzen_kernel(x):\n",
    "    num = K.square(x)\n",
    "    return norm * K.exp(-num / den)\n",
    "\n",
    "# we use 10,000 samples to create our entropy estimate\n",
    "N = 10000\n",
    "log_2 = math.log(2.0)\n",
    "bins = K.variable(np.linspace(-1.0, 1.0, NBINS))\n",
    "r_bins = K.repeat_elements(bins.reshape((NBINS, 1)), N, 1)\n",
    "\n",
    "# we increase the weight of the entropy loss over time while\n",
    "# training\n",
    "entropy_weight = K.variable(0.0, name = 'entropy_weight')\n",
    "max_entropy_weight = 1.0\n",
    "entropy_weight_rate = 0.1\n",
    "\n",
    "def entropy_estimate(placeholder, code):\n",
    "    # if there are less than N samples in this batch, we just use however much data\n",
    "    # we have\n",
    "    flt = K.flatten(code)\n",
    "    end_idx = K.minimum(flt.shape[0], N)\n",
    "    \n",
    "    ref = flt[:end_idx]\n",
    "    r_ref = K.repeat_elements(ref.reshape((1, end_idx)), NBINS, 0)\n",
    "\n",
    "    r_kern = parzen_kernel(r_ref - r_bins[:, :end_idx])\n",
    "    r_kern = K.sum(r_kern, axis = 1)\n",
    "    r_kern /= K.sum(r_kern)\n",
    "\n",
    "    # clip to a low value so the log doesn't underflow\n",
    "    ent = K.clip(r_kern, 1e-9, 1.0)\n",
    "    ent = -K.sum(ent * K.log(ent) / log_2)\n",
    "    return ent#ent * entropy_weight\n",
    "\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = K.mean(K.square(y_pred - y_true))\n",
    "    mse = K.clip(mse, 1e-10, 1000000.0)\n",
    "    return K.sqrt(mse)\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [500.0, 1.0]\n",
    "loss_functions = ['mae', 'mse']\n",
    "n_recons = 1\n",
    "n_discrim = 1\n",
    "n_code = 0\n",
    "assert(n_recons + n_discrim + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))\n",
    "\n",
    "\n",
    "make_trainable(autoencoder, False)\n",
    "discriminator = Model(input = [dsc_input], output = [dsc_label])\n",
    "discriminator.compile(loss = ['mse'], optimizer = Adam())\n",
    "discriminator.summary()\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "make_trainable(discriminator, False)\n",
    "make_trainable(autoencoder, True)\n",
    "model = Model(input = [ac_input], output = [ac_reconstructed] * n_recons + \\\n",
    "                                           [ac_dsc_label] * n_discrim + \\\n",
    "                                           [ac_embedding] * n_code)\n",
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = Adam())\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "discrim_epoch = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    data = data.astype(np.float32)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    desired = np.clip(desired, -32767, 32767)\n",
    "    #sciwav.write(prefix + \"_res_desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = 128, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    recons = np.clip(recons, -32767, 32767)\n",
    "    \n",
    "    sciwav.write(prefix + \"_output.wav\", rate, recons.astype(np.int16))\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired)\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  16.796 0.0\n",
      "./SA1.WAV  mse:  154628.0\n",
      "./SA1.WAV  avg err:  210.384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4899.0, -4013.0, 16.795971, 0.0, 154628.2, 210.38448]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_res_uninit_\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interleave numpy arrays of the same size along the first axis\n",
    "def interleave(arr):    \n",
    "    num = len(arr)\n",
    "    \n",
    "    r = np.empty(arr[0].shape)\n",
    "    r = np.repeat(r, num, axis = 0)\n",
    "    \n",
    "    for i in xrange(0, num):\n",
    "        r[i::num] = arr[i]\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    101120: 0.15215370059  [5.065925 0.009188 0.471799] [5.065925 4.594126 0.471799] \n",
      "    Total time for epoch: 461.123466969s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 80.5% d_acc\n",
      "    Total time for evaluation: 1.62263607979s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.07134980912\n",
      "       Zero prob: 0.0494922\n",
      "       Mask entropy: 0.284235878936\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 121.665\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  3996.72 -3238.92\n",
      "    MSE:      6371.3\n",
      "    Avg err:  41.1869\n",
      "    Total time for evaluation: 0.121845006943s\n",
      "Epoch 2:\n",
      "    101120: 0.173751756549  [5.502212 0.009911 0.546820] [5.502212 4.955392 0.546820] \n",
      "    Total time for epoch: 437.83180809s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 76.75% d_acc\n",
      "    Total time for evaluation: 0.365374803543s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.57933678348\n",
      "       Zero prob: 0.0388672\n",
      "       Mask entropy: 0.237073955336\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.025\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4266.0 -3531.01\n",
      "    MSE:      4540.27\n",
      "    Avg err:  35.8806\n",
      "    Total time for evaluation: 0.116239070892s\n",
      "Epoch 3:\n",
      "    101120: 0.1780616045  [5.396670 0.009615 0.589128] [5.396670 4.807542 0.589128] \n",
      "    Total time for epoch: 437.633962154s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 76.25% d_acc\n",
      "    Total time for evaluation: 0.361088991165s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.6966308241\n",
      "       Zero prob: 0.0394531\n",
      "       Mask entropy: 0.239779151772\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 122.95\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4187.18 -3414.37\n",
      "    MSE:      4345.16\n",
      "    Avg err:  35.365\n",
      "    Total time for evaluation: 0.11542391777s\n",
      "Epoch 4:\n",
      "    101120: 0.169025152922  [5.906050 0.010661 0.575548] [5.906050 5.330502 0.575548] \n",
      "    Total time for epoch: 438.126894951s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 80.0% d_acc\n",
      "    Total time for evaluation: 0.361523866653s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.64482401168\n",
      "       Zero prob: 0.0309766\n",
      "       Mask entropy: 0.199265871324\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 124.035\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4292.94 -3672.93\n",
      "    MSE:      3621.54\n",
      "    Avg err:  32.3243\n",
      "    Total time for evaluation: 0.115603923798s\n",
      "Epoch 5:\n",
      "    101120: 0.157187581062  [4.765629 0.008805 0.363301] [4.765629 4.402328 0.363301] \n",
      "    Total time for epoch: 435.937926054s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 71.25% d_acc\n",
      "    Total time for evaluation: 0.362978935242s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.72084303741\n",
      "       Zero prob: 0.0350391\n",
      "       Mask entropy: 0.219064617003\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.515\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4321.48 -3733.55\n",
      "    MSE:      3584.38\n",
      "    Avg err:  32.5049\n",
      "    Total time for evaluation: 0.115509986877s\n",
      "Epoch 6:\n",
      "    101120: 0.173268795013  [4.746746 0.008752 0.370784] [4.746746 4.375962 0.370784] \n",
      "    Total time for epoch: 436.468067884s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.75% d_acc\n",
      "    Total time for evaluation: 0.365656137466s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.69913224065\n",
      "       Zero prob: 0.0463281\n",
      "       Mask entropy: 0.270589409796\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 122.07\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4343.79 -3586.81\n",
      "    MSE:      3310.86\n",
      "    Avg err:  30.8536\n",
      "    Total time for evaluation: 0.123958826065s\n",
      "Epoch 7:\n",
      "    101120: 0.211841270328  [4.402040 0.007570 0.617274] [4.402040 3.784766 0.617274] \n",
      "    Total time for epoch: 436.039968967s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 69.25% d_acc\n",
      "    Total time for evaluation: 0.359328985214s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.73627223621\n",
      "       Zero prob: 0.0283203\n",
      "       Mask entropy: 0.185897069617\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 124.375\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4330.29 -3552.91\n",
      "    MSE:      3246.2\n",
      "    Avg err:  31.3601\n",
      "    Total time for evaluation: 0.115693807602s\n",
      "Epoch 8:\n",
      "    101120: 0.202665522695  [4.631258 0.008389 0.436701] [4.631258 4.194556 0.436701] \n",
      "    Total time for epoch: 435.444460869s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 68.5% d_acc\n",
      "    Total time for evaluation: 0.358922958374s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.55868195209\n",
      "       Zero prob: 0.0394531\n",
      "       Mask entropy: 0.239779151772\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 122.95\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4340.86 -3543.51\n",
      "    MSE:      3004.09\n",
      "    Avg err:  30.4681\n",
      "    Total time for evaluation: 0.115792989731s\n",
      "Epoch 9:\n",
      "    101120: 0.165948972106  [4.663665 0.008393 0.466991] [4.663665 4.196673 0.466991] \n",
      "    Total time for epoch: 435.317679167s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 74.5% d_acc\n",
      "    Total time for evaluation: 0.358429908752s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.90010189674\n",
      "       Zero prob: 0.0324219\n",
      "       Mask entropy: 0.206395692915\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.85\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4397.36 -3542.35\n",
      "    MSE:      2766.96\n",
      "    Avg err:  28.7826\n",
      "    Total time for evaluation: 0.115136861801s\n",
      "Epoch 10:\n",
      "    101120: 0.176610216498  [3.925738 0.006967 0.442346] [3.925738 3.483392 0.442346] \n",
      "    Total time for epoch: 435.289660931s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 77.25% d_acc\n",
      "    Total time for evaluation: 0.363204956055s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.77063276925\n",
      "       Zero prob: 0.0336719\n",
      "       Mask entropy: 0.212484369737\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.69\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4354.01 -3465.84\n",
      "    MSE:      2991.16\n",
      "    Avg err:  29.5421\n",
      "    Total time for evaluation: 0.117655992508s\n",
      "Epoch 11:\n",
      "    101120: 0.252138257027  [5.088227 0.009477 0.349759] [5.088227 4.738468 0.349759] \n",
      "    Total time for epoch: 435.301222086s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 63.25% d_acc\n",
      "    Total time for evaluation: 0.359564065933s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.70046809309\n",
      "       Zero prob: 0.0525781\n",
      "       Mask entropy: 0.297249309239\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 121.27\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4398.43 -3549.39\n",
      "    MSE:      2799.26\n",
      "    Avg err:  30.6118\n",
      "    Total time for evaluation: 0.115760087967s\n",
      "Epoch 12:\n",
      "    101120: 0.171109497547  [4.576855 0.008404 0.374714] [4.576855 4.202140 0.374714] \n",
      "    Total time for epoch: 435.386229992s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 73.0% d_acc\n",
      "    Total time for evaluation: 0.361752033234s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.86874191626\n",
      "       Zero prob: 0.0361719\n",
      "       Mask entropy: 0.224456252621\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.37\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4508.23 -3487.78\n",
      "    MSE:      2539.32\n",
      "    Avg err:  28.1082\n",
      "    Total time for evaluation: 0.115576028824s\n",
      "Epoch 13:\n",
      "    101120: 0.175922349095  [4.820369 0.008677 0.481900] [4.820369 4.338469 0.481900] \n",
      "    Total time for epoch: 436.375865936s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 71.25% d_acc\n",
      "    Total time for evaluation: 0.362316131592s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.73166507879\n",
      "       Zero prob: 0.0477344\n",
      "       Mask entropy: 0.27669365741\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 121.89\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4399.33 -3391.69\n",
      "    MSE:      2481.46\n",
      "    Avg err:  28.0711\n",
      "    Total time for evaluation: 0.116290092468s\n",
      "Epoch 14:\n",
      "    101120: 0.164210796356  [4.739248 0.008554 0.462243] [4.739248 4.277005 0.462243] \n",
      "    Total time for epoch: 435.596384048s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 73.25% d_acc\n",
      "    Total time for evaluation: 0.359663963318s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.61986271788\n",
      "       Zero prob: 0.0514062\n",
      "       Mask entropy: 0.292340834272\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 121.42\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4216.42 -3234.13\n",
      "    MSE:      3034.49\n",
      "    Avg err:  29.6645\n",
      "    Total time for evaluation: 0.115520954132s\n",
      "Epoch 15:\n",
      "    101120: 0.162540137768  [4.407943 0.007906 0.454750] [4.407943 3.953193 0.454750] \n",
      "    Total time for epoch: 435.480257988s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 80.5% d_acc\n",
      "    Total time for evaluation: 0.360486984253s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.79167753362\n",
      "       Zero prob: 0.0439844\n",
      "       Mask entropy: 0.260271227372\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 122.37\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4369.39 -3411.86\n",
      "    MSE:      2764.27\n",
      "    Avg err:  29.1655\n",
      "    Total time for evaluation: 0.115728139877s\n",
      "Epoch 16:\n",
      "    101120: 0.171056970954  [4.276851 0.007614 0.470045] [4.276851 3.806806 0.470045] \n",
      "    Total time for epoch: 435.360368967s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 74.5% d_acc\n",
      "    Total time for evaluation: 0.362076044083s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.83571502253\n",
      "       Zero prob: 0.0547266\n",
      "       Mask entropy: 0.306145461896\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 120.995\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4410.22 -3538.1\n",
      "    MSE:      2772.82\n",
      "    Avg err:  29.1667\n",
      "    Total time for evaluation: 0.115517854691s\n",
      "Epoch 17:\n",
      "    101120: 0.201244398952  [4.312256 0.007745 0.439640] [4.312256 3.872616 0.439640] \n",
      "    Total time for epoch: 435.327159882s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 69.25% d_acc\n",
      "    Total time for evaluation: 0.365790128708s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.72054141765\n",
      "       Zero prob: 0.0735156\n",
      "       Mask entropy: 0.378908385655\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 118.59\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4419.61 -3464.02\n",
      "    MSE:      2617.28\n",
      "    Avg err:  29.3969\n",
      "    Total time for evaluation: 0.118595123291s\n",
      "Epoch 18:\n",
      "    101120: 0.200974702835  [4.628757 0.008399 0.429459] [4.628757 4.199297 0.429459] \n",
      "    Total time for epoch: 435.408958912s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 71.5% d_acc\n",
      "    Total time for evaluation: 0.36070394516s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.83073080981\n",
      "       Zero prob: 0.0384766\n",
      "       Mask entropy: 0.23526315381\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.075\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4352.35 -3414.32\n",
      "    MSE:      2867.48\n",
      "    Avg err:  29.5877\n",
      "    Total time for evaluation: 0.116162061691s\n",
      "Epoch 19:\n",
      "    101120: 0.217593297362  [3.954629 0.007249 0.329970] [3.954629 3.624660 0.329970] \n",
      "    Total time for epoch: 435.317426205s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 70.0% d_acc\n",
      "    Total time for evaluation: 0.358779907227s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.70788937715\n",
      "       Zero prob: 0.105195\n",
      "       Mask entropy: 0.485251259031\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 114.535\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4429.93 -3439.46\n",
      "    MSE:      2701.85\n",
      "    Avg err:  29.2348\n",
      "    Total time for evaluation: 0.115763902664s\n",
      "Epoch 20:\n",
      "    101120: 0.188186645508  [4.451880 0.007904 0.499772] [4.451880 3.952108 0.499772] \n",
      "    Total time for epoch: 435.260797977s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 75.0% d_acc\n",
      "    Total time for evaluation: 0.360305070877s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.89465435155\n",
      "       Zero prob: 0.0435156\n",
      "       Mask entropy: 0.25818527322\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 122.43\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4518.91 -3426.59\n",
      "    MSE:      2417.28\n",
      "    Avg err:  27.1719\n",
      "    Total time for evaluation: 0.118077993393s\n",
      "Epoch 21:\n",
      "    101120: 0.209950178862  [4.502948 0.008124 0.441039] [4.502948 4.061909 0.441039] \n",
      "    Total time for epoch: 435.334858894s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 67.75% d_acc\n",
      "    Total time for evaluation: 0.358839035034s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.75638005544\n",
      "       Zero prob: 0.0536328\n",
      "       Mask entropy: 0.301632893634\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 121.135\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4475.42 -3481.15\n",
      "    MSE:      2902.07\n",
      "    Avg err:  30.2708\n",
      "    Total time for evaluation: 0.115655899048s\n",
      "Epoch 22:\n",
      "    101120: 0.175576880574  [4.853521 0.008747 0.480173] [4.853521 4.373348 0.480173] \n",
      "    Total time for epoch: 435.421911001s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 73.75% d_acc\n",
      "    Total time for evaluation: 0.359578132629s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.75290005182\n",
      "       Zero prob: 0.0803125\n",
      "       Mask entropy: 0.40327933999\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 117.72\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4491.94 -3405.21\n",
      "    MSE:      2551.08\n",
      "    Avg err:  28.3805\n",
      "    Total time for evaluation: 0.11529302597s\n",
      "Epoch 23:\n",
      "    101120: 0.19058586657  [4.539213 0.008125 0.476640] [4.539213 4.062572 0.476640] \n",
      "    Total time for epoch: 436.554446936s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 77.25% d_acc\n",
      "    Total time for evaluation: 0.359214067459s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.578007111\n",
      "       Zero prob: 0.0342578\n",
      "       Mask entropy: 0.215314446593\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.615\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4433.67 -3393.23\n",
      "    MSE:      2663.76\n",
      "    Avg err:  28.9589\n",
      "    Total time for evaluation: 0.115636110306s\n",
      "Epoch 24:\n",
      "    101120: 0.182772725821  [4.716478 0.008473 0.479780] [4.716478 4.236698 0.479780] \n",
      "    Total time for epoch: 436.865757942s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 71.75% d_acc\n",
      "    Total time for evaluation: 0.362536907196s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.87918419683\n",
      "       Zero prob: 0.0569141\n",
      "       Mask entropy: 0.315071090706\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 120.715\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4429.67 -3386.71\n",
      "    MSE:      2463.82\n",
      "    Avg err:  28.078\n",
      "    Total time for evaluation: 0.116651058197s\n",
      "Epoch 25:\n",
      "    101120: 0.194962516427  [4.197495 0.007380 0.507304] [4.197495 3.690191 0.507304] \n",
      "    Total time for epoch: 435.274399042s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 68.0% d_acc\n",
      "    Total time for evaluation: 0.356517076492s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.79145536046\n",
      "       Zero prob: 0.0284766\n",
      "       Mask entropy: 0.186693394353\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 124.355\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4451.8 -3319.69\n",
      "    MSE:      2821.67\n",
      "    Avg err:  30.0433\n",
      "    Total time for evaluation: 0.11576294899s\n",
      "Epoch 26:\n",
      "    101120: 0.171046793461  [4.514454 0.008287 0.370705] [4.514454 4.143749 0.370705] \n",
      "    Total time for epoch: 433.531666994s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.5% d_acc\n",
      "    Total time for evaluation: 0.35546207428s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.88370712286\n",
      "       Zero prob: 0.0454688\n",
      "       Mask entropy: 0.266827381211\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 122.18\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4397.92 -3246.32\n",
      "    MSE:      2691.87\n",
      "    Avg err:  28.4772\n",
      "    Total time for evaluation: 0.114912033081s\n",
      "Epoch 27:\n",
      "    101120: 0.175255551934  [4.356171 0.007846 0.432943] [4.356171 3.923228 0.432943] \n",
      "    Total time for epoch: 433.586708069s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 73.25% d_acc\n",
      "    Total time for evaluation: 0.358290910721s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.90043433309\n",
      "       Zero prob: 0.0615234\n",
      "       Mask entropy: 0.333462945562\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 120.125\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4528.7 -3459.93\n",
      "    MSE:      2358.27\n",
      "    Avg err:  27.4233\n",
      "    Total time for evaluation: 0.115592956543s\n",
      "Epoch 28:\n",
      "    101120: 0.158006638288  [4.804774 0.008597 0.506307] [4.804774 4.298466 0.506307] \n",
      "    Total time for epoch: 434.682413101s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.5% d_acc\n",
      "    Total time for evaluation: 0.355666875839s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.86022771191\n",
      "       Zero prob: 0.0363672\n",
      "       Mask entropy: 0.225380436107\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 123.345\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4424.12 -3504.62\n",
      "    MSE:      2409.23\n",
      "    Avg err:  27.4653\n",
      "    Total time for evaluation: 0.11475610733s\n",
      "Epoch 29:\n",
      "    101120: 0.170422434807  [4.684219 0.008497 0.435729] [4.684219 4.248490 0.435729] \n",
      "    Total time for epoch: 433.526365042s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 74.0% d_acc\n",
      "    Total time for evaluation: 0.369081020355s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.67788830042\n",
      "       Zero prob: 0.0738672\n",
      "       Mask entropy: 0.380192268061\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 118.545\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4408.47 -3476.42\n",
      "    MSE:      2577.69\n",
      "    Avg err:  28.1952\n",
      "    Total time for evaluation: 0.115231990814s\n",
      "Epoch 30:\n",
      "    101120: 0.212089642882  [4.806826 0.008421 0.596215] [4.806826 4.210611 0.596215] \n",
      "    Total time for epoch: 433.618657827s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 64.25% d_acc\n",
      "    Total time for evaluation: 0.360276937485s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.76434328874\n",
      "       Zero prob: 0.0628906\n",
      "       Mask entropy: 0.338814326695\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 119.95\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4439.83 -3410.32\n",
      "    MSE:      2470.07\n",
      "    Avg err:  28.5386\n",
      "    Total time for evaluation: 0.115435838699s\n",
      "Epoch 31:\n",
      "    101120: 0.187918305397  [4.129737 0.007268 0.495776] [4.129737 3.633961 0.495776] \n",
      "    Total time for epoch: 436.724771976s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 71.0% d_acc\n",
      "    Total time for evaluation: 0.362221002579s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.68467668644\n",
      "       Zero prob: 0.0731641\n",
      "       Mask entropy: 0.377621885277\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 118.635\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4467.65 -3621.96\n",
      "    MSE:      2470.94\n",
      "    Avg err:  28.4618\n",
      "    Total time for evaluation: 0.11558008194s\n",
      "Epoch 32:\n",
      "    101120: 0.160141706467  [3.879854 0.006757 0.501297] [3.879854 3.378557 0.501297] \n",
      "    Total time for epoch: 436.369726896s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 76.0% d_acc\n",
      "    Total time for evaluation: 0.36122584343s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.71082900977\n",
      "       Zero prob: 0.109141\n",
      "       Mask entropy: 0.497318376036\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 114.03\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4451.79 -3549.58\n",
      "    MSE:      2342.33\n",
      "    Avg err:  26.9449\n",
      "    Total time for evaluation: 0.116189956665s\n",
      "Epoch 33:\n",
      "    101120: 0.206068962812  [4.002048 0.006941 0.531444] [4.002048 3.470603 0.531444] \n",
      "    Total time for epoch: 436.887992859s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 72.5% d_acc\n",
      "    Total time for evaluation: 0.363752126694s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.87252258432\n",
      "       Zero prob: 0.0453516\n",
      "       Mask entropy: 0.266312471636\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 122.195\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4569.58 -3597.54\n",
      "    MSE:      2565.22\n",
      "    Avg err:  28.7906\n",
      "    Total time for evaluation: 0.11589384079s\n",
      "Epoch 34:\n",
      "    101120: 0.20013025403  [3.862676 0.006899 0.413385] [3.862676 3.449291 0.413385] \n",
      "    Total time for epoch: 436.187654018s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 68.0% d_acc\n",
      "    Total time for evaluation: 0.36350607872s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.80763266941\n",
      "       Zero prob: 0.102734\n",
      "       Mask entropy: 0.477603900441\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 114.85\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4514.92 -3520.55\n",
      "    MSE:      2474.17\n",
      "    Avg err:  28.4913\n",
      "    Total time for evaluation: 0.12273812294s\n",
      "Epoch 35:\n",
      "    101120: 0.145675703883  [4.859055 0.008670 0.524172] [4.859055 4.334883 0.524172] \n",
      "    Total time for epoch: 436.7761271s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 77.25% d_acc\n",
      "    Total time for evaluation: 0.362759828568s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.75156639316\n",
      "       Zero prob: 0.0766797\n",
      "       Mask entropy: 0.390370407521\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 118.185\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4406.0 -3352.25\n",
      "    MSE:      2512.63\n",
      "    Avg err:  27.4439\n",
      "    Total time for evaluation: 0.117499113083s\n",
      "Epoch 36:\n",
      "    101120: 0.171324580908  [4.044985 0.007147 0.471725] [4.044985 3.573260 0.471725] \n",
      "    Total time for epoch: 436.09573102s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 81.25% d_acc\n",
      "    Total time for evaluation: 0.360413074493s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.89315456126\n",
      "       Zero prob: 0.0870313\n",
      "       Mask entropy: 0.426482117351\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 116.86\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4534.65 -3623.95\n",
      "    MSE:      2433.41\n",
      "    Avg err:  27.3037\n",
      "    Total time for evaluation: 0.11683511734s\n",
      "Epoch 37:\n",
      "    101120: 0.172235757113  [4.743451 0.008394 0.546370] [4.743451 4.197081 0.546370] \n",
      "    Total time for epoch: 436.786228895s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 73.5% d_acc\n",
      "    Total time for evaluation: 0.359758853912s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.81406989689\n",
      "       Zero prob: 0.0573047\n",
      "       Mask entropy: 0.316651289602\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 120.665\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4379.18 -3511.69\n",
      "    MSE:      2432.18\n",
      "    Avg err:  27.6315\n",
      "    Total time for evaluation: 0.116223096848s\n",
      "Epoch 38:\n",
      "    101120: 0.167887717485  [5.188311 0.009341 0.517632] [5.188311 4.670679 0.517632] \n",
      "    Total time for epoch: 436.803659916s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 70.5% d_acc\n",
      "    Total time for evaluation: 0.359941959381s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.73568895253\n",
      "       Zero prob: 0.0990234\n",
      "       Mask entropy: 0.465892302551\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 115.325\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4479.88 -3432.24\n",
      "    MSE:      2555.86\n",
      "    Avg err:  27.7498\n",
      "    Total time for evaluation: 0.116532087326s\n",
      "Epoch 39:\n",
      "    101120: 0.224656879902  [3.866941 0.006869 0.432437] [3.866941 3.434504 0.432437] \n",
      "    Total time for epoch: 436.122426987s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 69.75% d_acc\n",
      "    Total time for evaluation: 0.361481904984s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.99411491053\n",
      "       Zero prob: 0.0508203\n",
      "       Mask entropy: 0.289871422415\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 121.495\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4586.22 -3715.79\n",
      "    MSE:      2864.81\n",
      "    Avg err:  29.8426\n",
      "    Total time for evaluation: 0.116482973099s\n",
      "Epoch 40:\n",
      "    101120: 0.210079044104  [4.104683 0.007131 0.539208] [4.104683 3.565475 0.539208] \n",
      "    Total time for epoch: 436.056919098s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 69.5% d_acc\n",
      "    Total time for evaluation: 0.358918190002s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.9433056494\n",
      "       Zero prob: 0.0982422\n",
      "       Mask entropy: 0.463398559381\n",
      "       Pct. in last bins: 0.0\n",
      "       Avg # nonzero elts: 115.425\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4339.52 -3394.14\n",
      "    MSE:      2302.94\n",
      "    Avg err:  27.4242\n",
      "    Total time for evaluation: 0.115998983383s\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    train_gen = True\n",
    "    train_discrim = True\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # if both are disabled, we re-enable both\n",
    "        if (not train_gen and not train_discrim):\n",
    "            train_gen = True\n",
    "            train_discrim = True\n",
    "\n",
    "        \n",
    "        if (train_gen or n_discrim == 0):\n",
    "            # train autoencoder (\"generator\")\n",
    "            make_trainable(autoencoder, True)\n",
    "            make_trainable(discriminator, False)\n",
    "            \n",
    "            a_y = [batch] * n_recons + \\\n",
    "                  [np.ones(nbatch)] * n_discrim + \\\n",
    "                  [np.zeros(nbatch)] * n_code\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "            \n",
    "            #ad_loss = a_losses[-1]\n",
    "        else:\n",
    "            # re-enable generator training if disabled\n",
    "            train_gen = True\n",
    "        \n",
    "        \n",
    "        if (train_discrim and n_discrim > 0):\n",
    "            # train discriminator\n",
    "            make_trainable(autoencoder, False)\n",
    "            make_trainable(discriminator, True)\n",
    "            \n",
    "            generated = autoencoder.predict(batch)\n",
    "            discrim_batch_X = interleave([batch, generated])\n",
    "            discrim_batch_y = interleave([np.ones(nbatch), np.zeros(nbatch)])\n",
    "\n",
    "            d_loss = discriminator.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "            \n",
    "            # turn loss into probability of predicting correctly\n",
    "            #d_loss = np.exp(-d_loss)\n",
    "            \n",
    "            #if (d_loss > 0.8):\n",
    "                # if discriminator is over 80% accurate, we don't train\n",
    "                # the discriminator next batch\n",
    "                #train_discrim = False\n",
    "            #elif (d_loss < 0.5):\n",
    "                # if discriminator is under 50% accurate, we don't train\n",
    "                # the generator next batch\n",
    "                #train_gen = False\n",
    "        else:\n",
    "            # re-enable discriminator training if disabled\n",
    "            train_discrim = True\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"   \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    if (n_discrim > 0):\n",
    "        NUM = 200\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        generated = autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "        d_X = np.concatenate((X_train[rows, :], generated))\n",
    "        d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "        d_acc = test_discriminator(discriminator, autoencoder,\n",
    "                                   d_X, d_y, verbose = False)\n",
    "\n",
    "        print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "        elapsed = time.time() - startTime\n",
    "        print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    else:\n",
    "        print lead + \"No discriminator\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # generate code histogram from said random samples\n",
    "    # ---------------------------------------------------------\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    code = ac_enc.predict(X_train[rows, :], verbose = 0)\n",
    "    \n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Code histogram:\"\n",
    "    scalars = code.flatten()\n",
    "    \n",
    "    b = np.linspace(-1.0, 1.0, NBINS + 1)\n",
    "    hist = np.histogram(scalars, bins = b)\n",
    "    sample_hist_probs = hist[0].astype('float32')\n",
    "    sample_hist_bins = hist[1].astype('float32')\n",
    "    sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "    entropy = 0\n",
    "    for i in sample_hist_probs:\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "    \n",
    "    zero_prob = sample_hist_probs[NBINS / 2]\n",
    "    zero_prob = np.clip(zero_prob, 0.001, 0.999)\n",
    "    mask_entropy = -(zero_prob * math.log(zero_prob, 2) + (1.0 - zero_prob) * math.log(1.0 - zero_prob, 2))\n",
    "    \n",
    "    print \"       Entropy:\", entropy\n",
    "    print \"       Zero prob:\", sample_hist_probs[NBINS / 2]\n",
    "    print \"       Mask entropy:\", mask_entropy\n",
    "    print \"       Pct. in last bins:\", sample_hist_probs[0] + sample_hist_probs[-1]\n",
    "    \n",
    "    nnz = 0.0\n",
    "    for i in xrange(0, code.shape[0]):\n",
    "        r = np.round(code[i] * 1000.0) / 1000.0\n",
    "        nnz += np.count_nonzero(r)\n",
    "    nnz /= code.shape[0]\n",
    "    print \"       Avg # nonzero elts:\", nnz\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_train_epoch\" + str(epoch+1), autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # update entropy loss weight every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    if (n_code > 0 and (epoch + 1) >= 5):\n",
    "        v = K.get_value(entropy_weight)\n",
    "        \n",
    "        if (v < max_entropy_weight):\n",
    "            v += entropy_weight_rate\n",
    "            print lead + \"Updated entropy constraint weight:\", v\n",
    "        else:\n",
    "            v = max_entropy_weight\n",
    "            print lead + \"Didn't update entropy constraint weight:\", v\n",
    "\n",
    "        K.set_value(entropy_weight, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('model_res_reg.h5')\n",
    "autoencoder.save('auto_res_reg.h5')\n",
    "\n",
    "discriminator.save('discrim_res_reg.h5')\n",
    "\n",
    "import h5py\n",
    "\n",
    "f = h5py.File('model_res_reg.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D}\\n\\nmodel = load_model('model_res_reg.h5', objs)\\nautoencoder = load_model('auto_res_reg.h5', objs)\\ndiscriminator = load_model('discrim_res_reg.h5', objs)\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D}\n",
    "\n",
    "model = load_model('model_res_reg.h5', objs)\n",
    "autoencoder = load_model('auto_res_reg.h5', objs)\n",
    "discriminator = load_model('discrim_res_reg.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 1\n",
      "    Avg weight norm: 0.0802826\n",
      "    Max weight norm: 0.331577\n",
      "    Avg bias norm: 0.00577187\n",
      "    Max bias norm: 0.0394375\n",
      "Conv layer 2\n",
      "    Avg weight norm: 0.0650726\n",
      "    Max weight norm: 0.594455\n",
      "    Avg bias norm: 0.0128634\n",
      "    Max bias norm: 0.0476927\n",
      "Conv layer 3\n",
      "    Avg weight norm: 0.0663539\n",
      "    Max weight norm: 0.813768\n",
      "    Avg bias norm: 0.0181965\n",
      "    Max bias norm: 0.073829\n",
      "Conv layer 4\n",
      "    Avg weight norm: 0.068533\n",
      "    Max weight norm: 0.78077\n",
      "    Avg bias norm: 0.0213783\n",
      "    Max bias norm: 0.0604194\n",
      "Conv layer 5\n",
      "    Avg weight norm: 0.0616126\n",
      "    Max weight norm: 1.00029\n",
      "    Avg bias norm: 0.014648\n",
      "    Max bias norm: 0.0822517\n",
      "Conv layer 6\n",
      "    Avg weight norm: 0.0539292\n",
      "    Max weight norm: 0.474506\n",
      "    Avg bias norm: 0.00927198\n",
      "    Max bias norm: 0.0404039\n",
      "Conv layer 7\n",
      "    Avg weight norm: 0.0601777\n",
      "    Max weight norm: 0.477039\n",
      "    Avg bias norm: 0.0373309\n",
      "    Max bias norm: 0.186382\n",
      "Conv layer 8\n",
      "    Avg weight norm: 0.0320996\n",
      "    Max weight norm: 0.451594\n",
      "    Avg bias norm: 0.00837034\n",
      "    Max bias norm: 0.0275624\n",
      "Conv layer 9\n",
      "    Avg weight norm: 0.00637893\n",
      "    Max weight norm: 0.169303\n",
      "    Avg bias norm: 0.00186091\n",
      "    Max bias norm: 0.00186091\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for e in enc:\n",
    "    if type(e) is Convolution1D:\n",
    "        i += 1\n",
    "        print \"Conv layer\", i\n",
    "        w = e.weights[0].eval()\n",
    "        print \"    Avg weight norm:\", np.mean(np.abs(w))\n",
    "        print \"    Max weight norm:\", np.max(np.abs(w))\n",
    "        \n",
    "        if (len(e.weights) == 1): continue\n",
    "        b = e.weights[1].eval()\n",
    "        print \"    Avg bias norm:\", np.mean(np.abs(b))\n",
    "        print \"    Max bias norm:\", np.max(np.abs(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "i = 0\n",
    "print \"-- Encoder --\"\n",
    "print \"\"\n",
    "for e in enc:\n",
    "    if type(e) is Convolution1D:\n",
    "        i += 1\n",
    "        print \"Conv layer\", i\n",
    "        w = e.weights[0].eval()\n",
    "        print \"    Avg weight norm:\", np.mean(np.abs(w))\n",
    "        print \"    Max weight norm:\", np.max(np.abs(w))\n",
    "        \n",
    "        if (len(e.weights) == 1): continue\n",
    "        b = e.weights[1].eval()\n",
    "        print \"    Avg bias norm:\", np.mean(np.abs(b))\n",
    "        print \"    Max bias norm:\", np.max(np.abs(b))\n",
    "print \"\"\n",
    "\n",
    "print \"-- Decoder --\"\n",
    "print \"\"\n",
    "for e in dec:\n",
    "    if type(e) is Convolution1D:\n",
    "        i += 1\n",
    "        print \"Conv layer\", i\n",
    "        w = e.weights[0].eval()\n",
    "        print \"    Avg weight norm:\", np.mean(np.abs(w))\n",
    "        print \"    Max weight norm:\", np.max(np.abs(w))\n",
    "        \n",
    "        if (len(e.weights) == 1): continue\n",
    "        b = e.weights[1].eval()\n",
    "        print \"    Avg bias norm:\", np.mean(np.abs(b))\n",
    "        print \"    Max bias norm:\", np.max(np.abs(b))\n",
    "\n",
    "#print [e.eval() for e in enc[-3].weights]\n",
    "'''\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluated the discriminator: 71.25% d_acc\n"
     ]
    }
   ],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "generated = autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "d_X = np.concatenate((X_train[rows, :], generated))\n",
    "d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "d_acc = test_discriminator(discriminator, autoencoder,\n",
    "                           d_X, d_y, verbose = False)\n",
    "\n",
    "print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  4339.52 -3394.14\n",
      "./SA1.WAV  mse:  2302.94\n",
      "./SA1.WAV  avg err:  27.4242\n",
      "(93, 512)\n",
      "93/93 [==============================] - 0s\n",
      "(93, 512, 1)\n",
      "(93, 512)\n",
      "Max/min desired: 2961.0 -3057.0\n",
      "Max/min recons:  2753.31 -2752.18\n",
      "./SX383.WAV  mse:  2142.24\n",
      "./SX383.WAV  avg err:  21.8031\n",
      "(181, 512)\n",
      "181/181 [==============================] - 0s     \n",
      "(181, 512, 1)\n",
      "(181, 512)\n",
      "Max/min desired: 24636.0 -20122.0\n",
      "Max/min recons:  18973.4 -15128.7\n",
      "./fiveYears.wav  mse:  1.99375e+06\n",
      "./fiveYears.wav  avg err:  1004.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24636.0, -20122.0, 18973.352, -15128.687, 1993753.2, 1004.988]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_\", autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_res_reg_\", autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_res_reg_\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "all_embed = ac_enc.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scalars = all_embed.flatten()\n",
    "log_scalars = np.log((scalars + 1.0) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0107239\n",
      "0.0348554\n"
     ]
    }
   ],
   "source": [
    "print np.mean(scalars)\n",
    "print np.var(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAFkCAYAAAB4sKK5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7f8DBus8ay/aqK4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efccccad550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of distribution: 5.84094802166\n"
     ]
    }
   ],
   "source": [
    "hist = np.histogram(scalars, bins = np.linspace(-1.0, 1.0, NBINS + 1))\n",
    "sample_hist_probs = hist[0].astype('float32')\n",
    "sample_hist_bins = hist[1].astype('float32')\n",
    "sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "sample_hist_width = 1 * (sample_hist_bins[1] - sample_hist_bins[0])\n",
    "sample_hist_centers = (sample_hist_bins[:-1] + sample_hist_bins[1:]) / 2\n",
    "plt.bar(sample_hist_centers, sample_hist_probs, align='center', width=sample_hist_width)\n",
    "plt.show()\n",
    "\n",
    "entropy = 0\n",
    "for i in sample_hist_probs:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print \"Entropy of distribution:\", entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.WAV\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = ac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 nonzero\n",
      "[-0.160000 -0.080000 0.120000 0.100000 0.070000 0.030000 -0.130000\n",
      " -0.250000 -0.210000 -0.330000 -0.050000 0.180000 0.100000 0.230000\n",
      " 0.140000 0.000000 -0.040000 -0.200000 -0.150000 -0.120000 -0.010000\n",
      " 0.120000 0.050000 0.060000 -0.050000 -0.220000 -0.200000 -0.270000\n",
      " -0.220000 0.150000 0.100000 0.210000 0.210000 0.030000 0.050000 -0.130000\n",
      " -0.180000 -0.070000 -0.100000 0.080000 0.110000 0.060000 0.020000\n",
      " -0.120000 -0.220000 -0.200000 -0.310000 -0.020000 0.140000 0.090000\n",
      " 0.210000 0.120000 0.010000 -0.040000 -0.180000 -0.140000 -0.110000\n",
      " -0.030000 0.100000 0.070000 0.090000 -0.040000 -0.140000 -0.200000\n",
      " -0.230000 -0.260000 0.070000 0.100000 0.140000 0.180000 0.070000 0.040000\n",
      " -0.090000 -0.160000 -0.100000 -0.110000 0.010000 0.100000 0.060000\n",
      " 0.100000 -0.060000 -0.120000 -0.190000 -0.200000 -0.250000 0.010000\n",
      " 0.110000 0.090000 0.170000 0.080000 0.000000 -0.060000 -0.160000 -0.120000\n",
      " -0.090000 -0.030000 0.080000 0.060000 0.080000 0.020000 -0.120000\n",
      " -0.130000 -0.190000 -0.170000 -0.170000 0.040000 0.120000 0.090000\n",
      " 0.130000 0.040000 -0.030000 -0.080000 -0.150000 -0.090000 -0.070000\n",
      " -0.010000 0.090000 0.040000 0.060000 -0.040000 -0.130000 -0.140000\n",
      " -0.180000 -0.180000 -0.080000 0.060000 0.070000 0.090000]\n",
      "1280000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "idx = 44\n",
    "print np.count_nonzero(embed[idx]), \"nonzero\"\n",
    "print embed[idx]\n",
    "\n",
    "print len(scalars)\n",
    "print np.count_nonzero((abs(scalars) > 1).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
