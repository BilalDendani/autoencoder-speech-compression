{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n",
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA1.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX339.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1059.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1689.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX429.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX69.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX159.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI2319.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA2.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX249.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX221.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA1.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX41.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1751.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1725.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX401.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX24.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA2.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1121.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX131.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA1.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX336.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1236.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI606.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1866.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX156.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA2.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX426.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX246.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX66.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA1.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1233.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI603.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX333.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX153.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1863.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX243.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA2.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX423.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX63.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA1.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX434.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX74.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX254.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI1064.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX344.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX164.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA2.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI582.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI2324.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX82.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1041.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX442.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA1.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1702.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX262.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX172.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX352.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA2.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1072.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI669.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA1.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX39.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX309.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1929.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX129.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1299.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX219.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX399.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA2.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI2325.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX435.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX75.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA1.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1695.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX345.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1065.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX255.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX165.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA2.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI2290.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA1.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI650.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI1660.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX220.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX310.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX40.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX400.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA2.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX130.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX149.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA1.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI2309.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX419.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX239.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX329.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1679.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX59.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA2.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1049.WAV\r",
      "100: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI520.WAV\r",
      "101: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA1.WAV\r",
      "102: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX160.WAV\r",
      "103: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX340.WAV\r",
      "104: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI2035.WAV\r",
      "105: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX250.WAV\r",
      "106: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX430.WAV\r",
      "107: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX70.WAV\r",
      "108: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA2.WAV\r",
      "109: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI1780.WAV\r",
      "110: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA1.WAV\r",
      "111: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX65.WAV\r",
      "112: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX425.WAV\r",
      "113: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1685.WAV\r",
      "114: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1055.WAV\r",
      "115: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX335.WAV\r",
      "116: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA2.WAV\r",
      "117: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX245.WAV\r",
      "118: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI2315.WAV\r",
      "119: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX155.WAV\r",
      "120: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA1.WAV\r",
      "121: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX339.WAV\r",
      "122: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI879.WAV\r",
      "123: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX429.WAV\r",
      "124: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI1509.WAV\r",
      "125: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX69.WAV\r",
      "126: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX159.WAV\r",
      "127: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI2139.WAV\r",
      "128: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA2.WAV\r",
      "129: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX249.WAV\r",
      "130: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX166.WAV\r",
      "131: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA1.WAV\r",
      "132: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX346.WAV\r",
      "133: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI2326.WAV\r",
      "134: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1696.WAV\r",
      "135: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX256.WAV\r",
      "136: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1066.WAV\r",
      "137: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA2.WAV\r",
      "138: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX76.WAV\r",
      "139: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX436.WAV\r",
      "140: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX56.WAV\r",
      "141: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA1.WAV\r",
      "142: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI866.WAV\r",
      "143: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX146.WAV\r",
      "144: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX326.WAV\r",
      "145: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI2126.WAV\r",
      "146: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX416.WAV\r",
      "147: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX236.WAV\r",
      "148: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI1760.WAV\r",
      "149: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA2.WAV\r",
      "150: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX82.WAV\r",
      "151: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX442.WAV\r",
      "152: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA1.WAV\r",
      "153: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI2062.WAV\r",
      "154: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI1432.WAV\r",
      "155: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX262.WAV\r",
      "156: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI802.WAV\r",
      "157: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX172.WAV\r",
      "158: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX352.WAV\r",
      "159: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA2.WAV\r",
      "160: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX311.WAV\r",
      "161: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA1.WAV\r",
      "162: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI2274.WAV\r",
      "163: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX114.WAV\r",
      "164: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX384.WAV\r",
      "165: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX294.WAV\r",
      "166: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1014.WAV\r",
      "167: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA2.WAV\r",
      "168: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1644.WAV\r",
      "169: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX204.WAV\r",
      "170: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX42.WAV\r",
      "171: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX222.WAV\r",
      "172: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA1.WAV\r",
      "173: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX312.WAV\r",
      "174: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI1572.WAV\r",
      "175: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI942.WAV\r",
      "176: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX132.WAV\r",
      "177: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA2.WAV\r",
      "178: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI2202.WAV\r",
      "179: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX402.WAV\r",
      "180: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX149.WAV\r",
      "181: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA1.WAV\r",
      "182: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1949.WAV\r",
      "183: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI689.WAV\r",
      "184: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1319.WAV\r",
      "185: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX419.WAV\r",
      "186: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX239.WAV\r",
      "187: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX329.WAV\r",
      "188: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX59.WAV\r",
      "189: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA2.WAV\r",
      "190: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1187.WAV\r",
      "191: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX17.WAV\r",
      "192: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX107.WAV\r",
      "193: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA1.WAV\r",
      "194: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI630.WAV\r",
      "195: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1817.WAV\r",
      "196: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX287.WAV\r",
      "197: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX197.WAV\r",
      "198: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA2.WAV\r",
      "199: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX377.WAV\r",
      "200: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX248.WAV\r",
      "201: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX428.WAV\r",
      "202: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA1.WAV\r",
      "203: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI2318.WAV\r",
      "204: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX68.WAV\r",
      "205: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1058.WAV\r",
      "206: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX338.WAV\r",
      "207: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX158.WAV\r",
      "208: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1688.WAV\r",
      "209: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA2.WAV\r",
      "210: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI534.WAV\r",
      "211: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI1164.WAV\r",
      "212: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA1.WAV\r",
      "213: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX354.WAV\r",
      "214: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX174.WAV\r",
      "215: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX264.WAV\r",
      "216: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI797.WAV\r",
      "217: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX444.WAV\r",
      "218: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX84.WAV\r",
      "219: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA2.WAV\r",
      "220: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA1.WAV\r",
      "221: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX39.WAV\r",
      "222: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI2199.WAV\r",
      "223: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX309.WAV\r",
      "224: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI1569.WAV\r",
      "225: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX129.WAV\r",
      "226: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX219.WAV\r",
      "227: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI939.WAV\r",
      "228: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX399.WAV\r",
      "229: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA2.WAV\r",
      "230: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI1609.WAV\r",
      "231: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX30.WAV\r",
      "232: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX169.WAV\r",
      "233: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA1.WAV\r",
      "234: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX439.WAV\r",
      "235: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI979.WAV\r",
      "236: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX259.WAV\r",
      "237: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA2.WAV\r",
      "238: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI2239.WAV\r",
      "239: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX79.WAV\r",
      "240: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX42.WAV\r",
      "241: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX222.WAV\r",
      "242: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2112.WAV\r",
      "243: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA1.WAV\r",
      "244: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX312.WAV\r",
      "245: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2026.WAV\r",
      "246: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX132.WAV\r",
      "247: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA2.WAV\r",
      "248: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI1482.WAV\r",
      "249: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX402.WAV\r",
      "250: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX81.WAV\r",
      "251: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA1.WAV\r",
      "252: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX351.WAV\r",
      "253: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI2331.WAV\r",
      "254: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX27.WAV\r",
      "255: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1071.WAV\r",
      "256: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX441.WAV\r",
      "257: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX261.WAV\r",
      "258: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1701.WAV\r",
      "259: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA2.WAV\r",
      "260: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA1.WAV\r",
      "261: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX241.WAV\r",
      "262: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX331.WAV\r",
      "263: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX61.WAV\r",
      "264: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX151.WAV\r",
      "265: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1681.WAV\r",
      "266: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX421.WAV\r",
      "267: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI2311.WAV\r",
      "268: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA2.WAV\r",
      "269: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1051.WAV\r",
      "270: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX167.WAV\r",
      "271: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX437.WAV\r",
      "272: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA1.WAV\r",
      "273: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX77.WAV\r",
      "274: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX257.WAV\r",
      "275: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX347.WAV\r",
      "276: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI1607.WAV\r",
      "277: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA2.WAV\r",
      "278: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI977.WAV\r",
      "279: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI2237.WAV\r",
      "280: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI1485.WAV\r",
      "281: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA1.WAV\r",
      "282: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI855.WAV\r",
      "283: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX225.WAV\r",
      "284: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX405.WAV\r",
      "285: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA2.WAV\r",
      "286: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX45.WAV\r",
      "287: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX315.WAV\r",
      "288: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX135.WAV\r",
      "289: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI2115.WAV\r",
      "290: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1068.WAV\r",
      "291: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA1.WAV\r",
      "292: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX78.WAV\r",
      "293: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX202.WAV\r",
      "294: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX258.WAV\r",
      "295: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX168.WAV\r",
      "296: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1698.WAV\r",
      "297: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI2328.WAV\r",
      "298: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA2.WAV\r",
      "299: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX348.WAV\r",
      "300: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI579.WAV\r",
      "301: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA1.WAV\r",
      "302: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX39.WAV\r",
      "303: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX309.WAV\r",
      "304: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX129.WAV\r",
      "305: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX219.WAV\r",
      "306: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX399.WAV\r",
      "307: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1839.WAV\r",
      "308: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA2.WAV\r",
      "309: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1209.WAV\r",
      "310: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA1.WAV\r",
      "311: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX161.WAV\r",
      "312: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX71.WAV\r",
      "313: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX431.WAV\r",
      "314: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX341.WAV\r",
      "315: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI611.WAV\r",
      "316: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX251.WAV\r",
      "317: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1241.WAV\r",
      "318: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA2.WAV\r",
      "319: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1871.WAV\r",
      "320: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA1.WAV\r",
      "321: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX355.WAV\r",
      "322: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX445.WAV\r",
      "323: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX265.WAV\r",
      "324: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX85.WAV\r",
      "325: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1165.WAV\r",
      "326: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1802.WAV\r",
      "327: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX175.WAV\r",
      "328: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI535.WAV\r",
      "329: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA2.WAV\r",
      "330: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX62.WAV\r",
      "331: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI872.WAV\r",
      "332: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA1.WAV\r",
      "333: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI2132.WAV\r",
      "334: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI588.WAV\r",
      "335: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX152.WAV\r",
      "336: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX332.WAV\r",
      "337: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX242.WAV\r",
      "338: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA2.WAV\r",
      "339: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX422.WAV\r",
      "340: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA1.WAV\r",
      "341: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI1671.WAV\r",
      "342: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX321.WAV\r",
      "343: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2332.WAV\r",
      "344: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX141.WAV\r",
      "345: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX231.WAV\r",
      "346: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX411.WAV\r",
      "347: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX51.WAV\r",
      "348: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA2.WAV\r",
      "349: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2301.WAV\r",
      "350: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA1.WAV\r",
      "351: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX433.WAV\r",
      "352: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX343.WAV\r",
      "353: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX73.WAV\r",
      "354: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX163.WAV\r",
      "355: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI793.WAV\r",
      "356: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI1913.WAV\r",
      "357: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA2.WAV\r",
      "358: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX253.WAV\r",
      "359: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI2053.WAV\r",
      "360: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX234.WAV\r",
      "361: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA1.WAV\r",
      "362: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX324.WAV\r",
      "363: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2225.WAV\r",
      "364: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2304.WAV\r",
      "365: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI1674.WAV\r",
      "366: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX54.WAV\r",
      "367: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX414.WAV\r",
      "368: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX144.WAV\r",
      "369: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA2.WAV\r",
      "370: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA1.WAV\r",
      "371: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX235.WAV\r",
      "372: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX145.WAV\r",
      "373: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX55.WAV\r",
      "374: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX325.WAV\r",
      "375: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX415.WAV\r",
      "376: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI685.WAV\r",
      "377: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1315.WAV\r",
      "378: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA2.WAV\r",
      "379: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1945.WAV\r",
      "380: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA1.WAV\r",
      "381: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1295.WAV\r",
      "382: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI538.WAV\r",
      "383: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1798.WAV\r",
      "384: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX268.WAV\r",
      "385: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX178.WAV\r",
      "386: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA2.WAV\r",
      "387: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX448.WAV\r",
      "388: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX358.WAV\r",
      "389: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX88.WAV\r",
      "390: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX127.WAV\r",
      "391: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA1.WAV\r",
      "392: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX217.WAV\r",
      "393: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI847.WAV\r",
      "394: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX307.WAV\r",
      "395: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1477.WAV\r",
      "396: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX397.WAV\r",
      "397: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA2.WAV\r",
      "398: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX37.WAV\r",
      "399: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1313.WAV\r",
      "400: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA1.WAV\r",
      "401: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1005.WAV\r",
      "402: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX15.WAV\r",
      "403: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1342.WAV\r",
      "404: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX285.WAV\r",
      "405: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1635.WAV\r",
      "406: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX105.WAV\r",
      "407: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX195.WAV\r",
      "408: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA2.WAV\r",
      "409: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX375.WAV\r",
      "410: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI961.WAV\r",
      "411: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA1.WAV\r",
      "412: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX241.WAV\r",
      "413: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI1591.WAV\r",
      "414: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX331.WAV\r",
      "415: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX61.WAV\r",
      "416: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX151.WAV\r",
      "417: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX421.WAV\r",
      "418: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA2.WAV\r",
      "419: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI511.WAV\r",
      "420: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1251.WAV\r",
      "421: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX17.WAV\r",
      "422: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX107.WAV\r",
      "423: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA1.WAV\r",
      "424: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1457.WAV\r",
      "425: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX287.WAV\r",
      "426: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI827.WAV\r",
      "427: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX197.WAV\r",
      "428: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA2.WAV\r",
      "429: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX377.WAV\r",
      "430: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA1.WAV\r",
      "431: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1888.WAV\r",
      "432: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX268.WAV\r",
      "433: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI628.WAV\r",
      "434: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX178.WAV\r",
      "435: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA2.WAV\r",
      "436: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX448.WAV\r",
      "437: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX358.WAV\r",
      "438: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX88.WAV\r",
      "439: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1258.WAV\r",
      "440: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX157.WAV\r",
      "441: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA1.WAV\r",
      "442: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX337.WAV\r",
      "443: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX67.WAV\r",
      "444: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1687.WAV\r",
      "445: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI2317.WAV\r",
      "446: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX427.WAV\r",
      "447: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA2.WAV\r",
      "448: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1057.WAV\r",
      "449: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX247.WAV\r",
      "450: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA1.WAV\r",
      "451: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1170.WAV\r",
      "452: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX270.WAV\r",
      "453: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1800.WAV\r",
      "454: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX360.WAV\r",
      "455: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX450.WAV\r",
      "456: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX90.WAV\r",
      "457: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI540.WAV\r",
      "458: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA2.WAV\r",
      "459: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX180.WAV\r",
      "460: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX435.WAV\r",
      "461: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX75.WAV\r",
      "462: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA1.WAV\r",
      "463: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI1605.WAV\r",
      "464: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX345.WAV\r",
      "465: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX255.WAV\r",
      "466: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI975.WAV\r",
      "467: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX165.WAV\r",
      "468: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI2235.WAV\r",
      "469: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA2.WAV\r",
      "470: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI539.WAV\r",
      "471: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA1.WAV\r",
      "472: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1169.WAV\r",
      "473: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX359.WAV\r",
      "474: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX449.WAV\r",
      "475: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX179.WAV\r",
      "476: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX269.WAV\r",
      "477: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA2.WAV\r",
      "478: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1799.WAV\r",
      "479: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX89.WAV\r",
      "480: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA1.WAV\r",
      "481: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX32.WAV\r",
      "482: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX212.WAV\r",
      "483: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX392.WAV\r",
      "484: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1652.WAV\r",
      "485: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX302.WAV\r",
      "486: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX122.WAV\r",
      "487: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI2282.WAV\r",
      "488: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1022.WAV\r",
      "489: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA2.WAV\r",
      "490: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA1.WAV\r",
      "491: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX161.WAV\r",
      "492: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX217.WAV\r",
      "493: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1747.WAV\r",
      "494: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1117.WAV\r",
      "495: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX366.WAV\r",
      "496: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX397.WAV\r",
      "497: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA2.WAV\r",
      "498: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX37.WAV\r",
      "499: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI487.WAV\r"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):\n",
    "    # scale window between -1 and 1\n",
    "    mn = np.min(waveform)\n",
    "    mx = np.max(waveform)\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "        \n",
    "    return np.copy(waveform) / maxabs, (maxabs,)\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return np.copy(waveform) * params[0]\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    return windows, ()\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(rawWaveforms[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (50449, 512)\n",
      "Max:  1.0\n",
      "Min:  -1.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (50449, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50449, 512, 1)\n",
      "-1.08948e-05\n",
      "0.0983449\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CodeRound(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, nbins):\n",
    "        self.nbins = nbins\n",
    "        super(CodeRound, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        s = (x + 1.0) / 2.0\n",
    "        s = np.round(s * float(self.nbins - 1)) / float(self.nbins - 1)\n",
    "        s = (s * 2.0) - 1.0\n",
    "        \n",
    "        z[0] = s\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        x, = input\n",
    "        g, = output_gradients\n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhaseShiftUp1D(Layer):\n",
    "    \"\"\" PhaseShiftUp1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShiftUp1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "        super(PhaseShiftUp1D, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShiftUp1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_upsample_1d(x):\n",
    "    r = T.repeat(x, 2, axis = 1)\n",
    "    s = T.roll(r, -1, axis = 1)\n",
    "    u = ((r[:, :-1] + s[:, :-1]) / 2.0)\n",
    "    u = T.concatenate((u, r[:, -1:]), axis = 1)\n",
    "    return u\n",
    "\n",
    "def linear_upsample_shape(shape):\n",
    "    return (shape[0], shape[1] * 2, shape[2])\n",
    "\n",
    "# linear upsampling \"layer\"\n",
    "def LinearUpSampling1D():\n",
    "    return Lambda(linear_upsample_1d, output_shape = linear_upsample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# RMSE LOSS FUNCTION (NaN-safe)\n",
    "# ------------------------------------------------------------------\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "    return K.sqrt(mse + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# THEANO DFT FUNCTIONS / FREQUENCY LOSS\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# generate square dft matrix (similar to how we generate the DFT one)\n",
    "#     note that this matrix will have real and imaginary components\n",
    "def generate_dft_mat(n):\n",
    "    return (np.fft.fft(np.eye(n)))\n",
    "\n",
    "# we compute both the real and imaginary part of the FFT separately, at program start\n",
    "dftMat = generate_dft_mat(WINDOW_SIZE)\n",
    "th_dftMat_imag = K.variable(np.imag(dftMat))\n",
    "th_dftMat_real = K.variable(np.real(dftMat))\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE (x 1)\n",
    "#     this returns an array M x WINDOW_SIZE x 2 where every one of the M samples has been\n",
    "#     its DFT magnitude\n",
    "def theano_dft(x):\n",
    "    global th_dftMat_imag\n",
    "    global th_dftMat_real\n",
    "\n",
    "    reshaped_x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "\n",
    "    imag = T.tensordot(th_dftMat_imag, reshaped_x, [[0], [2]])\n",
    "    imag = imag.reshape((1, imag.shape[0], imag.shape[2])).T\n",
    "\n",
    "    real = T.tensordot(th_dftMat_real, reshaped_x, [[0], [2]])\n",
    "    real = real.reshape((1, real.shape[0], real.shape[2])).T\n",
    "    \n",
    "    dft = K.concatenate([real, imag], axis = 2)\n",
    "    return dft\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE (x 1)\n",
    "#     this returns an array M x WINDOW_SIZE where every one of the M samples has been replaced by\n",
    "#     its DFT magnitude\n",
    "def theano_dft_mag(x):\n",
    "    dft = theano_dft(x)\n",
    "    \n",
    "    real = dft[:, :, 0]\n",
    "    imag = dft[:, :, 1]\n",
    "    \n",
    "    result = K.sqrt(K.square(real) + K.square(imag) + K.epsilon())\n",
    "    return result\n",
    "\n",
    "# return loss over upper frequencies of DFT (2000Hz+)\n",
    "def upper_freq_loss(y_true, y_pred):\n",
    "    dft_true = theano_dft(y_true)\n",
    "    dft_pred = theano_dft(y_pred)\n",
    "    \n",
    "    start = WINDOW_SIZE * (3000.0 / 16000.0)\n",
    "    start = int(start)\n",
    "    \n",
    "    upper_true = dft_true[:, start:]\n",
    "    upper_pred = dft_pred[:, start:]\n",
    "    \n",
    "    return rmse(upper_true, upper_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, 1)                 48985     \n",
      "=================================================================\n",
      "Total params: 48,985.0\n",
      "Trainable params: 48,985.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 128)               62953     \n",
      "_________________________________________________________________\n",
      "model_5 (Model)              (None, 512, 1)            73369     \n",
      "=================================================================\n",
      "Total params: 136,322.0\n",
      "Trainable params: 136,322.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 128)               62953     \n",
      "_________________________________________________________________\n",
      "model_5 (Model)              (None, 512, 1)            73369     \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, 1)                 48985     \n",
      "=================================================================\n",
      "Total params: 185,307.0\n",
      "Trainable params: 185,307.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import softmax, sigmoid\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# ====================================================\n",
    "# PARAMETERS FOR AUTOENCODER STRUCTURE\n",
    "# ====================================================\n",
    "NBINS = 201\n",
    "TIMES_DOWNSAMPLE = 2\n",
    "\n",
    "NCHAN = 24\n",
    "FILT_SIZE = 9\n",
    "FILT_MID = FILT_SIZE / 2 + 1\n",
    "\n",
    "NUM_RES_BLOCKS = 3\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = WINDOW_SIZE / int(2 ** TIMES_DOWNSAMPLE)\n",
    "\n",
    "res_init = 'glorot_normal'\n",
    "\n",
    "def activation():\n",
    "    return LeakyReLU(0.3)\n",
    "    #return ELU()\n",
    "    #return PReLU()\n",
    "    #return Activation('relu')\n",
    "    \n",
    "# ----------------------------------------------------\n",
    "# blocks of network\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# residual block, going from NCHAN to NCHAN channels\n",
    "def residual_block(num_chans = NCHAN):\n",
    "    def f(input):\n",
    "        shortcut = input\n",
    "        \n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                          kernel_initializer = res_init,\n",
    "                          activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        res = activation()(res)\n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                          kernel_initializer = res_init,\n",
    "                          activation = 'linear',\n",
    "                          use_bias = True)(res)\n",
    "        \n",
    "        m = merge([shortcut, res], mode = 'sum')\n",
    "        return m\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "# increase number of channels from 1 to NCHAN via convolution\n",
    "def channel_increase_block(num_chans = NCHAN):\n",
    "    def f(input):\n",
    "        shortcut = Lambda(lambda x :\n",
    "                              K.repeat_elements(x, num_chans, axis = 2),\n",
    "                          lambda shape :\n",
    "                              (shape[0], shape[1], shape[2] * num_chans)\n",
    "                          )(input)\n",
    "        \n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                              activation = 'linear',\n",
    "                              kernel_initializer = res_init,\n",
    "                              use_bias = True)(input)\n",
    "        res = activation()(res)\n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                              kernel_initializer = res_init,\n",
    "                              activation = 'linear',\n",
    "                              use_bias = True)(res)\n",
    "        \n",
    "        m = merge([shortcut, res], mode = 'sum')\n",
    "        return m\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "# downsample the signal 2x\n",
    "def downsample_block(num_chans = NCHAN):\n",
    "    def f(input):\n",
    "        shortcut = AveragePooling1D(2)(input)\n",
    "        \n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                              kernel_initializer = res_init,\n",
    "                              activation = 'linear',\n",
    "                              strides = 2,\n",
    "                              use_bias = True)(input)\n",
    "        res = activation()(res)\n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                              kernel_initializer = res_init,\n",
    "                              activation = 'linear',\n",
    "                              use_bias = True)(res)\n",
    "        \n",
    "        m = merge([shortcut, res], mode = 'sum')\n",
    "        return m\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "# upsample the signal 2x\n",
    "def upsample_block(num_chans = NCHAN):\n",
    "    def f(input):\n",
    "        upsampled = LinearUpSampling1D()(input)\n",
    "        \n",
    "        res = Convolution1D(num_chans * 2, FILT_SIZE, padding = 'same',\n",
    "                              kernel_initializer = res_init,\n",
    "                              activation = 'linear',\n",
    "                              use_bias = True)(input)\n",
    "        res = activation()(res)\n",
    "        res = PhaseShiftUp1D(2)(res)\n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                              kernel_initializer = res_init,\n",
    "                              activation = 'linear',\n",
    "                              use_bias = True)(res)\n",
    "        \n",
    "        m = merge([upsampled, res], mode = 'sum')\n",
    "        return m\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "# increase number of channels from NCHAN to 1 via convolution\n",
    "def channel_decrease_block(num_chans = NCHAN):\n",
    "    def f(input):\n",
    "        shortcut = Lambda(lambda x :\n",
    "                              K.mean(x, axis = 2, keepdims = True),\n",
    "                          lambda shape :\n",
    "                              (shape[0], shape[1], 1)\n",
    "                          )(input)\n",
    "        \n",
    "        res = Convolution1D(num_chans, FILT_SIZE, padding = 'same',\n",
    "                              activation = 'linear',\n",
    "                              kernel_initializer = res_init,\n",
    "                              use_bias = True)(input)\n",
    "        res = activation()(res)\n",
    "        res = Convolution1D(1, FILT_SIZE, padding = 'same',\n",
    "                              kernel_initializer = res_init,\n",
    "                              activation = 'linear',\n",
    "                              use_bias = True)(res)\n",
    "        \n",
    "        m = merge([shortcut, res], mode = 'sum')\n",
    "        return m\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "    \n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = Reshape(dim, input_shape = dim)(enc_input)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    enc = channel_increase_block()(enc)\n",
    "    \n",
    "    # downsampling blocks\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE): \n",
    "        enc = downsample_block()(enc)\n",
    "        \n",
    "    # residual blocks\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        enc = residual_block()(enc)\n",
    "    \n",
    "    # decrease back down to 1 channel\n",
    "    enc = channel_decrease_block()(enc)\n",
    "    \n",
    "    enc = Reshape((bottleneck_size,))(enc)\n",
    "    \n",
    "    enc = Lambda(lambda x : K.clip(x, -1.0, 1.0))(enc)\n",
    "    #enc = Activation('tanh')(enc)\n",
    "    enc = Lambda(lambda x : CodeRound(NBINS)(x))(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_input = Input(shape = (bottleneck_size,))    \n",
    "    dec = Reshape((bottleneck_size, 1))(dec_input)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    dec = channel_increase_block()(dec)\n",
    "    \n",
    "    # residual blocks\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        dec = residual_block()(dec)\n",
    "    \n",
    "    # upsampling blocks\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE):\n",
    "        dec = upsample_block()(dec)\n",
    "    \n",
    "    # decrease back down to 1 channel\n",
    "    dec = channel_decrease_block()(dec)\n",
    "\n",
    "    dec = Lambda(lambda x : K.clip(x, -1.0, 1.0))(dec)\n",
    "    #dec = Activation('tanh')(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "DSC_FILTS = 24\n",
    "DSC_DENSE = 24\n",
    "DSC_FILT_SIZE = 9\n",
    "\n",
    "def discriminator_structure(dim):\n",
    "    '''\n",
    "    def cos_dist(vects):\n",
    "        x, y = vects\n",
    "        \n",
    "        numerator = K.batch_dot(x, y, axes = 1)\n",
    "        \n",
    "        mag_x = K.batch_dot(x, x, axes = 1)\n",
    "        mag_y = K.batch_dot(y, y, axes = 1)\n",
    "        denominator = K.sqrt(mag_x * mag_y + K.epsilon())\n",
    "        \n",
    "        cos_similarity = numerator / denominator\n",
    "        return (1.0 - cos_similarity)\n",
    "\n",
    "    def cos_shape(shapes):\n",
    "        shape1, shape2 = shapes\n",
    "        return (shape1[0], 1)\n",
    "    \n",
    "    def siamese_half():\n",
    "        dsc_input = Input(shape = dim)\n",
    "        dsc = Reshape(dim, input_shape = dim)(dsc_input)\n",
    "        \n",
    "        dsc = channel_increase_block(DSC_FILTS)(dsc)\n",
    "        dsc = downsample_block(DSC_FILTS)(dsc)\n",
    "        dsc = residual_block(DSC_FILTS)(dsc)\n",
    "        dsc = downsample_block(DSC_FILTS)(dsc)\n",
    "        dsc = residual_block(DSC_FILTS)(dsc)\n",
    "\n",
    "        dsc = Flatten()(dsc)\n",
    "        \n",
    "        dsc = Dense(DSC_DENSE, init = res_init, activation = 'linear')(dsc)\n",
    "\n",
    "        dsc = Model(input = dsc_input, output = dsc)\n",
    "        return dsc\n",
    "    \n",
    "    input_a = Input(shape = dim)\n",
    "    input_b = Input(shape = dim)\n",
    "    \n",
    "    base_network = siamese_half()\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "\n",
    "    out = Lambda(cos_dist, output_shape=cos_shape)([processed_a, processed_b])\n",
    "    \n",
    "    model = Model(input = [input_a, input_b], output = out)\n",
    "    return model\n",
    "    '''\n",
    "    dsc_input = Input(shape = dim)\n",
    "    dsc = Reshape(dim, input_shape = dim)(dsc_input)\n",
    "\n",
    "    dsc = channel_increase_block(DSC_FILTS)(dsc)\n",
    "    dsc = residual_block(DSC_FILTS)(dsc)\n",
    "    dsc = residual_block(DSC_FILTS)(dsc)\n",
    "    dsc = residual_block(DSC_FILTS)(dsc)\n",
    "    #dsc = residual_block(DSC_FILTS)(dsc)\n",
    "    #dsc = residual_block(DSC_FILTS)(dsc)\n",
    "    #dsc = residual_block(DSC_FILTS)(dsc)\n",
    "    \n",
    "    dsc = Flatten()(dsc)\n",
    "    dsc = Dense(1, kernel_initializer = res_init,\n",
    "                activation = 'linear')(dsc)\n",
    "\n",
    "    dsc = Model(input = dsc_input, output = dsc)\n",
    "    return dsc\n",
    "    \n",
    "\n",
    "\n",
    "# construct autoencoder to be used in adversarial training\n",
    "ac_input = Input(shape = input_dim)\n",
    "ac_enc, ac_dec = autoencoder_structure(input_dim)\n",
    "ac_embedding = ac_enc(ac_input)\n",
    "ac_reconstructed = ac_dec(ac_embedding)\n",
    "\n",
    "# construct discriminator: regular\n",
    "dsc_input_dim = (WINDOW_SIZE, 1)\n",
    "'''\n",
    "dsc_input_1 = Input(shape = input_dim)\n",
    "dsc_input_2 = Input(shape = input_dim)\n",
    "dsc_struct = discriminator_structure(dsc_input_dim)\n",
    "dsc_label = dsc_struct([dsc_input_1, dsc_input_2])\n",
    "ac_dsc_label = dsc_struct([ac_input, ac_reconstructed])\n",
    "'''\n",
    "dsc_input = Input(shape = input_dim)\n",
    "dsc_struct = discriminator_structure(dsc_input_dim)\n",
    "dsc_label = dsc_struct(dsc_input)\n",
    "ac_dsc_label = dsc_struct(ac_reconstructed)\n",
    "\n",
    "\n",
    "    \n",
    "# ------------------------------------------------------------------\n",
    "# PARZEN ENTROPY ESTIMATION\n",
    "# ------------------------------------------------------------------\n",
    "# the Parzen kernel is a zero-centered gaussian with bin-width standard deviation\n",
    "std = (1.0 / (NBINS - 1))\n",
    "norm = 1.0 / math.sqrt(2.0 * 3.14159 * std * std)\n",
    "den = (2.0 * std * std)\n",
    "\n",
    "def parzen_kernel(x):\n",
    "    num = K.square(x)\n",
    "    return norm * K.exp(-num / den)\n",
    "\n",
    "# we use 10,000 samples to create our entropy estimate\n",
    "N = 10000\n",
    "log_2 = math.log(2.0)\n",
    "bins = K.variable(np.linspace(-1.0, 1.0, NBINS))\n",
    "r_bins = K.repeat_elements(bins.reshape((NBINS, 1)), N, 1)\n",
    "\n",
    "# we increase the weight of the entropy loss over time while\n",
    "# training\n",
    "entropy_weight = K.variable(0.0, name = 'entropy_weight')\n",
    "max_entropy_weight = 1.0\n",
    "entropy_weight_rate = 0.1\n",
    "\n",
    "def entropy_estimate(placeholder, code):\n",
    "    # if there are less than N samples in this batch, we just use however much data\n",
    "    # we have\n",
    "    flt = K.flatten(code)\n",
    "    end_idx = K.minimum(flt.shape[0], N)\n",
    "    \n",
    "    ref = flt[:end_idx]\n",
    "    r_ref = K.repeat_elements(ref.reshape((1, end_idx)), NBINS, 0)\n",
    "\n",
    "    r_kern = parzen_kernel(r_ref - r_bins[:, :end_idx])\n",
    "    r_kern = K.sum(r_kern, axis = 1)\n",
    "    r_kern /= K.sum(r_kern)\n",
    "\n",
    "    # clip to a low value so the log doesn't underflow\n",
    "    ent = K.clip(r_kern, 1e-9, 1.0)\n",
    "    ent = -K.sum(ent * K.log(ent) / log_2)\n",
    "    return ent#ent * entropy_weight\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# WGAN-ESQUE OBJECTIVES\n",
    "# ------------------------------------------------------------------\n",
    "def minimize_value(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n",
    "def maximize_value(y_true, y_pred):\n",
    "    return -y_pred\n",
    "\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [300.0, 3.0, 1.0]\n",
    "loss_functions = [rmse, upper_freq_loss, rmse]\n",
    "n_recons = 2\n",
    "n_discrim = 1\n",
    "n_code = 0\n",
    "assert(n_recons + n_discrim + n_code == len(loss_weights))\n",
    "assert(len(loss_weights) == len(loss_functions))\n",
    "\n",
    "def opti():\n",
    "    return Adam(lr = 1e-3)\n",
    "    #return Adam(lr = 1e-4, beta_1 = 0.5)\n",
    "\n",
    "autoencoder = Model(input = [ac_input], output = [ac_reconstructed])\n",
    "autoencoder.compile(loss = rmse, optimizer = opti())\n",
    "\n",
    "make_trainable(autoencoder, False)\n",
    "#discriminator = Model(input = [dsc_input_1, dsc_input_2], output = [dsc_label])\n",
    "discriminator = Model(input = [dsc_input], output = [dsc_label])\n",
    "discriminator.compile(loss = [rmse], optimizer = opti())\n",
    "discriminator.summary()\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "make_trainable(discriminator, False)\n",
    "make_trainable(autoencoder, True)\n",
    "model = Model(input = [ac_input], output = [ac_reconstructed] * n_recons + \\\n",
    "                                           [ac_dsc_label] * n_discrim + \\\n",
    "                                           [ac_embedding] * n_code)\n",
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "discrim_epoch = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interleave numpy arrays of the same size along the first axis\n",
    "def interleave(arr):    \n",
    "    num = len(arr)\n",
    "    \n",
    "    r = np.empty(arr[0].shape)\n",
    "    r = np.repeat(r, num, axis = 0)\n",
    "    \n",
    "    for i in xrange(0, num):\n",
    "        r[i::num] = arr[i]\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interface to PESQ evaluation\n",
    "def run_pesq(clean, to_eval):\n",
    "    pesq_regex = re.compile(\"\\(MOS-LQO\\):  = ([0-9]+\\.[0-9]+)\")\n",
    "    \n",
    "    pesq_out = os.popen(\"./PESQ +16000 +wb \" + clean + \" \" + to_eval).read()\n",
    "    pesq = float(pesq_regex.search(pesq_out).group(1))\n",
    "    return pesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_discrim_pairs(autoencoder, batch):\n",
    "    num = batch.shape[0]\n",
    "    generated = autoencoder.predict(batch)\n",
    "    \n",
    "    X = interleave([batch, generated])\n",
    "    y = interleave([np.ones(num), -np.ones(num)])\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in xrange(0, num):\n",
    "        batch_sample = batch[i, :, :]\n",
    "        gen_sample = generated[i, :, :]\n",
    "\n",
    "        # \"real\" sample comes first\n",
    "        pairs += [[batch_sample, gen_sample]]\n",
    "    \n",
    "    pairs = np.array(pairs)\n",
    "    labels = np.ones(num)\n",
    "    pairs = [pairs[:, 0, :, :], pairs[:, 1, :, :]]\n",
    "    \n",
    "    return pairs, labels\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, orig_samples, verbose = True):\n",
    "    X, y = create_discrim_pairs(autoencoder, orig_samples)\n",
    "    \n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    \n",
    "    #dist = np.mean(y_hat)\n",
    "    \n",
    "    y_hat[y_hat >= 0] = 1\n",
    "    y_hat[y_hat < 0] = -1\n",
    "    \n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Discriminator evaluation: %0.02f\"%(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True, deleteFile = False):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    data = data.astype(np.float32)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    desired = np.clip(desired, -32767, 32767)\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = 128, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    recons = np.clip(recons, -32767, 32767)\n",
    "    \n",
    "    outFilename = prefix + \"_output.wav\"\n",
    "    sciwav.write(outFilename, rate, recons.astype(np.int16))\n",
    "    \n",
    "    pesq = run_pesq(waveFilename, outFilename)\n",
    "    if (deleteFile):\n",
    "        os.system(\"rm \" + outFilename)\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired),\n",
    "        pesq\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        print \"PESQ\", metrics[6]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  3746.66 -3107.84\n",
      "./SA1.wav  mse:  46470.9\n",
      "./SA1.wav  avg err:  103.986\n",
      "PESQ 1.403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4899.0, -4013.0, 3746.6609, -3107.8398, 46470.859, 103.9864, 1.403]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.wav\", \"SA1_res_uninit_\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    49920: 0.792067170143  [5.037447 0.012107 0.168737 0.899250] [5.037447 3.631986 0.506211 0.899250] \n",
      "    Total time for epoch: 248.27679491s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 62.25\n",
      "    Total time for evaluation: 1.36641311646s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.05384240449\n",
      "       Zero prob: 0.170312\n",
      "       Mask entropy: 0.658419133806\n",
      "       Pct. in last bins: 0.00136719\n",
      "       Avg # nonzero elts: 106.2\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4131.4 -3186.74\n",
      "    MSE:         8665.44\n",
      "    Avg err:     47.2702\n",
      "    PESQ:        2.098\n",
      "    PESQ (tst):  1.996\n",
      "    Total time for evaluation: 0.682183027267s\n",
      "Epoch 2:\n",
      "    49920: 0.791562080383  [4.632723 0.011538 0.160436 0.690041] [4.632723 3.461373 0.481309 0.690041] \n",
      "    Total time for epoch: 219.117236137s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 64.5\n",
      "    Total time for evaluation: 0.362565040588s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 4.93939220613\n",
      "       Zero prob: 0.0770312\n",
      "       Mask entropy: 0.391631231621\n",
      "       Pct. in last bins: 0.0003125\n",
      "       Avg # nonzero elts: 118.14\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4241.76 -3652.39\n",
      "    MSE:         7604.77\n",
      "    Avg err:     43.4836\n",
      "    PESQ:        2.469\n",
      "    PESQ (tst):  2.311\n",
      "    Total time for evaluation: 0.580841064453s\n",
      "Epoch 3:\n",
      "    49920: 0.777638494968  [5.272290 0.013598 0.184091 0.640539] [5.272290 4.079478 0.552273 0.640539] \n",
      "    Total time for epoch: 218.020806789s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 64.25\n",
      "    Total time for evaluation: 0.35817193985s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.1257441654\n",
      "       Zero prob: 0.0478516\n",
      "       Mask entropy: 0.277199481658\n",
      "       Pct. in last bins: 0.000585937\n",
      "       Avg # nonzero elts: 121.875\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4515.94 -3144.17\n",
      "    MSE:         7542.75\n",
      "    Avg err:     46.6238\n",
      "    PESQ:        2.264\n",
      "    PESQ (tst):  2.211\n",
      "    Total time for evaluation: 0.554439067841s\n",
      "Epoch 4:\n",
      "    49920: 0.784141421318  [4.706136 0.011447 0.161503 0.787537] [4.706136 3.434089 0.484510 0.787537] \n",
      "    Total time for epoch: 219.415962934s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 61.5\n",
      "    Total time for evaluation: 0.359480142593s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 5.06268348298\n",
      "       Zero prob: 0.211484\n",
      "       Mask entropy: 0.744310499848\n",
      "       Pct. in last bins: 0.000195312\n",
      "       Avg # nonzero elts: 100.93\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4237.76 -2850.37\n",
      "    MSE:         8358.34\n",
      "    Avg err:     46.96\n",
      "    PESQ:        2.345\n",
      "    PESQ (tst):  2.273\n",
      "    Total time for evaluation: 0.566829919815s\n",
      "Epoch 5:\n",
      "    38400: 0.813278198242  [4.235011 0.009961 0.149158 0.799163] [4.235011 2.988375 0.447473 0.799163]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4b230610d610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0ma_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_recons\u001b[0m \u001b[0;34m+\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_discrim\u001b[0m \u001b[0;34m+\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_auto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0ma_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#if (i > 50):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "DSC_CLIP_WEIGHTS = False\n",
    "DSC_CLAMP_RANGE = 0.01\n",
    "DSC_TIMES_TRAIN = 1\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "train_auto = True\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "\n",
    "        \n",
    "        # train autoencoder (\"generator\")\n",
    "        make_trainable(autoencoder, True)\n",
    "        make_trainable(discriminator, False)\n",
    "\n",
    "        a_y = [batch] * n_recons + \\\n",
    "              [np.zeros(nbatch)] * n_discrim + \\\n",
    "              [np.zeros(nbatch)] * n_code\n",
    "        if (train_auto):\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        #if (i > 50):\n",
    "        #    train_auto = False\n",
    "        \n",
    "        if (n_discrim > 0):\n",
    "            # train discriminator\n",
    "            make_trainable(autoencoder, False)\n",
    "            make_trainable(discriminator, True)\n",
    "            \n",
    "            # clip discriminator weights, if necessary\n",
    "            if (DSC_CLIP_WEIGHTS):\n",
    "                for l in discriminator.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -DSC_CLAMP_RANGE, DSC_CLAMP_RANGE) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "            \n",
    "            discrim_batch_X, discrim_batch_y =  create_discrim_pairs(autoencoder, batch)\n",
    "            for k in xrange(0, DSC_TIMES_TRAIN):\n",
    "                d_loss = discriminator.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for w in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[w + 1] *= loss_weights[w]\n",
    "                print loss_arr,\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"   \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    if (n_discrim > 0):\n",
    "        NUM = 200\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        d_acc = test_discriminator(discriminator, autoencoder,\n",
    "                                   X_train[rows, :], verbose = False)\n",
    "\n",
    "        print lead + \"Evaluated the discriminator: \" + str(d_acc)\n",
    "        elapsed = time.time() - startTime\n",
    "        print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    else:\n",
    "        print lead + \"No discriminator\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # generate code histogram from said random samples\n",
    "    # ---------------------------------------------------------\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    code = ac_enc.predict(X_train[rows, :], verbose = 0)\n",
    "    \n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Code histogram:\"\n",
    "    scalars = code.flatten()\n",
    "    \n",
    "    b = np.linspace(-1.0, 1.0, NBINS + 1)\n",
    "    hist = np.histogram(scalars, bins = b)\n",
    "    sample_hist_probs = hist[0].astype('float32')\n",
    "    sample_hist_bins = hist[1].astype('float32')\n",
    "    sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "    entropy = 0\n",
    "    for i in sample_hist_probs:\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "    \n",
    "    zero_prob = sample_hist_probs[NBINS / 2]\n",
    "    zero_prob = np.clip(zero_prob, 0.001, 0.999)\n",
    "    mask_entropy = -(zero_prob * math.log(zero_prob, 2) + (1.0 - zero_prob) * math.log(1.0 - zero_prob, 2))\n",
    "    \n",
    "    print \"       Entropy:\", entropy\n",
    "    print \"       Zero prob:\", sample_hist_probs[NBINS / 2]\n",
    "    print \"       Mask entropy:\", mask_entropy\n",
    "    print \"       Pct. in last bins:\", sample_hist_probs[0] + sample_hist_probs[-1]\n",
    "    \n",
    "    nnz = 0.0\n",
    "    for i in xrange(0, code.shape[0]):\n",
    "        r = np.round(code[i] * 1000.0) / 1000.0\n",
    "        nnz += np.count_nonzero(r)\n",
    "    nnz /= code.shape[0]\n",
    "    print \"       Avg # nonzero elts:\", nnz\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data evey epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.wav\", \"SA1_res_reg_train_epoch\" + str(epoch+1),\n",
    "                              autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:        \", metrics[4]\n",
    "    print lead + \"Avg err:    \", metrics[5]\n",
    "    print lead + \"PESQ:       \", metrics[6]\n",
    "    \n",
    "    metrics_tst = autoencoderTest(\"./SX383.wav\", \"SX383_res_reg_train_epoch\" + str(epoch+1),\n",
    "                                  autoencoder, verbose = False, deleteFile = True)\n",
    "    print lead + \"PESQ (tst): \", metrics_tst[6]\n",
    "    \n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # update entropy loss weight every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    if (n_code > 0 and (epoch + 1) >= 5):\n",
    "        v = K.get_value(entropy_weight)\n",
    "        \n",
    "        if (v < max_entropy_weight):\n",
    "            v += entropy_weight_rate\n",
    "            print lead + \"Updated entropy constraint weight:\", v\n",
    "        else:\n",
    "            v = max_entropy_weight\n",
    "            print lead + \"Didn't update entropy constraint weight:\", v\n",
    "\n",
    "        K.set_value(entropy_weight, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.save('model_res_reg.h5')\n",
    "autoencoder.save('auto_res_reg.h5')\n",
    "\n",
    "discriminator.save('discrim_res_reg.h5')\n",
    "\n",
    "import h5py\n",
    "\n",
    "f = h5py.File('model_res_reg.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D}\\n\\nmodel = load_model('model_res_reg.h5', objs)\\nautoencoder = load_model('auto_res_reg.h5', objs)\\ndiscriminator = load_model('discrim_res_reg.h5', objs)\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D}\n",
    "\n",
    "model = load_model('model_res_reg.h5', objs)\n",
    "autoencoder = load_model('auto_res_reg.h5', objs)\n",
    "discriminator = load_model('discrim_res_reg.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Discriminator layers ---\n",
      "Conv layer 1\n",
      "    Avg weight norm: 0.101453\n",
      "    Max weight norm: 0.322446\n",
      "    Avg bias norm: 0.0145985\n",
      "    Max bias norm: 0.0322819\n",
      "Conv layer 2\n",
      "    Avg weight norm: 0.0433798\n",
      "    Max weight norm: 0.265564\n",
      "    Avg bias norm: 0.00663473\n",
      "    Max bias norm: 0.0238827\n",
      "Conv layer 3\n",
      "    Avg weight norm: 0.0313305\n",
      "    Max weight norm: 0.188594\n",
      "    Avg bias norm: 0.0100644\n",
      "    Max bias norm: 0.0293644\n",
      "Conv layer 4\n",
      "    Avg weight norm: 0.0281917\n",
      "    Max weight norm: 0.175096\n",
      "    Avg bias norm: 0.00271847\n",
      "    Max bias norm: 0.00724543\n",
      "Conv layer 5\n",
      "    Avg weight norm: 0.0294624\n",
      "    Max weight norm: 0.199238\n",
      "    Avg bias norm: 0.0123491\n",
      "    Max bias norm: 0.0237663\n",
      "Conv layer 6\n",
      "    Avg weight norm: 0.0288526\n",
      "    Max weight norm: 0.204341\n",
      "    Avg bias norm: 0.00775272\n",
      "    Max bias norm: 0.0171934\n",
      "Conv layer 7\n",
      "    Avg weight norm: 0.0231948\n",
      "    Max weight norm: 0.169827\n",
      "    Avg bias norm: 0.018443\n",
      "    Max bias norm: 0.0706084\n",
      "Conv layer 8\n",
      "    Avg weight norm: 0.0220437\n",
      "    Max weight norm: 0.188134\n",
      "    Avg bias norm: 0.00496031\n",
      "    Max bias norm: 0.0114332\n",
      "Dense layer 9\n",
      "    Avg weight norm: 0.0153248\n",
      "    Max weight norm: 0.171249\n",
      "    Avg bias norm: 0.00663647\n",
      "    Max bias norm: 0.00663647\n"
     ]
    }
   ],
   "source": [
    "dsc_layers = discriminator.layers[1].layers\n",
    "\n",
    "print \"--- Discriminator layers ---\"\n",
    "\n",
    "i = 0\n",
    "for l in dsc_layers:\n",
    "    if type(l) is Convolution1D or type(l) is Dense:\n",
    "        i += 1\n",
    "        if type(l) is Convolution1D:\n",
    "            print \"Conv layer\", i\n",
    "        else:\n",
    "            print \"Dense layer\", i\n",
    "        w = l.weights[0].eval()\n",
    "        print \"    Avg weight norm:\", np.mean(np.abs(w))\n",
    "        print \"    Max weight norm:\", np.max(np.abs(w))\n",
    "        \n",
    "        if (len(l.weights) == 1): continue\n",
    "        b = l.weights[1].eval()\n",
    "        print \"    Avg bias norm:\", np.mean(np.abs(b))\n",
    "        print \"    Max bias norm:\", np.max(np.abs(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "\n",
    "d_acc = test_discriminator(discriminator, autoencoder,\n",
    "                           X_train[rows, :], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoencoderTest(\"./SA1.wav\", \"SA1_res_reg_\", autoencoder)\n",
    "autoencoderTest(\"./SX383.wav\", \"SX383_res_reg_\", autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_res_reg_\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_embed = ac_enc.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scalars = all_embed.flatten()\n",
    "log_scalars = np.log((scalars + 1.0) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(scalars)\n",
    "print np.var(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist = np.histogram(scalars, bins = np.linspace(-1.0, 1.0, NBINS + 1))\n",
    "sample_hist_probs = hist[0].astype('float32')\n",
    "sample_hist_bins = hist[1].astype('float32')\n",
    "sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "sample_hist_width = 1 * (sample_hist_bins[1] - sample_hist_bins[0])\n",
    "sample_hist_centers = (sample_hist_bins[:-1] + sample_hist_bins[1:]) / 2\n",
    "plt.bar(sample_hist_centers, sample_hist_probs, align='center', width=sample_hist_width)\n",
    "plt.show()\n",
    "\n",
    "entropy = 0\n",
    "for i in sample_hist_probs:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print \"Entropy of distribution:\", entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.wav\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = ac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recons = ac_dec.predict(embed, batch_size = BATCH_SIZE, verbose = 1)\n",
    "recons = unpreprocessWindows(recons, tparams)\n",
    "#recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "#recons = unpreprocessWaveform(recons, wparams)\n",
    "#recons = np.clip(recons, -32767, 32767)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 44\n",
    "print np.count_nonzero(embed[idx]), \"nonzero\"\n",
    "print embed[idx]\n",
    "\n",
    "print len(scalars)\n",
    "print np.count_nonzero((abs(scalars) > 1).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 56\n",
    "\n",
    "orig = windows[idx].flatten()\n",
    "recn = recons[idx].flatten()\n",
    "\n",
    "plt.plot(orig)\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(recn)\n",
    "plt.ylim(ylim)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(abs(orig - recn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
