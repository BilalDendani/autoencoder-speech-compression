{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n",
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA1.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX339.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1059.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1689.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX429.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX69.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX159.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI2319.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA2.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX249.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX221.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA1.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX41.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1751.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1725.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX401.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX24.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA2.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1121.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX131.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA1.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX336.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1236.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI606.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1866.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX156.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA2.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX426.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX246.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX66.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA1.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1233.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI603.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX333.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX153.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1863.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX243.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA2.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX423.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX63.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA1.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX434.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX74.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX254.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI1064.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX344.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX164.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA2.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI582.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI2324.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX82.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1041.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX442.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA1.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1702.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX262.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX172.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX352.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA2.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1072.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI669.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA1.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX39.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX309.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1929.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX129.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1299.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX219.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX399.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA2.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI2325.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX435.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX75.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA1.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1695.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX345.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1065.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX255.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX165.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA2.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI2290.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA1.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI650.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI1660.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX220.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX310.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX40.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX400.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA2.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX130.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX149.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA1.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI2309.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX419.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX239.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX329.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1679.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX59.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA2.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1049.WAV\r",
      "100: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI520.WAV\r",
      "101: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA1.WAV\r",
      "102: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX160.WAV\r",
      "103: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX340.WAV\r",
      "104: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI2035.WAV\r",
      "105: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX250.WAV\r",
      "106: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX430.WAV\r",
      "107: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX70.WAV\r",
      "108: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA2.WAV\r",
      "109: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI1780.WAV\r",
      "110: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA1.WAV\r",
      "111: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX65.WAV\r",
      "112: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX425.WAV\r",
      "113: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1685.WAV\r",
      "114: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1055.WAV\r",
      "115: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX335.WAV\r",
      "116: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA2.WAV\r",
      "117: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX245.WAV\r",
      "118: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI2315.WAV\r",
      "119: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX155.WAV\r",
      "120: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA1.WAV\r",
      "121: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX339.WAV\r",
      "122: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI879.WAV\r",
      "123: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX429.WAV\r",
      "124: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI1509.WAV\r",
      "125: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX69.WAV\r",
      "126: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX159.WAV\r",
      "127: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI2139.WAV\r",
      "128: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA2.WAV\r",
      "129: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX249.WAV\r",
      "130: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX166.WAV\r",
      "131: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA1.WAV\r",
      "132: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX346.WAV\r",
      "133: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI2326.WAV\r",
      "134: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1696.WAV\r",
      "135: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX256.WAV\r",
      "136: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1066.WAV\r",
      "137: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA2.WAV\r",
      "138: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX76.WAV\r",
      "139: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX436.WAV\r",
      "140: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX56.WAV\r",
      "141: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA1.WAV\r",
      "142: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI866.WAV\r",
      "143: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX146.WAV\r",
      "144: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX326.WAV\r",
      "145: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI2126.WAV\r",
      "146: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX416.WAV\r",
      "147: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX236.WAV\r",
      "148: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI1760.WAV\r",
      "149: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA2.WAV\r",
      "150: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX82.WAV\r",
      "151: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX442.WAV\r",
      "152: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA1.WAV\r",
      "153: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI2062.WAV\r",
      "154: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI1432.WAV\r",
      "155: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX262.WAV\r",
      "156: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI802.WAV\r",
      "157: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX172.WAV\r",
      "158: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX352.WAV\r",
      "159: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA2.WAV\r",
      "160: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX311.WAV\r",
      "161: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA1.WAV\r",
      "162: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI2274.WAV\r",
      "163: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX114.WAV\r",
      "164: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX384.WAV\r",
      "165: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX294.WAV\r",
      "166: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1014.WAV\r",
      "167: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA2.WAV\r",
      "168: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1644.WAV\r",
      "169: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX204.WAV\r",
      "170: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX42.WAV\r",
      "171: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX222.WAV\r",
      "172: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA1.WAV\r",
      "173: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX312.WAV\r",
      "174: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI1572.WAV\r",
      "175: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI942.WAV\r",
      "176: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX132.WAV\r",
      "177: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA2.WAV\r",
      "178: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI2202.WAV\r",
      "179: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX402.WAV\r",
      "180: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX149.WAV\r",
      "181: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA1.WAV\r",
      "182: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1949.WAV\r",
      "183: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI689.WAV\r",
      "184: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1319.WAV\r",
      "185: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX419.WAV\r",
      "186: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX239.WAV\r",
      "187: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX329.WAV\r",
      "188: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX59.WAV\r",
      "189: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA2.WAV\r",
      "190: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1187.WAV\r",
      "191: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX17.WAV\r",
      "192: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX107.WAV\r",
      "193: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA1.WAV\r",
      "194: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI630.WAV\r",
      "195: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1817.WAV\r",
      "196: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX287.WAV\r",
      "197: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX197.WAV\r",
      "198: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA2.WAV\r",
      "199: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX377.WAV\r",
      "200: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX248.WAV\r",
      "201: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX428.WAV\r",
      "202: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA1.WAV\r",
      "203: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI2318.WAV\r",
      "204: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX68.WAV\r",
      "205: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1058.WAV\r",
      "206: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX338.WAV\r",
      "207: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX158.WAV\r",
      "208: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1688.WAV\r",
      "209: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA2.WAV\r",
      "210: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI534.WAV\r",
      "211: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI1164.WAV\r",
      "212: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA1.WAV\r",
      "213: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX354.WAV\r",
      "214: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX174.WAV\r",
      "215: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX264.WAV\r",
      "216: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI797.WAV\r",
      "217: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX444.WAV\r",
      "218: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX84.WAV\r",
      "219: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA2.WAV\r",
      "220: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA1.WAV\r",
      "221: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX39.WAV\r",
      "222: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI2199.WAV\r",
      "223: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX309.WAV\r",
      "224: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI1569.WAV\r",
      "225: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX129.WAV\r",
      "226: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX219.WAV\r",
      "227: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI939.WAV\r",
      "228: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX399.WAV\r",
      "229: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA2.WAV\r",
      "230: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI1609.WAV\r",
      "231: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX30.WAV\r",
      "232: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX169.WAV\r",
      "233: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA1.WAV\r",
      "234: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX439.WAV\r",
      "235: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI979.WAV\r",
      "236: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX259.WAV\r",
      "237: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA2.WAV\r",
      "238: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI2239.WAV\r",
      "239: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX79.WAV\r",
      "240: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX42.WAV\r",
      "241: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX222.WAV\r",
      "242: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2112.WAV\r",
      "243: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA1.WAV\r",
      "244: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX312.WAV\r",
      "245: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2026.WAV\r",
      "246: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX132.WAV\r",
      "247: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA2.WAV\r",
      "248: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI1482.WAV\r",
      "249: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX402.WAV\r",
      "250: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX81.WAV\r",
      "251: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA1.WAV\r",
      "252: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX351.WAV\r",
      "253: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI2331.WAV\r",
      "254: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX27.WAV\r",
      "255: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1071.WAV\r",
      "256: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX441.WAV\r",
      "257: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX261.WAV\r",
      "258: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1701.WAV\r",
      "259: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA2.WAV\r",
      "260: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA1.WAV\r",
      "261: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX241.WAV\r",
      "262: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX331.WAV\r",
      "263: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX61.WAV\r",
      "264: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX151.WAV\r",
      "265: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1681.WAV\r",
      "266: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX421.WAV\r",
      "267: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI2311.WAV\r",
      "268: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA2.WAV\r",
      "269: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1051.WAV\r",
      "270: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX167.WAV\r",
      "271: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX437.WAV\r",
      "272: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA1.WAV\r",
      "273: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX77.WAV\r",
      "274: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX257.WAV\r",
      "275: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX347.WAV\r",
      "276: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI1607.WAV\r",
      "277: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA2.WAV\r",
      "278: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI977.WAV\r",
      "279: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI2237.WAV\r",
      "280: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI1485.WAV\r",
      "281: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA1.WAV\r",
      "282: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI855.WAV\r",
      "283: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX225.WAV\r",
      "284: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX405.WAV\r",
      "285: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA2.WAV\r",
      "286: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX45.WAV\r",
      "287: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX315.WAV\r",
      "288: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX135.WAV\r",
      "289: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI2115.WAV\r",
      "290: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1068.WAV\r",
      "291: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA1.WAV\r",
      "292: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX78.WAV\r",
      "293: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX202.WAV\r",
      "294: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX258.WAV\r",
      "295: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX168.WAV\r",
      "296: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1698.WAV\r",
      "297: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI2328.WAV\r",
      "298: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA2.WAV\r",
      "299: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX348.WAV\r",
      "300: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI579.WAV\r",
      "301: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA1.WAV\r",
      "302: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX39.WAV\r",
      "303: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX309.WAV\r",
      "304: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX129.WAV\r",
      "305: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX219.WAV\r",
      "306: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX399.WAV\r",
      "307: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1839.WAV\r",
      "308: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA2.WAV\r",
      "309: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1209.WAV\r",
      "310: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA1.WAV\r",
      "311: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX161.WAV\r",
      "312: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX71.WAV\r",
      "313: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX431.WAV\r",
      "314: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX341.WAV\r",
      "315: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI611.WAV\r",
      "316: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX251.WAV\r",
      "317: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1241.WAV\r",
      "318: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA2.WAV\r",
      "319: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1871.WAV\r",
      "320: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA1.WAV\r",
      "321: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX355.WAV\r",
      "322: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX445.WAV\r",
      "323: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX265.WAV\r",
      "324: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX85.WAV\r",
      "325: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1165.WAV\r",
      "326: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1802.WAV\r",
      "327: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX175.WAV\r",
      "328: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI535.WAV\r",
      "329: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA2.WAV\r",
      "330: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX62.WAV\r",
      "331: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI872.WAV\r",
      "332: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA1.WAV\r",
      "333: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI2132.WAV\r",
      "334: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI588.WAV\r",
      "335: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX152.WAV\r",
      "336: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX332.WAV\r",
      "337: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX242.WAV\r",
      "338: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA2.WAV\r",
      "339: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX422.WAV\r",
      "340: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA1.WAV\r",
      "341: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI1671.WAV\r",
      "342: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX321.WAV\r",
      "343: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2332.WAV\r",
      "344: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX141.WAV\r",
      "345: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX231.WAV\r",
      "346: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX411.WAV\r",
      "347: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX51.WAV\r",
      "348: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA2.WAV\r",
      "349: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2301.WAV\r",
      "350: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA1.WAV\r",
      "351: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX433.WAV\r",
      "352: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX343.WAV\r",
      "353: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX73.WAV\r",
      "354: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX163.WAV\r",
      "355: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI793.WAV\r",
      "356: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI1913.WAV\r",
      "357: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA2.WAV\r",
      "358: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX253.WAV\r",
      "359: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI2053.WAV\r",
      "360: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX234.WAV\r",
      "361: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA1.WAV\r",
      "362: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX324.WAV\r",
      "363: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2225.WAV\r",
      "364: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2304.WAV\r",
      "365: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI1674.WAV\r",
      "366: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX54.WAV\r",
      "367: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX414.WAV\r",
      "368: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX144.WAV\r",
      "369: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA2.WAV\r",
      "370: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA1.WAV\r",
      "371: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX235.WAV\r",
      "372: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX145.WAV\r",
      "373: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX55.WAV\r",
      "374: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX325.WAV\r",
      "375: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX415.WAV\r",
      "376: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI685.WAV\r",
      "377: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1315.WAV\r",
      "378: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA2.WAV\r",
      "379: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1945.WAV\r",
      "380: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA1.WAV\r",
      "381: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1295.WAV\r",
      "382: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI538.WAV\r",
      "383: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1798.WAV\r",
      "384: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX268.WAV\r",
      "385: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX178.WAV\r",
      "386: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA2.WAV\r",
      "387: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX448.WAV\r",
      "388: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX358.WAV\r",
      "389: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX88.WAV\r",
      "390: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX127.WAV\r",
      "391: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA1.WAV\r",
      "392: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX217.WAV\r",
      "393: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI847.WAV\r",
      "394: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX307.WAV\r",
      "395: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1477.WAV\r",
      "396: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX397.WAV\r",
      "397: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA2.WAV\r",
      "398: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX37.WAV\r",
      "399: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1313.WAV\r",
      "400: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA1.WAV\r",
      "401: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1005.WAV\r",
      "402: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX15.WAV\r",
      "403: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1342.WAV\r",
      "404: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX285.WAV\r",
      "405: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SI1635.WAV\r",
      "406: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX105.WAV\r",
      "407: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX195.WAV\r",
      "408: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SA2.WAV\r",
      "409: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXV0/SX375.WAV\r",
      "410: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI961.WAV\r",
      "411: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA1.WAV\r",
      "412: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX241.WAV\r",
      "413: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI1591.WAV\r",
      "414: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX331.WAV\r",
      "415: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX61.WAV\r",
      "416: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX151.WAV\r",
      "417: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SX421.WAV\r",
      "418: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SA2.WAV\r",
      "419: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MREM0/SI511.WAV\r",
      "420: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1251.WAV\r",
      "421: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX17.WAV\r",
      "422: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX107.WAV\r",
      "423: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA1.WAV\r",
      "424: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI1457.WAV\r",
      "425: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX287.WAV\r",
      "426: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SI827.WAV\r",
      "427: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX197.WAV\r",
      "428: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SA2.WAV\r",
      "429: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJJM0/SX377.WAV\r",
      "430: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA1.WAV\r",
      "431: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1888.WAV\r",
      "432: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX268.WAV\r",
      "433: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI628.WAV\r",
      "434: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX178.WAV\r",
      "435: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SA2.WAV\r",
      "436: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX448.WAV\r",
      "437: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX358.WAV\r",
      "438: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SX88.WAV\r",
      "439: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPFU0/SI1258.WAV\r",
      "440: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX157.WAV\r",
      "441: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA1.WAV\r",
      "442: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX337.WAV\r",
      "443: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX67.WAV\r",
      "444: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1687.WAV\r",
      "445: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI2317.WAV\r",
      "446: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX427.WAV\r",
      "447: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SA2.WAV\r",
      "448: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SI1057.WAV\r",
      "449: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRE0/SX247.WAV\r",
      "450: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA1.WAV\r",
      "451: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1170.WAV\r",
      "452: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX270.WAV\r",
      "453: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI1800.WAV\r",
      "454: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX360.WAV\r",
      "455: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX450.WAV\r",
      "456: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX90.WAV\r",
      "457: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SI540.WAV\r",
      "458: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SA2.WAV\r",
      "459: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDED0/SX180.WAV\r",
      "460: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX435.WAV\r",
      "461: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX75.WAV\r",
      "462: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA1.WAV\r",
      "463: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI1605.WAV\r",
      "464: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX345.WAV\r",
      "465: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX255.WAV\r",
      "466: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI975.WAV\r",
      "467: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SX165.WAV\r",
      "468: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SI2235.WAV\r",
      "469: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJFR0/SA2.WAV\r",
      "470: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI539.WAV\r",
      "471: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA1.WAV\r",
      "472: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1169.WAV\r",
      "473: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX359.WAV\r",
      "474: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX449.WAV\r",
      "475: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX179.WAV\r",
      "476: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX269.WAV\r",
      "477: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SA2.WAV\r",
      "478: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SI1799.WAV\r",
      "479: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBML0/SX89.WAV\r",
      "480: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA1.WAV\r",
      "481: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX32.WAV\r",
      "482: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX212.WAV\r",
      "483: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX392.WAV\r",
      "484: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1652.WAV\r",
      "485: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX302.WAV\r",
      "486: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SX122.WAV\r",
      "487: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI2282.WAV\r",
      "488: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SI1022.WAV\r",
      "489: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJHK0/SA2.WAV\r",
      "490: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA1.WAV\r",
      "491: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX161.WAV\r",
      "492: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX217.WAV\r",
      "493: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1747.WAV\r",
      "494: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI1117.WAV\r",
      "495: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX366.WAV\r",
      "496: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX397.WAV\r",
      "497: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SA2.WAV\r",
      "498: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SX37.WAV\r",
      "499: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKSR0/SI487.WAV\r",
      "500: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX237.WAV\r",
      "501: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SA1.WAV\r",
      "502: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX277.WAV\r",
      "503: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX147.WAV\r",
      "504: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI1137.WAV\r",
      "505: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX417.WAV\r",
      "506: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI507.WAV\r",
      "507: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SI1767.WAV\r",
      "508: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SA2.WAV\r",
      "509: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLET0/SX57.WAV\r",
      "510: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI882.WAV\r",
      "511: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SA1.WAV\r",
      "512: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX252.WAV\r",
      "513: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX342.WAV\r",
      "514: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI1512.WAV\r",
      "515: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SI2142.WAV\r",
      "516: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX162.WAV\r",
      "517: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX72.WAV\r",
      "518: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SX432.WAV\r",
      "519: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTWH1/SA2.WAV\r",
      "520: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI1575.WAV\r",
      "521: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SA1.WAV\r",
      "522: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX225.WAV\r",
      "523: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX405.WAV\r",
      "524: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI945.WAV\r",
      "525: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SA2.WAV\r",
      "526: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX45.WAV\r",
      "527: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX315.WAV\r",
      "528: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SX135.WAV\r",
      "529: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHBS0/SI2205.WAV\r",
      "530: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX62.WAV\r",
      "531: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SA1.WAV\r",
      "532: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI1682.WAV\r",
      "533: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX152.WAV\r",
      "534: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX332.WAV\r",
      "535: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI1052.WAV\r",
      "536: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX242.WAV\r",
      "537: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SI2312.WAV\r",
      "538: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SA2.WAV\r",
      "539: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJSK0/SX422.WAV\r",
      "540: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SA1.WAV\r",
      "541: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX220.WAV\r",
      "542: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI850.WAV\r",
      "543: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI1480.WAV\r",
      "544: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX310.WAV\r",
      "545: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SI2110.WAV\r",
      "546: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX40.WAV\r",
      "547: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX400.WAV\r",
      "548: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SA2.WAV\r",
      "549: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDCM0/SX130.WAV\r",
      "550: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI1234.WAV\r",
      "551: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX64.WAV\r",
      "552: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI604.WAV\r",
      "553: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SA1.WAV\r",
      "554: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SI1864.WAV\r",
      "555: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX334.WAV\r",
      "556: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX244.WAV\r",
      "557: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX424.WAV\r",
      "558: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SA2.WAV\r",
      "559: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLM0/SX154.WAV\r",
      "560: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI2267.WAV\r",
      "561: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX17.WAV\r",
      "562: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX107.WAV\r",
      "563: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SA1.WAV\r",
      "564: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI1007.WAV\r",
      "565: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX287.WAV\r",
      "566: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX197.WAV\r",
      "567: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SA2.WAV\r",
      "568: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SI1637.WAV\r",
      "569: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSDB0/SX377.WAV\r",
      "570: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX149.WAV\r",
      "571: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SA1.WAV\r",
      "572: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI1589.WAV\r",
      "573: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX419.WAV\r",
      "574: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX239.WAV\r",
      "575: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX329.WAV\r",
      "576: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SX59.WAV\r",
      "577: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI2219.WAV\r",
      "578: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SI2216.WAV\r",
      "579: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSES0/SA2.WAV\r",
      "580: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI2281.WAV\r",
      "581: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SA1.WAV\r",
      "582: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX121.WAV\r",
      "583: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX391.WAV\r",
      "584: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI1021.WAV\r",
      "585: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX211.WAV\r",
      "586: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SI1349.WAV\r",
      "587: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX301.WAV\r",
      "588: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SA2.WAV\r",
      "589: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMH0/SX31.WAV\r",
      "590: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SA1.WAV\r",
      "591: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX241.WAV\r",
      "592: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI1771.WAV\r",
      "593: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX331.WAV\r",
      "594: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX61.WAV\r",
      "595: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI2221.WAV\r",
      "596: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX151.WAV\r",
      "597: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SX421.WAV\r",
      "598: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SA2.WAV\r",
      "599: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FKDE0/SI1141.WAV\r",
      "600: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SA1.WAV\r",
      "601: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX136.WAV\r",
      "602: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX406.WAV\r",
      "603: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI2206.WAV\r",
      "604: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI946.WAV\r",
      "605: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX316.WAV\r",
      "606: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX226.WAV\r",
      "607: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SX46.WAV\r",
      "608: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SI1576.WAV\r",
      "609: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MPAR0/SA2.WAV\r",
      "610: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SA1.WAV\r",
      "611: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX121.WAV\r",
      "612: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX391.WAV\r",
      "613: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX211.WAV\r",
      "614: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI2101.WAV\r",
      "615: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI1471.WAV\r",
      "616: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX301.WAV\r",
      "617: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SA2.WAV\r",
      "618: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SI841.WAV\r",
      "619: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAB1/SX31.WAV\r",
      "620: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI1443.WAV\r",
      "621: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SA1.WAV\r",
      "622: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX273.WAV\r",
      "623: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI2073.WAV\r",
      "624: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SI1525.WAV\r",
      "625: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX183.WAV\r",
      "626: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX93.WAV\r",
      "627: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX3.WAV\r",
      "628: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SA2.WAV\r",
      "629: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MWRP0/SX363.WAV\r",
      "630: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SA1.WAV\r",
      "631: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX270.WAV\r",
      "632: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI2340.WAV\r",
      "633: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX360.WAV\r",
      "634: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX450.WAV\r",
      "635: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX90.WAV\r",
      "636: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI1080.WAV\r",
      "637: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SA2.WAV\r",
      "638: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SI1710.WAV\r",
      "639: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRMG0/SX180.WAV\r",
      "640: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX169.WAV\r",
      "641: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA1.WAV\r",
      "642: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX439.WAV\r",
      "643: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX259.WAV\r",
      "644: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI529.WAV\r",
      "645: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SA2.WAV\r",
      "646: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX79.WAV\r",
      "647: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI1159.WAV\r",
      "648: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SX349.WAV\r",
      "649: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FVKB0/SI1789.WAV\r",
      "650: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SA1.WAV\r",
      "651: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX355.WAV\r",
      "652: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX445.WAV\r",
      "653: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX265.WAV\r",
      "654: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX85.WAV\r",
      "655: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI2144.WAV\r",
      "656: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SX175.WAV\r",
      "657: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI2065.WAV\r",
      "658: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SA2.WAV\r",
      "659: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLC1/SI1435.WAV\r",
      "660: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI2011.WAV\r",
      "661: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SA1.WAV\r",
      "662: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX121.WAV\r",
      "663: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX391.WAV\r",
      "664: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI661.WAV\r",
      "665: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX211.WAV\r",
      "666: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SI1921.WAV\r",
      "667: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX301.WAV\r",
      "668: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SA2.WAV\r",
      "669: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FPAC0/SX31.WAV\r",
      "670: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SA1.WAV\r",
      "671: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX32.WAV\r",
      "672: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI505.WAV\r",
      "673: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX212.WAV\r",
      "674: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX392.WAV\r",
      "675: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI757.WAV\r",
      "676: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX302.WAV\r",
      "677: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SI2102.WAV\r",
      "678: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SX122.WAV\r",
      "679: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBTH0/SA2.WAV\r",
      "680: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX42.WAV\r",
      "681: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX222.WAV\r",
      "682: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SA1.WAV\r",
      "683: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX312.WAV\r",
      "684: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1694.WAV\r",
      "685: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1212.WAV\r",
      "686: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX132.WAV\r",
      "687: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SA2.WAV\r",
      "688: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SI1842.WAV\r",
      "689: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAR0/SX402.WAV\r",
      "690: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX237.WAV\r",
      "691: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SA1.WAV\r",
      "692: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI2307.WAV\r",
      "693: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX147.WAV\r",
      "694: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX327.WAV\r",
      "695: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX417.WAV\r",
      "696: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI1047.WAV\r",
      "697: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SA2.WAV\r",
      "698: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SI1677.WAV\r",
      "699: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJEN0/SX57.WAV\r",
      "700: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SA1.WAV\r",
      "701: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX160.WAV\r",
      "702: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX340.WAV\r",
      "703: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI2230.WAV\r",
      "704: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX250.WAV\r",
      "705: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX430.WAV\r",
      "706: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SX70.WAV\r",
      "707: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SA2.WAV\r",
      "708: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI506.WAV\r",
      "709: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTPR0/SI1600.WAV\r",
      "710: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI682.WAV\r",
      "711: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SA1.WAV\r",
      "712: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI710.WAV\r",
      "713: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX434.WAV\r",
      "714: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX74.WAV\r",
      "715: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX254.WAV\r",
      "716: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SI1604.WAV\r",
      "717: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX344.WAV\r",
      "718: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SX164.WAV\r",
      "719: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJAI0/SA2.WAV\r",
      "720: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA1.WAV\r",
      "721: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX336.WAV\r",
      "722: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1326.WAV\r",
      "723: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1956.WAV\r",
      "724: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SI1655.WAV\r",
      "725: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX156.WAV\r",
      "726: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SA2.WAV\r",
      "727: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX426.WAV\r",
      "728: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX246.WAV\r",
      "729: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAEO0/SX66.WAV\r",
      "730: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SA1.WAV\r",
      "731: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX232.WAV\r",
      "732: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX142.WAV\r",
      "733: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX412.WAV\r",
      "734: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX52.WAV\r",
      "735: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1672.WAV\r",
      "736: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1705.WAV\r",
      "737: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SI1042.WAV\r",
      "738: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SA2.WAV\r",
      "739: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJDG0/SX322.WAV\r",
      "740: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX167.WAV\r",
      "741: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX17.WAV\r",
      "742: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX437.WAV\r",
      "743: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SA1.WAV\r",
      "744: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX77.WAV\r",
      "745: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI1787.WAV\r",
      "746: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SX257.WAV\r",
      "747: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI527.WAV\r",
      "748: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SI1157.WAV\r",
      "749: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTER0/SA2.WAV\r",
      "750: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX62.WAV\r",
      "751: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI612.WAV\r",
      "752: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SA1.WAV\r",
      "753: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI1772.WAV\r",
      "754: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SI512.WAV\r",
      "755: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX152.WAV\r",
      "756: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX332.WAV\r",
      "757: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX242.WAV\r",
      "758: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SA2.WAV\r",
      "759: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MHXL0/SX422.WAV\r",
      "760: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI1666.WAV\r",
      "761: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SA1.WAV\r",
      "762: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX136.WAV\r",
      "763: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX406.WAV\r",
      "764: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX316.WAV\r",
      "765: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX226.WAV\r",
      "766: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SX46.WAV\r",
      "767: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI1036.WAV\r",
      "768: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SA2.WAV\r",
      "769: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAK0/SI2296.WAV\r",
      "770: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA1.WAV\r",
      "771: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX240.WAV\r",
      "772: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI780.WAV\r",
      "773: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI1410.WAV\r",
      "774: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX60.WAV\r",
      "775: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SI2040.WAV\r",
      "776: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SA2.WAV\r",
      "777: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX420.WAV\r",
      "778: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX330.WAV\r",
      "779: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGR0/SX150.WAV\r",
      "780: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI1763.WAV\r",
      "781: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SA1.WAV\r",
      "782: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX354.WAV\r",
      "783: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX174.WAV\r",
      "784: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI1434.WAV\r",
      "785: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX264.WAV\r",
      "786: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX444.WAV\r",
      "787: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SX84.WAV\r",
      "788: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SA2.WAV\r",
      "789: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FJSP0/SI804.WAV\r",
      "790: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SA1.WAV\r",
      "791: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI1102.WAV\r",
      "792: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI472.WAV\r",
      "793: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX112.WAV\r",
      "794: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX202.WAV\r",
      "795: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX22.WAV\r",
      "796: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX292.WAV\r",
      "797: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SI1732.WAV\r",
      "798: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SX382.WAV\r",
      "799: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRWS0/SA2.WAV\r",
      "800: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SA1.WAV\r",
      "801: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI1291.WAV\r",
      "802: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX121.WAV\r",
      "803: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI1381.WAV\r",
      "804: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX391.WAV\r",
      "805: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX211.WAV\r",
      "806: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX301.WAV\r",
      "807: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SA2.WAV\r",
      "808: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SI751.WAV\r",
      "809: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MJWT0/SX31.WAV\r",
      "810: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX311.WAV\r",
      "811: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX221.WAV\r",
      "812: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI1844.WAV\r",
      "813: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA1.WAV\r",
      "814: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI1571.WAV\r",
      "815: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX41.WAV\r",
      "816: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SI2201.WAV\r",
      "817: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX401.WAV\r",
      "818: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SA2.WAV\r",
      "819: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLW0/SX131.WAV\r",
      "820: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX248.WAV\r",
      "821: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX428.WAV\r",
      "822: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA1.WAV\r",
      "823: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX68.WAV\r",
      "824: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1778.WAV\r",
      "825: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI518.WAV\r",
      "826: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX338.WAV\r",
      "827: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SI1148.WAV\r",
      "828: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SX158.WAV\r",
      "829: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FETB0/SA2.WAV\r",
      "830: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1779.WAV\r",
      "831: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SA1.WAV\r",
      "832: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI1149.WAV\r",
      "833: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX339.WAV\r",
      "834: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX429.WAV\r",
      "835: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX69.WAV\r",
      "836: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX159.WAV\r",
      "837: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SI2075.WAV\r",
      "838: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SA2.WAV\r",
      "839: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDML0/SX249.WAV\r",
      "840: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX111.WAV\r",
      "841: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI921.WAV\r",
      "842: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA1.WAV\r",
      "843: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX21.WAV\r",
      "844: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX201.WAV\r",
      "845: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI1402.WAV\r",
      "846: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SA2.WAV\r",
      "847: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SI2181.WAV\r",
      "848: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX291.WAV\r",
      "849: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FTBR0/SX381.WAV\r",
      "850: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX248.WAV\r",
      "851: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX428.WAV\r",
      "852: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SA1.WAV\r",
      "853: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX68.WAV\r",
      "854: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX338.WAV\r",
      "855: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SX158.WAV\r",
      "856: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI1418.WAV\r",
      "857: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI788.WAV\r",
      "858: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SA2.WAV\r",
      "859: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FECD0/SI2048.WAV\r",
      "860: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX271.WAV\r",
      "861: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SA1.WAV\r",
      "862: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX91.WAV\r",
      "863: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX451.WAV\r",
      "864: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI991.WAV\r",
      "865: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX181.WAV\r",
      "866: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SA2.WAV\r",
      "867: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI2251.WAV\r",
      "868: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SI1621.WAV\r",
      "869: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FSMA0/SX361.WAV\r",
      "870: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX167.WAV\r",
      "871: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI1697.WAV\r",
      "872: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX437.WAV\r",
      "873: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA1.WAV\r",
      "874: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX77.WAV\r",
      "875: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX257.WAV\r",
      "876: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI2327.WAV\r",
      "877: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SX24.WAV\r",
      "878: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SA2.WAV\r",
      "879: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPSW0/SI1067.WAV\r",
      "880: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX234.WAV\r",
      "881: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SA1.WAV\r",
      "882: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX324.WAV\r",
      "883: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI774.WAV\r",
      "884: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI2034.WAV\r",
      "885: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SI717.WAV\r",
      "886: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX54.WAV\r",
      "887: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX414.WAV\r",
      "888: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SX144.WAV\r",
      "889: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MMRP0/SA2.WAV\r",
      "890: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SA1.WAV\r",
      "891: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI1192.WAV\r",
      "892: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX112.WAV\r",
      "893: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX202.WAV\r",
      "894: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX22.WAV\r",
      "895: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX292.WAV\r",
      "896: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI562.WAV\r",
      "897: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SX382.WAV\r",
      "898: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SI1822.WAV\r",
      "899: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTJS0/SA2.WAV\r",
      "900: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI1554.WAV\r",
      "901: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SA1.WAV\r",
      "902: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX114.WAV\r",
      "903: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX384.WAV\r",
      "904: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX294.WAV\r",
      "905: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI675.WAV\r",
      "906: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SI924.WAV\r",
      "907: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX24.WAV\r",
      "908: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SA2.WAV\r",
      "909: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MPGH0/SX204.WAV\r",
      "910: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SA1.WAV\r",
      "911: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX114.WAV\r",
      "912: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX384.WAV\r",
      "913: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX294.WAV\r",
      "914: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI744.WAV\r",
      "915: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX24.WAV\r",
      "916: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI2004.WAV\r",
      "917: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SI1374.WAV\r",
      "918: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SA2.WAV\r",
      "919: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MEDR0/SX204.WAV\r",
      "920: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI2067.WAV\r",
      "921: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SA1.WAV\r",
      "922: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX87.WAV\r",
      "923: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX357.WAV\r",
      "924: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX447.WAV\r",
      "925: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX177.WAV\r",
      "926: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI1533.WAV\r",
      "927: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SX267.WAV\r",
      "928: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SA2.WAV\r",
      "929: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MKLS0/SI1437.WAV\r",
      "930: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX271.WAV\r",
      "931: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI1837.WAV\r",
      "932: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SA1.WAV\r",
      "933: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI1261.WAV\r",
      "934: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX91.WAV\r",
      "935: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SI631.WAV\r",
      "936: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX451.WAV\r",
      "937: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX181.WAV\r",
      "938: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SA2.WAV\r",
      "939: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MDAC0/SX361.WAV\r",
      "940: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI2036.WAV\r",
      "941: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX56.WAV\r",
      "942: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SA1.WAV\r",
      "943: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX146.WAV\r",
      "944: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX326.WAV\r",
      "945: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI1271.WAV\r",
      "946: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX416.WAV\r",
      "947: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SX236.WAV\r",
      "948: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SI1406.WAV\r",
      "949: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FDAW0/SA2.WAV\r",
      "950: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI798.WAV\r",
      "951: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SA1.WAV\r",
      "952: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX78.WAV\r",
      "953: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI2058.WAV\r",
      "954: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX258.WAV\r",
      "955: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX438.WAV\r",
      "956: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX168.WAV\r",
      "957: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SA2.WAV\r",
      "958: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SI1428.WAV\r",
      "959: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRCG0/SX348.WAV\r",
      "960: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI792.WAV\r",
      "961: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SA1.WAV\r",
      "962: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX252.WAV\r",
      "963: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX342.WAV\r",
      "964: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI2052.WAV\r",
      "965: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX162.WAV\r",
      "966: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX72.WAV\r",
      "967: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SX432.WAV\r",
      "968: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SA2.WAV\r",
      "969: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MRAI0/SI1954.WAV\r",
      "970: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX127.WAV\r",
      "971: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA1.WAV\r",
      "972: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX217.WAV\r",
      "973: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI648.WAV\r",
      "974: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX307.WAV\r",
      "975: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1657.WAV\r",
      "976: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX397.WAV\r",
      "977: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SA2.WAV\r",
      "978: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SX37.WAV\r",
      "979: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FCJF0/SI1027.WAV\r",
      "980: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI1865.WAV\r",
      "981: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SA1.WAV\r",
      "982: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX65.WAV\r",
      "983: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX425.WAV\r",
      "984: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI605.WAV\r",
      "985: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SI1235.WAV\r",
      "986: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX335.WAV\r",
      "987: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SA2.WAV\r",
      "988: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX245.WAV\r",
      "989: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/MTPF0/SX155.WAV\r",
      "990: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA1.WAV\r",
      "991: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI2096.WAV\r",
      "992: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX116.WAV\r",
      "993: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI836.WAV\r",
      "994: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX26.WAV\r",
      "995: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX386.WAV\r",
      "996: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SI1466.WAV\r",
      "997: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SA2.WAV\r",
      "998: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX206.WAV\r",
      "999: /home/sri/Desktop/timit/TIMIT/TRAIN/DR1/FVMH0/SX296.WAV\r"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):\n",
    "    # scale window between -1 and 1\n",
    "    mn = np.min(waveform)\n",
    "    mx = np.max(waveform)\n",
    "    maxabs = np.maximum(np.abs(mn), np.abs(mx))\n",
    "        \n",
    "    return np.copy(waveform) / maxabs, (maxabs,)\n",
    "   \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    return np.copy(waveform) * params[0]\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    return windows, ()\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6672.0\n",
      "8744.0\n",
      "(47616,)\n",
      "-0.763037511436\n",
      "1.0\n",
      "(8744.0,)\n"
     ]
    }
   ],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    if (i == 0):\n",
    "        print np.min(processedWaveforms[i])\n",
    "        print np.max(processedWaveforms[i])\n",
    "    processedWaveforms[i], wc = preprocessWaveform(rawWaveforms[i])\n",
    "    if (i == 0):\n",
    "        print processedWaveforms[i].shape\n",
    "        print np.min(processedWaveforms[i])\n",
    "        print np.max(processedWaveforms[i])\n",
    "        print wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5.   3.   3. ..., -18. -19. -17.]\n",
      "[-0.00057182  0.00034309  0.00034309 ..., -0.00205855 -0.00217292\n",
      " -0.00194419]\n",
      "[ -5.   3.   3. ..., -18. -19. -17.]\n",
      "\n",
      "0.0\n",
      "0.0853271408162\n",
      "746.09852761\n",
      "[-5.  3.  3. ...,  0.  0.  0.]\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "print rawWaveforms[0]\n",
    "\n",
    "processedWave, wparams = preprocessWaveform(rawWaveforms[0])\n",
    "print processedWave\n",
    "print processedWave * wparams[0]\n",
    "print \"\"\n",
    "\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "# first, write desired reconstruction\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "desired = unpreprocessWindows(transformed, tparams)\n",
    "print np.sum(desired - windows)\n",
    "\n",
    "desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "print np.sum(desired[:47616] - processedWave)\n",
    "\n",
    "desired = unpreprocessWaveform(desired, wparams)\n",
    "print np.sum(desired[:47616] - rawWaveforms[0])\n",
    "\n",
    "print desired\n",
    "print np.sum(desired.astype(np.int16)[:47616] - rawWaveforms[0].astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (101135, 512)\n",
      "Max:  1.0\n",
      "Min:  -1.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (101135, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101135, 512, 1)\n",
      "9.77603e-07\n",
      "0.099766\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhaseShiftDown1D(Layer):\n",
    "    \"\"\" PhaseShiftDown1D\n",
    "    Takes vector of size: B x nS x F\n",
    "    And returns vector: B x S x nF\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShiftDown1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1] / self.n, self.n, x.shape[2]))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] / self.n, x.shape[2] * self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] / self.n, input_shape[2] * self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShiftDown1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhaseShiftUp1D(Layer):\n",
    "    \"\"\" PhaseShiftUp1D\n",
    "    Takes vector of size: B x S x nF\n",
    "    And returns vector: B x nS x F\n",
    "    \"\"\"\n",
    "    def __init__(self, n, **kwargs):\n",
    "        super(PhaseShiftUp1D, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        r = T.reshape(x, (x.shape[0], x.shape[1], x.shape[2] / self.n, self.n))\n",
    "        r = T.transpose(r, (0, 1, 3, 2))\n",
    "        r = T.reshape(r, (x.shape[0], x.shape[1] * self.n, x.shape[2] / self.n))\n",
    "        return r\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * self.n, input_shape[2] / self.n)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'n' : self.n}\n",
    "        base_config = super(PhaseShiftUp1D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quantizes [-1.0, 1.0] into a certain number of uniform bins\n",
    "class UniformQuantizer(Layer):\n",
    "    def __init__(self, nbins, noise_in_train = True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.nbins = nbins\n",
    "        self.noise_in_train = noise_in_train\n",
    "        self.uses_learning_phase = True\n",
    "        super(UniformQuantizer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # during training, add uniform noise the width of one bin\n",
    "        noise_x = x + K.random_uniform(shape = K.shape(x),\n",
    "                                       low = -(1.0 / (self.nbins - 1)),\n",
    "                                       high = 1.0 / (self.nbins - 1))\n",
    "        \n",
    "        # during testing, actually quantize the thing\n",
    "        qnt_x = (x + 1.0) / 2.0\n",
    "        qnt_x = K.round(qnt_x * float(self.nbins - 1)) / float(self.nbins - 1)\n",
    "        qnt_x = (qnt_x * 2.0) - 1.0\n",
    "        \n",
    "        if (self.noise_in_train):\n",
    "            return K.in_train_phase(noise_x, qnt_x)\n",
    "        else:\n",
    "            return K.in_train_phase(x, qnt_x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'nbins': self.nbins}\n",
    "        base_config = super(UniformQuantizer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SelectMax(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        super(SelectMax, self).__init__()\n",
    "        self.n = n\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        zero_idxs = np.argsort(np.abs(x), axis = -1)[:, :-self.n]\n",
    "        col_idxs = np.arange(x.shape[0])[:, None]\n",
    "        out = np.copy(x)\n",
    "        x[col_idxs, zero_idxs] = 0\n",
    "        z[0] = x\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        x, = input\n",
    "        g, = output_gradients\n",
    "        \n",
    "        zero_idxs = T.argsort(T.abs_(x), axis = -1)[:, :-self.n, None]\n",
    "        \n",
    "        idnt = T.eye(x.shape[-1]) * 0.99\n",
    "        \n",
    "        grad_mult = idnt[zero_idxs]\n",
    "        grad_mult = T.sum(grad_mult, axis = -3)[:, 0, :]\n",
    "        grad_mult = 1.0 - grad_mult\n",
    "        \n",
    "        grad_mult = grad_mult + 0.01\n",
    "        \n",
    "        out_grad = g * grad_mult\n",
    "        \n",
    "        return [out_grad]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only works with theano dawg\n",
    "class OrthogonalDense(Layer):\n",
    "    def __init__(self, tied_to = None, has_bias = False, **kwargs):\n",
    "        super(OrthogonalDense, self).__init__(**kwargs)\n",
    "        self.tied_to = tied_to\n",
    "        self.has_bias = has_bias\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[1]\n",
    "        \n",
    "        self.n = input_dim\n",
    "        \n",
    "        # we store a full matrix, but use it as a skew-symmetric one\n",
    "        if (self.tied_to is None):\n",
    "            self.W = np.random.uniform(-0.001, 0.001, (self.n, self.n))\n",
    "            self.W = K.variable(self.W)\n",
    "            self.trainable_weights = [self.W]\n",
    "            \n",
    "            if (self.has_bias):\n",
    "                self.b = K.variable(np.zeros((self.n,)))\n",
    "                self.trainable_weights = [self.W, self.b]\n",
    "    \n",
    "    def produce_unitary(self):\n",
    "        # produce skew-symmetric matrix from W\n",
    "        upper = T.triu(self.W, k = 1)\n",
    "        skew = upper - K.transpose(upper)\n",
    "        \n",
    "        # compute approximate matrix exponential\n",
    "        a = K.eye(self.n)\n",
    "        unitary = K.zeros((self.n, self.n))\n",
    "        \n",
    "        for i in xrange(0, 11):\n",
    "            c = 1.0 / math.factorial(i)\n",
    "\n",
    "            unitary += c * a\n",
    "            a = T.dot(a, skew)\n",
    "        \n",
    "        return unitary\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        if (self.tied_to is None):\n",
    "            unitary = self.produce_unitary()\n",
    "            out = K.dot(x, unitary)\n",
    "            return ((out + self.b) if self.has_bias else out)\n",
    "        else:\n",
    "            #unitary = T.nlinalg.matrix_inverse(self.tied_to.produce_unitary())\n",
    "            unitary = K.transpose(self.tied_to.produce_unitary())\n",
    "            inp = (x - self.tied_to.b) if self.tied_to.has_bias else x\n",
    "            return K.dot(inp, unitary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CodeRound(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, nbins):\n",
    "        self.nbins = nbins\n",
    "        super(CodeRound, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        s = (x + 1.0) / 2.0\n",
    "        s = np.round(s * float(self.nbins - 1)) / float(self.nbins - 1)\n",
    "        s = (s * 2.0) - 1.0\n",
    "        \n",
    "        z[0] = s\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        x, = input\n",
    "        g, = output_gradients\n",
    "        return [g]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only works with theano dawg\n",
    "class TiedDense(Layer):\n",
    "    def __init__(self, has_bias = False, tied_to = None, inverse = False, **kwargs):\n",
    "        super(TiedDense, self).__init__(**kwargs)\n",
    "        self.has_bias = has_bias\n",
    "        self.tied_to = tied_to\n",
    "        self.inverse = inverse\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[1]\n",
    "        \n",
    "        self.n = input_dim\n",
    "        \n",
    "        # we store a full matrix, but use it as a skew-symmetric one\n",
    "        if (self.tied_to is None):\n",
    "            self.W = np.eye(self.n) + np.random.uniform(-0.001, 0.001, (self.n, self.n))\n",
    "            self.W = K.variable(self.W)\n",
    "            \n",
    "            if (self.has_bias):\n",
    "                self.b = np.random.uniform(-0.001, 0.001, (self.n,))\n",
    "                self.b = K.variable(self.b)\n",
    "                self.trainable_weights = [self.W, self.b]     \n",
    "            else:\n",
    "                self.b = np.zeros((self.n,))\n",
    "                self.b = K.variable(self.b)\n",
    "                self.trainable_weights = [self.W]\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        if (self.tied_to is None):\n",
    "            return K.dot(x + self.b, self.W) + self.b\n",
    "        else:\n",
    "            if (self.inverse):\n",
    "                w = T.nlinalg.matrix_inverse(self.tied_to.W)\n",
    "            else:\n",
    "                w = K.transpose(self.tied_to.W)\n",
    "            return K.dot(x - self.tied_to.b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariableSelectMax(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        super(VariableSelectMax, self).__init__()\n",
    "        self.n = n\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        zero_idxs = np.argsort(np.abs(x), axis = -1)[:, :-K.get_value(self.n)]\n",
    "        col_idxs = np.arange(x.shape[0])[:, None]\n",
    "        out = np.copy(x)\n",
    "        x[col_idxs, zero_idxs] = 0\n",
    "        z[0] = x\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        x, = input\n",
    "        g, = output_gradients\n",
    "        \n",
    "        zero_idxs = T.argsort(T.abs_(x), axis = -1)[:, :-K.get_value(self.n), None]\n",
    "        \n",
    "        idnt = T.eye(x.shape[-1]) * 0.99\n",
    "        \n",
    "        grad_mult = idnt[zero_idxs]\n",
    "        grad_mult = T.sum(grad_mult, axis = -3)[:, 0, :]\n",
    "        grad_mult = 1.0 - grad_mult\n",
    "        \n",
    "        grad_mult = grad_mult + 0.01\n",
    "        \n",
    "        out_grad = g * grad_mult\n",
    "        \n",
    "        return [out_grad]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 to 6\n",
      "6 to 12\n",
      "12 to 20\n",
      "20 to 29\n",
      "29 to 39\n",
      "39 to 50\n",
      "50 to 63\n",
      "63 to 77\n",
      "77 to 94\n",
      "94 to 113\n",
      "113 to 134\n",
      "134 to 158\n",
      "158 to 185\n",
      "185 to 216\n",
      "216 to 251\n",
      "251 to 291\n",
      "291 to 336\n",
      "336 to 387\n",
      "387 to 446\n",
      "446 to 512\n"
     ]
    }
   ],
   "source": [
    "NUM_MEL_BINS = 20\n",
    "\n",
    "def freqToMel(freq):\n",
    "    return 1127.01048 * math.log(1 + freq / 700.0)\n",
    "\n",
    "def melToFreq(mel):\n",
    "    return 700 * (math.exp(mel / 1127.01048) - 1)\n",
    "\n",
    "def generateMelWindows():\n",
    "    minHz = 0\n",
    "    maxHz = SAMPLE_RATE / 2\n",
    "    numDCTBins = WINDOW_SIZE\n",
    "    \n",
    "    minMel = freqToMel(minHz)\n",
    "    maxMel = freqToMel(maxHz)\n",
    "\n",
    "    # evenly spaced bins between minMel and maxMel\n",
    "    melRange = np.arange(0, NUM_MEL_BINS + 1).astype('float32')\n",
    "    melIdxs = melRange * (maxMel - minMel) / (NUM_MEL_BINS) + minMel\n",
    "    \n",
    "    # convert back to freq / dct domain\n",
    "    for i in xrange(0, NUM_MEL_BINS + 1):\n",
    "        melIdxs[i] = melToFreq(melIdxs[i])\n",
    "        melIdxs[i] = math.floor(numDCTBins * melIdxs[i] / maxHz)\n",
    "    melIdxs = melIdxs.astype(np.int32)\n",
    "    \n",
    "    return melIdxs\n",
    "\n",
    "melIdxs = generateMelWindows()\n",
    "for i in xrange(0, NUM_MEL_BINS):\n",
    "    print melIdxs[i], \"to\", melIdxs[i + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5,  6.5], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = K.variable([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "K.mean(s, axis = -1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 1)             40945       input_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 40,945\n",
      "Trainable params: 40,497\n",
      "Non-trainable params: 448\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 128)           89857       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 512, 1)        105313      model_1[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 195,170\n",
      "Trainable params: 193,122\n",
      "Non-trainable params: 2,048\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 128)           89857       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 512, 1)        105313      model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 1)             40945       model_2[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 236,115\n",
      "Trainable params: 233,619\n",
      "Non-trainable params: 2,496\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import softmax, sigmoid\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# we generate a new optimizer of the same kind for every model\n",
    "# we train\n",
    "def opti():\n",
    "    return RMSprop()\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 128\n",
    "\n",
    "\n",
    "tau = K.variable(1.0, name = 'temperature')\n",
    "anneal_rate = 0.02\n",
    "min_temperature = 0.1\n",
    "\n",
    "BNORM = False\n",
    "\n",
    "dct_mat = dct(np.eye(bottleneck_size), norm = 'ortho')\n",
    "inv_dct_mat = idct(np.eye(bottleneck_size), norm = 'ortho')\n",
    "\n",
    "# construct Haar wavelet matrices\n",
    "h2 = 1.0/math.sqrt(2.0) * np.array([[1, 1], [1, -1]])\n",
    "prev = h2\n",
    "for i in xrange(0, 8):\n",
    "    a = np.kron(prev, [1, 1])\n",
    "    d = np.kron(np.eye(prev.shape[0]), [1, -1])\n",
    "    prev = 1.0/math.sqrt(2.0) * np.vstack((a, d))\n",
    "haar_mat = np.copy(prev)\n",
    "inv_haar_mat = np.linalg.inv(haar_mat)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def activation():\n",
    "    return LeakyReLU(0.3)#ThresholdedReLU()#Activation('tanh')\n",
    "autoenc_init = 'uniform'\n",
    "\n",
    "def residual_block(output_dim = 64, filt_size = 5, conv = True):\n",
    "    def f(input):\n",
    "        #bn1 = BatchNormalization()(input)\n",
    "        #act1 = activation()(bn1)\n",
    "        conv1 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = autoenc_init, activation = 'linear',\n",
    "                          bias = True)(input)\n",
    "        if (BNORM): conv1 = BatchNormalization()(conv1)\n",
    "        act1 = activation()(conv1)\n",
    "        conv2 = Convolution1D(output_dim, filt_size, border_mode = 'same',\n",
    "                          init = autoenc_init, activation = 'linear',\n",
    "                          bias = True)(act1)\n",
    "        if (BNORM): conv2 = BatchNormalization()(conv2)\n",
    "        \n",
    "        #'''\n",
    "        residual = conv2\n",
    "        if (conv):\n",
    "            #shortcut = Convolution1D(output_dim, 1, border_mode = 'same',\n",
    "            #                         init = autoenc_init, activation = 'linear',\n",
    "            #                         bias = False)(input)\n",
    "            shortcut = Lambda(lambda x : K.repeat_elements(x, output_dim, axis = -1),\n",
    "                              output_shape = (lambda s : (s[0], s[1], output_dim)))(input)\n",
    "        else:\n",
    "            shortcut = input\n",
    "        \n",
    "        m = merge([shortcut, residual], mode = 'sum')\n",
    "        return m\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "# total # layers: NUM_RES_BLOCKS * 4\n",
    "NUM_RES_BLOCKS = 8\n",
    "NBINS = 64\n",
    "nselect = K.variable(511, dtype = 'int32')\n",
    "NCHAN = 32\n",
    "TIMES_DOWNSAMPLE = 2\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    # convolutional layers have weight matrices of shape:\n",
    "    #     (filter_length, 1, input_dim, nb_filter)\n",
    "    # and biases of size (nb_filter,)\n",
    "    \n",
    "    # weights for an \"identity convolution\" (which just\n",
    "    # replicates the input across all channels)\n",
    "    #     filter of length 5, going from 1 channel to NCHAN\n",
    "    def identity_conv():\n",
    "        weights = np.zeros((5, 1, 1, NCHAN))\n",
    "        weights[3] = np.ones((1, 1, NCHAN))\n",
    "        weights += np.random.uniform(-0.01, 0.01, weights.shape)\n",
    "        biases = np.zeros((NCHAN,))\n",
    "        return [weights, biases]\n",
    "    \n",
    "    \n",
    "    # weights for an \"average convolution\" (which just\n",
    "    # replicates the input across all channels)\n",
    "    #     filter of length 1, going from NCHAN channels to 1\n",
    "    def average_conv():\n",
    "        weights = np.ones((1, 1, NCHAN, 1)) / float(NCHAN)\n",
    "        weights += np.random.uniform(-0.01, 0.01, weights.shape)\n",
    "        biases = np.zeros((1,))\n",
    "        return [weights, biases]\n",
    "    \n",
    "    \n",
    "    # weights for a \"phase shift up\" convolution (by default,\n",
    "    # performs an upsample)\n",
    "    #     filter of length 5, going from NCHAN to NCHAN * 2\n",
    "    def shift_up_conv():\n",
    "        weights = np.zeros((5, 1, NCHAN, NCHAN * 2))\n",
    "        weights[3, 0] = np.repeat(np.eye(NCHAN), 2, axis = 1)\n",
    "        weights += np.random.uniform(-0.01, 0.01, weights.shape)\n",
    "        biases = np.zeros((NCHAN * 2,))\n",
    "        return [weights, biases]\n",
    "    \n",
    "    \n",
    "    # weights for a \"phase shift down\" convolution (by default,\n",
    "    # performs an average)\n",
    "    #     filter of length 5, going from NCHAN to NCHAN / 2\n",
    "    def shift_down_conv():\n",
    "        weights = np.zeros((5, 1, NCHAN, NCHAN / 2))\n",
    "        weights[3, 0] = np.repeat(np.eye(NCHAN / 2), 2, axis = 0) / 2.0\n",
    "        weights += np.random.uniform(-0.01, 0.01, weights.shape)\n",
    "        biases = np.zeros((NCHAN / 2,))\n",
    "        return [weights, biases]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    enc_input = Input(shape = dim)\n",
    "    enc = Reshape(dim, input_shape = dim)(enc_input)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    enc = Convolution1D(NCHAN, 5, border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'linear',\n",
    "                          weights = identity_conv(),\n",
    "                          bias = True)(enc)\n",
    "    enc = activation()(enc)\n",
    "    \n",
    "    # downsample\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE):\n",
    "        enc = Convolution1D(NCHAN / 2, 5, border_mode = 'same',\n",
    "                              init = 'uniform', activation = 'linear',\n",
    "                              weights = shift_down_conv(),\n",
    "                              bias = True)(enc)\n",
    "        enc = PhaseShiftDown1D(2)(enc)\n",
    "        enc = activation()(enc)\n",
    "    \n",
    "    # residual blocks\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        enc = residual_block(NCHAN, 5, False)(enc)\n",
    "    \n",
    "    # convolution across feature maps\n",
    "    enc = Convolution1D(1, 1, border_mode = 'same',\n",
    "                              init = autoenc_init,\n",
    "                              bias = True,\n",
    "                              weights = average_conv())(enc)\n",
    "    enc = Activation('tanh')(enc)\n",
    "    enc = Reshape((bottleneck_size,))(enc)\n",
    "    \n",
    "    enc = Model(input = enc_input, output = enc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dec_input = Input(shape = (bottleneck_size,))\n",
    "    dec = Reshape((bottleneck_size,), input_shape = (bottleneck_size,))(dec_input)\n",
    "    \n",
    "    # increase number of channels via convolution\n",
    "    dec = Reshape((bottleneck_size, 1,))(dec)\n",
    "    dec = Convolution1D(NCHAN, 5, border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'linear',\n",
    "                          weights = identity_conv(),\n",
    "                          bias = True)(dec)\n",
    "    dec = activation()(dec)\n",
    "\n",
    "    # residual blocks\n",
    "    for i in xrange(0, NUM_RES_BLOCKS):\n",
    "        dec = residual_block(NCHAN, 5, False)(dec)    \n",
    "    \n",
    "    # upsample\n",
    "    for i in xrange(0, TIMES_DOWNSAMPLE):\n",
    "        dec = Convolution1D(NCHAN * 2, 5, border_mode = 'same',\n",
    "                              init = 'uniform', activation = 'linear',\n",
    "                              weights = shift_up_conv(),\n",
    "                              bias = True)(dec)\n",
    "        dec = PhaseShiftUp1D(2)(dec)\n",
    "        dec = activation()(dec)\n",
    "    \n",
    "    # convolution across feature maps\n",
    "    dec = Convolution1D(1, 1, border_mode = 'same',\n",
    "                              activation = 'linear',\n",
    "                              bias = True,\n",
    "                              weights = average_conv())(dec)\n",
    "    dec = Activation('tanh')(dec)\n",
    "    \n",
    "    dec = Model(input = dec_input, output = dec)\n",
    "    \n",
    "    return enc, dec\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    \n",
    "    #dsc.add(GaussianNoise(0.05, input_shape = dim))\n",
    "    \n",
    "    dsc.add(Convolution1D(16, 5, border_mode='same',\n",
    "                                    init = 'he_uniform',\n",
    "                                    input_shape = dim, activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    if (BNORM): dsc.add(BatchNormalization())\n",
    "    \n",
    "    dsc.add(Convolution1D(16, 5, border_mode='same', input_shape = dim,\n",
    "                                    init = 'he_uniform',\n",
    "                                    subsample_length = 1, activation = 'linear'))\n",
    "    dsc.add(AveragePooling1D(2))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    if (BNORM): dsc.add(BatchNormalization())\n",
    "    \n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same',\n",
    "                                    init = 'he_uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    if (BNORM): dsc.add(BatchNormalization())\n",
    "\n",
    "    dsc.add(Convolution1D(32, 5, border_mode='same',\n",
    "                                    init = 'he_uniform',\n",
    "                                    subsample_length = 1, activation = 'linear'))\n",
    "    dsc.add(AveragePooling1D(2))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    if (BNORM): dsc.add(BatchNormalization())\n",
    "    \n",
    "    dsc.add(Convolution1D(64, 5, border_mode='same',\n",
    "                                    init = 'he_uniform',\n",
    "                                    activation = 'linear'))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    if (BNORM): dsc.add(BatchNormalization())\n",
    "    \n",
    "    dsc.add(Convolution1D(64, 5, border_mode='same',\n",
    "                                    init = 'he_uniform',\n",
    "                                    subsample_length = 1, activation = 'linear'))\n",
    "    dsc.add(AveragePooling1D(2))\n",
    "    dsc.add(LeakyReLU(0.3))\n",
    "    if (BNORM): dsc.add(BatchNormalization())\n",
    "    \n",
    "    dsc.add(GlobalAveragePooling1D())\n",
    "    dsc.add(Dense(1, activation = 'sigmoid', init = 'he_uniform'))\n",
    "    \n",
    "    return dsc\n",
    "\n",
    "\n",
    "# construct autoencoder to be used in adversarial training (AAC - Adversarial AutoenCoder)\n",
    "# uhhhh... whoops i screwed up the acronym\n",
    "aac_input = Input(shape = input_dim)\n",
    "aac_enc, aac_dec = autoencoder_structure(input_dim)\n",
    "aac_embedding = aac_enc(aac_input)\n",
    "aac_reconstructed = aac_dec(aac_embedding)\n",
    "\n",
    "aac_autoencoder = Model(input = [aac_input], output = [aac_reconstructed])\n",
    "aac_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "\n",
    "\n",
    "# construct discriminator: regular\n",
    "regdsc_input_dim = (WINDOW_SIZE, 1)\n",
    "regdsc_input = Input(shape = input_dim)\n",
    "regdsc_struct = discriminator_structure(regdsc_input_dim)\n",
    "\n",
    "regdsc_label = regdsc_struct(regdsc_input)\n",
    "aac_reg_label = regdsc_struct(aac_reconstructed)\n",
    "#aac_decode_label = regdsc_struct(aac_decode_recons)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def code_ternary_constraint(placeholder, code):\n",
    "    entropy = K.minimum(K.abs(-1.0 - code), K.minimum(K.abs(code), K.abs(1.0 - code)))\n",
    "    entropy = K.clip(entropy, 0.01, 1.0)\n",
    "    entropy = K.sqrt(entropy)\n",
    "    return K.mean(entropy, axis = -1)\n",
    "\n",
    "\n",
    "def code_binary_constraint(placeholder, code):\n",
    "    scaled = (code + 1.0) / 2.0\n",
    "    scaled = K.clip(scaled, 0.001, 0.999)\n",
    "    entropy = -(scaled * K.log(scaled) + (1.0 - scaled) * K.log(1.0 - scaled))\n",
    "    return K.mean(entropy, axis = -1)\n",
    "\n",
    "def code_balance_constraint(placeholder, code):\n",
    "    # code ranges from 0 to 1\n",
    "    # we try to maximize the approx. variance of it\n",
    "    var = K.var(code, axis = -1) + 0.001\n",
    "    return (1.0 / var)\n",
    "    #return K.abs(K.mean(code, axis = -1))\n",
    "\n",
    "clip_point = 0.0001\n",
    "k = 0.5\n",
    "def code_sparsity_constraint(placeholder, code):\n",
    "    clipped = K.clip(K.abs(code), clip_point, 1.0)\n",
    "    lk_norm = K.pow(clipped, k)\n",
    "    return K.mean(lk_norm, axis = -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dct_mat = K.variable(dct(np.eye(WINDOW_SIZE), norm = 'ortho'))\n",
    "\n",
    "def apply_dct(batch):\n",
    "    reshaped = batch.reshape((1, batch.shape[0], batch.shape[1]))\n",
    "    result = T.tensordot(dct_mat, reshaped, [[0], [2]])\n",
    "    result = result.reshape((result.shape[0], result.shape[2])).T\n",
    "    result = result.reshape((result.shape[0], result.shape[1]))\n",
    "    return result\n",
    "\n",
    "\n",
    "def mel_dct_loss(y_true, y_pred):\n",
    "    dct_true = apply_dct(y_true)\n",
    "    dct_pred = apply_dct(y_pred)\n",
    "    \n",
    "    loss = None\n",
    "    for i in xrange(0, NUM_MEL_BINS):\n",
    "        start = melIdxs[i]\n",
    "        end = melIdxs[i + 1]\n",
    "        \n",
    "        sq = K.square(dct_pred[:, start:end] - dct_true[:, start:end])\n",
    "        mse = K.mean(sq, axis = -1)\n",
    "        mse = K.clip(mse, 0.000001, 10000.0)\n",
    "        if (loss is None):\n",
    "            loss = K.sqrt(mse)\n",
    "        else:\n",
    "            loss += K.sqrt(mse)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "def compaction_loss(placeholder, code):\n",
    "    norm = K.sqrt(K.sum(K.square(code), axis = -1))\n",
    "    \n",
    "    #mx_norm = K.sqrt(K.max(K.abs(code), axis = -1))\n",
    "    top = T.sort(K.square(code))[:, -16:]\n",
    "    mx_norm = K.sqrt(K.sum(top, axis = -1))\n",
    "    ratio = mx_norm / norm\n",
    "    \n",
    "    return -K.log(K.clip(ratio, 0.0001, 0.9999))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    mse = K.mean(K.square(y_pred - y_true), axis = -1)\n",
    "    mse = K.clip(mse, 0.000001, 10000.0)\n",
    "    return K.sqrt(mse)\n",
    "\n",
    "\n",
    "# compile model\n",
    "#loss_weights = [500.0, 25.0]\n",
    "loss_weights = [40.0, 10.0, 1.0]\n",
    "loss_functions = [rmse, mel_dct_loss, 'binary_crossentropy']\n",
    "n_discrim = 1\n",
    "n_code = 0\n",
    "lmult = len(loss_weights) - n_discrim - n_code\n",
    "\n",
    "\n",
    "make_trainable(aac_autoencoder, False)\n",
    "\n",
    "aac_discrim_reg = Model(input = [regdsc_input], output = [regdsc_label])\n",
    "aac_discrim_reg.compile(loss = ['binary_crossentropy'], optimizer = opti())\n",
    "aac_discrim_reg.summary()\n",
    "\n",
    "aac_autoencoder.summary()\n",
    "\n",
    "make_trainable(aac_discrim_reg, False)\n",
    "make_trainable(aac_autoencoder, True)\n",
    "model = Model(input = [aac_input], output = [aac_reconstructed, aac_reconstructed] + \\\n",
    "                                            [aac_reg_label] * n_discrim + \\\n",
    "                                            [aac_embedding] * n_code)\n",
    "model.compile(loss = loss_functions,\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "discrim_epoch = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder, verbose = True):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    data = data.astype(np.float32)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    if (verbose):\n",
    "        print transformed.shape\n",
    "    \n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    desired = np.clip(desired, -32767, 32767)\n",
    "    #sciwav.write(prefix + \"_res_desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = BATCH_SIZE, verbose = (1 if verbose else 0))\n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    if (verbose):\n",
    "        print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    recons = np.clip(recons, -32767, 32767)\n",
    "    \n",
    "    sciwav.write(prefix + \"_output.wav\", rate, recons.astype(np.int16))\n",
    "    \n",
    "    metrics = [\n",
    "        np.max(desired),\n",
    "        np.min(desired),\n",
    "        np.max(recons),\n",
    "        np.min(recons),\n",
    "        mse(recons, desired),\n",
    "        avgErr(recons, desired)\n",
    "    ]\n",
    "    \n",
    "    if (verbose):\n",
    "        print \"Max/min desired:\", metrics[0], metrics[1]\n",
    "        print \"Max/min recons: \", metrics[2], metrics[3]\n",
    "        print waveFilename, \" mse: \", metrics[4]\n",
    "        print waveFilename, \" avg err: \", metrics[5]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interleave numpy arrays of the same size along the first axis\n",
    "def interleave(arr):    \n",
    "    num = len(arr)\n",
    "    \n",
    "    r = np.empty(arr[0].shape)\n",
    "    r = np.repeat(r, num, axis = 0)\n",
    "    \n",
    "    for i in xrange(0, num):\n",
    "        r[i::num] = arr[i]\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    0: 0.717552006245  ['autoencoder not training'] 1.0 \n",
      "    Terminating epoch early (don't wanna overfit!)\n",
      "\n",
      "    Total time for epoch: 39.6158280373s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 50.0% d_acc\n",
      "    Total time for evaluation: 2.901004076s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 1.89050873601\n",
      "       Zero prob: 0.562969\n",
      "       Mask entropy: 0.98852881642\n",
      "       Avg # nonzero elts: 96.865\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  2726.73 -0.0546441\n",
      "    MSE:      275603.0\n",
      "    Avg err:  280.36\n",
      "    Total time for evaluation: 0.170010089874s\n",
      "\n",
      "Epoch 2:\n",
      "    1280: 0.442574739456  [4.637026 0.015177 0.352895 0.500980] [4.637026 0.607094 3.528952 0.500980] 0.135326087475 \n",
      "    Total time for epoch: 781.074901104s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 96.0% d_acc\n",
      "    Total time for evaluation: 0.374019861221s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 3.13051397762\n",
      "       Zero prob: 0.0984766\n",
      "       Mask entropy: 0.464147713282\n",
      "       Avg # nonzero elts: 127.395\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  3601.73 -3052.34\n",
      "    MSE:      11823.9\n",
      "    Avg err:  60.2995\n",
      "    Total time for evaluation: 0.126225948334s\n",
      "    Updated SelectMax from 511 to 485\n",
      "\n",
      "Epoch 3:\n",
      "    1280: 0.0283879376948  [3.571274 0.012291 0.284390 0.235726] [3.571274 0.491647 2.843901 0.235726] 0.10000000149 \n",
      "    Total time for epoch: 597.58302784s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 57.75% d_acc\n",
      "    Total time for evaluation: 0.374602079391s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 3.03121687526\n",
      "       Zero prob: 0.0616406\n",
      "       Mask entropy: 0.333923447265\n",
      "       Avg # nonzero elts: 127.6\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  3850.65 -3225.66\n",
      "    MSE:      8777.93\n",
      "    Avg err:  47.4205\n",
      "    Total time for evaluation: 0.126430034637s\n",
      "    Updated SelectMax from 485 to 460\n",
      "\n",
      "Epoch 4:\n",
      "    1280: 0.0614774189889  [3.550139 0.012156 0.249369 0.570218] [3.550139 0.486233 2.493688 0.570218] 0.10000000149 \n",
      "    Total time for epoch: 595.674343109s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.0% d_acc\n",
      "    Total time for evaluation: 0.372171163559s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 2.93203930763\n",
      "       Zero prob: 0.0839844\n",
      "       Mask entropy: 0.416065091363\n",
      "       Avg # nonzero elts: 127.485\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  3640.07 -3008.72\n",
      "    MSE:      10994.5\n",
      "    Avg err:  67.2493\n",
      "    Total time for evaluation: 0.126132965088s\n",
      "    Updated SelectMax from 460 to 437\n",
      "\n",
      "Epoch 5:\n",
      "    1280: 0.00483512599021  [4.123613 0.016422 0.336602 0.100718] [4.123613 0.656876 3.366019 0.100718] 0.10000000149 \n",
      "    Total time for epoch: 595.205852985s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 98.25% d_acc\n",
      "    Total time for evaluation: 0.373600959778s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 2.83034304525\n",
      "       Zero prob: 0.200391\n",
      "       Mask entropy: 0.722708651342\n",
      "       Avg # nonzero elts: 123.52\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  3954.69 -3326.28\n",
      "    MSE:      9989.36\n",
      "    Avg err:  57.3048\n",
      "    Total time for evaluation: 0.126480102539s\n",
      "    Updated SelectMax from 437 to 415\n",
      "\n",
      "Epoch 6:\n",
      "    1280: 8.63339082571e-05  [2.780684 0.011163 0.227008 0.064100] [2.780684 0.446505 2.270080 0.064100] 0.10000000149 \n",
      "    Total time for epoch: 593.473258018s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 78.25% d_acc\n",
      "    Total time for evaluation: 0.36865401268s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 2.95751097641\n",
      "       Zero prob: 0.112773\n",
      "       Mask entropy: 0.508225228731\n",
      "       Avg # nonzero elts: 126.9\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  3930.41 -3142.33\n",
      "    MSE:      8952.8\n",
      "    Avg err:  49.2815\n",
      "    Total time for evaluation: 0.12496304512s\n",
      "    Updated SelectMax from 415 to 394\n",
      "\n",
      "Epoch 7:\n",
      "    1280: 0.000148482198711  [3.533767 0.014543 0.287888 0.073152] [3.533767 0.581732 2.878883 0.073152] 0.10000000149 \n",
      "    Total time for epoch: 589.639549017s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 61.75% d_acc\n",
      "    Total time for evaluation: 0.36573600769s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 2.71652851285\n",
      "       Zero prob: 0.0759375\n",
      "       Mask entropy: 0.387700407912\n",
      "       Avg # nonzero elts: 127.305\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4234.1 -3564.95\n",
      "    MSE:      20698.2\n",
      "    Avg err:  77.6318\n",
      "    Total time for evaluation: 0.125893115997s\n",
      "    Updated SelectMax from 394 to 374\n",
      "\n",
      "Epoch 8:\n",
      "    1280: 0.000210761994822  [3.064451 0.013332 0.241570 0.115452] [3.064451 0.533296 2.415703 0.115452] 0.10000000149 \n",
      "    Total time for epoch: 587.383065224s\n",
      "    ----------------\n",
      "    Evaluated the discriminator: 99.75% d_acc\n",
      "    Total time for evaluation: 0.36651301384s\n",
      "    ----------------\n",
      "    Code histogram:\n",
      "       Entropy: 2.93823082923\n",
      "       Zero prob: 0.472813\n",
      "       Mask entropy: 0.997866182963\n",
      "       Avg # nonzero elts: 127.27\n",
      "    ----------------\n",
      "    Evaluating autoencoder...\n",
      "    Max/min desired: 4899.0 -4013.0\n",
      "    Max/min recons:  4192.15 -3390.1\n",
      "    MSE:      9010.26\n",
      "    Avg err:  50.81\n",
      "    Total time for evaluation: 0.124882936478s\n",
      "    Updated SelectMax from 374 to 355\n",
      "\n",
      "Epoch 9:\n",
      "    1280: 0.000252348807408  [2.950504 0.012526 0.236123 0.088230] [2.950504 0.501040 2.361233 0.088230] 0.10000000149"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1f3e788301d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#discrim_batch_X = interleave([batch, generated, generated_binarized])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m#discrim_batch_y = interleave([np.ones(nbatch), np.zeros(nbatch), np.zeros(nbatch)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maac_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mdiscrim_batch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdiscrim_batch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1219\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/ifelse.pyc\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train autoencoder, if discriminator accuracy is greater than 70%\n",
    "        if (discrim_epoch or epoch > 0):\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            make_trainable(aac_discrim_reg, False)\n",
    "            discrim_epoch = True\n",
    "            \n",
    "            a_y = [batch] * lmult + \\\n",
    "                  [np.ones(nbatch)] * n_discrim + \\\n",
    "                  [np.zeros((nbatch, bottleneck_size))] * n_code\n",
    "            a_losses = model.train_on_batch(batch, a_y)\n",
    "        \n",
    "        if (n_discrim > 0):\n",
    "            #code = aac_enc.predict(batch)\n",
    "            #code_binarized = np.sign(code)\n",
    "            #c_losses = decoder_model.train_on_batch(code_binarized, [batch, np.ones(nbatch)])\n",
    "\n",
    "            # train discriminator(s) on what the autoencoder now generates\n",
    "            #generated = aac_dec.predict(code)\n",
    "            #generated_binarized = aac_dec.predict(code_binarized)\n",
    "            #discrim_batch_X = interleave([batch, generated, generated_binarized])\n",
    "            #discrim_batch_y = interleave([np.ones(nbatch), np.zeros(nbatch), np.zeros(nbatch)])\n",
    "            generated = aac_autoencoder.predict(batch)\n",
    "            discrim_batch_X = interleave([batch, generated])\n",
    "            discrim_batch_y = interleave([np.ones(nbatch), np.zeros(nbatch)])\n",
    "\n",
    "            make_trainable(aac_autoencoder, False)\n",
    "            make_trainable(aac_discrim_reg, True)\n",
    "            d_loss = aac_discrim_reg.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "            \n",
    "            if ((not discrim_epoch) and epoch == 0 and d_loss < 0.2):\n",
    "                print \"\"\n",
    "                print lead + \"Terminating epoch early (don't wanna overfit!)\"\n",
    "                discrim_epoch = True\n",
    "                break\n",
    "        else:\n",
    "            d_loss = -1\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            #'''\n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_weights) > 1 and len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "            #loss_arr = np.asarray(c_losses)\n",
    "            #print loss_arr,\n",
    "            #'''\n",
    "            \n",
    "            '''\n",
    "            for l in [a_losses, c_losses]:\n",
    "            #for l in [a_losses]:\n",
    "                loss_arr = np.asarray(l)\n",
    "                print loss_arr,\n",
    "\n",
    "                if (len(loss_arr) > 1):\n",
    "                    for i in xrange(0, len(loss_weights)):\n",
    "                        loss_arr[i + 1] *= loss_weights[i]\n",
    "                    print loss_arr,\n",
    "            '''\n",
    "            \n",
    "            print K.get_value(tau),\n",
    "            K.set_value(tau, np.max([K.get_value(tau) * (1 - anneal_rate), min_temperature]))\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time for epoch\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"   \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate discriminator on random samples every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    if (n_discrim > 0):\n",
    "        NUM = 200\n",
    "        rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "        generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "        d_X = np.concatenate((X_train[rows, :], generated))\n",
    "        d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "        d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                                   d_X, d_y, verbose = False)\n",
    "\n",
    "        print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\"\n",
    "        elapsed = time.time() - startTime\n",
    "        print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    else:\n",
    "        print lead + \"No discriminator\"\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # generate code histogram from said random samples\n",
    "    # ---------------------------------------------------------\n",
    "    NUM = 200\n",
    "    rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "    code = aac_enc.predict(X_train[rows, :], verbose = 0)\n",
    "    \n",
    "    print lead + \"----------------\"\n",
    "    print lead + \"Code histogram:\"\n",
    "    scalars = code.flatten()\n",
    "    \n",
    "    b = np.linspace(-1.0, 1.0, NBINS + 1)\n",
    "    hist = np.histogram(scalars, bins = b)\n",
    "    sample_hist_probs = hist[0].astype('float32')\n",
    "    sample_hist_bins = hist[1].astype('float32')\n",
    "    sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "    entropy = 0\n",
    "    for i in sample_hist_probs:\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "    \n",
    "    zero_prob = sample_hist_probs[NBINS / 2]\n",
    "    zero_prob = np.clip(zero_prob, 0.001, 0.999)\n",
    "    mask_entropy = -(zero_prob * math.log(zero_prob, 2) + (1.0 - zero_prob) * math.log(1.0 - zero_prob, 2))\n",
    "    \n",
    "    print \"       Entropy:\", entropy\n",
    "    print \"       Zero prob:\", sample_hist_probs[NBINS / 2]\n",
    "    print \"       Mask entropy:\", mask_entropy\n",
    "    \n",
    "    nnz = 0.0\n",
    "    for i in xrange(0, code.shape[0]):\n",
    "        r = np.round(code[i] * 1000.0) / 1000.0\n",
    "        nnz += np.count_nonzero(r)\n",
    "    nnz /= code.shape[0]\n",
    "    print \"       Avg # nonzero elts:\", nnz\n",
    "    \n",
    "    '''\n",
    "    sample_hist_width = 1 * (sample_hist_bins[1] - sample_hist_bins[0])\n",
    "    sample_hist_centers = (sample_hist_bins[:-1] + sample_hist_bins[1:]) / 2\n",
    "    plt.figure()\n",
    "    plt.bar(sample_hist_centers, nonzero_probs, align='center', width=sample_hist_width)\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    for i in xrange(0, 3):\n",
    "        print \"       Within\", i,  \"bin(s):\",\n",
    "        tot = 0\n",
    "        for j in xrange(0, i + 1):\n",
    "            tot += sample_hist_probs[j]\n",
    "            tot += sample_hist_probs[-(j+1)]\n",
    "        print tot\n",
    "        \n",
    "    sample_hist_width = 1 * (sample_hist_bins[1] - sample_hist_bins[0])\n",
    "    sample_hist_centers = (sample_hist_bins[:-1] + sample_hist_bins[1:]) / 2\n",
    "    plt.figure()\n",
    "    plt.bar(sample_hist_centers, sample_hist_probs, align='center', width=sample_hist_width)\n",
    "    plt.show()\n",
    "    '''\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # evaluate autoencoder on real data every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    startTime = time.time()\n",
    "    print lead + \"----------------\"\n",
    "    \n",
    "    print lead + \"Evaluating autoencoder...\"\n",
    "    metrics = autoencoderTest(\"./SA1.WAV\", \"SA1_res_reg_train_epoch\" + str(epoch+1), aac_autoencoder, verbose = False)\n",
    "    \n",
    "    print lead + \"Max/min desired:\", metrics[0], metrics[1]\n",
    "    print lead + \"Max/min recons: \", metrics[2], metrics[3]\n",
    "    print lead + \"MSE:     \", metrics[4]\n",
    "    print lead + \"Avg err: \", metrics[5]\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # update loss weights every epoch\n",
    "    # ---------------------------------------------------------\n",
    "    if (len(loss_weights) > 1 and n_code > 0 and epoch > 0):\n",
    "        w_idx = len(loss_weights) - 1\n",
    "        \n",
    "        limit = 30.0\n",
    "        if (loss_weights[w_idx] < limit):\n",
    "            loss_weights[w_idx] += 0.25\n",
    "            if (loss_weights[w_idx] > limit): loss_weights[w_idx] = limit\n",
    "            \n",
    "            make_trainable(aac_discrim_reg, True)\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            model.compile(loss = loss_functions,\n",
    "                          loss_weights = loss_weights,\n",
    "                          optimizer = opti())\n",
    "            print lead + \"Updated code constraint weight:\", loss_weights[w_idx]\n",
    "        else:\n",
    "            loss_weights[w_idx] = limit\n",
    "            print lead + \"Didn't update code constraint weight:\", loss_weights[w_idx]\n",
    "    #'''\n",
    "    \n",
    "    if (epoch > 0):\n",
    "        old_n = K.get_value(nselect)\n",
    "        if (old_n > 16):\n",
    "            new_n = int(float(old_n) * 0.95)\n",
    "            K.set_value(nselect, new_n)\n",
    "            print lead + \"Updated SelectMax from\", old_n, \"to\", K.get_value(nselect)\n",
    "        else:\n",
    "            K.set_value(nselect, 16)\n",
    "            print lead + \"Didn't update SelectMax from\", old_n\n",
    "    \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.save('model_reg_adversary.h5')\n",
    "aac_autoencoder.save('auto_reg_adversary.h5')\n",
    "\n",
    "aac_discrim_reg.save('discrim_reg_adversary.h5')\n",
    "\n",
    "import h5py\n",
    "\n",
    "f = h5py.File('model_reg_adversary.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from keras.models import load_model\\n\\nobjs = {'PhaseShift1D' : PhaseShift1D}\\n\\nmodel = load_model('model_reg_adversary.h5', objs)\\naac_autoencoder = load_model('auto_reg_adversary.h5', objs)\\naac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "objs = {'PhaseShift1D' : PhaseShift1D}\n",
    "\n",
    "model = load_model('model_reg_adversary.h5', objs)\n",
    "aac_autoencoder = load_model('auto_reg_adversary.h5', objs)\n",
    "aac_discrim_reg = load_model('discrim_reg_adversary.h5', objs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = model.layers[1].layers\n",
    "dec = model.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "i = 0\n",
    "print \"-- Encoder --\"\n",
    "print \"\"\n",
    "for e in enc:\n",
    "    if type(e) is Convolution1D:\n",
    "        i += 1\n",
    "        print \"Conv layer\", i\n",
    "        w = e.weights[0].eval()\n",
    "        print \"    Avg weight norm:\", np.mean(np.abs(w))\n",
    "        print \"    Max weight norm:\", np.max(np.abs(w))\n",
    "        \n",
    "        if (len(e.weights) == 1): continue\n",
    "        b = e.weights[1].eval()\n",
    "        print \"    Avg bias norm:\", np.mean(np.abs(b))\n",
    "        print \"    Max bias norm:\", np.max(np.abs(b))\n",
    "print \"\"\n",
    "\n",
    "print \"-- Decoder --\"\n",
    "print \"\"\n",
    "for e in dec:\n",
    "    if type(e) is Convolution1D:\n",
    "        i += 1\n",
    "        print \"Conv layer\", i\n",
    "        w = e.weights[0].eval()\n",
    "        print \"    Avg weight norm:\", np.mean(np.abs(w))\n",
    "        print \"    Max weight norm:\", np.max(np.abs(w))\n",
    "        \n",
    "        if (len(e.weights) == 1): continue\n",
    "        b = e.weights[1].eval()\n",
    "        print \"    Avg bias norm:\", np.mean(np.abs(b))\n",
    "        print \"    Max bias norm:\", np.max(np.abs(b))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print [e.eval() for e in enc[-3].weights]\n",
    "'''\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Evaluated the discriminator: 97.625% d_acc\n"
     ]
    }
   ],
   "source": [
    "NUM = 400\n",
    "rows = np.random.randint(X_train.shape[0], size = NUM)\n",
    "generated = aac_autoencoder.predict(X_train[rows, :], verbose = 0)\n",
    "d_X = np.concatenate((X_train[rows, :], generated))\n",
    "d_y = np.concatenate((np.ones(NUM), np.zeros(NUM)))\n",
    "d_acc = test_discriminator(aac_discrim_reg, aac_autoencoder,\n",
    "                           d_X, d_y, verbose = False)\n",
    "\n",
    "print lead + \"Evaluated the discriminator: \" + str(d_acc) + \"% d_acc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n",
      "Max/min desired: 4899.0 -4013.0\n",
      "Max/min recons:  4028.06 -3160.08\n",
      "./SA1.WAV  mse:  8236.5\n",
      "./SA1.WAV  avg err:  44.1538\n",
      "(93, 512)\n",
      "93/93 [==============================] - 0s\n",
      "(93, 512, 1)\n",
      "(93, 512)\n",
      "Max/min desired: 2961.0 -3057.0\n",
      "Max/min recons:  2796.6 -2580.69\n",
      "./SX383.WAV  mse:  6503.84\n",
      "./SX383.WAV  avg err:  31.9948\n",
      "(181, 512)\n",
      "181/181 [==============================] - 0s     \n",
      "(181, 512, 1)\n",
      "(181, 512)\n",
      "Max/min desired: 24636.0 -20122.0\n",
      "Max/min recons:  18711.6 -14119.1\n",
      "./fiveYears.wav  mse:  1.84926e+06\n",
      "./fiveYears.wav  avg err:  967.072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24636.0, -20122.0, 18711.602, -14119.114, 1849261.6, 967.07172]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_reg_\", aac_autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_reg_\", aac_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "all_embed = aac_enc.predict(X_train[:10000], batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scalars = all_embed.flatten()\n",
    "log_scalars = np.log((scalars + 1.0) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0077164\n",
      "0.00851541\n"
     ]
    }
   ],
   "source": [
    "print np.mean(scalars)\n",
    "print np.var(scalars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAFkCAYAAAB4sKK5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43800204d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.12499992106e-06\n",
      "1.17187502724e-05\n",
      "2.96875001595e-05\n"
     ]
    }
   ],
   "source": [
    "hist = np.histogram(scalars, bins = np.linspace(-1.0, 1.0, NBINS + 1))\n",
    "sample_hist_probs = hist[0].astype('float32')\n",
    "sample_hist_bins = hist[1].astype('float32')\n",
    "sample_hist_probs /= np.sum(sample_hist_probs)\n",
    "\n",
    "sample_hist_width = 1 * (sample_hist_bins[1] - sample_hist_bins[0])\n",
    "sample_hist_centers = (sample_hist_bins[:-1] + sample_hist_bins[1:]) / 2\n",
    "plt.bar(sample_hist_centers, sample_hist_probs, align='center', width=sample_hist_width)\n",
    "plt.show()\n",
    "\n",
    "if (NBINS > 9):\n",
    "    for i in xrange(1, 8):\n",
    "        p = 0\n",
    "        for j in xrange(0, i):\n",
    "            p += sample_hist_probs[j]\n",
    "            p += sample_hist_probs[-j - 1]\n",
    "        print p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "[rate, data] = sciwav.read(\"./SA1.WAV\")\n",
    "data = data.astype(np.float32)\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "embed = aac_enc.predict(transformed, batch_size = BATCH_SIZE, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.227223\n",
      "128\n",
      "[-0.042891 0.016404 0.111970 0.128005 0.155905 0.097488 0.062101 -0.027482\n",
      " -0.061657 -0.097623 -0.075259 -0.035517 0.021025 0.031701 0.021856\n",
      " -0.032786 -0.086593 -0.142016 -0.179433 -0.142458 -0.058207 0.020863\n",
      " 0.083537 0.094474 0.088612 0.029143 -0.013464 -0.078252 -0.089416\n",
      " -0.098650 -0.038043 -0.009279 0.029006 0.010330 -0.017164 -0.075023\n",
      " -0.121070 -0.166712 -0.133399 -0.065924 0.009139 0.066015 0.086858\n",
      " 0.085922 0.041043 0.003120 -0.054844 -0.077063 -0.081838 -0.045973\n",
      " -0.018948 0.009874 0.003805 -0.017530 -0.065717 -0.107681 -0.151343\n",
      " -0.106589 -0.058044 0.016970 0.053365 0.083608 0.073731 0.044744 0.003856\n",
      " -0.041281 -0.064828 -0.067376 -0.042340 -0.018171 0.000584 -0.002640\n",
      " -0.027380 -0.064478 -0.109799 -0.131944 -0.084579 -0.037305 0.028303\n",
      " 0.055152 0.082882 0.063949 0.041992 -0.003117 -0.035450 -0.064967\n",
      " -0.064436 -0.032875 -0.008374 0.004690 -0.006659 -0.036243 -0.070182\n",
      " -0.117549 -0.127505 -0.085245 -0.032054 0.027584 0.058627 0.080907\n",
      " 0.065720 0.041290 -0.000385 -0.036934 -0.060939 -0.055755 -0.038283\n",
      " -0.014935 -0.008291 -0.011261 -0.041697 -0.071852 -0.114096 -0.110003\n",
      " -0.069328 -0.015684 0.033306 0.063956 0.078928 0.065765 0.042201 0.003793\n",
      " -0.022684 -0.047364 -0.031963 -0.033203 0.007660 -0.024785]\n",
      "[-0.047619 0.015873 0.111111 0.142857 0.142857 0.111111 0.047619 -0.015873\n",
      " -0.047619 -0.111111 -0.079365 -0.047619 0.015873 0.015873 0.015873\n",
      " -0.047619 -0.079365 -0.142857 -0.174603 -0.142857 -0.047619 0.015873\n",
      " 0.079365 0.079365 0.079365 0.015873 -0.015873 -0.079365 -0.079365\n",
      " -0.111111 -0.047619 -0.015873 0.015873 0.015873 -0.015873 -0.079365\n",
      " -0.111111 -0.174603 -0.142857 -0.079365 0.015873 0.079365 0.079365\n",
      " 0.079365 0.047619 0.015873 -0.047619 -0.079365 -0.079365 -0.047619\n",
      " -0.015873 0.015873 0.015873 -0.015873 -0.079365 -0.111111 -0.142857\n",
      " -0.111111 -0.047619 0.015873 0.047619 0.079365 0.079365 0.047619 0.015873\n",
      " -0.047619 -0.079365 -0.079365 -0.047619 -0.015873 0.015873 -0.015873\n",
      " -0.015873 -0.079365 -0.111111 -0.142857 -0.079365 -0.047619 0.015873\n",
      " 0.047619 0.079365 0.079365 0.047619 -0.015873 -0.047619 -0.079365\n",
      " -0.079365 -0.047619 -0.015873 0.015873 -0.015873 -0.047619 -0.079365\n",
      " -0.111111 -0.142857 -0.079365 -0.047619 0.015873 0.047619 0.079365\n",
      " 0.079365 0.047619 -0.015873 -0.047619 -0.047619 -0.047619 -0.047619\n",
      " -0.015873 -0.015873 -0.015873 -0.047619 -0.079365 -0.111111 -0.111111\n",
      " -0.079365 -0.015873 0.047619 0.079365 0.079365 0.079365 0.047619 0.015873\n",
      " -0.015873 -0.047619 -0.047619 -0.047619 0.015873 -0.015873]\n",
      "112/112 [==============================] - 0s\n",
      "(112, 512, 1)\n",
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "idx = 56\n",
    "print np.sqrt(np.sum(np.sort(np.square(embed[idx]))[-1:])) / np.linalg.norm(embed[idx])\n",
    "print np.count_nonzero(embed[idx])\n",
    "print embed[idx]\n",
    "\n",
    "r = np.copy(embed)\n",
    "threshold = 0\n",
    "#r = np.sign(r)\n",
    "qnt_bins = NBINS\n",
    "#r[r < threshold] = -1.0\n",
    "#r[r >= threshold] = 1.0\n",
    "#r = np.round(r)\n",
    "#r[(r < 0) & (r > -0.93)] = -0.936508\n",
    "#r[(r > 0) & (r < 0.93)] = 0.936508\n",
    "r = (r + 1.0) / 2.0\n",
    "r = np.round(r * float(qnt_bins - 1))\n",
    "qnt = r[idx].astype('int')\n",
    "r /= float(qnt_bins - 1)\n",
    "r = (r * 2.0) - 1.0\n",
    "#r = np.sign(r)\n",
    "\n",
    "print r[idx]\n",
    "#print qnt\n",
    "\n",
    "\n",
    "\n",
    "autoencOutput = aac_dec.predict(r, batch_size = BATCH_SIZE, verbose = 1)\n",
    "print autoencOutput.shape\n",
    "autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "\n",
    "print autoencOutput.shape\n",
    "recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "\n",
    "wav = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "wav = unpreprocessWaveform(wav, wparams)\n",
    "wav = np.clip(wav, -32767.0, 32767.0)\n",
    "\n",
    "sciwav.write(\"tst_output_reg.wav\", rate, wav.astype(np.int16))\n",
    "\n",
    "idx = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.000000 -0.968750 -0.937500 -0.906250 -0.875000 -0.843750 -0.812500\n",
      " -0.781250 -0.750000 -0.718750 -0.687500 -0.656250 -0.625000 -0.593750\n",
      " -0.562500 -0.531250 -0.500000 -0.468750 -0.437500 -0.406250 -0.375000\n",
      " -0.343750 -0.312500 -0.281250 -0.250000 -0.218750 -0.187500 -0.156250\n",
      " -0.125000 -0.093750 -0.062500 -0.031250 0.000000 0.031250 0.062500\n",
      " 0.093750 0.125000 0.156250 0.187500 0.218750 0.250000 0.281250 0.312500\n",
      " 0.343750 0.375000 0.406250 0.437500 0.468750 0.500000 0.531250 0.562500\n",
      " 0.593750 0.625000 0.656250 0.687500 0.718750 0.750000 0.781250 0.812500\n",
      " 0.843750 0.875000 0.906250 0.937500 0.968750 1.000000]\n",
      "[     0      0      0      0      0      1      1      0      6      6\n",
      "     11     17     22     38     72    127    226    405    590    993\n",
      "   1570   2522   3786   5819   9207  14523  22601  33741  50237  71804\n",
      " 107200 261393 506085  64995  35826  22692  15517  11111   7985   6124\n",
      "   4750   3625   2834   2286   1859   1513   1266    979    825    738\n",
      "    556    457    386    293    193     95     56     22     10      4\n",
      "      0      0      0      0]\n",
      "1280000\n",
      "[-1.000000 -0.968750 -0.937500 -0.906250 -0.875000 -0.843750 -0.812500\n",
      " -0.781250 -0.750000 -0.718750 -0.687500 -0.656250 -0.625000 -0.593750\n",
      " -0.562500 -0.531250 -0.500000 -0.468750 -0.437500 -0.406250 -0.375000\n",
      " -0.343750 -0.312500 -0.281250 -0.250000 -0.218750 -0.187500 -0.156250\n",
      " -0.125000 -0.093750 -0.062500 -0.031250 0.000000 0.031250 0.062500\n",
      " 0.093750 0.125000 0.156250 0.187500 0.218750 0.250000 0.281250 0.312500\n",
      " 0.343750 0.375000 0.406250 0.437500 0.468750 0.500000 0.531250 0.562500\n",
      " 0.593750 0.625000 0.656250 0.687500 0.718750 0.750000 0.781250 0.812500\n",
      " 0.843750 0.875000 0.906250 0.937500 0.968750 1.000000]\n",
      "[0.000000 0.000000 0.000000 0.000000 0.000000 0.000001 0.000001 0.000000\n",
      " 0.000005 0.000005 0.000009 0.000013 0.000017 0.000030 0.000056 0.000099\n",
      " 0.000177 0.000316 0.000461 0.000776 0.001227 0.001970 0.002958 0.004546\n",
      " 0.007193 0.011346 0.017657 0.026360 0.039248 0.056097 0.083750 0.204213\n",
      " 0.395379 0.050777 0.027989 0.017728 0.012123 0.008680 0.006238 0.004784\n",
      " 0.003711 0.002832 0.002214 0.001786 0.001452 0.001182 0.000989 0.000765\n",
      " 0.000645 0.000577 0.000434 0.000357 0.000302 0.000229 0.000151 0.000074\n",
      " 0.000044 0.000017 0.000008 0.000003 0.000000 0.000000 0.000000 0.000000]\n",
      "3.03581719554\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "b = np.linspace(-1.0, 1.0, NBINS + 1)\n",
    "print b\n",
    "\n",
    "h = np.histogram(scalars, bins = b)\n",
    "print h[0]\n",
    "print h[0].sum()\n",
    "print h[1]\n",
    "h = h[0].astype('float32')\n",
    "h = h / h.sum()\n",
    "print h\n",
    "\n",
    "entropy = 0\n",
    "for i in h:\n",
    "    if (i < 1e-4): continue\n",
    "    entropy += i * math.log(i, 2)\n",
    "entropy = -entropy\n",
    "print entropy\n",
    "\n",
    "if (NBINS > 4):\n",
    "    entropy = 0\n",
    "    for idx in [0, 1, 2, -1, -2, -3]:\n",
    "        i = h[idx]\n",
    "        if (i < 1e-4): continue\n",
    "        entropy += i * math.log(i, 2)\n",
    "    entropy = -entropy\n",
    "    print entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
