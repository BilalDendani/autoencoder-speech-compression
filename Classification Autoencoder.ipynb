{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n",
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA1.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX339.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1059.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1689.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX429.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX69.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX159.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI2319.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA2.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX249.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX221.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA1.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX41.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1751.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1725.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX401.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX24.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA2.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1121.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX131.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA1.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX336.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1236.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI606.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1866.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX156.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA2.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX426.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX246.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX66.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA1.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1233.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI603.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX333.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX153.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1863.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX243.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA2.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX423.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX63.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA1.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX434.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX74.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX254.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI1064.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX344.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX164.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA2.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI582.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI2324.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX82.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1041.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX442.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA1.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1702.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX262.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX172.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX352.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA2.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1072.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI669.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA1.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX39.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX309.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1929.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX129.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1299.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX219.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX399.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA2.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI2325.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX435.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX75.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA1.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1695.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX345.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1065.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX255.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX165.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA2.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI2290.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA1.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI650.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI1660.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX220.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX310.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX40.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX400.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA2.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX130.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX149.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA1.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI2309.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX419.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX239.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX329.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1679.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX59.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA2.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1049.WAV\r"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):\n",
    "    mn = np.min(waveform)\n",
    "    mx = np.max(waveform)\n",
    "    \n",
    "    maxabs = max(abs(mn), abs(mx))\n",
    "    scl = 32768.0 / maxabs    \n",
    "    \n",
    "    processed = waveform * scl\n",
    "    \n",
    "    return processed, (scl,)\n",
    "    \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    unprocessed = waveform / params[0]\n",
    "    return unprocessed\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    # scale window between -1 and 1\n",
    "    processed = np.copy(windows)\n",
    "    processed /= 32768.0\n",
    "    \n",
    "    # apply u-law transformation\n",
    "    processed = np.sign(processed) * np.log(1.0 + 255.0 * np.abs(processed)) / np.log(1.0 + 255.0)\n",
    "    \n",
    "    # scale from 0 to 255\n",
    "    processed = ((processed + 1.0) / 2.0) * 255.0\n",
    "    \n",
    "    # quantize into 255 bins\n",
    "    processed = np.round(processed)\n",
    "    processed = processed.astype(np.int16)\n",
    "    \n",
    "    return processed, ()\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    # de-quantize (go from ints [0, 255] to float [-1.0, 1.0])\n",
    "    unprocessed = np.copy(windows)\n",
    "    unprocessed = unprocessed.astype(np.float32)\n",
    "    unprocessed = (unprocessed / 255.0) * 2.0 - 1.0\n",
    "    \n",
    "    # un-apply u-law transformation\n",
    "    unprocessed = np.sign(unprocessed) * (np.power(256, np.abs(unprocessed)) - 1) / 255.0\n",
    "    \n",
    "    # scale window from [-1, 1] to [-32768, 32768]\n",
    "    unprocessed *= 32768.0\n",
    "    return unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "7\n",
      "mean l1: 1.56021363606\n",
      "max l1:  38.0\n",
      "means: 0.471988200854 0.466357\n",
      "stds:  210.915280373 210.674\n",
      "max/min orig:   1379.0 -1023.0\n",
      "max/min recons: 1379.0 -1016.0\n"
     ]
    }
   ],
   "source": [
    "# test data preprocessing and loss\n",
    "data = np.copy(rawWaveforms[55])\n",
    "\n",
    "processedWave, wparams = preprocessWaveform(data)\n",
    "windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "transformed, tparams = preprocessWindows(windows)\n",
    "\n",
    "print np.max(transformed)\n",
    "print np.min(transformed)\n",
    "\n",
    "desired = unpreprocessWindows(transformed, tparams)\n",
    "desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "desired = unpreprocessWaveform(desired, wparams)\n",
    "\n",
    "# trim desired down to length of data\n",
    "if (desired.shape[0] > data.shape[0]):\n",
    "    desired = desired[:data.shape[0]]\n",
    "desired = np.round(desired)\n",
    "    \n",
    "sciwav.write(\"orig.wav\", 16000, data.astype(np.int16))\n",
    "sciwav.write(\"processed.wav\", 16000, desired.astype(np.int16))\n",
    "\n",
    "print \"mean l1:\", np.mean(np.abs(data - desired))\n",
    "print \"max l1: \", np.max(np.abs(data - desired))\n",
    "print \"means:\", np.mean(data), np.mean(desired)\n",
    "print \"stds: \", np.std(data), np.std(desired)\n",
    "print \"max/min orig:  \", np.max(data), np.min(data)\n",
    "print \"max/min recons:\", np.max(desired), np.min(desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(processedWaveforms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (10116, 512)\n",
      "Max:  32768.0\n",
      "Min:  -32768.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (10116, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10116, 512)\n",
      "124.970972655\n",
      "50.8355320904\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)\n",
    "\n",
    "# reshape into (WINDOW_SIZE x 1) vector form for training\n",
    "X_train = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))\n",
    "ntrain = X_train.shape[0]\n",
    "\n",
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# operations for binarization layer (THEANO ONLY)\n",
    "class Binarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Binarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(x)\n",
    "        z[0][z[0] < 0] = -1\n",
    "        z[0][z[0] >= 0] = 1\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        # (i don't think there's a mathematical justification for this?)\n",
    "        return [output_gradients[0]]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes\n",
    "\n",
    "    \n",
    "class BinarizeLayer(Layer):\n",
    "    \"\"\" Binarizes input \n",
    "    <feedforward> binarizes output of tanh to -1 and 1\n",
    "    <backward> returns delta unchanged\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BinarizeLayer, self).__init__(**kwargs)\n",
    "        self.op = Binarize()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        return self.op(x)\n",
    "\n",
    "    #def get_output_shape_for(self, input_shape):\n",
    "    #    return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(BinarizeLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)        (None, 320)           142538      input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)        (None, 512, 256)      289344      sequential_3[1][0]               \n",
      "====================================================================================================\n",
      "Total params: 431882\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 320\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc = Sequential()\n",
    "    dec = Sequential()\n",
    "    \n",
    "    # based on architecture in this paper:\n",
    "    #     http://arxiv.org/pdf/1602.02644.pdf\n",
    "    # adapted to a 32x32 image instead of 64x64\n",
    "   \n",
    "    # (512x1) => (256x64)   \n",
    "    enc.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          input_shape = dim, activation = 'relu',\n",
    "                          init = 'uniform', bias = True))\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # (256x64) => (128x64)    \n",
    "    enc.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          activation = 'relu',\n",
    "                          init = 'uniform', bias = True))\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # (128x64) => (64x64)\n",
    "    enc.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          activation = 'relu',\n",
    "                          init = 'uniform', bias = True))\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # (64x64) => (32x10)\n",
    "    enc.add(Convolution1D(10, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          activation = 'tanh',\n",
    "                          init = 'uniform', bias = True))\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # binarize   \n",
    "    enc.add(Reshape((bottleneck_size,)))\n",
    "    enc.add(BinarizeLayer())\n",
    "    \n",
    "    dec.add(Reshape((32, 10,), input_shape = (bottleneck_size,)))\n",
    "    \n",
    "    # (32x10) => (64x64)\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    \n",
    "    # (64x64) => (128x64)\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    \n",
    "    # (128x64) => (256x64)\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    \n",
    "    # (256x64) => (512x64)\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    \n",
    "    # (512x64) => (512x64)\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    \n",
    "    # (512x64) => (512x256) where each 256-len vector is a softmax\n",
    "    dec.add(Convolution1D(256, 1, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'softmax',\n",
    "                          bias = True))\n",
    "\n",
    "    return enc, dec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras import metrics\n",
    "all_metrics = [\n",
    "    metrics.categorical_accuracy,\n",
    "    metrics.mean_absolute_error\n",
    "]\n",
    "    \n",
    "# plain autoencoder\n",
    "inp = Input(shape = input_dim)\n",
    "enc, dec = autoencoder_structure(input_dim)\n",
    "embedding = enc(inp)\n",
    "recons = dec(embedding)\n",
    "autoencoder = Model(input = inp, output = recons)\n",
    "autoencoder.compile(loss = 'categorical_crossentropy', optimizer = Adam())\n",
    "autoencoder.summary()\n",
    "\n",
    "# compile another model (in case i want to do other stuff during training)\n",
    "model = Model(input = inp, output = recons)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(), metrics = all_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10116, 512, 1)\n",
      "0.0\n",
      "1.88981103897 secs\n",
      "0.000838994979858 secs\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# turns quantized windows to one-hot vectors\n",
    "#     (optimized function ;) \n",
    "def windows_to_one_hot(windows, soft = False, sz = 9, std = 1.0):\n",
    "    one_hot = np.zeros((windows.shape[0], windows.shape[1], 256))\n",
    "    \n",
    "    if (soft):\n",
    "        # soft one-hot vector\n",
    "        kernel = scipy.signal.gaussian(sz, std)\n",
    "        kernel /= sum(kernel)\n",
    "        \n",
    "        # for each window in windows\n",
    "        for i in xrange(0, windows.shape[0]):\n",
    "            # this is really hacky, but it's the fastest way to do this\n",
    "            # special convolution\n",
    "            for j in xrange(-4, 5):\n",
    "                try:\n",
    "                    one_hot[i, np.arange(windows[i].shape[0]),\n",
    "                            np.where(windows[i] + j < 0, 256+1, windows[i] + j)] = kernel[j+4]\n",
    "                except:\n",
    "                    pass\n",
    "    else:\n",
    "        # for each window in windows\n",
    "        for i in xrange(0, windows.shape[0]):\n",
    "            # set indices to 1\n",
    "            one_hot[i, np.arange(windows[i].shape[0]), windows[i]] = 1\n",
    "    \n",
    "    return one_hot\n",
    "    \n",
    "# turns one-hot-vectors into quantized (by taking argmax)\n",
    "def one_hot_to_windows(one_hot):\n",
    "    return np.array([[np.argmax(v) for v in w] for w in one_hot])\n",
    "    \n",
    "print X_train.shape\n",
    "\n",
    "batch = X_train[:128, :,  0]\n",
    "batch_onehot = windows_to_one_hot(batch, True)\n",
    "batch_rec = one_hot_to_windows(batch_onehot)\n",
    "\n",
    "print np.mean(batch_rec - batch)\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in xrange(0, 80):\n",
    "    windows_to_one_hot(batch, True)\n",
    "t1 = time.time()\n",
    "print t1-t0, \"secs\"\n",
    "\n",
    "t0 = time.time()\n",
    "for i in xrange(0, 80):\n",
    "    sz = 9\n",
    "    std = 1.0\n",
    "    kernel = scipy.signal.gaussian(sz, std)\n",
    "    kernel /= sum(kernel)\n",
    "t1 = time.time()\n",
    "print t1-t0, \"secs\"\n",
    "\n",
    "\n",
    "#one_hot = np.eye(16)[[5, 4]]\n",
    "#print one_hot\n",
    "#print [np.convolve(w, kernel, mode = 'same') / ksum for w in one_hot]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    print transformed.shape\n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    sciwav.write(prefix + \"desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict(transformed, batch_size = 64, verbose = 1)\n",
    "    print autoencOutput.shape\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE, 256))\n",
    "    autoencOutput = one_hot_to_windows(autoencOutput)\n",
    "    \n",
    "    print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    \n",
    "    print \"Max desired:\", np.max(desired)\n",
    "    print \"Min desired:\", np.min(desired)\n",
    "    print \"Max recons: \", np.max(recons)\n",
    "    print \"Min recons: \", np.min(recons)\n",
    "    \n",
    "    sciwav.write(prefix + \"output.wav\", rate, recons.astype(np.int16))\n",
    "\n",
    "    print waveFilename, \" mse: \", mse(recons, desired)\n",
    "    print waveFilename, \" avg err: \", avgErr(recons, desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3015b0ace895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mbatch_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindows_to_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotalLosses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtotalLosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                              \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                              \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                              **self._function_kwargs)\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid argument '%s' passed to K.function\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                                         \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m             defaults)\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1456\u001b[0m                         optimizer, inputs, outputs)\n\u001b[1;32m   1457\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                     \u001b[0moptimizer_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m   7140\u001b[0m                 \u001b[0;31m# Don't try to fuse node that have already been fused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7142\u001b[0;31m                     \u001b[0mnew_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7143\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7144\u001b[0m                         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_outputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mlocal_fuse\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m   7087\u001b[0m         \u001b[0;31m# debug mode will be faster as it won't test all intermediate step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7088\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7089\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7090\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7091\u001b[0m                 \u001b[0;31m# print n,ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mlocal_fuse\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m   7087\u001b[0m         \u001b[0;31m# debug mode will be faster as it won't test all intermediate step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7088\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7089\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7090\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7091\u001b[0m                 \u001b[0;31m# print n,ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36mlocal_fuse\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m   7057\u001b[0m                                          \u001b[0;34m\"test_presence_of_c_code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7058\u001b[0m                                          \u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7059\u001b[0;31m                                          [\"z\" for x in s_new_out], {})\n\u001b[0m\u001b[1;32m   7060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7061\u001b[0m             _logger.info((\"%s does not implement the c_code function.\"\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/scalar/basic.pyc\u001b[0m in \u001b[0;36mc_code\u001b[0;34m(self, node, nodename, inames, onames, sub)\u001b[0m\n\u001b[1;32m   3718\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_c_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m         d = dict(chain(izip((\"i%i\" % i for i in xrange(len(inames))), inames),\n\u001b[0m\u001b[1;32m   3721\u001b[0m                        izip((\"o%i\" % i for i in xrange(len(onames))),\n\u001b[1;32m   3722\u001b[0m                             onames)), **sub)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    totalLosses = []\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        batch_onehot = windows_to_one_hot(batch[:, :, 0], True)\n",
    "        \n",
    "        losses = model.train_on_batch(batch, batch_onehot)\n",
    "        if (totalLosses == []):\n",
    "            totalLosses = np.array(losses)\n",
    "        else:\n",
    "            totalLosses += np.array(losses)\n",
    "           \n",
    "        avgLosses = totalLosses / (i + 1)\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(avgLosses)\n",
    "            print printStr,\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 512)\n"
     ]
    }
   ],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_\", autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_\", autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_\", autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
