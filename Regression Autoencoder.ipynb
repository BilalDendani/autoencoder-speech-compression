{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 690 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import h5py\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import *\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from sklearn import metrics\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy.misc import toimage\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from skimage import io, exposure, feature, color, transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal as sig\n",
    "import operator\n",
    "import math\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(1337) \n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for sliding window, and window function (Hann)\n",
    "STEP_SIZE = 480\n",
    "OVERLAP_SIZE = 32\n",
    "WINDOW_SIZE = STEP_SIZE + OVERLAP_SIZE\n",
    "OVERLAP_FUNC = sig.hann(OVERLAP_SIZE * 2)\n",
    "\n",
    "# directory that contains TIMIT files\n",
    "TIMIT_DIR = \"/home/sri/Desktop/timit\"\n",
    "\n",
    "# directory that contains .wav files to process\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# randomly shuffle data before partitioning into training/validation?\n",
    "RANDOM_SHUFFLE = True\n",
    "\n",
    "# sample rate of input file (used in MFCC calculation)\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from load_TIMIT import *\n",
    "from windowingFunctions import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in .wav files...\n",
      "0: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA1.WAV\r",
      "1: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX339.WAV\r",
      "2: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1059.WAV\r",
      "3: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI1689.WAV\r",
      "4: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX429.WAV\r",
      "5: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX69.WAV\r",
      "6: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX159.WAV\r",
      "7: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SI2319.WAV\r",
      "8: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SA2.WAV\r",
      "9: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKLR0/SX249.WAV\r",
      "10: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX221.WAV\r",
      "11: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA1.WAV\r",
      "12: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX41.WAV\r",
      "13: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1751.WAV\r",
      "14: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1725.WAV\r",
      "15: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX401.WAV\r",
      "16: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX24.WAV\r",
      "17: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SA2.WAV\r",
      "18: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SI1121.WAV\r",
      "19: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCRE0/SX131.WAV\r",
      "20: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA1.WAV\r",
      "21: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX336.WAV\r",
      "22: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1236.WAV\r",
      "23: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI606.WAV\r",
      "24: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SI1866.WAV\r",
      "25: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX156.WAV\r",
      "26: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SA2.WAV\r",
      "27: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX426.WAV\r",
      "28: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX246.WAV\r",
      "29: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MJRA0/SX66.WAV\r",
      "30: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA1.WAV\r",
      "31: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1233.WAV\r",
      "32: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI603.WAV\r",
      "33: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX333.WAV\r",
      "34: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX153.WAV\r",
      "35: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SI1863.WAV\r",
      "36: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX243.WAV\r",
      "37: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SA2.WAV\r",
      "38: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX423.WAV\r",
      "39: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR0/SX63.WAV\r",
      "40: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA1.WAV\r",
      "41: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX434.WAV\r",
      "42: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX74.WAV\r",
      "43: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX254.WAV\r",
      "44: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI1064.WAV\r",
      "45: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX344.WAV\r",
      "46: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SX164.WAV\r",
      "47: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SA2.WAV\r",
      "48: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI582.WAV\r",
      "49: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTMN0/SI2324.WAV\r",
      "50: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX82.WAV\r",
      "51: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1041.WAV\r",
      "52: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX442.WAV\r",
      "53: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA1.WAV\r",
      "54: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1702.WAV\r",
      "55: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX262.WAV\r",
      "56: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX172.WAV\r",
      "57: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SX352.WAV\r",
      "58: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SA2.WAV\r",
      "59: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMKC0/SI1072.WAV\r",
      "60: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI669.WAV\r",
      "61: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA1.WAV\r",
      "62: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX39.WAV\r",
      "63: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX309.WAV\r",
      "64: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1929.WAV\r",
      "65: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX129.WAV\r",
      "66: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SI1299.WAV\r",
      "67: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX219.WAV\r",
      "68: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SX399.WAV\r",
      "69: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDLR1/SA2.WAV\r",
      "70: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI2325.WAV\r",
      "71: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX435.WAV\r",
      "72: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX75.WAV\r",
      "73: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA1.WAV\r",
      "74: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1695.WAV\r",
      "75: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX345.WAV\r",
      "76: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SI1065.WAV\r",
      "77: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX255.WAV\r",
      "78: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SX165.WAV\r",
      "79: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTML0/SA2.WAV\r",
      "80: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI2290.WAV\r",
      "81: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA1.WAV\r",
      "82: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI650.WAV\r",
      "83: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SI1660.WAV\r",
      "84: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX220.WAV\r",
      "85: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX310.WAV\r",
      "86: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX40.WAV\r",
      "87: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX400.WAV\r",
      "88: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SA2.WAV\r",
      "89: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCLK0/SX130.WAV\r",
      "90: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX149.WAV\r",
      "91: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA1.WAV\r",
      "92: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI2309.WAV\r",
      "93: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX419.WAV\r",
      "94: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX239.WAV\r",
      "95: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX329.WAV\r",
      "96: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1679.WAV\r",
      "97: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SX59.WAV\r",
      "98: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SA2.WAV\r",
      "99: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MSAH1/SI1049.WAV\r",
      "100: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI520.WAV\r",
      "101: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA1.WAV\r",
      "102: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX160.WAV\r",
      "103: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX340.WAV\r",
      "104: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI2035.WAV\r",
      "105: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX250.WAV\r",
      "106: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX430.WAV\r",
      "107: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SX70.WAV\r",
      "108: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SA2.WAV\r",
      "109: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMDG0/SI1780.WAV\r",
      "110: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA1.WAV\r",
      "111: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX65.WAV\r",
      "112: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX425.WAV\r",
      "113: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1685.WAV\r",
      "114: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI1055.WAV\r",
      "115: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX335.WAV\r",
      "116: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SA2.WAV\r",
      "117: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX245.WAV\r",
      "118: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SI2315.WAV\r",
      "119: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBBR0/SX155.WAV\r",
      "120: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA1.WAV\r",
      "121: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX339.WAV\r",
      "122: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI879.WAV\r",
      "123: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX429.WAV\r",
      "124: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI1509.WAV\r",
      "125: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX69.WAV\r",
      "126: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX159.WAV\r",
      "127: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SI2139.WAV\r",
      "128: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SA2.WAV\r",
      "129: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FMAH1/SX249.WAV\r",
      "130: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX166.WAV\r",
      "131: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA1.WAV\r",
      "132: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX346.WAV\r",
      "133: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI2326.WAV\r",
      "134: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1696.WAV\r",
      "135: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX256.WAV\r",
      "136: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SI1066.WAV\r",
      "137: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SA2.WAV\r",
      "138: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX76.WAV\r",
      "139: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDKS0/SX436.WAV\r",
      "140: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX56.WAV\r",
      "141: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA1.WAV\r",
      "142: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI866.WAV\r",
      "143: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX146.WAV\r",
      "144: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX326.WAV\r",
      "145: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI2126.WAV\r",
      "146: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX416.WAV\r",
      "147: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SX236.WAV\r",
      "148: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SI1760.WAV\r",
      "149: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MDPB0/SA2.WAV\r",
      "150: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX82.WAV\r",
      "151: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX442.WAV\r",
      "152: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA1.WAV\r",
      "153: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI2062.WAV\r",
      "154: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI1432.WAV\r",
      "155: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX262.WAV\r",
      "156: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SI802.WAV\r",
      "157: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX172.WAV\r",
      "158: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SX352.WAV\r",
      "159: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FJRP1/SA2.WAV\r",
      "160: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX311.WAV\r",
      "161: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA1.WAV\r",
      "162: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI2274.WAV\r",
      "163: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX114.WAV\r",
      "164: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX384.WAV\r",
      "165: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX294.WAV\r",
      "166: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1014.WAV\r",
      "167: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SA2.WAV\r",
      "168: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SI1644.WAV\r",
      "169: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBOM0/SX204.WAV\r",
      "170: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX42.WAV\r",
      "171: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX222.WAV\r",
      "172: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA1.WAV\r",
      "173: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX312.WAV\r",
      "174: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI1572.WAV\r",
      "175: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI942.WAV\r",
      "176: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX132.WAV\r",
      "177: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SA2.WAV\r",
      "178: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SI2202.WAV\r",
      "179: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTAB0/SX402.WAV\r",
      "180: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX149.WAV\r",
      "181: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA1.WAV\r",
      "182: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1949.WAV\r",
      "183: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI689.WAV\r",
      "184: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SI1319.WAV\r",
      "185: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX419.WAV\r",
      "186: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX239.WAV\r",
      "187: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX329.WAV\r",
      "188: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SX59.WAV\r",
      "189: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MBAR0/SA2.WAV\r",
      "190: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1187.WAV\r",
      "191: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX17.WAV\r",
      "192: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX107.WAV\r",
      "193: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA1.WAV\r",
      "194: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI630.WAV\r",
      "195: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SI1817.WAV\r",
      "196: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX287.WAV\r",
      "197: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX197.WAV\r",
      "198: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SA2.WAV\r",
      "199: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTKD0/SX377.WAV\r",
      "200: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX248.WAV\r",
      "201: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX428.WAV\r",
      "202: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA1.WAV\r",
      "203: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI2318.WAV\r",
      "204: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX68.WAV\r",
      "205: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1058.WAV\r",
      "206: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX338.WAV\r",
      "207: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SX158.WAV\r",
      "208: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SI1688.WAV\r",
      "209: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FBLV0/SA2.WAV\r",
      "210: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI534.WAV\r",
      "211: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI1164.WAV\r",
      "212: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA1.WAV\r",
      "213: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX354.WAV\r",
      "214: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX174.WAV\r",
      "215: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX264.WAV\r",
      "216: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SI797.WAV\r",
      "217: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX444.WAV\r",
      "218: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SX84.WAV\r",
      "219: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGSL0/SA2.WAV\r",
      "220: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA1.WAV\r",
      "221: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX39.WAV\r",
      "222: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI2199.WAV\r",
      "223: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX309.WAV\r",
      "224: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI1569.WAV\r",
      "225: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX129.WAV\r",
      "226: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX219.WAV\r",
      "227: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SI939.WAV\r",
      "228: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SX399.WAV\r",
      "229: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MAFM0/SA2.WAV\r",
      "230: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI1609.WAV\r",
      "231: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX30.WAV\r",
      "232: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX169.WAV\r",
      "233: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA1.WAV\r",
      "234: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX439.WAV\r",
      "235: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI979.WAV\r",
      "236: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX259.WAV\r",
      "237: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SA2.WAV\r",
      "238: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SI2239.WAV\r",
      "239: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKAG0/SX79.WAV\r",
      "240: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX42.WAV\r",
      "241: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX222.WAV\r",
      "242: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2112.WAV\r",
      "243: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA1.WAV\r",
      "244: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX312.WAV\r",
      "245: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI2026.WAV\r",
      "246: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX132.WAV\r",
      "247: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SA2.WAV\r",
      "248: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SI1482.WAV\r",
      "249: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRPC1/SX402.WAV\r",
      "250: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX81.WAV\r",
      "251: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA1.WAV\r",
      "252: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX351.WAV\r",
      "253: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI2331.WAV\r",
      "254: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX27.WAV\r",
      "255: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1071.WAV\r",
      "256: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX441.WAV\r",
      "257: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SX261.WAV\r",
      "258: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SI1701.WAV\r",
      "259: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MMWS1/SA2.WAV\r",
      "260: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA1.WAV\r",
      "261: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX241.WAV\r",
      "262: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX331.WAV\r",
      "263: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX61.WAV\r",
      "264: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX151.WAV\r",
      "265: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1681.WAV\r",
      "266: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SX421.WAV\r",
      "267: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI2311.WAV\r",
      "268: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SA2.WAV\r",
      "269: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FLEH0/SI1051.WAV\r",
      "270: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX167.WAV\r",
      "271: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX437.WAV\r",
      "272: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA1.WAV\r",
      "273: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX77.WAV\r",
      "274: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX257.WAV\r",
      "275: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SX347.WAV\r",
      "276: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI1607.WAV\r",
      "277: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SA2.WAV\r",
      "278: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI977.WAV\r",
      "279: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCJS0/SI2237.WAV\r",
      "280: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI1485.WAV\r",
      "281: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA1.WAV\r",
      "282: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI855.WAV\r",
      "283: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX225.WAV\r",
      "284: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX405.WAV\r",
      "285: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SA2.WAV\r",
      "286: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX45.WAV\r",
      "287: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX315.WAV\r",
      "288: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SX135.WAV\r",
      "289: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MVRW0/SI2115.WAV\r",
      "290: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1068.WAV\r",
      "291: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA1.WAV\r",
      "292: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX78.WAV\r",
      "293: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX202.WAV\r",
      "294: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX258.WAV\r",
      "295: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX168.WAV\r",
      "296: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI1698.WAV\r",
      "297: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SI2328.WAV\r",
      "298: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SA2.WAV\r",
      "299: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MNTW0/SX348.WAV\r",
      "300: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI579.WAV\r",
      "301: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA1.WAV\r",
      "302: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX39.WAV\r",
      "303: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX309.WAV\r",
      "304: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX129.WAV\r",
      "305: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX219.WAV\r",
      "306: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SX399.WAV\r",
      "307: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1839.WAV\r",
      "308: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SA2.WAV\r",
      "309: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MCTH0/SI1209.WAV\r",
      "310: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA1.WAV\r",
      "311: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX161.WAV\r",
      "312: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX71.WAV\r",
      "313: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX431.WAV\r",
      "314: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX341.WAV\r",
      "315: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI611.WAV\r",
      "316: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SX251.WAV\r",
      "317: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1241.WAV\r",
      "318: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SA2.WAV\r",
      "319: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FSPM0/SI1871.WAV\r",
      "320: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA1.WAV\r",
      "321: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX355.WAV\r",
      "322: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX445.WAV\r",
      "323: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX265.WAV\r",
      "324: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX85.WAV\r",
      "325: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1165.WAV\r",
      "326: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI1802.WAV\r",
      "327: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SX175.WAV\r",
      "328: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SI535.WAV\r",
      "329: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MGAW0/SA2.WAV\r",
      "330: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX62.WAV\r",
      "331: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI872.WAV\r",
      "332: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA1.WAV\r",
      "333: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI2132.WAV\r",
      "334: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SI588.WAV\r",
      "335: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX152.WAV\r",
      "336: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX332.WAV\r",
      "337: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX242.WAV\r",
      "338: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SA2.WAV\r",
      "339: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MKDB0/SX422.WAV\r",
      "340: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA1.WAV\r",
      "341: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI1671.WAV\r",
      "342: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX321.WAV\r",
      "343: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2332.WAV\r",
      "344: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX141.WAV\r",
      "345: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX231.WAV\r",
      "346: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX411.WAV\r",
      "347: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SX51.WAV\r",
      "348: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SA2.WAV\r",
      "349: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MRLJ1/SI2301.WAV\r",
      "350: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA1.WAV\r",
      "351: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX433.WAV\r",
      "352: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX343.WAV\r",
      "353: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX73.WAV\r",
      "354: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX163.WAV\r",
      "355: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI793.WAV\r",
      "356: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI1913.WAV\r",
      "357: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SA2.WAV\r",
      "358: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SX253.WAV\r",
      "359: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FCRZ0/SI2053.WAV\r",
      "360: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX234.WAV\r",
      "361: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA1.WAV\r",
      "362: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX324.WAV\r",
      "363: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2225.WAV\r",
      "364: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI2304.WAV\r",
      "365: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SI1674.WAV\r",
      "366: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX54.WAV\r",
      "367: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX414.WAV\r",
      "368: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SX144.WAV\r",
      "369: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MFXS0/SA2.WAV\r",
      "370: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA1.WAV\r",
      "371: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX235.WAV\r",
      "372: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX145.WAV\r",
      "373: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX55.WAV\r",
      "374: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX325.WAV\r",
      "375: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SX415.WAV\r",
      "376: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI685.WAV\r",
      "377: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1315.WAV\r",
      "378: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SA2.WAV\r",
      "379: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/FREH0/SI1945.WAV\r",
      "380: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA1.WAV\r",
      "381: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1295.WAV\r",
      "382: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI538.WAV\r",
      "383: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SI1798.WAV\r",
      "384: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX268.WAV\r",
      "385: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX178.WAV\r",
      "386: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SA2.WAV\r",
      "387: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX448.WAV\r",
      "388: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX358.WAV\r",
      "389: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MADD0/SX88.WAV\r",
      "390: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX127.WAV\r",
      "391: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA1.WAV\r",
      "392: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX217.WAV\r",
      "393: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI847.WAV\r",
      "394: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX307.WAV\r",
      "395: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1477.WAV\r",
      "396: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX397.WAV\r",
      "397: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SA2.WAV\r",
      "398: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SX37.WAV\r",
      "399: /home/sri/Desktop/timit/TIMIT/TRAIN/DR7/MTLC0/SI1313.WAV\r"
     ]
    }
   ],
   "source": [
    "# read in 100 WAVs from TIMIT training set\n",
    "rawWaveforms = load_TIMIT_train(TIMIT_DIR, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "def preprocessWaveform(waveform):\n",
    "    mn = np.min(waveform)\n",
    "    mx = np.max(waveform)\n",
    "    \n",
    "    maxabs = max(abs(mn), abs(mx))\n",
    "    scl = 32768.0 / maxabs    \n",
    "    \n",
    "    processed = waveform * scl\n",
    "    \n",
    "    return processed, (scl,)\n",
    "    \n",
    "def unpreprocessWaveform(waveform, params):\n",
    "    \n",
    "    #unprocessed = (waveform + 32768.0) / 65536.0\n",
    "    #unprocessed = (unprocessed * (mx - mn)) + mn\n",
    "    unprocessed = waveform / params[0]\n",
    "    return unprocessed\n",
    "\n",
    "\n",
    "\n",
    "# window preprocessing\n",
    "def preprocessWindows(windows):\n",
    "    processed = np.copy(windows)\n",
    "    processed /= 32768.0\n",
    "    return processed, ()\n",
    "    \n",
    "    '''\n",
    "    # maximize the values of each window (max(abs(max), abs(min)) is 32767)\n",
    "    # save scale values in scl\n",
    "    processed = np.copy(windows)\n",
    "    scl = []\n",
    "\n",
    "    for i in xrange(0, processed.shape[0]):\n",
    "        scaleVal = max(abs(np.min(processed[i, :])), abs(np.max(processed[i, :])))\n",
    "        processed[i, :] /= scaleVal\n",
    "        scl.append(scaleVal)\n",
    "    \n",
    "    return processed, (scl,)\n",
    "    '''\n",
    "\n",
    "def unpreprocessWindows(windows, params):\n",
    "    unprocessed = np.copy(windows)\n",
    "    unprocessed *= 32768.0\n",
    "    return unprocessed\n",
    "    \n",
    "    '''\n",
    "    unprocessed = np.copy(windows)\n",
    "    scl = params[0]\n",
    "   \n",
    "    for i in xrange(0, unprocessed.shape[0]):\n",
    "        unprocessed[i, :] *= scl[i]\n",
    "    \n",
    "    return unprocessed\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# waveform preprocessing\n",
    "processedWaveforms = np.copy(rawWaveforms)\n",
    "\n",
    "# we maximize the volume of every waveform\n",
    "for i in xrange(0, len(processedWaveforms)):\n",
    "    processedWaveforms[i], _ = preprocessWaveform(processedWaveforms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw windows shape:  (40118, 512)\n",
      "Max:  32768.0\n",
      "Min:  -32768.0\n"
     ]
    }
   ],
   "source": [
    "# extract windows\n",
    "rawWindows = extractWindowsMultiple(processedWaveforms, STEP_SIZE, OVERLAP_SIZE,\n",
    "                                    collapse = True)\n",
    "\n",
    "# randomly shuffle data\n",
    "if (RANDOM_SHUFFLE):\n",
    "    rawWindows = np.random.permutation(rawWindows)\n",
    "\n",
    "print \"Raw windows shape: \", rawWindows.shape\n",
    "print \"Max: \", np.amax(rawWindows)\n",
    "print \"Min: \", np.amin(rawWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug windows shape:  (40118, 512)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation goes here, at some point\n",
    "augWindows = np.copy(rawWindows)\n",
    "\n",
    "print \"Aug windows shape: \", augWindows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processedWindows, pwParams = preprocessWindows(augWindows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape into vector form\n",
    "processedWindows = np.reshape(processedWindows, (processedWindows.shape[0], WINDOW_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40118, 512, 1)\n",
      "-1.13992e-05\n",
      "0.0997437\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print processedWindows.shape\n",
    "\n",
    "print np.mean(processedWindows, axis=None)\n",
    "print np.std(processedWindows, axis=None)\n",
    "print np.min(processedWindows, axis = None)\n",
    "print np.max(processedWindows, axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# operations for binarization layer (THEANO ONLY)\n",
    "\n",
    "class Binarize(T.Op):\n",
    "    # properties attribute\n",
    "    __props__ = ()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Binarize, self).__init__()\n",
    "        \n",
    "    def make_node(self, x):\n",
    "        assert hasattr(self, '_props'), \"Your version of theano is too old to support __props__.\"\n",
    "        x = T.as_tensor_variable(x)\n",
    "        return theano.Apply(self, [x], [x.type()])\n",
    "    \n",
    "    def perform(self, node, inputs, output_storage):\n",
    "        x, = inputs\n",
    "        z, = output_storage\n",
    "        \n",
    "        # TODO: learn threshold per parameter?\n",
    "        z[0] = np.copy(x)\n",
    "        z[0][z[0] < 0] = -1\n",
    "        z[0][z[0] >= 0] = 1\n",
    "    \n",
    "    def grad(self, input, output_gradients):\n",
    "        # pass through gradients unchanged\n",
    "        # (i don't think there's a mathematical justification for this?)\n",
    "        return [output_gradients[0]]\n",
    "        \n",
    "    def infer_shape(self, node, i0_shapes):\n",
    "        # output shape is same as input shape\n",
    "        return i0_shapes\n",
    "\n",
    "    \n",
    "class BinarizeLayer(Layer):\n",
    "    \"\"\" Binarizes input \n",
    "    <feedforward> binarizes output of tanh to -1 and 1\n",
    "    <backward> returns delta unchanged\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BinarizeLayer, self).__init__(**kwargs)\n",
    "        self.op = Binarize()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # no trainable parameters\n",
    "        self.trainable_weights = []\n",
    "    \n",
    "    def call(self, x, mask=None):\n",
    "        return self.op(x)\n",
    "\n",
    "    #def get_output_shape_for(self, input_shape):\n",
    "    #    return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(BinarizeLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.84470177  0.06558141  0.22756109 -0.35346976 -0.38718146 -0.58886111]\n",
      " [ 0.95484763 -0.7758649  -0.119601    0.22221267  0.93538392  0.44310841]\n",
      " [-0.64756352  0.10144141  0.90061957 -0.65772057 -0.9105404  -0.78036946]\n",
      " [ 0.91749954 -0.00463992 -0.49747071 -0.73639739 -0.99088544 -0.79426765]\n",
      " [ 0.41897658 -0.45832676 -0.13093996  0.78641725  0.07697349 -0.37049091]\n",
      " [ 0.0683493   0.36846444  0.50642645 -0.8704316  -0.44832006 -0.13129556]]\n",
      "[[ 1.  1.  1. -1. -1. -1.]\n",
      " [ 1. -1. -1.  1.  1.  1.]\n",
      " [-1.  1.  1. -1. -1. -1.]\n",
      " [ 1. -1. -1. -1. -1. -1.]\n",
      " [ 1. -1. -1.  1.  1. -1.]\n",
      " [ 1.  1.  1. -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "# verify Binarize op works\n",
    "x = T.matrix()\n",
    "f = theano.function([x], Binarize()(x))\n",
    "inp = np.random.uniform(high = 1, low = -1, size = (6, 6)).astype('float32')\n",
    "out = f(inp)\n",
    "\n",
    "print(inp)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import dct as scidct\n",
    "\n",
    "# ====================================================================\n",
    "#  DCT (Discrete Cosine Transform)\n",
    "# ====================================================================\n",
    "\n",
    "# generate square dct matrix\n",
    "#     how to use: generate n-by-n matrix M. then, if you have a signal w, then:\n",
    "#                 dct(w) = M * w\n",
    "#     where w must be n-by-1\n",
    "#\n",
    "#     backed by scipy\n",
    "def generate_dct_mat(n, norm = 'ortho'):\n",
    "    return (scidct(np.eye(n), norm = norm))\n",
    "\n",
    "# DCT matrix is precomputed at start of program\n",
    "dctMat = generate_dct_mat(WINDOW_SIZE)\n",
    "th_dctMat = theano.shared(dctMat)\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE\n",
    "#     this returns an array M x WINDOW_SIZE where every one of the M samples has been independently\n",
    "#     filtered by the DCT\n",
    "def theano_dct(x, dctMat = None):\n",
    "    global th_dctMat\n",
    "    \n",
    "    if (dctMat is None):\n",
    "        dctMat = th_dctMat\n",
    "        \n",
    "    # reshape x into 2D array, and perform appropriate matrix operation\n",
    "    reshaped_x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "\n",
    "    result = T.tensordot(dctMat, reshaped_x, [[0], [2]])\n",
    "    result = result.reshape((result.shape[0], result.shape[2])).T\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ====================================================================\n",
    "#  DFT (Discrete Fourier Transform)\n",
    "# ====================================================================\n",
    "\n",
    "# generate square dft matrix (similar to how we generate the DFT one)\n",
    "#     note that this matrix will have real and imaginary components\n",
    "def generate_dft_mat(n):\n",
    "    return (np.fft.fft(np.eye(n)))\n",
    "\n",
    "# we compute both the real and imaginary part of the FFT separately, at program start\n",
    "dftMat = generate_dft_mat(WINDOW_SIZE)\n",
    "\n",
    "th_dftMat_imag = theano.shared(np.imag(dftMat))\n",
    "th_dftMat_real = theano.shared(np.real(dftMat))\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE\n",
    "#     this returns an array M x WINDOW_SIZE where every one of the M samples has been replaced by\n",
    "#     its DFT magnitude\n",
    "def theano_dft_mag(x):\n",
    "    global th_dftMat_imag\n",
    "    global th_dftMat_real\n",
    "\n",
    "    reshaped_x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "\n",
    "    imag = T.tensordot(th_dftMat_imag, reshaped_x, [[0], [2]])\n",
    "    imag = imag.reshape((imag.shape[0], imag.shape[2])).T\n",
    "\n",
    "    real = T.tensordot(th_dftMat_real, reshaped_x, [[0], [2]])\n",
    "    real = real.reshape((real.shape[0], real.shape[2])).T\n",
    "\n",
    "    result = T.sqrt(T.sqr(real) + T.sqr(imag))\n",
    "\n",
    "    return result\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE\n",
    "#     this returns an array M x (2 * WINDOW_SIZE) where coefficients are alternating real and imaginary\n",
    "#     FFT coeffs\n",
    "def theano_dft(x):\n",
    "    global th_dftMat_imag\n",
    "    global th_dftMat_real\n",
    "\n",
    "    reshaped_x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "\n",
    "    imag = T.tensordot(th_dftMat_imag, reshaped_x, [[0], [2]])\n",
    "    imag = imag.reshape((imag.shape[0], imag.shape[2])).T\n",
    "\n",
    "    real = T.tensordot(th_dftMat_real, reshaped_x, [[0], [2]])\n",
    "    real = real.reshape((real.shape[0], real.shape[2])).T\n",
    "\n",
    "    result = T.concatenate([imag, real], axis=1)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# based on a combination of this article:\n",
    "#     http://practicalcryptography.com/miscellaneous/machine-learning/...\n",
    "#         guide-mel-frequency-cepstral-coefficients-mfccs/\n",
    "# and some of this code:\n",
    "#     http://stackoverflow.com/questions/5835568/...\n",
    "#         how-to-get-mfcc-from-an-fft-on-a-signal\n",
    "\n",
    "from numpy.fft import fft\n",
    "from scipy.fftpack import idct, dct\n",
    "\n",
    "NUM_MFCC_COEFFS = 32\n",
    "\n",
    "def freqToMel(freq):\n",
    "    return 1127.01048 * math.log(1 + freq / 700.0)\n",
    "\n",
    "def melToFreq(mel):\n",
    "    return 700 * (math.exp(mel / 1127.01048) - 1)\n",
    "\n",
    "def melFilterBank(numCoeffs):\n",
    "    minHz = 0\n",
    "    maxHz = SAMPLE_RATE / 2            # by Nyquist theorem\n",
    "    numFFTBins = WINDOW_SIZE\n",
    "\n",
    "    maxMel = freqToMel(maxHz)\n",
    "    minMel = freqToMel(minHz)\n",
    "\n",
    "    # we need (numCoeffs + 2) points to create (numCoeffs) filterbanks\n",
    "    melRange = np.array(xrange(numCoeffs + 2))\n",
    "    melRange = melRange.astype(np.float32)\n",
    "\n",
    "    # create (numCoeffs + 2) points evenly spaced between minMel and maxMel\n",
    "    melCenterFilters = melRange * (maxMel - minMel) / (numCoeffs + 1) + minMel\n",
    "\n",
    "    \n",
    "    for i in xrange(numCoeffs + 2):\n",
    "        # mel domain => frequency domain\n",
    "        melCenterFilters[i] = melToFreq(melCenterFilters[i])\n",
    "\n",
    "        # frequency domain => FFT bins\n",
    "        melCenterFilters[i] = math.floor(numFFTBins * melCenterFilters[i] / maxHz)       \n",
    "\n",
    "    # create matrix of filters (one row is one filter)\n",
    "    filterMat = np.zeros((numCoeffs, numFFTBins))\n",
    "\n",
    "    # generate filters (in frequency domain) and plot\n",
    "    for i in range(1, numCoeffs + 1):\n",
    "        filter = np.zeros(numFFTBins)\n",
    "        \n",
    "        startRange = melCenterFilters[i - 1]\n",
    "        midRange   = melCenterFilters[i]\n",
    "        endRange   = melCenterFilters[i + 1]\n",
    "\n",
    "        for j in range(startRange, midRange):\n",
    "            filter[j] = (float(j) - startRange) / (midRange - startRange)\n",
    "        for j in range(midRange, endRange):\n",
    "            filter[j] = 1 - ((float(j) - midRange) / (endRange - midRange))\n",
    "        \n",
    "        filterMat[i - 1] = filter\n",
    "        #plt.plot(filter)\n",
    "    #plt.show()\n",
    "\n",
    "    # return filterbank as matrix\n",
    "    return filterMat\n",
    "\n",
    "\n",
    "\n",
    "# precomputed Mel filterbank\n",
    "#     (transpose so we can do dot products with the power spectrum)\n",
    "FILTERBANK = melFilterBank(NUM_MFCC_COEFFS).transpose()\n",
    "th_filterbank = theano.shared(FILTERBANK)\n",
    "\n",
    "# we also need to precompute another DCT matrix\n",
    "th_mfcc_dct = theano.shared(generate_dct_mat(NUM_MFCC_COEFFS, None))\n",
    "\n",
    "\n",
    "\n",
    "# given a (symbolic Theano) array of size M x WINDOW_SIZE\n",
    "#     this returns an array M x NUM_MFCC_COEFFS where each window has been replaced\n",
    "#     by its MFCC coeffs\n",
    "def theano_mfcc(x):\n",
    "    powerSpectrum = T.pow(theano_dft_mag(x), 2)\n",
    "    \n",
    "    filteredSpectrum = T.tensordot(powerSpectrum, th_filterbank, axes = 1)\n",
    "    \n",
    "    # replace places where filtered spectrum is zero\n",
    "    filteredSpectrum = T.switch(T.eq(filteredSpectrum, 0), np.finfo(float).eps, \\\n",
    "                                filteredSpectrum)\n",
    "    \n",
    "    logSpectrum = T.log(filteredSpectrum)\n",
    "    mfccs = theano_dct(logSpectrum, th_mfcc_dct)\n",
    "    return mfccs\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute MFCC for single window\n",
    "def mfcc(signal):\n",
    "    # preemphasize signal\n",
    "    #preemphasizedSignal = np.copy(signal)\n",
    "    #for i in xrange(1, len(signal)):\n",
    "    #    preemphasizedSignal[i] = signal[i] - 0.9 * signal[i - 1]\n",
    "\n",
    "    complexSpectrum = fft(signal)\n",
    "    \n",
    "    powerSpectrum = abs(complexSpectrum) ** 2\n",
    "    filteredSpectrum = np.dot(powerSpectrum, FILTERBANK)\n",
    "\n",
    "    # replace places where filtered spectrum is zero\n",
    "    filteredSpectrum = np.where(filteredSpectrum == 0, np.finfo(float).eps, \\\n",
    "                                filteredSpectrum)\n",
    "\n",
    "    # get log spectrum and take DCT to get MFCC\n",
    "    logSpectrum = np.log(filteredSpectrum)\n",
    "    mfcc = dct(logSpectrum, type=2)\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# compute MFCC for list of windows\n",
    "def getMFCCsForWindows(windows):\n",
    "    numWindows = windows.shape[0]\n",
    "\n",
    "    mfccs = np.zeros((numWindows, NUM_MFCC_COEFFS))\n",
    "\n",
    "    i = 0\n",
    "    for window in windows:\n",
    "        windowMFCC = mfcc(window)\n",
    "        windowMFCC = np.reshape(np.array(windowMFCC), (1, len(windowMFCC)))\n",
    "\n",
    "        mfccs[i, :] = windowMFCC\n",
    "\n",
    "        i += 1\n",
    "        if (VERBOSE):\n",
    "            if (i % 500 == 0):\n",
    "                print i, \"/\", numWindows\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 128.52021649   47.16834083   63.42652628  -14.88412633   38.38372902\n",
      "   -3.65415857   -2.18125846  -56.04352779   -4.02326145  -16.81048628\n",
      "    3.67668869  -16.49747926   -3.30349622   -5.84025798    2.60266926\n",
      "    1.08023251    4.10627015    6.2846743     1.3645454    -6.56143511\n",
      "    0.82235805   -0.19911454    0.1952784   -10.79400347    0.59716666\n",
      "   -2.31810616    3.5371392    -4.0208601     4.99506391    0.88951063\n",
      "    2.19376232    2.91515797]\n",
      "[ 112.82601637   51.64531226   55.9094073   -12.71880473   49.61121806\n",
      "  -25.75018622   -5.01874974   -8.93960258   -8.80470475  -22.09445646\n",
      "    1.88618069    6.50933725   -6.26449223   -2.58729335    5.06898316\n",
      "  -12.58265798    5.18056011   -8.90861896    9.43600602   -2.82183809\n",
      "    0.44322806  -13.97184359    1.22650381    3.81420334   -2.35872988\n",
      "   -4.83522628    2.3805886    -3.40953465    0.79964538    0.69020623\n",
      "    1.10798192   -0.54966343]\n",
      "[[ 128.52021649   47.16834083   63.42652628  -14.88412633   38.38372902\n",
      "    -3.65415857   -2.18125846  -56.04352779   -4.02326145  -16.81048628\n",
      "     3.67668869  -16.49747926   -3.30349622   -5.84025798    2.60266926\n",
      "     1.08023251    4.10627015    6.2846743     1.3645454    -6.56143511\n",
      "     0.82235805   -0.19911454    0.1952784   -10.79400347    0.59716666\n",
      "    -2.31810616    3.5371392    -4.0208601     4.99506391    0.88951063\n",
      "     2.19376232    2.91515797]\n",
      " [ 112.82601637   51.64531226   55.9094073   -12.71880473   49.61121806\n",
      "   -25.75018622   -5.01874974   -8.93960258   -8.80470475  -22.09445646\n",
      "     1.88618069    6.50933725   -6.26449223   -2.58729335    5.06898316\n",
      "   -12.58265798    5.18056011   -8.90861896    9.43600602   -2.82183809\n",
      "     0.44322806  -13.97184359    1.22650381    3.81420334   -2.35872988\n",
      "    -4.83522628    2.3805886    -3.40953465    0.79964538    0.69020623\n",
      "     1.10798192   -0.54966343]]\n"
     ]
    }
   ],
   "source": [
    "# verification for MFCCs\n",
    "for i in xrange(9, 11):\n",
    "    w = np.copy(processedWindows[i])\n",
    "    w = np.reshape(w, (512,))\n",
    "\n",
    "    powerSpectrum = abs(fft(w)) ** 2\n",
    "    filteredSpectrum = np.dot(powerSpectrum, FILTERBANK)\n",
    "    \n",
    "    logSpectrum = np.log(filteredSpectrum)\n",
    "    mfcc = dct(logSpectrum, type=2)\n",
    "    print mfcc\n",
    "\n",
    "\n",
    "x = np.copy(processedWindows[9:11])\n",
    "print theano_mfcc(x).eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)       (None, 1)             225601      input_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 225601\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)        (None, 320)           0           input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)        (None, 512, 1)        0           sequential_8[1][0]               \n",
      "====================================================================================================\n",
      "Total params: 415307\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 512, 1)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)        (None, 320)           142538      input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)        (None, 512, 1)        272769      sequential_8[1][0]               \n",
      "____________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)       (None, 1)             0           sequential_9[1][0]               \n",
      "====================================================================================================\n",
      "Total params: 640908\n",
      "____________________________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lambda to compute MSE between 2 vectors\n",
    "def mse_lambda(vects):\n",
    "    x, y = vects\n",
    "    return K.mean(K.square(x - y))\n",
    "\n",
    "# freeze weights for stacked training\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "# we generate a new optimizer of the same kind for every model\n",
    "# we train\n",
    "def opti():\n",
    "    return Adam()\n",
    "\n",
    "input_dim = (WINDOW_SIZE, 1)\n",
    "input_size = np.prod(input_dim)\n",
    "bottleneck_size = 320\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# autoencoder: takes an audio window, compresses it, and tries to reconstruct it\n",
    "# ---------------------------------------------------------------------------\n",
    "def autoencoder_structure(dim):\n",
    "    enc = Sequential()\n",
    "    dec = Sequential()\n",
    "    \n",
    "    # based on architecture in this paper:\n",
    "    #     http://arxiv.org/pdf/1602.02644.pdf\n",
    "    # adapted to a 32x32 image instead of 64x64\n",
    "    \n",
    "    # dropout at input layer\n",
    "    #enc.add(GaussianDropout(0.1, input_shape = dim))\n",
    "    \n",
    "    # (512x1) => (256x64) [9]    \n",
    "    enc.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          input_shape = dim, activation = 'relu',\n",
    "                          init = 'uniform', bias = True))\n",
    "    #enc.add(PReLU())\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # (256x64) => (128x64) [9]    \n",
    "    enc.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          activation = 'relu',\n",
    "                          init = 'uniform', bias = True))\n",
    "    #enc.add(PReLU())\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # (128x64) => (64x64) [9]\n",
    "    enc.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          activation = 'relu',\n",
    "                          init = 'uniform', bias = True))\n",
    "    #enc.add(PReLU())\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # (64x64) => (32x10) [9]\n",
    "    enc.add(Convolution1D(10, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          activation = 'tanh',\n",
    "                          init = 'uniform', bias = True))\n",
    "    enc.add(MaxPooling1D(2))\n",
    "    \n",
    "    # binarize   \n",
    "    enc.add(Reshape((bottleneck_size,)))\n",
    "    enc.add(BinarizeLayer())\n",
    "    \n",
    "    dec.add(Reshape((32, 10,), input_shape = (bottleneck_size,)))\n",
    "    \n",
    "    # (32x10) => (64x64) [5x5]\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    \n",
    "    # (64x64) => (128x64) [5x5]\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    #dec.add(PReLU())\n",
    "    \n",
    "    # (128x64) => (256x64) [5x5]\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    #dec.add(PReLU())\n",
    "    \n",
    "    # (256x64) => (512x64) [5x5]\n",
    "    dec.add(UpSampling1D(2))\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    #dec.add(PReLU())\n",
    "    \n",
    "    # (512x64) => (512x64) [5x5]\n",
    "    dec.add(Convolution1D(64, 16, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'relu',\n",
    "                          bias = True))\n",
    "    #dec.add(PReLU())\n",
    "    \n",
    "    # (512x64) => (512x1)\n",
    "    dec.add(Convolution1D(1, 1, W_regularizer = l2(0.001), border_mode = 'same',\n",
    "                          init = 'uniform', activation = 'tanh',\n",
    "                          bias = True))\n",
    "\n",
    "    return enc, dec\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# discriminator: tries to differentiate between original and reconstructed samples\n",
    "# ---------------------------------------------------------------------------\n",
    "def discriminator_structure(dim):\n",
    "    dsc = Sequential()\n",
    "    dsc.add(Convolution1D(64, 12, border_mode='valid', input_shape = dim,\n",
    "                                    W_regularizer = l2(0.001), init = 'uniform',\n",
    "                                    activation = 'relu'))\n",
    "\n",
    "    dsc.add(Convolution1D(64, 8, border_mode='same',\n",
    "                                    W_regularizer = l2(0.001), init = 'uniform',\n",
    "                                    activation = 'relu'))\n",
    "\n",
    "    dsc.add(AtrousConvolution1D(64, 12, border_mode='valid',\n",
    "                                    W_regularizer = l2(0.001), init = 'uniform',\n",
    "                                    atrous_rate = 2, activation = 'relu'))\n",
    "\n",
    "    dsc.add(AtrousConvolution1D(64, 8, border_mode='same',\n",
    "                                    W_regularizer = l2(0.001), init = 'uniform',\n",
    "                                    atrous_rate = 2, activation = 'relu'))\n",
    "    \n",
    "    dsc.add(AtrousConvolution1D(64, 12, border_mode='valid',\n",
    "                                    W_regularizer = l2(0.001), init = 'uniform',\n",
    "                                    atrous_rate = 4, activation = 'relu'))\n",
    "\n",
    "    dsc.add(AtrousConvolution1D(64, 8, border_mode='same',\n",
    "                                    W_regularizer = l2(0.001), init = 'uniform',\n",
    "                                    atrous_rate = 8, activation = 'relu'))\n",
    "\n",
    "    dsc.add(Flatten())\n",
    "    #dsc.add(MinibatchDiscrimination())\n",
    "    dsc.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return dsc\n",
    "\n",
    "\n",
    "# plain autoencoder\n",
    "plain_input = Input(shape = input_dim)\n",
    "plain_enc, plain_dec = autoencoder_structure(input_dim)\n",
    "plain_embedding = plain_enc(plain_input)\n",
    "plain_reconstructed = plain_dec(plain_embedding)\n",
    "plain_autoencoder = Model(input = [plain_input], output = [plain_reconstructed])\n",
    "plain_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "# construct autoencoder to be used in adversarial training (AAC - Adversarial AutoenCoder)\n",
    "# uhhhh... whoops i screwed up the acronym\n",
    "aac_input = Input(shape = input_dim)\n",
    "aac_enc, aac_dec = autoencoder_structure(input_dim)\n",
    "aac_embedding = aac_enc(aac_input)\n",
    "aac_reconstructed = aac_dec(aac_embedding)\n",
    "\n",
    "aac_autoencoder = Model(input = [aac_input], output = [aac_reconstructed])\n",
    "aac_autoencoder.compile(loss = 'mean_squared_error', optimizer = opti())\n",
    "\n",
    "# construct discriminator\n",
    "dsc_input = Input(shape = input_dim)\n",
    "dsc_struct = discriminator_structure(input_dim)\n",
    "\n",
    "# output: activation on original image (should be 1) or reconstruction (should be 0)\n",
    "dsc_label = dsc_struct(dsc_input)\n",
    "\n",
    "# also compute label of reconstruction, for autoencoder feedback\n",
    "aac_recons_discrim = dsc_struct(aac_reconstructed)\n",
    "\n",
    "\n",
    "\n",
    "def dft_loss(y_true, y_pred):\n",
    "    # transfer signals from time to frequency domain\n",
    "    dft_true = theano_dft(y_true)\n",
    "    dft_pred = theano_dft(y_pred)\n",
    "    \n",
    "    # compute MSE in frequency domain\n",
    "    error = T.sum(T.sqr(dft_true - dft_pred)) / dft_true.shape[0]\n",
    "    #error = T.sqrt(T.mean(T.sqr(dft_pred - dft_true)))\n",
    "    return error\n",
    "\n",
    "\n",
    "def mfcc_loss(y_true, y_pred):\n",
    "    # transfer signals from time to frequency domain\n",
    "    mfcc_true = theano_mfcc(y_true)\n",
    "    mfcc_pred = theano_mfcc(y_pred)\n",
    "    \n",
    "    # compute MSE in frequency domain\n",
    "    error = T.mean(T.sqr(mfcc_true - mfcc_pred))\n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sum_squared_error(y_true, y_pred):\n",
    "    return T.sum(T.abs_(y_true - y_pred)) / y_true.shape[0]\n",
    "    #return T.sqrt(T.mean(T.abs_(y_true - y_pred)))\n",
    "    #return K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "    \n",
    "def rmse(y_true, y_pred):\n",
    "    return T.sqrt(T.mean(T.sqr(y_true - y_pred)))\n",
    "\n",
    "def ulaw_rmse(y_true, y_pred):\n",
    "    # transformation from wavenet paper\n",
    "    ulaw_true = K.sign(y_true) * K.log(1.0 + 255.0 * K.abs(y_true)) / K.log(1.0 + 255.0)\n",
    "    ulaw_pred = K.sign(y_pred) * K.log(1.0 + 255.0 * K.abs(y_pred)) / K.log(1.0 + 255.0)\n",
    "    \n",
    "    return T.sqrt(T.mean(T.sqr(ulaw_true - ulaw_pred)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compile model\n",
    "loss_weights = [350.0, 1.0 / 10.0, 5.0]\n",
    "\n",
    "\n",
    "\n",
    "make_trainable(aac_autoencoder, False)\n",
    "aac_discriminator = Model(input = [dsc_input], output = [dsc_label])\n",
    "aac_discriminator.compile(loss = ['binary_crossentropy'], optimizer = opti())\n",
    "aac_discriminator.summary()\n",
    "aac_autoencoder.summary()\n",
    "\n",
    "make_trainable(aac_discriminator, False)\n",
    "make_trainable(aac_autoencoder, True)\n",
    "model = Model(input = [aac_input], output = [aac_reconstructed, aac_reconstructed, aac_recons_discrim])\n",
    "model.compile(loss = [ulaw_rmse, mfcc_loss, 'binary_crossentropy'],\n",
    "              loss_weights = loss_weights,\n",
    "              optimizer = opti())\n",
    "model.summary()\n",
    "\n",
    "X_train = np.copy(processedWindows)\n",
    "ntrain = X_train.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40118, 512, 1)\n",
      "(40118, 1024)\n",
      "0.171497039685\n",
      "0.00757917\n"
     ]
    }
   ],
   "source": [
    "s = theano_dft(X_train).eval()\n",
    "print X_train.shape\n",
    "print s.shape\n",
    "\n",
    "print np.linalg.norm(s[3])\n",
    "print np.linalg.norm(X_train[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_discriminator(discriminator, autoencoder, X, y, verbose = True):\n",
    "    # verify discriminator was trained properly\n",
    "    y_hat = discriminator.predict(X)\n",
    "    y_hat[y_hat >= 0.5] = 1\n",
    "    y_hat[y_hat < 0.5] = 0\n",
    "\n",
    "    n_total = y.shape[0]\n",
    "    n_correct = np.sum(np.ravel(y_hat) == y)\n",
    "\n",
    "    acc = n_correct * 100.0 / n_total\n",
    "    if (verbose):\n",
    "        print \"Discriminator accuracy: %0.02f pct (%d of %d) right\"%(acc, n_correct, n_total)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autoencoderTest(waveFilename, prefix, autoencoder):\n",
    "    [rate, data] = sciwav.read(waveFilename)\n",
    "    processedWave, wparams = preprocessWaveform(data)\n",
    "    windows = extractWindows(processedWave, STEP_SIZE, OVERLAP_SIZE)\n",
    "    \n",
    "\n",
    "    # first, write desired reconstruction\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    print transformed.shape\n",
    "    desired = unpreprocessWindows(transformed, tparams)\n",
    "    desired = reconstructFromWindows(desired, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    desired = unpreprocessWaveform(desired, wparams)\n",
    "    sciwav.write(prefix + \"desired.wav\", rate, desired.astype(np.int16))\n",
    "    \n",
    "    # then, run NN on transformed windows\n",
    "    transformed, tparams = preprocessWindows(windows)\n",
    "    \n",
    "    transformed = np.reshape(transformed, (transformed.shape[0], WINDOW_SIZE, 1))\n",
    "    autoencOutput = autoencoder.predict([transformed], batch_size = 64, verbose = 1)\n",
    "    autoencOutput = np.reshape(autoencOutput, (autoencOutput.shape[0], WINDOW_SIZE))\n",
    "    \n",
    "    print autoencOutput.shape\n",
    "    recons = unpreprocessWindows(autoencOutput, tparams)\n",
    "    recons = reconstructFromWindows(recons, OVERLAP_SIZE, OVERLAP_FUNC)\n",
    "    recons = unpreprocessWaveform(recons, wparams)\n",
    "    \n",
    "    print \"Max desired:\", np.max(desired)\n",
    "    print \"Min desired:\", np.min(desired)\n",
    "    print \"Max recons: \", np.max(recons)\n",
    "    print \"Min recons: \", np.min(recons)\n",
    "    \n",
    "    sciwav.write(prefix + \"output.wav\", rate, recons.astype(np.int16))\n",
    "\n",
    "    print waveFilename, \" mse: \", mse(recons, desired)\n",
    "    print waveFilename, \" avg err: \", avgErr(recons, desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "    7680: 0.693358242512  ['autoencoder not training']"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4f}'.format})\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_BATCHES = ntrain / BATCH_SIZE\n",
    "NUM_EPOCHS = 35\n",
    "\n",
    "lead = \"    \"\n",
    "d_loss = 0.0\n",
    "a_losses = []\n",
    "d_acc = 0.0\n",
    "discrim_train_y = np.concatenate((np.ones(ntrain), np.zeros(ntrain)))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print \"Epoch \" + str(epoch + 1) + \":\"\n",
    "\n",
    "    # present batches randomly each epoch\n",
    "    lis = range(0, ntrain, BATCH_SIZE)\n",
    "    random.shuffle(lis)\n",
    "    \n",
    "    # keep track of start time and current batch #\n",
    "    i = 0\n",
    "    startTime = time.time()\n",
    "    for idx in lis:\n",
    "        batch = X_train[idx:idx+BATCH_SIZE, :,  :]\n",
    "        nbatch = batch.shape[0]\n",
    "        \n",
    "        a_losses = [\"autoencoder not training\"]\n",
    "        d_loss = \"discriminator not training\"\n",
    "        \n",
    "        # train autoencoder, if discriminator accuracy is greater than 70%\n",
    "        if (epoch > 0):\n",
    "            make_trainable(aac_discriminator, False)\n",
    "            make_trainable(aac_autoencoder, True)\n",
    "            a_losses = model.train_on_batch(batch, [batch, batch, np.ones(nbatch)])\n",
    "        \n",
    "        # train discriminator on what the autoencoder now generates\n",
    "        make_trainable(aac_discriminator, True)\n",
    "        make_trainable(aac_autoencoder, False)\n",
    "        generated = aac_autoencoder.predict(batch)\n",
    "        discrim_batch_X = np.concatenate((batch, generated))\n",
    "        discrim_batch_y = np.concatenate((np.ones(nbatch), np.zeros(nbatch)))\n",
    "        d_loss = aac_discriminator.train_on_batch(discrim_batch_X, discrim_batch_y)\n",
    "        \n",
    "        # print statistics every 10 batches so we know stuff is still going down\n",
    "        if (i % 10 == 0):\n",
    "            printStr = \"        \\r\" + lead + str(i * BATCH_SIZE) + \": \" + str(d_loss) + \" \"\n",
    "            print printStr,\n",
    "            \n",
    "            loss_arr = np.asarray(a_losses)\n",
    "            print loss_arr,\n",
    "            \n",
    "            if (len(loss_arr) > 1):\n",
    "                for i in xrange(0, len(loss_weights)):\n",
    "                    loss_arr[i + 1] *= loss_weights[i]\n",
    "                print loss_arr,\n",
    "            \n",
    "        i += 1\n",
    "    print \"\"\n",
    "    \n",
    "    # print elapsed time\n",
    "    elapsed = time.time() - startTime\n",
    "    print lead + \"Total time for epoch: \" + str(elapsed) + \"s\"\n",
    "    \n",
    "    # evaluate on full training set every 10 epochs\n",
    "    if (epoch == 0 or (epoch + 1) % 10 == 0):\n",
    "        startTime = time.time()\n",
    "        \n",
    "        a_losses = model.evaluate(X_train, [X_train, X_train, np.ones(ntrain)], verbose = 0)\n",
    "        generated = aac_autoencoder.predict(X_train, verbose = 0)\n",
    "        discrim_train_X = np.concatenate((X_train, generated))\n",
    "        d_acc = test_discriminator(aac_discriminator, aac_autoencoder,\n",
    "                                   discrim_train_X, discrim_train_y, verbose = False)\n",
    "    \n",
    "        print lead + \"Evaluated on full training set: \" + str(d_acc) + \"% d_acc -- a_losses \",\n",
    "        print np.asarray(a_losses)\n",
    "        elapsed = time.time() - startTime\n",
    "        print lead + \"Total time for evaluation: \" + str(elapsed) + \"s\"\n",
    "        \n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoencoderTest(\"./SA1.WAV\", \"SA1_aac_\", aac_autoencoder)\n",
    "autoencoderTest(\"./SX383.WAV\", \"SX383_aac_\", aac_autoencoder)\n",
    "autoencoderTest(\"./fiveYears.wav\", \"fy_aac_\", aac_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
